{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WF_TRACE_SERVER_URL\"] = \"http://127.0.01:6345\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: timssweeney.\n",
      "View Weave data at https://wandb.ai/timssweeney/remote_model_demo_4/weave\n"
     ]
    }
   ],
   "source": [
    "client = weave.init(\"remote_model_demo_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/timssweeney/remote_model_demo_4/r/call/0193ba4f-de91-79a2-9028-67c3c500703e\n",
      "weave:///timssweeney/remote_model_demo_4/object/LiteLLMCompletionModel:KBsfUswVpEHFYmZuJjmhM2YH4EttkRZJSoH0Z0ZaNRY\n",
      "{'name': 'Fred', 'age': 30}\n"
     ]
    }
   ],
   "source": [
    "# Demonstrates creating a model in python\n",
    "\n",
    "from weave.builtin_objects.models.CompletionModel import LiteLLMCompletionModel\n",
    "\n",
    "model = LiteLLMCompletionModel(\n",
    "    model=\"gpt-4o\",\n",
    "    messages_template=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Please extract the name and age from the following text\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"{user_input}\"},\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"Person\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"age\": {\"type\": \"integer\"},\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "res = model.predict(user_input=\"Hello, my name is Fred and I am 30 years old.\")\n",
    "\n",
    "print(model.ref.uri())\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallMethodRes(call_id='0193ba4f-fc13-79c2-b217-03e6fdd7e7c4', output={'name': 'Charles', 'age': 40})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrates calling a model created in python\n",
    "\n",
    "from weave.trace_server.trace_server_interface import CallMethodReq\n",
    "\n",
    "call_res = client.server.call_method(\n",
    "    CallMethodReq(\n",
    "        project_id=client._project_id(),\n",
    "        object_ref=model.ref.uri(),\n",
    "        method_name=\"predict\",\n",
    "        args={\"user_input\": \"Hello, my name is Charles and I am 40 years old.\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "call_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjCreateRes(digest='k85wXnWLVxpHujpohAqNBIirXZSM6XRSOSk84n1XR84')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrates creating a model in the UI - notice the digest match\n",
    "\n",
    "from weave.trace_server.trace_server_interface import ObjCreateReq\n",
    "\n",
    "obj_res = client.server.obj_create(\n",
    "    ObjCreateReq.model_validate(\n",
    "        {\n",
    "            \"obj\": {\n",
    "                \"project_id\": client._project_id(),\n",
    "                \"object_id\": \"LiteLLMCompletionModel\",\n",
    "                \"val\": {\n",
    "                    \"model\": \"gpt-4o\",\n",
    "                    \"messages_template\": [\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": \"Please extract the name and age from the following text!\",\n",
    "                        },\n",
    "                        {\"role\": \"user\", \"content\": \"{user_input}\"},\n",
    "                    ],\n",
    "                    \"response_format\": {\n",
    "                        \"type\": \"json_schema\",\n",
    "                        \"json_schema\": {\n",
    "                            \"name\": \"Person\",\n",
    "                            \"schema\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"age\": {\"type\": \"integer\"},\n",
    "                                    \"name\": {\"type\": \"string\"},\n",
    "                                },\n",
    "                            },\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "                \"set_leaf_object_class\": \"LiteLLMCompletionModel\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "obj_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/timssweeney/remote_model_demo_4/r/call/0193ba50-1be0-70d2-84cd-dcf8fac3ff09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Fred', 'age': 30}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrates fetching a model in python that was created in the UI\n",
    "\n",
    "from weave.trace.refs import ObjectRef\n",
    "\n",
    "gotten_model = weave.ref(\n",
    "    ObjectRef(\n",
    "        entity=client.entity,\n",
    "        project=client.project,\n",
    "        name=\"LiteLLMCompletionModel\",\n",
    "        _digest=obj_res.digest,\n",
    "    ).uri()\n",
    ").get()\n",
    "\n",
    "res = gotten_model.predict(user_input=\"Hello, my name is Fred and I am 30 years old.\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LiteLLMCompletionModel(name=None, description=None, model='gpt-4o', messages_template=WeaveList([{'role': 'system', 'content': 'Please extract the name and age from the following text!'}, {'role': 'user', 'content': '{user_input}'}]), response_format=WeaveDict({'type': 'json_schema', 'json_schema': {'name': 'Person', 'schema': {'type': 'object', 'properties': {'age': {'type': 'integer'}, 'name': {'type': 'string'}}}}}))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gotten_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScoreCallRes(feedback_id='0193ba55-d466-74a3-a4de-da0a456b08a7', score_call=CallSchema(id='0193ba55-cb43-7c61-a712-f7249e6dfe4f', project_id='UHJvamVjdEludGVybmFsSWQ6NDA1NzYyOTQ=', op_name='weave:///timssweeney/remote_model_demo_4/op/LLMJudgeScorer.score:LSxb3VBdL8YmPr9vqYhxsMe74D8C04dJL1IKQ61Ke7M', display_name=None, trace_id='0193ba55-cb43-7c61-a712-f71512a66d3b', parent_id=None, started_at=datetime.datetime(2024, 12, 12, 10, 6, 45, 59887, tzinfo=TzInfo(UTC)), attributes={'weave': {'client_version': '0.51.25-dev0', 'source': 'python-sdk', 'os_name': 'Darwin', 'os_version': 'Darwin Kernel Version 23.2.0: Wed Nov 15 21:53:18 PST 2023; root:xnu-10002.61.3~2/RELEASE_ARM64_T6000', 'os_release': '23.2.0', 'sys_version': '3.10.8 (main, Dec  5 2022, 18:10:41) [Clang 14.0.0 (clang-1400.0.29.202)]'}}, inputs={'self': 'weave:///timssweeney/remote_model_demo_4/object/LLMJudgeScorer:uCL086uULzE1HKLFn8YIezCG98HiqayaAp3d1R9ktA0', 'inputs': {'kwargs': {'user_input': 'Hello, my name is Charles and I am 40 years old.'}}, 'output': {'name': 'Charles', 'age': 40}}, ended_at=datetime.datetime(2024, 12, 12, 10, 6, 47, 368348, tzinfo=TzInfo(UTC)), exception=None, output={'is_correct': True}, summary={'usage': {'gpt-4o-2024-08-06': {'prompt_tokens': 91, 'completion_tokens': 6, 'requests': 1, 'total_tokens': 97, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}, 'weave': {'status': <TraceStatus.SUCCESS: 'success'>, 'trace_name': 'LLMJudgeScorer.score', 'latency_ms': 2308}}, wb_user_id='VXNlcjo2Mzg4Nw==', wb_run_id=None, deleted_at=None))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weave\n",
    "from weave.trace.refs import CallRef\n",
    "from weave.trace_server import trace_server_interface as tsi\n",
    "\n",
    "obj_create_res = client.server.obj_create(\n",
    "    tsi.ObjCreateReq.model_validate(\n",
    "        {\n",
    "            \"obj\": {\n",
    "                \"project_id\": client._project_id(),\n",
    "                \"object_id\": \"CorrectnessJudge\",\n",
    "                \"val\": {\n",
    "                    \"model\": \"gpt-4o\",\n",
    "                    \"system_prompt\": \"You are a judge that scores the correctness of a response.\",\n",
    "                    \"response_format\": {\n",
    "                        \"type\": \"json_schema\",\n",
    "                        \"json_schema\": {\n",
    "                            \"name\": \"Correctness\",\n",
    "                            \"schema\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"is_correct\": {\"type\": \"boolean\"},\n",
    "                                },\n",
    "                            },\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "                \"set_leaf_object_class\": \"LLMJudgeScorer\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    ")\n",
    "client._flush()\n",
    "scorer_ref = weave.ObjectRef(\n",
    "    entity=client._project_id().split(\"/\")[0],\n",
    "    project=client._project_id().split(\"/\")[1],\n",
    "    name=\"CorrectnessJudge\",\n",
    "    _digest=obj_create_res.digest,\n",
    ")\n",
    "\n",
    "call_ref = CallRef(\n",
    "    entity=client._project_id().split(\"/\")[0],\n",
    "    project=client._project_id().split(\"/\")[1],\n",
    "    id=call_res.call_id,\n",
    ")\n",
    "\n",
    "score_res = client.server.score_call(\n",
    "    tsi.ScoreCallReq.model_validate(\n",
    "        {\n",
    "            \"project_id\": client._project_id(),\n",
    "            \"call_ref\": call_ref.uri(),\n",
    "            \"scorer_ref\": scorer_ref.uri(),\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "score_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wandb-weave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
