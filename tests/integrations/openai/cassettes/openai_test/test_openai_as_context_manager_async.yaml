interactions:
- request:
    body: null
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate, zstd
      Connection:
      - keep-alive
      User-Agent:
      - python-requests/2.31.0
    method: GET
    uri: https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json
  response:
    body:
      string: "{\n    \"gpt-4\": {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096, \n        \"input_cost_per_token\":
        0.00003,\n        \"output_cost_per_token\": 0.00006,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true\n    },\n    \"gpt-4o\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.000005,\n        \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true\n    },\n    \"gpt-4o-2024-05-13\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000005,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true\n    },\n    \"gpt-4-turbo-preview\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00001,\n
        \       \"output_cost_per_token\": 0.00003,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true\n    },\n    \"gpt-4-0314\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00003,\n        \"output_cost_per_token\":
        0.00006,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\"\n
        \   },\n    \"gpt-4-0613\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00003,\n        \"output_cost_per_token\": 0.00006,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true\n    },\n    \"gpt-4-32k\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        32768,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00006,\n        \"output_cost_per_token\": 0.00012,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\"\n    },\n    \"gpt-4-32k-0314\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00006,\n        \"output_cost_per_token\":
        0.00012,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\"\n
        \   },\n    \"gpt-4-32k-0613\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        32768,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00006,\n        \"output_cost_per_token\": 0.00012,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\"\n    },\n    \"gpt-4-turbo\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00001,\n        \"output_cost_per_token\":
        0.00003,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true\n    },\n    \"gpt-4-turbo-2024-04-09\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00001,\n
        \       \"output_cost_per_token\": 0.00003,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true\n    },\n    \"gpt-4-1106-preview\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.00001,\n        \"output_cost_per_token\":
        0.00003,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"gpt-4-0125-preview\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.00001,\n        \"output_cost_per_token\":
        0.00003,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"gpt-4-vision-preview\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.00001,\n        \"output_cost_per_token\":
        0.00003,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_vision\": true\n    },\n    \"gpt-4-1106-vision-preview\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00001,\n
        \       \"output_cost_per_token\": 0.00003,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_vision\": true\n
        \   },\n    \"gpt-3.5-turbo\": {\n        \"max_tokens\": 4097,\n        \"max_input_tokens\":
        16385,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0000015,\n        \"output_cost_per_token\": 0.000002,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true\n    },\n    \"gpt-3.5-turbo-0301\": {\n        \"max_tokens\": 4097,\n
        \       \"max_input_tokens\": 4097,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.0000015,\n        \"output_cost_per_token\":
        0.000002,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\"\n
        \   },\n    \"gpt-3.5-turbo-0613\": {\n        \"max_tokens\": 4097,\n        \"max_input_tokens\":
        4097,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0000015,\n        \"output_cost_per_token\": 0.000002,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true\n    },\n    \"gpt-3.5-turbo-1106\": {\n        \"max_tokens\": 16385,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.0000010,\n        \"output_cost_per_token\":
        0.0000020,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"gpt-3.5-turbo-0125\": {\n        \"max_tokens\": 16385,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000015,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"gpt-3.5-turbo-16k\": {\n        \"max_tokens\": 16385,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000004,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\"\n
        \   },\n    \"gpt-3.5-turbo-16k-0613\": {\n        \"max_tokens\": 16385,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000004,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\"\n
        \   },\n    \"ft:gpt-3.5-turbo\": {\n        \"max_tokens\": 4097,\n        \"max_input_tokens\":
        4097,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.000003,\n        \"output_cost_per_token\": 0.000006,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\"\n    },\n    \"ft:gpt-4-0613\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00003,\n        \"output_cost_per_token\":
        0.00006,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"source\": \"OpenAI
        needs to add pricing for this ft model, will be updated when added by OpenAI.
        Defaulting to base model pricing\"\n    },\n    \"ft:gpt-4o-2024-05-13\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000005,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"OpenAI needs to add pricing for this ft model,
        will be updated when added by OpenAI. Defaulting to base model pricing\"\n
        \   },\n    \"ft:davinci-002\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        16384,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.000002,\n        \"output_cost_per_token\": 0.000002,\n        \"litellm_provider\":
        \"text-completion-openai\",\n        \"mode\": \"completion\"\n    },\n    \"ft:babbage-002\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.0000004,\n
        \       \"output_cost_per_token\": 0.0000004,\n        \"litellm_provider\":
        \"text-completion-openai\",\n        \"mode\": \"completion\"\n    },\n    \"text-embedding-3-large\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 8191,\n        \"output_vector_size\":
        3072,\n        \"input_cost_per_token\": 0.00000013,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"text-embedding-3-small\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 8191,\n        \"output_vector_size\": 1536,
        \n        \"input_cost_per_token\": 0.00000002,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"text-embedding-ada-002\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 8191,\n        \"output_vector_size\": 1536,
        \n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"text-embedding-ada-002-v2\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 8191,\n        \"input_cost_per_token\": 0.0000001,\n
        \       \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"embedding\"\n    },\n    \"text-moderation-stable\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 0,\n        \"input_cost_per_token\": 0.000000,\n
        \       \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"moderations\"\n    },\n    \"text-moderation-007\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 0,\n        \"input_cost_per_token\": 0.000000,\n
        \       \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"moderations\"\n    },\n    \"text-moderation-latest\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 0,\n        \"input_cost_per_token\": 0.000000,\n
        \       \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"moderations\"\n    },\n    \"256-x-256/dall-e-2\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        0.00000024414,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\"\n    },\n    \"512-x-512/dall-e-2\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 0.0000000686,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\"\n    },\n    \"1024-x-1024/dall-e-2\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        0.000000019,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\"\n    },\n    \"hd/1024-x-1792/dall-e-3\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 0.00000006539,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"openai\"\n
        \   },\n    \"hd/1792-x-1024/dall-e-3\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 0.00000006539,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\"\n    },\n    \"hd/1024-x-1024/dall-e-3\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        0.00000007629,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\"\n    },\n    \"standard/1024-x-1792/dall-e-3\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 0.00000004359,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"openai\"\n
        \   },\n    \"standard/1792-x-1024/dall-e-3\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 0.00000004359,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\"\n    },\n    \"standard/1024-x-1024/dall-e-3\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        0.0000000381469,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\"\n    },\n    \"whisper-1\": {\n        \"mode\": \"audio_transcription\",\n
        \       \"input_cost_per_second\": 0,\n        \"output_cost_per_second\":
        0.0001, \n        \"litellm_provider\": \"openai\"\n    }, \n    \"azure/whisper-1\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0, \n        \"output_cost_per_second\": 0.0001, \n        \"litellm_provider\":
        \"azure\"\n    },\n    \"azure/gpt-4o\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000005,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true\n    },\n    \"azure/gpt-4-turbo-2024-04-09\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00001,\n
        \       \"output_cost_per_token\": 0.00003,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true\n    },\n    \"azure/gpt-4-0125-preview\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00001,\n        \"output_cost_per_token\":
        0.00003,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"azure/gpt-4-1106-preview\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00001,\n        \"output_cost_per_token\":
        0.00003,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"azure/gpt-4-0613\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.00003,\n        \"output_cost_per_token\":
        0.00006,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"azure/gpt-4-32k-0613\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00006,\n        \"output_cost_per_token\":
        0.00012,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\"\n
        \   },\n    \"azure/gpt-4-32k\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        32768,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00006,\n        \"output_cost_per_token\": 0.00012,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\"\n    },\n    \"azure/gpt-4\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00003,\n        \"output_cost_per_token\":
        0.00006,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"azure/gpt-4-turbo\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00001,\n
        \       \"output_cost_per_token\": 0.00003,\n        \"litellm_provider\":
        \"azure\", \n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true\n    },\n    \"azure/gpt-4-turbo-vision-preview\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00001,\n
        \       \"output_cost_per_token\": 0.00003,\n        \"litellm_provider\":
        \"azure\", \n        \"mode\": \"chat\",\n        \"supports_vision\": true\n
        \   },\n    \"azure/gpt-35-turbo-16k-0613\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000004,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"azure/gpt-35-turbo-1106\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000002,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"azure/gpt-35-turbo-0125\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000015,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"azure/gpt-35-turbo-16k\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000004,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\"\n
        \   },\n    \"azure/gpt-35-turbo\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        4097,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0000005,\n        \"output_cost_per_token\": 0.0000015,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true\n    },\n    \"azure/gpt-3.5-turbo-instruct-0914\": {\n        \"max_tokens\":
        4097,\n        \"max_input_tokens\": 4097,\n        \"input_cost_per_token\":
        0.0000015,\n        \"output_cost_per_token\": 0.000002,\n        \"litellm_provider\":
        \"text-completion-openai\",\n        \"mode\": \"completion\"\n    },\n    \"azure/gpt-35-turbo-instruct\":
        {\n        \"max_tokens\": 4097,\n        \"max_input_tokens\": 4097,\n        \"input_cost_per_token\":
        0.0000015,\n        \"output_cost_per_token\": 0.000002,\n        \"litellm_provider\":
        \"text-completion-openai\",\n        \"mode\": \"completion\"\n    },\n    \"azure/mistral-large-latest\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"azure/mistral-large-2402\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"azure/command-r-plus\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true\n    },\n    \"azure/ada\": {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"azure/text-embedding-ada-002\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 8191,\n        \"input_cost_per_token\": 0.0000001,\n
        \       \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"embedding\"\n    },\n    \"azure/text-embedding-3-large\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 8191,\n        \"input_cost_per_token\":
        0.00000013,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"embedding\"\n    },\n    \"azure/text-embedding-3-small\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 8191,\n        \"input_cost_per_token\":
        0.00000002,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"embedding\"\n    },    \n    \"azure/standard/1024-x-1024/dall-e-3\":
        {\n        \"input_cost_per_pixel\": 0.0000000381469,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure\", \n        \"mode\": \"image_generation\"\n
        \   },\n    \"azure/hd/1024-x-1024/dall-e-3\": {\n        \"input_cost_per_pixel\":
        0.00000007629,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"azure\", \n        \"mode\": \"image_generation\"\n    },\n    \"azure/standard/1024-x-1792/dall-e-3\":
        {\n        \"input_cost_per_pixel\": 0.00000004359,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure\", \n        \"mode\": \"image_generation\"\n
        \   },\n    \"azure/standard/1792-x-1024/dall-e-3\": {\n        \"input_cost_per_pixel\":
        0.00000004359,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"azure\", \n        \"mode\": \"image_generation\"\n    },\n    \"azure/hd/1024-x-1792/dall-e-3\":
        {\n        \"input_cost_per_pixel\": 0.00000006539,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure\", \n        \"mode\": \"image_generation\"\n
        \   },\n    \"azure/hd/1792-x-1024/dall-e-3\": {\n        \"input_cost_per_pixel\":
        0.00000006539,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"azure\", \n        \"mode\": \"image_generation\"\n    },\n    \"azure/standard/1024-x-1024/dall-e-2\":
        {\n        \"input_cost_per_pixel\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure\", \n        \"mode\": \"image_generation\"\n
        \   },\n    \"babbage-002\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        16384,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0000004,\n        \"output_cost_per_token\": 0.0000004,\n        \"litellm_provider\":
        \"text-completion-openai\",\n        \"mode\": \"completion\"\n    },\n    \"davinci-002\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000002,\n
        \       \"output_cost_per_token\": 0.000002,\n        \"litellm_provider\":
        \"text-completion-openai\",\n        \"mode\": \"completion\"\n    },    \n
        \   \"gpt-3.5-turbo-instruct\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0000015,\n        \"output_cost_per_token\": 0.000002,\n        \"litellm_provider\":
        \"text-completion-openai\",\n        \"mode\": \"completion\"\n    },\n    \"gpt-3.5-turbo-instruct-0914\":
        {\n        \"max_tokens\": 4097,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4097,\n        \"input_cost_per_token\": 0.0000015,\n        \"output_cost_per_token\":
        0.000002,\n        \"litellm_provider\": \"text-completion-openai\",\n        \"mode\":
        \"completion\"\n\n    },\n    \"claude-instant-1\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000163,\n        \"output_cost_per_token\":
        0.00000551,\n        \"litellm_provider\": \"anthropic\",\n        \"mode\":
        \"chat\"\n    },\n    \"mistral/mistral-tiny\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000025,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\"\n    },\n    \"mistral/mistral-small\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000003,\n        \"litellm_provider\": \"mistral\",\n        \"supports_function_calling\":
        true,\n        \"mode\": \"chat\"\n    },\n    \"mistral/mistral-small-latest\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000003,\n        \"litellm_provider\": \"mistral\",\n        \"supports_function_calling\":
        true,\n        \"mode\": \"chat\"\n    },\n    \"mistral/mistral-medium\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000027,\n        \"output_cost_per_token\":
        0.0000081,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\"\n    },\n    \"mistral/mistral-medium-latest\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000027,\n        \"output_cost_per_token\":
        0.0000081,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\"\n    },\n    \"mistral/mistral-medium-2312\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000027,\n        \"output_cost_per_token\":
        0.0000081,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\"\n    },\n    \"mistral/mistral-large-latest\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000004,\n        \"output_cost_per_token\":
        0.000012,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"mistral/mistral-large-2402\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000004,\n        \"output_cost_per_token\":
        0.000012,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"mistral/open-mistral-7b\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000025,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\"\n    },\n    \"mistral/open-mixtral-8x7b\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000007,\n        \"output_cost_per_token\":
        0.0000007,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true\n    },\n    \"mistral/open-mixtral-8x22b\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 64000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000002,\n        \"output_cost_per_token\":
        0.000006,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"mistral/codestral-latest\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000003,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\"\n
        \   },\n    \"mistral/codestral-2405\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 8191,\n
        \       \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000003,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\"\n
        \   },\n    \"mistral/mistral-embed\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"input_cost_per_token\": 0.0000001,\n
        \       \"litellm_provider\": \"mistral\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"deepseek-chat\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        32000,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00000014,\n        \"output_cost_per_token\": 0.00000028,\n        \"litellm_provider\":
        \"deepseek\",\n        \"mode\": \"chat\"\n    },\n    \"codestral/codestral-latest\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000000,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"codestral\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://docs.mistral.ai/capabilities/code_generation/\"\n
        \   },\n    \"codestral/codestral-2405\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 8191,\n
        \       \"input_cost_per_token\": 0.000000,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"codestral\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://docs.mistral.ai/capabilities/code_generation/\"\n
        \   },\n    \"text-completion-codestral/codestral-latest\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000000,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"text-completion-codestral\",\n
        \       \"mode\": \"completion\",\n        \"source\": \"https://docs.mistral.ai/capabilities/code_generation/\"\n
        \   },\n    \"text-completion-codestral/codestral-2405\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000000,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"text-completion-codestral\",\n
        \       \"mode\": \"completion\",\n        \"source\": \"https://docs.mistral.ai/capabilities/code_generation/\"\n
        \   },\n    \"deepseek-coder\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        32000,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00000014,\n        \"output_cost_per_token\": 0.00000028,\n        \"litellm_provider\":
        \"deepseek\",\n        \"mode\": \"chat\"\n    },\n    \"groq/llama2-70b-4096\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000070,\n        \"output_cost_per_token\":
        0.00000080,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"groq/llama3-8b-8192\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000005,\n        \"output_cost_per_token\":
        0.00000008,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"groq/llama3-70b-8192\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000059,\n        \"output_cost_per_token\":
        0.00000079,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"groq/mixtral-8x7b-32768\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 0.00000024,\n
        \       \"output_cost_per_token\": 0.00000024,\n        \"litellm_provider\":
        \"groq\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true\n    },\n    \"groq/gemma-7b-it\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.00000007,\n        \"output_cost_per_token\":
        0.00000007,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"friendliai/mixtral-8x7b-instruct-v0-1\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 0.0000004,\n
        \       \"output_cost_per_token\": 0.0000004,\n        \"litellm_provider\":
        \"friendliai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true\n    },\n    \"friendliai/meta-llama-3-8b-instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0000001,\n        \"litellm_provider\": \"friendliai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true\n    },\n    \"friendliai/meta-llama-3-70b-instruct\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0000008,\n        \"output_cost_per_token\":
        0.0000008,\n        \"litellm_provider\": \"friendliai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true\n    },\n    \"claude-instant-1.2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000000163,\n
        \       \"output_cost_per_token\": 0.000000551,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\"\n    },\n    \"claude-2\": {\n
        \       \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"anthropic\",\n        \"mode\":
        \"chat\"\n    },\n    \"claude-2.1\": {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\":
        200000,\n        \"max_output_tokens\": 8191,\n        \"input_cost_per_token\":
        0.000008,\n        \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\"\n    },\n    \"claude-3-haiku-20240307\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000025,\n
        \       \"output_cost_per_token\": 0.00000125,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        264\n    },\n    \"claude-3-opus-20240229\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000015,\n        \"output_cost_per_token\":
        0.000075,\n        \"litellm_provider\": \"anthropic\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 395\n    },\n    \"claude-3-sonnet-20240229\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159\n    },\n    \"claude-3-5-sonnet-20240620\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"anthropic\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 159\n    },\n    \"text-bison\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_character\": 0.00000025,\n        \"output_cost_per_character\":
        0.0000005,\n        \"litellm_provider\": \"vertex_ai-text-models\",\n        \"mode\":
        \"completion\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-bison@001\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-bison@002\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-bison32k\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-bison32k@002\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-unicorn\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.00001,\n        \"output_cost_per_token\": 0.000028,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-unicorn@001\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.00001,\n        \"output_cost_per_token\": 0.000028,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"chat-bison\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-chat-models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"chat-bison@001\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-chat-models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"chat-bison@002\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-chat-models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"chat-bison-32k\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        32000,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-chat-models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"chat-bison-32k@002\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        32000,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-chat-models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-bison\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        6144,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-bison@001\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        6144,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-bison@002\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        6144,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-bison32k\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        6144,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-bison-32k@002\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        6144,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-gecko@001\": {\n        \"max_tokens\": 64,\n        \"max_input_tokens\":
        2048,\n        \"max_output_tokens\": 64,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-gecko@002\": {\n        \"max_tokens\": 64,\n        \"max_input_tokens\":
        2048,\n        \"max_output_tokens\": 64,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-gecko\": {\n        \"max_tokens\": 64,\n        \"max_input_tokens\":
        2048,\n        \"max_output_tokens\": 64,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-gecko-latest\": {\n        \"max_tokens\": 64,\n        \"max_input_tokens\":
        2048,\n        \"max_output_tokens\": 64,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"codechat-bison@latest\": {\n        \"max_tokens\": 1024,\n
        \       \"max_input_tokens\": 6144,\n        \"max_output_tokens\": 1024,\n
        \       \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"input_cost_per_character\": 0.00000025,\n        \"output_cost_per_character\":
        0.0000005,\n        \"litellm_provider\": \"vertex_ai-code-chat-models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"codechat-bison\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        6144,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-code-chat-models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"codechat-bison@001\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        6144,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-code-chat-models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"codechat-bison@002\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        6144,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-code-chat-models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"codechat-bison-32k\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        32000,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-code-chat-models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"codechat-bison-32k@002\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"input_cost_per_character\": 0.00000025,\n        \"output_cost_per_character\":
        0.0000005,\n        \"litellm_provider\": \"vertex_ai-code-chat-models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-pro\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        32760,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_image\":
        0.0025,\n        \"input_cost_per_video_per_second\": 0.002,\n        \"input_cost_per_token\":
        0.0000005, \n        \"input_cost_per_character\": 0.000000125, \n        \"output_cost_per_token\":
        0.0000015,\n        \"output_cost_per_character\": 0.000000375,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n
        \   },\n    \"gemini-1.0-pro\": { \n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        32760,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_image\":
        0.0025,\n        \"input_cost_per_video_per_second\": 0.002,\n        \"input_cost_per_token\":
        0.0000005, \n        \"input_cost_per_character\": 0.000000125, \n        \"output_cost_per_token\":
        0.0000015,\n        \"output_cost_per_character\": 0.000000375,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models\"\n
        \   },\n    \"gemini-1.0-pro-001\": { \n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        32760,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_image\":
        0.0025,\n        \"input_cost_per_video_per_second\": 0.002,\n        \"input_cost_per_token\":
        0.0000005, \n        \"input_cost_per_character\": 0.000000125, \n        \"output_cost_per_token\":
        0.0000015,\n        \"output_cost_per_character\": 0.000000375,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.0-ultra\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 2048,\n        \"input_cost_per_image\":
        0.0025,\n        \"input_cost_per_video_per_second\": 0.002,\n        \"input_cost_per_token\":
        0.0000005, \n        \"input_cost_per_character\": 0.000000125, \n        \"output_cost_per_token\":
        0.0000015,\n        \"output_cost_per_character\": 0.000000375,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"As of Jun, 2024. There is no available doc on
        vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got
        max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.0-ultra-001\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 2048,\n        \"input_cost_per_image\":
        0.0025,\n        \"input_cost_per_video_per_second\": 0.002,\n        \"input_cost_per_token\":
        0.0000005, \n        \"input_cost_per_character\": 0.000000125, \n        \"output_cost_per_token\":
        0.0000015,\n        \"output_cost_per_character\": 0.000000375,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"As of Jun, 2024. There is no available doc on
        vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got
        max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.0-pro-002\": { \n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        32760,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_image\":
        0.0025,\n        \"input_cost_per_video_per_second\": 0.002,\n        \"input_cost_per_token\":
        0.0000005, \n        \"input_cost_per_character\": 0.000000125, \n        \"output_cost_per_token\":
        0.0000015,\n        \"output_cost_per_character\": 0.000000375,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.5-pro\": { \n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        2097152,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_image\":
        0.001315,\n        \"input_cost_per_audio_per_second\": 0.000125,\n        \"input_cost_per_video_per_second\":
        0.001315,\n        \"input_cost_per_token\": 0.000005, \n        \"input_cost_per_character\":
        0.00000125, \n        \"input_cost_per_token_above_128k_tokens\": 0.00001,
        \n        \"input_cost_per_character_above_128k_tokens\": 0.0000025, \n        \"output_cost_per_token\":
        0.000015,\n        \"output_cost_per_character\": 0.00000375,\n        \"output_cost_per_token_above_128k_tokens\":
        0.00003,\n        \"output_cost_per_character_above_128k_tokens\": 0.0000075,\n
        \       \"output_cost_per_image\": 0.00263,\n        \"output_cost_per_video_per_second\":
        0.00263,\n        \"output_cost_per_audio_per_second\": 0.00025,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true, \n        \"supports_response_schema\": true, \n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.5-pro-001\": { \n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        1000000,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_image\":
        0.001315,\n        \"input_cost_per_audio_per_second\": 0.000125,\n        \"input_cost_per_video_per_second\":
        0.001315,\n        \"input_cost_per_token\": 0.000005, \n        \"input_cost_per_character\":
        0.00000125, \n        \"input_cost_per_token_above_128k_tokens\": 0.00001,
        \n        \"input_cost_per_character_above_128k_tokens\": 0.0000025, \n        \"output_cost_per_token\":
        0.000015,\n        \"output_cost_per_character\": 0.00000375,\n        \"output_cost_per_token_above_128k_tokens\":
        0.00003,\n        \"output_cost_per_character_above_128k_tokens\": 0.0000075,\n
        \       \"output_cost_per_image\": 0.00263,\n        \"output_cost_per_video_per_second\":
        0.00263,\n        \"output_cost_per_audio_per_second\": 0.00025,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true, \n        \"supports_response_schema\": true, \n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.5-pro-preview-0514\": { \n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1000000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_image\": 0.001315,\n        \"input_cost_per_audio_per_second\":
        0.000125,\n        \"input_cost_per_video_per_second\": 0.001315,\n        \"input_cost_per_token\":
        0.000005, \n        \"input_cost_per_character\": 0.00000125, \n        \"input_cost_per_token_above_128k_tokens\":
        0.00001, \n        \"input_cost_per_character_above_128k_tokens\": 0.0000025,
        \n        \"output_cost_per_token\": 0.000015,\n        \"output_cost_per_character\":
        0.00000375,\n        \"output_cost_per_token_above_128k_tokens\": 0.00003,\n
        \       \"output_cost_per_character_above_128k_tokens\": 0.0000075,\n        \"output_cost_per_image\":
        0.00263,\n        \"output_cost_per_video_per_second\": 0.00263,\n        \"output_cost_per_audio_per_second\":
        0.00025,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true, \n        \"supports_response_schema\":
        true, \n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.5-pro-preview-0215\": { \n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1000000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_image\": 0.001315,\n        \"input_cost_per_audio_per_second\":
        0.000125,\n        \"input_cost_per_video_per_second\": 0.001315,\n        \"input_cost_per_token\":
        0.000005, \n        \"input_cost_per_character\": 0.00000125, \n        \"input_cost_per_token_above_128k_tokens\":
        0.00001, \n        \"input_cost_per_character_above_128k_tokens\": 0.0000025,
        \n        \"output_cost_per_token\": 0.000015,\n        \"output_cost_per_character\":
        0.00000375,\n        \"output_cost_per_token_above_128k_tokens\": 0.00003,\n
        \       \"output_cost_per_character_above_128k_tokens\": 0.0000075,\n        \"output_cost_per_image\":
        0.00263,\n        \"output_cost_per_video_per_second\": 0.00263,\n        \"output_cost_per_audio_per_second\":
        0.00025,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true, \n        \"supports_response_schema\":
        true, \n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.5-pro-preview-0409\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1000000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_image\": 0.001315,\n        \"input_cost_per_audio_per_second\":
        0.000125,\n        \"input_cost_per_video_per_second\": 0.001315,\n        \"input_cost_per_token\":
        0.000005, \n        \"input_cost_per_character\": 0.00000125, \n        \"input_cost_per_token_above_128k_tokens\":
        0.00001, \n        \"input_cost_per_character_above_128k_tokens\": 0.0000025,
        \n        \"output_cost_per_token\": 0.000015,\n        \"output_cost_per_character\":
        0.00000375,\n        \"output_cost_per_token_above_128k_tokens\": 0.00003,\n
        \       \"output_cost_per_character_above_128k_tokens\": 0.0000075,\n        \"output_cost_per_image\":
        0.00263,\n        \"output_cost_per_video_per_second\": 0.00263,\n        \"output_cost_per_audio_per_second\":
        0.00025,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true, \n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.5-flash\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        1000000,\n        \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_image\": 0.0001315,\n
        \       \"input_cost_per_video_per_second\": 0.0001315,\n        \"input_cost_per_audio_per_second\":
        0.000125,\n        \"input_cost_per_token\": 0.0000005, \n        \"input_cost_per_character\":
        0.000000125, \n        \"input_cost_per_token_above_128k_tokens\": 0.000001,
        \n        \"input_cost_per_character_above_128k_tokens\": 0.00000025, \n        \"output_cost_per_token\":
        0.0000015,\n        \"output_cost_per_character\": 0.000000375,\n        \"output_cost_per_token_above_128k_tokens\":
        0.000003,\n        \"output_cost_per_character_above_128k_tokens\": 0.00000075,\n
        \       \"output_cost_per_image\": 0.000263,\n        \"output_cost_per_video_per_second\":
        0.000263,\n        \"output_cost_per_audio_per_second\": 0.00025,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.5-flash-001\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        1000000,\n        \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_image\": 0.0001315,\n
        \       \"input_cost_per_video_per_second\": 0.0001315,\n        \"input_cost_per_audio_per_second\":
        0.000125,\n        \"input_cost_per_token\": 0.0000005, \n        \"input_cost_per_character\":
        0.000000125, \n        \"input_cost_per_token_above_128k_tokens\": 0.000001,
        \n        \"input_cost_per_character_above_128k_tokens\": 0.00000025, \n        \"output_cost_per_token\":
        0.0000015,\n        \"output_cost_per_character\": 0.000000375,\n        \"output_cost_per_token_above_128k_tokens\":
        0.000003,\n        \"output_cost_per_character_above_128k_tokens\": 0.00000075,\n
        \       \"output_cost_per_image\": 0.000263,\n        \"output_cost_per_video_per_second\":
        0.000263,\n        \"output_cost_per_audio_per_second\": 0.00025,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.5-flash-preview-0514\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1000000,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_image\": 0.0001315,\n        \"input_cost_per_video_per_second\":
        0.0001315,\n        \"input_cost_per_audio_per_second\": 0.000125,\n        \"input_cost_per_token\":
        0.0000005, \n        \"input_cost_per_character\": 0.000000125, \n        \"input_cost_per_token_above_128k_tokens\":
        0.000001, \n        \"input_cost_per_character_above_128k_tokens\": 0.00000025,
        \n        \"output_cost_per_token\": 0.0000015,\n        \"output_cost_per_character\":
        0.000000375,\n        \"output_cost_per_token_above_128k_tokens\": 0.000003,\n
        \       \"output_cost_per_character_above_128k_tokens\": 0.00000075,\n        \"output_cost_per_image\":
        0.000263,\n        \"output_cost_per_video_per_second\": 0.000263,\n        \"output_cost_per_audio_per_second\":
        0.00025,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-experimental\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        1000000,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": false,\n
        \       \"supports_tool_choice\": true, \n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-pro-vision\": {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\":
        16384,\n        \"max_output_tokens\": 2048,\n        \"max_images_per_prompt\":
        16,\n        \"max_videos_per_prompt\": 1,\n        \"max_video_length\":
        2,\n        \"input_cost_per_token\": 0.00000025, \n        \"output_cost_per_token\":
        0.0000005,\n        \"litellm_provider\": \"vertex_ai-vision-models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.0-pro-vision\": {\n        \"max_tokens\": 2048,\n
        \       \"max_input_tokens\": 16384,\n        \"max_output_tokens\": 2048,\n
        \       \"max_images_per_prompt\": 16,\n        \"max_videos_per_prompt\":
        1,\n        \"max_video_length\": 2,\n        \"input_cost_per_token\": 0.00000025,
        \n        \"output_cost_per_token\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-vision-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.0-pro-vision-001\": {\n        \"max_tokens\": 2048,\n
        \       \"max_input_tokens\": 16384,\n        \"max_output_tokens\": 2048,\n
        \       \"max_images_per_prompt\": 16,\n        \"max_videos_per_prompt\":
        1,\n        \"max_video_length\": 2,\n        \"input_cost_per_token\": 0.00000025,
        \n        \"output_cost_per_token\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-vision-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"vertex_ai/claude-3-sonnet@20240229\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"vertex_ai-anthropic_models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_vision\": true\n    },\n    \"vertex_ai/claude-3-5-sonnet@20240620\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true\n    },\n    \"vertex_ai/claude-3-haiku@20240307\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000025,\n
        \       \"output_cost_per_token\": 0.00000125,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true\n    },\n    \"vertex_ai/claude-3-opus@20240229\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000015,\n
        \       \"output_cost_per_token\": 0.000075,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true\n    },\n    \"vertex_ai/imagegeneration@006\":
        {\n        \"cost_per_image\": 0.020,\n        \"litellm_provider\": \"vertex_ai-image-models\",\n
        \       \"mode\": \"image_generation\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n
        \   },\n    \"text-embedding-004\": {\n        \"max_tokens\": 3072,\n        \"max_input_tokens\":
        3072,\n        \"output_vector_size\": 768,\n        \"input_cost_per_token\":
        0.00000000625,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\"\n    },\n
        \   \"text-multilingual-embedding-002\": {\n        \"max_tokens\": 2048,\n
        \       \"max_input_tokens\": 2048,\n        \"output_vector_size\": 768,\n
        \       \"input_cost_per_token\": 0.00000000625,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\"\n
        \   },\n    \"textembedding-gecko\": {\n        \"max_tokens\": 3072,\n        \"max_input_tokens\":
        3072,\n        \"output_vector_size\": 768,\n        \"input_cost_per_token\":
        0.00000000625,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"textembedding-gecko-multilingual\": {\n        \"max_tokens\":
        3072,\n        \"max_input_tokens\": 3072,\n        \"output_vector_size\":
        768,\n        \"input_cost_per_token\": 0.00000000625,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"textembedding-gecko-multilingual@001\": {\n        \"max_tokens\":
        3072,\n        \"max_input_tokens\": 3072,\n        \"output_vector_size\":
        768,\n        \"input_cost_per_token\": 0.00000000625,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"textembedding-gecko@001\": {\n        \"max_tokens\": 3072,\n
        \       \"max_input_tokens\": 3072,\n        \"output_vector_size\": 768,\n
        \       \"input_cost_per_token\": 0.00000000625,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"textembedding-gecko@003\": {\n        \"max_tokens\": 3072,\n
        \       \"max_input_tokens\": 3072,\n        \"output_vector_size\": 768,\n
        \       \"input_cost_per_token\": 0.00000000625,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-embedding-preview-0409\": {\n        \"max_tokens\": 3072,\n
        \       \"max_input_tokens\": 3072,\n        \"output_vector_size\": 768,\n
        \       \"input_cost_per_token\": 0.00000000625,\n        \"input_cost_per_token_batch_requests\":
        0.000000005,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"text-multilingual-embedding-preview-0409\":{\n
        \       \"max_tokens\": 3072,\n        \"max_input_tokens\": 3072,\n        \"output_vector_size\":
        768,\n        \"input_cost_per_token\": 0.00000000625,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/chat-bison\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"palm\",\n        \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/chat-bison-001\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"palm\",\n        \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/text-bison\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"palm\",\n        \"mode\": \"completion\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/text-bison-001\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"palm\",\n        \"mode\": \"completion\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/text-bison-safety-off\": {\n        \"max_tokens\": 1024,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 1024,\n
        \       \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"litellm_provider\": \"palm\",\n        \"mode\": \"completion\",\n
        \       \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/text-bison-safety-recitation-off\": {\n        \"max_tokens\":
        1024,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"litellm_provider\": \"palm\",\n        \"mode\": \"completion\",\n
        \       \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini/gemini-1.5-flash\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1000000,\n        \"max_output_tokens\": 8192,\n
        \       \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,
        \n        \"input_cost_per_token\": 0.00000035, \n        \"input_cost_per_token_above_128k_tokens\":
        0.0000007, \n        \"output_cost_per_token\": 0.00000105, \n        \"output_cost_per_token_above_128k_tokens\":
        0.0000021, \n        \"litellm_provider\": \"gemini\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini/gemini-1.5-flash-latest\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1000000,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,
        \n        \"input_cost_per_token\": 0.00000035, \n        \"input_cost_per_token_above_128k_tokens\":
        0.0000007, \n        \"output_cost_per_token\": 0.00000105, \n        \"output_cost_per_token_above_128k_tokens\":
        0.0000021, \n        \"litellm_provider\": \"gemini\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini/gemini-pro\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        32760,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.00000035, \n        \"input_cost_per_token_above_128k_tokens\": 0.0000007,
        \n        \"output_cost_per_token\": 0.00000105, \n        \"output_cost_per_token_above_128k_tokens\":
        0.0000021, \n        \"litellm_provider\": \"gemini\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini/gemini-1.5-pro\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 2097152,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.00000035, \n        \"input_cost_per_token_above_128k_tokens\":
        0.0000007, \n        \"output_cost_per_token\": 0.00000105, \n        \"output_cost_per_token_above_128k_tokens\":
        0.0000021, \n        \"litellm_provider\": \"gemini\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true, \n        \"supports_response_schema\": true, \n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini/gemini-1.5-pro-latest\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1048576,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.00000035, \n        \"input_cost_per_token_above_128k_tokens\":
        0.0000007, \n        \"output_cost_per_token\": 0.00000105, \n        \"output_cost_per_token_above_128k_tokens\":
        0.0000021, \n        \"litellm_provider\": \"gemini\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true, \n        \"supports_response_schema\": true, \n        \"source\":
        \"https://ai.google.dev/models/gemini\"\n    },\n    \"gemini/gemini-pro-vision\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 30720,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 0.00000035, \n        \"input_cost_per_token_above_128k_tokens\":
        0.0000007, \n        \"output_cost_per_token\": 0.00000105, \n        \"output_cost_per_token_above_128k_tokens\":
        0.0000021, \n        \"litellm_provider\": \"gemini\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"command-r\": {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00000050,\n        \"output_cost_per_token\": 0.0000015,\n        \"litellm_provider\":
        \"cohere_chat\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true\n    },\n    \"command-light\": {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.000015,\n        \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"cohere_chat\",\n        \"mode\": \"chat\"\n    },\n    \"command-r-plus\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"cohere_chat\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true\n    },\n    \"command-nightly\": {\n        \"max_tokens\": 4096, \n
        \       \"max_input_tokens\": 4096,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000015,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"cohere\",\n        \"mode\": \"completion\"\n
        \   },\n     \"command\": {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.000015,\n        \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"cohere\",\n        \"mode\": \"completion\"\n    },\n     \"command-medium-beta\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000015,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"cohere\",\n        \"mode\": \"completion\"\n
        \   },\n     \"command-xlarge-beta\": {\n        \"max_tokens\": 4096, \n
        \       \"max_input_tokens\": 4096,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000015,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"cohere\",\n        \"mode\": \"completion\"\n
        \   },\n    \"replicate/llama-2-70b-chat:2c1608e18606fad2812020dc541930f2d0495ce32eee50074220b87300bc16e1\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000,\n        \"output_cost_per_token\":
        0.0000,\n        \"litellm_provider\": \"replicate\",\n        \"mode\": \"chat\"\n
        \   },\n    \"replicate/meta/llama-2-13b\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 4096,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0000005,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\"\n    },\n    \"replicate/meta/llama-2-13b-chat\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0000005,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\"\n    },\n    \"replicate/meta/llama-2-70b\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000065,\n        \"output_cost_per_token\":
        0.00000275,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\"\n    },\n    \"replicate/meta/llama-2-70b-chat\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000065,\n        \"output_cost_per_token\":
        0.00000275,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\"\n    },\n    \"replicate/meta/llama-2-7b\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000005,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\"\n    },\n    \"replicate/meta/llama-2-7b-chat\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000005,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\"\n    },\n    \"replicate/meta/llama-3-70b\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000065,\n        \"output_cost_per_token\":
        0.00000275,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\"\n    },\n    \"replicate/meta/llama-3-70b-instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000065,\n        \"output_cost_per_token\":
        0.00000275,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\"\n    },\n    \"replicate/meta/llama-3-8b\": {\n        \"max_tokens\":
        8086,\n        \"max_input_tokens\": 8086,\n        \"max_output_tokens\":
        8086,\n        \"input_cost_per_token\": 0.00000005,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\"\n    },\n    \"replicate/meta/llama-3-8b-instruct\": {\n        \"max_tokens\":
        8086,\n        \"max_input_tokens\": 8086,\n        \"max_output_tokens\":
        8086,\n        \"input_cost_per_token\": 0.00000005,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\"\n    },\n    \"replicate/mistralai/mistral-7b-v0.1\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000005,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\"\n    },\n    \"replicate/mistralai/mistral-7b-instruct-v0.2\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000005,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\"\n    },\n    \"replicate/mistralai/mixtral-8x7b-instruct-v0.1\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000003,\n        \"output_cost_per_token\":
        0.000001,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\"\n    },\n    \"openrouter/deepseek/deepseek-coder\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000014,\n        \"output_cost_per_token\":
        0.00000028,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\"\n    },\n    \"openrouter/microsoft/wizardlm-2-8x22b:nitro\": {\n
        \       \"max_tokens\": 65536,\n        \"input_cost_per_token\": 0.000001,\n
        \       \"output_cost_per_token\": 0.000001,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/google/gemini-pro-1.5\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.0000025,\n
        \       \"output_cost_per_token\": 0.0000075,\n        \"input_cost_per_image\":
        0.00265, \n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true\n    },\n    \"openrouter/mistralai/mixtral-8x22b-instruct\": {\n        \"max_tokens\":
        65536,\n        \"input_cost_per_token\": 0.00000065,\n        \"output_cost_per_token\":
        0.00000065,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\"\n    },\n    \"openrouter/cohere/command-r-plus\": {\n        \"max_tokens\":
        128000,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\"\n    },\n    \"openrouter/databricks/dbrx-instruct\": {\n        \"max_tokens\":
        32768,\n        \"input_cost_per_token\": 0.0000006,\n        \"output_cost_per_token\":
        0.0000006,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\"\n    },\n    \"openrouter/anthropic/claude-3-haiku\": {\n        \"max_tokens\":
        200000,\n        \"input_cost_per_token\": 0.00000025,\n        \"output_cost_per_token\":
        0.00000125,\n        \"input_cost_per_image\": 0.0004, \n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true\n    },\n    \"openrouter/anthropic/claude-3-haiku-20240307\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000025,\n
        \       \"output_cost_per_token\": 0.00000125,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        264\n    },\n    \"openrouter/anthropic/claude-3.5-sonnet\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 159\n    },\n    \"openrouter/anthropic/claude-3-sonnet\":
        {\n        \"max_tokens\": 200000,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"input_cost_per_image\":
        0.0048,  \n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true\n    },\n    \"openrouter/mistralai/mistral-large\": {\n        \"max_tokens\":
        32000,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\"\n    },\n    \"openrouter/cognitivecomputations/dolphin-mixtral-8x7b\":
        {\n        \"max_tokens\": 32769,\n        \"input_cost_per_token\": 0.0000005,\n
        \       \"output_cost_per_token\": 0.0000005,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/google/gemini-pro-vision\":
        {\n        \"max_tokens\": 45875,\n        \"input_cost_per_token\": 0.000000125,\n
        \       \"output_cost_per_token\": 0.000000375,\n        \"input_cost_per_image\":
        0.0025,  \n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true\n    },\n    \"openrouter/fireworks/firellava-13b\": {\n        \"max_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000002,\n        \"output_cost_per_token\":
        0.0000002,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\"\n    },\n    \"openrouter/meta-llama/llama-3-8b-instruct:free\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\"\n    },\n    \"openrouter/meta-llama/llama-3-8b-instruct:extended\":
        {\n        \"max_tokens\": 16384,\n        \"input_cost_per_token\": 0.000000225,\n
        \       \"output_cost_per_token\": 0.00000225,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/meta-llama/llama-3-70b-instruct:nitro\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 0.0000009,\n
        \       \"output_cost_per_token\": 0.0000009,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/meta-llama/llama-3-70b-instruct\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 0.00000059,\n
        \       \"output_cost_per_token\": 0.00000079,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/openai/gpt-4o\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000005,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true\n    },\n    \"openrouter/openai/gpt-4o-2024-05-13\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000005,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true\n    },\n    \"openrouter/openai/gpt-4-vision-preview\":
        {\n        \"max_tokens\": 130000,\n        \"input_cost_per_token\": 0.00001,\n
        \       \"output_cost_per_token\": 0.00003,\n        \"input_cost_per_image\":
        0.01445, \n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true\n    },\n    \"openrouter/openai/gpt-3.5-turbo\": {\n        \"max_tokens\":
        4095,\n        \"input_cost_per_token\": 0.0000015,\n        \"output_cost_per_token\":
        0.000002,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\"\n    },\n    \"openrouter/openai/gpt-3.5-turbo-16k\": {\n        \"max_tokens\":
        16383,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000004,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\"\n    },\n    \"openrouter/openai/gpt-4\": {\n        \"max_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00003,\n        \"output_cost_per_token\":
        0.00006,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\"\n    },\n    \"openrouter/anthropic/claude-instant-v1\": {\n        \"max_tokens\":
        100000,\n        \"max_output_tokens\": 8191,\n        \"input_cost_per_token\":
        0.00000163,\n        \"output_cost_per_token\": 0.00000551,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/anthropic/claude-2\":
        {\n        \"max_tokens\": 100000,\n        \"max_output_tokens\": 8191,\n
        \       \"input_cost_per_token\": 0.00001102,\n        \"output_cost_per_token\":
        0.00003268,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\"\n    },\n    \"openrouter/anthropic/claude-3-opus\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000015,\n        \"output_cost_per_token\":
        0.000075,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 395\n    },\n    \"openrouter/google/palm-2-chat-bison\":
        {\n        \"max_tokens\": 25804,\n        \"input_cost_per_token\": 0.0000005,\n
        \       \"output_cost_per_token\": 0.0000005,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/google/palm-2-codechat-bison\":
        {\n        \"max_tokens\": 20070,\n        \"input_cost_per_token\": 0.0000005,\n
        \       \"output_cost_per_token\": 0.0000005,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/meta-llama/llama-2-13b-chat\":
        {\n        \"max_tokens\": 4096,\n        \"input_cost_per_token\": 0.0000002,\n
        \       \"output_cost_per_token\": 0.0000002,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/meta-llama/llama-2-70b-chat\":
        {\n        \"max_tokens\": 4096,\n        \"input_cost_per_token\": 0.0000015,\n
        \       \"output_cost_per_token\": 0.0000015,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/meta-llama/codellama-34b-instruct\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 0.0000005,\n
        \       \"output_cost_per_token\": 0.0000005,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/nousresearch/nous-hermes-llama2-13b\":
        {\n        \"max_tokens\": 4096,\n        \"input_cost_per_token\": 0.0000002,\n
        \       \"output_cost_per_token\": 0.0000002,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/mancer/weaver\":
        {\n        \"max_tokens\": 8000,\n        \"input_cost_per_token\": 0.000005625,\n
        \       \"output_cost_per_token\": 0.000005625,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/gryphe/mythomax-l2-13b\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 0.000001875,\n
        \       \"output_cost_per_token\": 0.000001875,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/jondurbin/airoboros-l2-70b-2.1\":
        {\n        \"max_tokens\": 4096,\n        \"input_cost_per_token\": 0.000013875,\n
        \       \"output_cost_per_token\": 0.000013875,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/undi95/remm-slerp-l2-13b\":
        {\n        \"max_tokens\": 6144,\n        \"input_cost_per_token\": 0.000001875,\n
        \       \"output_cost_per_token\": 0.000001875,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/pygmalionai/mythalion-13b\":
        {\n        \"max_tokens\": 4096,\n        \"input_cost_per_token\": 0.000001875,\n
        \       \"output_cost_per_token\": 0.000001875,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/mistralai/mistral-7b-instruct\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 0.00000013,\n
        \       \"output_cost_per_token\": 0.00000013,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\"\n    },\n    \"openrouter/mistralai/mistral-7b-instruct:free\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\"\n    },\n    \"j2-ultra\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.000015,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"completion\"\n
        \   },\n    \"j2-mid\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.00001,\n        \"output_cost_per_token\": 0.00001,\n        \"litellm_provider\":
        \"ai21\",\n        \"mode\": \"completion\"\n    },\n    \"j2-light\": {\n
        \       \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000003,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"completion\"\n
        \   },\n    \"dolphin\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        16384,\n        \"max_output_tokens\": 16384,\n        \"input_cost_per_token\":
        0.0000005,\n        \"output_cost_per_token\": 0.0000005,\n        \"litellm_provider\":
        \"nlp_cloud\",\n        \"mode\": \"completion\"\n    },\n    \"chatdolphin\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000005,\n
        \       \"output_cost_per_token\": 0.0000005,\n        \"litellm_provider\":
        \"nlp_cloud\",\n        \"mode\": \"chat\"\n    },\n    \"luminous-base\":
        {\n        \"max_tokens\": 2048, \n        \"input_cost_per_token\": 0.00003,\n
        \       \"output_cost_per_token\": 0.000033,\n        \"litellm_provider\":
        \"aleph_alpha\",\n        \"mode\": \"completion\"\n    },\n    \"luminous-base-control\":
        {\n        \"max_tokens\": 2048, \n        \"input_cost_per_token\": 0.0000375,\n
        \       \"output_cost_per_token\": 0.00004125,\n        \"litellm_provider\":
        \"aleph_alpha\",\n        \"mode\": \"chat\"\n    },\n    \"luminous-extended\":
        {\n        \"max_tokens\": 2048, \n        \"input_cost_per_token\": 0.000045,\n
        \       \"output_cost_per_token\": 0.0000495,\n        \"litellm_provider\":
        \"aleph_alpha\",\n        \"mode\": \"completion\"\n    },\n    \"luminous-extended-control\":
        {\n        \"max_tokens\": 2048, \n        \"input_cost_per_token\": 0.00005625,\n
        \       \"output_cost_per_token\": 0.000061875,\n        \"litellm_provider\":
        \"aleph_alpha\",\n        \"mode\": \"chat\"\n    },\n    \"luminous-supreme\":
        {\n        \"max_tokens\": 2048, \n        \"input_cost_per_token\": 0.000175,\n
        \       \"output_cost_per_token\": 0.0001925,\n        \"litellm_provider\":
        \"aleph_alpha\",\n        \"mode\": \"completion\"\n    },\n    \"luminous-supreme-control\":
        {\n        \"max_tokens\": 2048, \n        \"input_cost_per_token\": 0.00021875,\n
        \       \"output_cost_per_token\": 0.000240625,\n        \"litellm_provider\":
        \"aleph_alpha\",\n        \"mode\": \"chat\"\n    },\n    \"ai21.j2-mid-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 8191, \n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_token\": 0.0000125,\n
        \       \"output_cost_per_token\": 0.0000125,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"ai21.j2-ultra-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 8191, \n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_token\": 0.0000188,\n
        \       \"output_cost_per_token\": 0.0000188,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"amazon.titan-text-lite-v1\":
        {\n        \"max_tokens\": 4000, \n        \"max_input_tokens\": 42000,\n
        \       \"max_output_tokens\": 4000, \n        \"input_cost_per_token\": 0.0000003,\n
        \       \"output_cost_per_token\": 0.0000004,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"amazon.titan-text-express-v1\":
        {\n        \"max_tokens\": 8000, \n        \"max_input_tokens\": 42000,\n
        \       \"max_output_tokens\": 8000, \n        \"input_cost_per_token\": 0.0000013,\n
        \       \"output_cost_per_token\": 0.0000017,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"amazon.titan-embed-text-v1\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"output_vector_size\": 1536,\n        \"input_cost_per_token\": 0.0000001,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"bedrock\",
        \n        \"mode\": \"embedding\"\n    },\n    \"amazon.titan-embed-text-v2:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"output_vector_size\": 1024,\n        \"input_cost_per_token\": 0.0000002,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"bedrock\",
        \n        \"mode\": \"embedding\"\n    },\n    \"mistral.mistral-7b-instruct-v0:2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000015,\n        \"output_cost_per_token\":
        0.0000002,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"mistral.mixtral-8x7b-instruct-v0:1\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000045,\n        \"output_cost_per_token\":
        0.0000007,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"mistral.mistral-large-2402-v1:0\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1\": {\n
        \       \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000045,\n        \"output_cost_per_token\":
        0.0000007,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000045,\n        \"output_cost_per_token\":
        0.0000007,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000059,\n        \"output_cost_per_token\":
        0.00000091,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000015,\n        \"output_cost_per_token\":
        0.0000002,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000015,\n        \"output_cost_per_token\":
        0.0000002,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000002,\n        \"output_cost_per_token\":
        0.00000026,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"bedrock/us-east-1/mistral.mistral-large-2402-v1:0\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/us-west-2/mistral.mistral-large-2402-v1:0\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/eu-west-3/mistral.mistral-large-2402-v1:0\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000104,\n        \"output_cost_per_token\":
        0.0000312,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"anthropic.claude-3-sonnet-20240229-v1:0\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true\n    },\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true\n    },\n    \"anthropic.claude-3-haiku-20240307-v1:0\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000025,\n        \"output_cost_per_token\":
        0.00000125,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true\n    },\n    \"anthropic.claude-3-opus-20240229-v1:0\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000015,\n        \"output_cost_per_token\":
        0.000075,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true\n    },\n    \"anthropic.claude-v1\": {\n        \"max_tokens\": 8191,
        \n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\": 8191,\n
        \       \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/us-east-1/anthropic.claude-v1\": {\n        \"max_tokens\":
        8191, \n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/us-west-2/anthropic.claude-v1\": {\n        \"max_tokens\":
        8191, \n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/ap-northeast-1/anthropic.claude-v1\": {\n        \"max_tokens\":
        8191, \n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0455,\n
        \       \"output_cost_per_second\": 0.0455,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.02527,\n
        \       \"output_cost_per_second\": 0.02527,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.0415,\n        \"output_cost_per_second\": 0.0415,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.02305,\n        \"output_cost_per_second\": 0.02305,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/1-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.0175,\n        \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/6-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.00972,\n        \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-2/1-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.0175,\n        \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-2/6-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.00972,\n        \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-2/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ap-northeast-1/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.0455,\n        \"output_cost_per_second\": 0.0455,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.02527,\n        \"output_cost_per_second\": 0.02527,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.0415,\n        \"output_cost_per_second\": 0.0415,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.02305,\n        \"output_cost_per_second\": 0.02305,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/1-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.0175,\n        \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/6-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.00972,\n        \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-2/1-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.0175,\n        \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-2/6-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.00972,\n        \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-2/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ap-northeast-1/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0455,\n
        \       \"output_cost_per_second\": 0.0455,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.02527,\n
        \       \"output_cost_per_second\": 0.02527,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0415,\n
        \       \"output_cost_per_second\": 0.0415,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.02305,\n
        \       \"output_cost_per_second\": 0.02305,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0175,\n
        \       \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00972,\n
        \       \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0175,\n
        \       \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00972,\n
        \       \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.00000163,\n
        \       \"output_cost_per_token\": 0.00000551,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.0000008,\n
        \       \"output_cost_per_token\": 0.0000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.011,\n
        \       \"output_cost_per_second\": 0.011,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00611,\n
        \       \"output_cost_per_second\": 0.00611,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.011,\n
        \       \"output_cost_per_second\": 0.011,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00611,\n
        \       \"output_cost_per_second\": 0.00611,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-2/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.0000008,\n
        \       \"output_cost_per_token\": 0.0000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ap-northeast-1/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.00000223,\n
        \       \"output_cost_per_token\": 0.00000755,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.01475,\n
        \       \"output_cost_per_second\": 0.01475,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.008194,\n
        \       \"output_cost_per_second\": 0.008194,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.00000248,\n
        \       \"output_cost_per_token\": 0.00000838,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.01635,\n
        \       \"output_cost_per_second\": 0.01635,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.009083,\n
        \       \"output_cost_per_second\": 0.009083,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"cohere.command-text-v14\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.0000015,\n        \"output_cost_per_token\":
        0.0000020,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"bedrock/*/1-month-commitment/cohere.command-text-v14\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_second\": 0.011,\n        \"output_cost_per_second\":
        0.011,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/*/6-month-commitment/cohere.command-text-v14\": {\n
        \       \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_second\": 0.0066027,\n        \"output_cost_per_second\":
        0.0066027,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"cohere.command-light-text-v14\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.0000003,\n        \"output_cost_per_token\":
        0.0000006,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"bedrock/*/1-month-commitment/cohere.command-light-text-v14\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_second\": 0.001902,\n        \"output_cost_per_second\":
        0.001902,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/*/6-month-commitment/cohere.command-light-text-v14\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_second\": 0.0011416,\n        \"output_cost_per_second\":
        0.0011416,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"cohere.command-r-plus-v1:0\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000030,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"cohere.command-r-v1:0\": {\n        \"max_tokens\": 4096, \n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000015,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"cohere.embed-english-v3\": {\n        \"max_tokens\":
        512, \n        \"max_input_tokens\": 512, \n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"embedding\"\n    },\n    \"cohere.embed-multilingual-v3\":
        {\n        \"max_tokens\": 512, \n        \"max_input_tokens\": 512, \n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"embedding\"\n    },\n    \"meta.llama2-13b-chat-v1\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096, \n
        \       \"max_output_tokens\": 4096, \n        \"input_cost_per_token\": 0.00000075,\n
        \       \"output_cost_per_token\": 0.000001,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"meta.llama2-70b-chat-v1\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096, \n
        \       \"max_output_tokens\": 4096, \n        \"input_cost_per_token\": 0.00000195,\n
        \       \"output_cost_per_token\": 0.00000256,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"meta.llama3-8b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.0000004,\n
        \       \"output_cost_per_token\": 0.0000006,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"meta.llama3-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.00000265,\n
        \       \"output_cost_per_token\": 0.0000035,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"512-x-512/50-steps/stability.stable-diffusion-xl-v0\":
        {\n        \"max_tokens\": 77, \n        \"max_input_tokens\": 77, \n        \"output_cost_per_image\":
        0.018,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"512-x-512/max-steps/stability.stable-diffusion-xl-v0\": {\n
        \       \"max_tokens\": 77, \n        \"max_input_tokens\": 77, \n        \"output_cost_per_image\":
        0.036,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"max-x-max/50-steps/stability.stable-diffusion-xl-v0\": {\n        \"max_tokens\":
        77, \n        \"max_input_tokens\": 77, \n        \"output_cost_per_image\":
        0.036,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"max-x-max/max-steps/stability.stable-diffusion-xl-v0\": {\n
        \       \"max_tokens\": 77, \n        \"max_input_tokens\": 77, \n        \"output_cost_per_image\":
        0.072,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"1024-x-1024/50-steps/stability.stable-diffusion-xl-v1\": {\n
        \       \"max_tokens\": 77, \n        \"max_input_tokens\": 77, \n        \"output_cost_per_image\":
        0.04,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"1024-x-1024/max-steps/stability.stable-diffusion-xl-v1\": {\n
        \       \"max_tokens\": 77, \n        \"max_input_tokens\": 77, \n        \"output_cost_per_image\":
        0.08,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-7b\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096, \n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.000,\n        \"output_cost_per_token\":
        0.000,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"completion\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-7b-f\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096, \n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.000,\n        \"output_cost_per_token\":
        0.000,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"chat\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-13b\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096, \n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.000,\n        \"output_cost_per_token\":
        0.000,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"completion\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-13b-f\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096, \n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.000,\n        \"output_cost_per_token\":
        0.000,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"chat\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-70b\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096, \n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.000,\n        \"output_cost_per_token\":
        0.000,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"completion\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-70b-b-f\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096, \n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.000,\n        \"output_cost_per_token\":
        0.000,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"chat\"\n
        \   },\n    \"together-ai-up-to-4b\": {\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.0000001,\n        \"litellm_provider\":
        \"together_ai\"\n    },\n    \"together-ai-4.1b-8b\": {\n        \"input_cost_per_token\":
        0.0000002,\n        \"output_cost_per_token\": 0.0000002,\n        \"litellm_provider\":
        \"together_ai\"\n    },\n    \"together-ai-8.1b-21b\": {\n        \"max_tokens\":
        1000,\n        \"input_cost_per_token\": 0.0000003,\n        \"output_cost_per_token\":
        0.0000003,\n        \"litellm_provider\": \"together_ai\"\n    },\n    \"together-ai-21.1b-41b\":
        {\n        \"input_cost_per_token\": 0.0000008,\n        \"output_cost_per_token\":
        0.0000008,\n        \"litellm_provider\": \"together_ai\"\n    },\n    \"together-ai-41.1b-80b\":
        {\n        \"input_cost_per_token\": 0.0000009,\n        \"output_cost_per_token\":
        0.0000009,\n        \"litellm_provider\": \"together_ai\"\n    },\n    \"together-ai-81.1b-110b\":
        {\n        \"input_cost_per_token\": 0.0000018,\n        \"output_cost_per_token\":
        0.0000018,\n        \"litellm_provider\": \"together_ai\"\n    },\n    \"together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1\":
        {\n        \"input_cost_per_token\": 0.0000006,\n        \"output_cost_per_token\":
        0.0000006,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true\n    },\n    \"together_ai/mistralai/Mistral-7B-Instruct-v0.1\":
        {\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true\n    },\n    \"together_ai/togethercomputer/CodeLlama-34b-Instruct\":
        {\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true\n    },\n    \"ollama/codegemma\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"completion\"\n    },\n    \"ollama/llama2\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096, \n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"completion\"\n
        \   },\n    \"ollama/llama2:13b\": {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\":
        4096, \n        \"max_output_tokens\": 4096, \n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"completion\"\n    },\n    \"ollama/llama2:70b\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096, \n
        \       \"max_output_tokens\": 4096, \n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"completion\"\n    },\n    \"ollama/llama2-uncensored\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096, \n
        \       \"max_output_tokens\": 4096, \n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"completion\"\n    },\n    \"ollama/llama3\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\"\n
        \   },\n    \"ollama/llama3:70b\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"chat\"\n    },\n    \"ollama/mistral\": {\n
        \       \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"completion\"\n
        \   },\n    \"ollama/mistral-7B-Instruct-v0.1\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\"\n
        \   },\n    \"ollama/mistral-7B-Instruct-v0.2\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\"\n
        \   },\n    \"ollama/mixtral-8x7B-Instruct-v0.1\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\"\n
        \   },\n    \"ollama/mixtral-8x22B-Instruct-v0.1\": {\n        \"max_tokens\":
        65536,\n        \"max_input_tokens\": 65536,\n        \"max_output_tokens\":
        65536,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\"\n
        \   },\n    \"ollama/codellama\": {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\":
        4096, \n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"completion\"\n    },\n    \"ollama/orca-mini\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096, \n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"completion\"\n    },\n    \"ollama/vicuna\": {\n        \"max_tokens\":
        2048,\n        \"max_input_tokens\": 2048,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"completion\"\n
        \   },\n    \"deepinfra/lizpreciatior/lzlv_70b_fp16_hf\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000070,\n        \"output_cost_per_token\":
        0.00000090,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/Gryphe/MythoMax-L2-13b\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000022,\n        \"output_cost_per_token\":
        0.00000022,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/mistralai/Mistral-7B-Instruct-v0.1\": {\n
        \       \"max_tokens\": 8191,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000013,\n        \"output_cost_per_token\":
        0.00000013,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/meta-llama/Llama-2-70b-chat-hf\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000070,\n        \"output_cost_per_token\":
        0.00000090,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/cognitivecomputations/dolphin-2.6-mixtral-8x7b\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000027,\n        \"output_cost_per_token\":
        0.00000027,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/codellama/CodeLlama-34b-Instruct-hf\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000060,\n        \"output_cost_per_token\":
        0.00000060,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/deepinfra/mixtral\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000027,\n        \"output_cost_per_token\":
        0.00000027,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"completion\"\n    },\n    \"deepinfra/Phind/Phind-CodeLlama-34B-v2\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000060,\n        \"output_cost_per_token\":
        0.00000060,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000027,\n        \"output_cost_per_token\":
        0.00000027,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/deepinfra/airoboros-70b\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000070,\n        \"output_cost_per_token\":
        0.00000090,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/01-ai/Yi-34B-Chat\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000060,\n        \"output_cost_per_token\":
        0.00000060,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/01-ai/Yi-6B-200K\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000013,\n        \"output_cost_per_token\":
        0.00000013,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"completion\"\n    },\n    \"deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000070,\n        \"output_cost_per_token\":
        0.00000090,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/meta-llama/Llama-2-13b-chat-hf\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000022,\n        \"output_cost_per_token\":
        0.00000022,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/amazon/MistralLite\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000020,\n        \"output_cost_per_token\":
        0.00000020,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/meta-llama/Llama-2-7b-chat-hf\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000013,\n        \"output_cost_per_token\":
        0.00000013,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/meta-llama/Meta-Llama-3-8B-Instruct\": {\n
        \       \"max_tokens\": 8191,\n        \"max_input_tokens\": 8191,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000008,\n        \"output_cost_per_token\":
        0.00000008,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/meta-llama/Meta-Llama-3-70B-Instruct\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 8191,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000059,\n        \"output_cost_per_token\":
        0.00000079,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepinfra/01-ai/Yi-34B-200K\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000060,\n        \"output_cost_per_token\":
        0.00000060,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"completion\"\n    },\n    \"deepinfra/openchat/openchat_3.5\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000013,\n        \"output_cost_per_token\":
        0.00000013,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\"\n    },\n    \"perplexity/codellama-34b-instruct\": { \n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000035, \n        \"output_cost_per_token\":
        0.00000140,  \n        \"litellm_provider\": \"perplexity\", \n        \"mode\":
        \"chat\" \n    },\n    \"perplexity/codellama-70b-instruct\": { \n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000070, \n        \"output_cost_per_token\":
        0.00000280,  \n        \"litellm_provider\": \"perplexity\", \n        \"mode\":
        \"chat\" \n    },\n    \"perplexity/pplx-7b-chat\": { \n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000007, \n        \"output_cost_per_token\":
        0.00000028, \n        \"litellm_provider\": \"perplexity\", \n        \"mode\":
        \"chat\" \n    },\n    \"perplexity/pplx-70b-chat\": {  \n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000070, \n        \"output_cost_per_token\":
        0.00000280, \n        \"litellm_provider\": \"perplexity\", \n        \"mode\":
        \"chat\" \n    },\n    \"perplexity/pplx-7b-online\": { \n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000000, \n        \"output_cost_per_token\":
        0.00000028, \n        \"input_cost_per_request\": 0.005,\n        \"litellm_provider\":
        \"perplexity\", \n        \"mode\": \"chat\" \n    },\n    \"perplexity/pplx-70b-online\":
        { \n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.0000000, \n        \"output_cost_per_token\":
        0.00000280, \n        \"input_cost_per_request\": 0.005,\n        \"litellm_provider\":
        \"perplexity\", \n        \"mode\": \"chat\" \n    },\n    \"perplexity/llama-2-70b-chat\":
        { \n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.00000070, \n        \"output_cost_per_token\":
        0.00000280,\n        \"litellm_provider\": \"perplexity\", \n        \"mode\":
        \"chat\" \n    },\n    \"perplexity/mistral-7b-instruct\": { \n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.00000007,\n        \"output_cost_per_token\":
        0.00000028,\n        \"litellm_provider\": \"perplexity\", \n        \"mode\":
        \"chat\" \n    },\n    \"perplexity/mixtral-8x7b-instruct\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000007,\n        \"output_cost_per_token\":
        0.00000028,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\":
        \"chat\"\n    },\n    \"perplexity/sonar-small-chat\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000007,\n        \"output_cost_per_token\":
        0.00000028,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\":
        \"chat\"\n    },\n    \"perplexity/sonar-small-online\": {\n        \"max_tokens\":
        12000,\n        \"max_input_tokens\": 12000,\n        \"max_output_tokens\":
        12000,\n        \"input_cost_per_token\": 0,\n        \"output_cost_per_token\":
        0.00000028,\n        \"input_cost_per_request\": 0.005,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\"\n    },\n    \"perplexity/sonar-medium-chat\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000006,\n
        \       \"output_cost_per_token\": 0.0000018,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\"\n    },\n    \"perplexity/sonar-medium-online\":
        {\n        \"max_tokens\": 12000,\n        \"max_input_tokens\": 12000,\n
        \       \"max_output_tokens\": 12000,\n        \"input_cost_per_token\": 0,\n
        \       \"output_cost_per_token\": 0.0000018,\n        \"input_cost_per_request\":
        0.005,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\": \"chat\"\n
        \   },\n      \"anyscale/mistralai/Mistral-7B-Instruct-v0.1\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000015, \n        \"output_cost_per_token\":
        0.00000015,\n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"source\":
        \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mistral-7B-Instruct-v0.1\"\n
        \     },\n      \"anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000015, \n        \"output_cost_per_token\":
        0.00000015,\n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"source\":
        \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x7B-Instruct-v0.1\"\n
        \     },\n      \"anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1\": {\n        \"max_tokens\":
        65536,\n        \"max_input_tokens\": 65536,\n        \"max_output_tokens\":
        65536,\n        \"input_cost_per_token\": 0.00000090, \n        \"output_cost_per_token\":
        0.00000090,\n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"source\":
        \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x22B-Instruct-v0.1\"\n
        \     },\n      \"anyscale/HuggingFaceH4/zephyr-7b-beta\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000015, \n        \"output_cost_per_token\":
        0.00000015,\n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\"\n      },\n      \"anyscale/google/gemma-7b-it\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000015, \n        \"output_cost_per_token\":
        0.00000015,\n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\",\n        \"source\": \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/google-gemma-7b-it\"\n
        \     },\n      \"anyscale/meta-llama/Llama-2-7b-chat-hf\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000015, \n        \"output_cost_per_token\":
        0.00000015, \n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\"\n      },\n      \"anyscale/meta-llama/Llama-2-13b-chat-hf\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000025, \n        \"output_cost_per_token\":
        0.00000025, \n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\"\n      },\n      \"anyscale/meta-llama/Llama-2-70b-chat-hf\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000001, \n        \"output_cost_per_token\":
        0.000001, \n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\"\n      },\n      \"anyscale/codellama/CodeLlama-34b-Instruct-hf\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000001, \n        \"output_cost_per_token\":
        0.000001, \n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\"\n      },\n      \"anyscale/codellama/CodeLlama-70b-Instruct-hf\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000001, \n        \"output_cost_per_token\":
        0.000001, \n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\",\n        \"source\" : \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/codellama-CodeLlama-70b-Instruct-hf\"\n
        \     },\n      \"anyscale/meta-llama/Meta-Llama-3-8B-Instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000015, \n        \"output_cost_per_token\":
        0.00000015, \n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\",\n        \"source\": \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-8B-Instruct\"\n
        \     },\n      \"anyscale/meta-llama/Meta-Llama-3-70B-Instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000100, \n        \"output_cost_per_token\":
        0.00000100, \n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\",\n        \"source\" : \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-70B-Instruct\"\n
        \     },\n      \"cloudflare/@cf/meta/llama-2-7b-chat-fp16\": {\n        \"max_tokens\":
        3072, \n        \"max_input_tokens\": 3072, \n        \"max_output_tokens\":
        3072, \n        \"input_cost_per_token\": 0.000001923, \n        \"output_cost_per_token\":
        0.000001923, \n        \"litellm_provider\": \"cloudflare\", \n        \"mode\":
        \"chat\"\n      },\n      \"cloudflare/@cf/meta/llama-2-7b-chat-int8\": {\n
        \       \"max_tokens\": 2048, \n        \"max_input_tokens\": 2048, \n        \"max_output_tokens\":
        2048, \n        \"input_cost_per_token\": 0.000001923, \n        \"output_cost_per_token\":
        0.000001923, \n        \"litellm_provider\": \"cloudflare\", \n        \"mode\":
        \"chat\"\n      },\n      \"cloudflare/@cf/mistral/mistral-7b-instruct-v0.1\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.000001923,
        \n        \"output_cost_per_token\": 0.000001923, \n        \"litellm_provider\":
        \"cloudflare\", \n        \"mode\": \"chat\"\n      },\n      \"cloudflare/@hf/thebloke/codellama-7b-instruct-awq\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096, \n
        \       \"max_output_tokens\": 4096, \n        \"input_cost_per_token\": 0.000001923,
        \n        \"output_cost_per_token\": 0.000001923, \n        \"litellm_provider\":
        \"cloudflare\", \n        \"mode\": \"chat\"\n      },\n      \"voyage/voyage-01\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-lite-01\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-large-2\":
        {\n        \"max_tokens\": 16000,\n        \"max_input_tokens\": 16000,\n
        \       \"input_cost_per_token\": 0.00000012,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"voyage\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"voyage/voyage-law-2\": {\n        \"max_tokens\": 16000,\n        \"max_input_tokens\":
        16000,\n        \"input_cost_per_token\": 0.00000012,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"voyage\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"voyage/voyage-code-2\": {\n        \"max_tokens\": 16000,\n
        \       \"max_input_tokens\": 16000,\n        \"input_cost_per_token\": 0.00000012,\n
        \       \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-2\":
        {\n        \"max_tokens\": 4000,\n        \"max_input_tokens\": 4000,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-lite-02-instruct\":
        {\n        \"max_tokens\": 4000,\n        \"max_input_tokens\": 4000,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"databricks/databricks-dbrx-instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768, \n        \"input_cost_per_token\":
        0.00000075,\n        \"output_cost_per_token\": 0.00000225,\n        \"litellm_provider\":
        \"databricks\",\n        \"mode\": \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\"\n
        \   },\n    \"databricks/databricks-meta-llama-3-70b-instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192, \n        \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000003,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\"\n
        \   },\n    \"databricks/databricks-llama-2-70b-chat\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000015,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\"\n\n
        \   },\n    \"databricks/databricks-mixtral-8x7b-instruct\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.000001,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\"\n
        \   },\n    \"databricks/databricks-mpt-30b-instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192, \n        \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000001,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\"\n
        \   },\n    \"databricks/databricks-mpt-7b-instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192, \n        \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000005,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\"\n
        \   },\n    \"databricks/databricks-bge-large-en\": {\n        \"max_tokens\":
        512,\n        \"max_input_tokens\": 512,\n        \"output_vector_size\":
        1024, \n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"databricks\",\n        \"mode\": \"embedding\",\n
        \       \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\"\n
        \   }\n}\n"
    headers:
      Accept-Ranges:
      - bytes
      Access-Control-Allow-Origin:
      - '*'
      Cache-Control:
      - max-age=300
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Length:
      - '8033'
      Content-Security-Policy:
      - default-src 'none'; style-src 'unsafe-inline'; sandbox
      Content-Type:
      - text/plain; charset=utf-8
      Cross-Origin-Resource-Policy:
      - cross-origin
      Date:
      - Thu, 04 Jul 2024 13:35:14 GMT
      ETag:
      - W/"acdd36963641f3925f59f19bd1cd84563b6134afb3cf9916d3716d467aac36a2"
      Expires:
      - Thu, 04 Jul 2024 13:40:14 GMT
      Source-Age:
      - '43'
      Strict-Transport-Security:
      - max-age=31536000
      Vary:
      - Authorization,Accept-Encoding,Origin
      Via:
      - 1.1 varnish
      X-Cache:
      - HIT
      X-Cache-Hits:
      - '2'
      X-Content-Type-Options:
      - nosniff
      X-Fastly-Request-ID:
      - 54c56ebc2ddcd189f6820a0cf599f313bb58ddf0
      X-Frame-Options:
      - deny
      X-GitHub-Request-Id:
      - EC88:517E5:2BD63A:3882F2:6680CEC7
      X-Served-By:
      - cache-del21745-DEL
      X-Timer:
      - S1720100115.826301,VS0,VE0
      X-XSS-Protection:
      - 1; mode=block
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Hello, I am async context manager!"}],
      "model": "gpt-4o", "stream": true, "stream_options": {"include_usage": true}}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '159'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - AsyncOpenAI/Python 1.29.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.29.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.10.12
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        It"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        sounds"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        like"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        you''re"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        referring"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        the"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        concept"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        of"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        an"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        asynchronous"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        context"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        manager"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        in"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        programming"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        typically"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        found"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        in"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        languages"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        like"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        Python"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"."},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        As"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"ynchronous"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        context"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        managers"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        are"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        useful"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        for"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        managing"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        resources"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        that"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        be"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        setup"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        and"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        cleaned"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        up"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        often"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        in"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        an"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        asynchronous"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        manner"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"."},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        Do"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        you"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        have"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        any"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        specific"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        questions"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        or"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        scenarios"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        you"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        help"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        with"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        regarding"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        async"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        context"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"
        managers"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null}


        data: {"id":"chatcmpl-9hGuBLnRFhXVLuTiQzwiyaGVjHXdw","object":"chat.completion.chunk","created":1720100115,"model":"gpt-4o-2024-05-13","system_fingerprint":"fp_d576307f90","choices":[],"usage":{"prompt_tokens":15,"completion_tokens":66,"total_tokens":81}}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 89df7f5a29467a2e-PAT
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream; charset=utf-8
      Date:
      - Thu, 04 Jul 2024 13:35:16 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=NAFeBRo0QBVk3eRy_e0ioJZRpF2Nxgp_blU7PFppx.E-1720100116-1.0.1.1-1D0C1yEdpcfNLx4lGBACqzYgkxFVNaxnUJzT4g4NGPPj__eF_O5eYvxMonioE4ihacNyC_dh0mtxx3RAu45O9w;
        path=/; expires=Thu, 04-Jul-24 14:05:16 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=FpQThf.yqX9at14ccGPhPNHbbqkegy3lXUNGvFit._E-1720100116361-0.0.1.1-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - wandb
      openai-processing-ms:
      - '304'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '16000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '15999974'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_63fde2bd193a56810d6b9bb0e3e8d037
    status:
      code: 200
      message: OK
version: 1
