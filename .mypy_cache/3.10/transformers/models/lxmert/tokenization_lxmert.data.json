{".class": "MypyFile", "_fullname": "transformers.models.lxmert.tokenization_lxmert", "future_import_flags": [], "is_partial_stub_package": false, "is_stub": false, "names": {".class": "SymbolTable", "BertTokenizer": {".class": "SymbolTableNode", "cross_ref": "transformers.models.bert.tokenization_bert.BertTokenizer", "kind": "Gdef"}, "LxmertTokenizer": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["transformers.models.bert.tokenization_bert.BertTokenizer"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.lxmert.tokenization_lxmert.LxmertTokenizer", "name": "LxmertTokenizer", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.lxmert.tokenization_lxmert.LxmertTokenizer", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.lxmert.tokenization_lxmert", "mro": ["transformers.models.lxmert.tokenization_lxmert.LxmertTokenizer", "transformers.models.bert.tokenization_bert.BertTokenizer", "transformers.tokenization_utils.PreTrainedTokenizer", "transformers.tokenization_utils_base.PreTrainedTokenizerBase", "transformers.tokenization_utils_base.SpecialTokensMixin", "transformers.utils.hub.PushToHubMixin", "builtins.object"], "names": {".class": "SymbolTable", "max_model_input_sizes": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.lxmert.tokenization_lxmert.LxmertTokenizer.max_model_input_sizes", "name": "max_model_input_sizes", "type": null}}, "pretrained_init_configuration": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.lxmert.tokenization_lxmert.LxmertTokenizer.pretrained_init_configuration", "name": "pretrained_init_configuration", "type": {".class": "Instance", "args": ["builtins.str", {".class": "Instance", "args": ["builtins.str", "builtins.bool"], "type_ref": "builtins.dict"}], "type_ref": "builtins.dict"}}}, "pretrained_vocab_files_map": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.lxmert.tokenization_lxmert.LxmertTokenizer.pretrained_vocab_files_map", "name": "pretrained_vocab_files_map", "type": {".class": "Instance", "args": ["builtins.str", {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}], "type_ref": "builtins.dict"}}}, "vocab_files_names": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.lxmert.tokenization_lxmert.LxmertTokenizer.vocab_files_names", "name": "vocab_files_names", "type": {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "PRETRAINED_INIT_CONFIGURATION": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_inferred", "has_explicit_value"], "fullname": "transformers.models.lxmert.tokenization_lxmert.PRETRAINED_INIT_CONFIGURATION", "name": "PRETRAINED_INIT_CONFIGURATION", "type": {".class": "Instance", "args": ["builtins.str", {".class": "Instance", "args": ["builtins.str", "builtins.bool"], "type_ref": "builtins.dict"}], "type_ref": "builtins.dict"}}}, "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_inferred", "has_explicit_value"], "fullname": "transformers.models.lxmert.tokenization_lxmert.PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES", "name": "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES", "type": {".class": "Instance", "args": ["builtins.str", "builtins.int"], "type_ref": "builtins.dict"}}}, "PRETRAINED_VOCAB_FILES_MAP": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_inferred", "has_explicit_value"], "fullname": "transformers.models.lxmert.tokenization_lxmert.PRETRAINED_VOCAB_FILES_MAP", "name": "PRETRAINED_VOCAB_FILES_MAP", "type": {".class": "Instance", "args": ["builtins.str", {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}], "type_ref": "builtins.dict"}}}, "VOCAB_FILES_NAMES": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_inferred", "has_explicit_value"], "fullname": "transformers.models.lxmert.tokenization_lxmert.VOCAB_FILES_NAMES", "name": "VOCAB_FILES_NAMES", "type": {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}}}, "__annotations__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.lxmert.tokenization_lxmert.__annotations__", "name": "__annotations__", "type": {".class": "Instance", "args": ["builtins.str", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.dict"}}}, "__doc__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.lxmert.tokenization_lxmert.__doc__", "name": "__doc__", "type": "builtins.str"}}, "__file__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.lxmert.tokenization_lxmert.__file__", "name": "__file__", "type": "builtins.str"}}, "__name__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.lxmert.tokenization_lxmert.__name__", "name": "__name__", "type": "builtins.str"}}, "__package__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.lxmert.tokenization_lxmert.__package__", "name": "__package__", "type": "builtins.str"}}}, "path": "/home/paperspace/.pyenv/versions/3.10.4/lib/python3.10/site-packages/transformers/models/lxmert/tokenization_lxmert.py"}