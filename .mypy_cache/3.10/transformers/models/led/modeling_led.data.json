{".class": "MypyFile", "_fullname": "transformers.models.led.modeling_led", "future_import_flags": [], "is_partial_stub_package": false, "is_stub": false, "names": {".class": "SymbolTable", "ACT2FN": {".class": "SymbolTableNode", "cross_ref": "transformers.activations.ACT2FN", "kind": "Gdef"}, "BCEWithLogitsLoss": {".class": "SymbolTableNode", "cross_ref": "torch.nn.modules.loss.BCEWithLogitsLoss", "kind": "Gdef"}, "BaseModelOutputWithPastAndCrossAttentions": {".class": "SymbolTableNode", "cross_ref": "transformers.modeling_outputs.BaseModelOutputWithPastAndCrossAttentions", "kind": "Gdef"}, "CrossEntropyLoss": {".class": "SymbolTableNode", "cross_ref": "torch.nn.modules.loss.CrossEntropyLoss", "kind": "Gdef"}, "LEDClassificationHead": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["torch.nn.modules.module.Module"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDClassificationHead", "name": "LEDClassificationHead", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDClassificationHead", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDClassificationHead", "torch.nn.modules.module.Module", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0, 0], "arg_names": ["self", "input_dim", "inner_dim", "num_classes", "pooler_dropout"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDClassificationHead.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 0, 0], "arg_names": ["self", "input_dim", "inner_dim", "num_classes", "pooler_dropout"], "arg_types": ["transformers.models.led.modeling_led.LEDClassificationHead", "builtins.int", "builtins.int", "builtins.int", "builtins.float"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of LEDClassificationHead", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "dense": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDClassificationHead.dense", "name": "dense", "type": "torch.nn.modules.linear.Linear"}}, "dropout": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDClassificationHead.dropout", "name": "dropout", "type": "torch.nn.modules.dropout.Dropout"}}, "forward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "hidden_states"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDClassificationHead.forward", "name": "forward", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "hidden_states"], "arg_types": ["transformers.models.led.modeling_led.LEDClassificationHead", "torch._tensor.Tensor"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "forward of LEDClassificationHead", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "out_proj": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDClassificationHead.out_proj", "name": "out_proj", "type": "torch.nn.modules.linear.Linear"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDConfig": {".class": "SymbolTableNode", "cross_ref": "transformers.models.led.configuration_led.LEDConfig", "kind": "Gdef"}, "LEDDecoder": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["transformers.models.led.modeling_led.LEDPreTrainedModel"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDDecoder", "name": "LEDDecoder", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDDecoder", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDDecoder", "transformers.models.led.modeling_led.LEDPreTrainedModel", "transformers.modeling_utils.PreTrainedModel", "torch.nn.modules.module.Module", "transformers.modeling_utils.ModuleUtilsMixin", "transformers.generation_utils.GenerationMixin", "transformers.utils.hub.PushToHubMixin", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1], "arg_names": ["self", "config", "embed_tokens"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDDecoder.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1], "arg_names": ["self", "config", "embed_tokens"], "arg_types": ["transformers.models.led.modeling_led.LEDDecoder", "transformers.models.led.configuration_led.LEDConfig", {".class": "UnionType", "items": ["torch.nn.modules.sparse.Embedding", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of LEDDecoder", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "dropout": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoder.dropout", "name": "dropout", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "embed_positions": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoder.embed_positions", "name": "embed_positions", "type": "transformers.models.led.modeling_led.LEDLearnedPositionalEmbedding"}}, "embed_tokens": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoder.embed_tokens", "name": "embed_tokens", "type": "torch.nn.modules.sparse.Embedding"}}, "forward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "input_ids", "attention_mask", "global_attention_mask", "encoder_hidden_states", "encoder_attention_mask", "head_mask", "cross_attn_head_mask", "past_key_values", "inputs_embeds", "use_cache", "output_attentions", "output_hidden_states", "return_dict"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDDecoder.forward", "name": "forward", "type": null}}, "gradient_checkpointing": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoder.gradient_checkpointing", "name": "gradient_checkpointing", "type": "builtins.bool"}}, "layerdrop": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoder.layerdrop", "name": "layerdrop", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "layernorm_embedding": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoder.layernorm_embedding", "name": "layernorm_embedding", "type": "torch.nn.modules.normalization.LayerNorm"}}, "layers": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoder.layers", "name": "layers", "type": "torch.nn.modules.container.ModuleList"}}, "max_target_positions": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoder.max_target_positions", "name": "max_target_positions", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "padding_idx": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoder.padding_idx", "name": "padding_idx", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDDecoderAttention": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["torch.nn.modules.module.Module"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDDecoderAttention", "name": "LEDDecoderAttention", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDDecoderAttention", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDDecoderAttention", "torch.nn.modules.module.Module", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 1, 1, 1], "arg_names": ["self", "embed_dim", "num_heads", "dropout", "is_decoder", "bias"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDDecoderAttention.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 1, 1, 1], "arg_names": ["self", "embed_dim", "num_heads", "dropout", "is_decoder", "bias"], "arg_types": ["transformers.models.led.modeling_led.LEDDecoderAttention", "builtins.int", "builtins.int", "builtins.float", "builtins.bool", "builtins.bool"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of LEDDecoderAttention", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_shape": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0], "arg_names": ["self", "tensor", "seq_len", "bsz"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDDecoderAttention._shape", "name": "_shape", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 0], "arg_names": ["self", "tensor", "seq_len", "bsz"], "arg_types": ["transformers.models.led.modeling_led.LEDDecoderAttention", "torch._tensor.Tensor", "builtins.int", "builtins.int"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_shape of LEDDecoderAttention", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "dropout": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderAttention.dropout", "name": "dropout", "type": "builtins.float"}}, "embed_dim": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderAttention.embed_dim", "name": "embed_dim", "type": "builtins.int"}}, "forward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1, 1, 1], "arg_names": ["self", "hidden_states", "key_value_states", "past_key_value", "attention_mask", "layer_head_mask", "output_attentions"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDDecoderAttention.forward", "name": "forward", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1, 1, 1], "arg_names": ["self", "hidden_states", "key_value_states", "past_key_value", "attention_mask", "layer_head_mask", "output_attentions"], "arg_types": ["transformers.models.led.modeling_led.LEDDecoderAttention", "torch._tensor.Tensor", {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._tensor.Tensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, "builtins.bool"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "forward of LEDDecoderAttention", "ret_type": {".class": "TupleType", "implicit": false, "items": ["torch._tensor.Tensor", {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._tensor.Tensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "head_dim": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderAttention.head_dim", "name": "head_dim", "type": "builtins.int"}}, "is_decoder": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderAttention.is_decoder", "name": "is_decoder", "type": "builtins.bool"}}, "k_proj": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderAttention.k_proj", "name": "k_proj", "type": "torch.nn.modules.linear.Linear"}}, "num_heads": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderAttention.num_heads", "name": "num_heads", "type": "builtins.int"}}, "out_proj": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderAttention.out_proj", "name": "out_proj", "type": "torch.nn.modules.linear.Linear"}}, "q_proj": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderAttention.q_proj", "name": "q_proj", "type": "torch.nn.modules.linear.Linear"}}, "scaling": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderAttention.scaling", "name": "scaling", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}}}, "v_proj": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderAttention.v_proj", "name": "v_proj", "type": "torch.nn.modules.linear.Linear"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDDecoderLayer": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["torch.nn.modules.module.Module"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDDecoderLayer", "name": "LEDDecoderLayer", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDDecoderLayer", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDDecoderLayer", "torch.nn.modules.module.Module", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "config"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDDecoderLayer.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "config"], "arg_types": ["transformers.models.led.modeling_led.LEDDecoderLayer", "transformers.models.led.configuration_led.LEDConfig"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of LEDDecoderLayer", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "activation_dropout": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderLayer.activation_dropout", "name": "activation_dropout", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "activation_fn": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderLayer.activation_fn", "name": "activation_fn", "type": "torch.nn.modules.module.Module"}}, "dropout": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderLayer.dropout", "name": "dropout", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "embed_dim": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderLayer.embed_dim", "name": "embed_dim", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "encoder_attn": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderLayer.encoder_attn", "name": "encoder_attn", "type": "transformers.models.led.modeling_led.LEDDecoderAttention"}}, "encoder_attn_layer_norm": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderLayer.encoder_attn_layer_norm", "name": "encoder_attn_layer_norm", "type": "torch.nn.modules.normalization.LayerNorm"}}, "fc1": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderLayer.fc1", "name": "fc1", "type": "torch.nn.modules.linear.Linear"}}, "fc2": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderLayer.fc2", "name": "fc2", "type": "torch.nn.modules.linear.Linear"}}, "final_layer_norm": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderLayer.final_layer_norm", "name": "final_layer_norm", "type": "torch.nn.modules.normalization.LayerNorm"}}, "forward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "hidden_states", "attention_mask", "encoder_hidden_states", "encoder_attention_mask", "layer_head_mask", "cross_attn_layer_head_mask", "past_key_value", "output_attentions", "use_cache"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDDecoderLayer.forward", "name": "forward", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "hidden_states", "attention_mask", "encoder_hidden_states", "encoder_attention_mask", "layer_head_mask", "cross_attn_layer_head_mask", "past_key_value", "output_attentions", "use_cache"], "arg_types": ["transformers.models.led.modeling_led.LEDDecoderLayer", "torch._tensor.Tensor", {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._tensor.Tensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "forward of LEDDecoderLayer", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "self_attn": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderLayer.self_attn", "name": "self_attn", "type": "transformers.models.led.modeling_led.LEDDecoderAttention"}}, "self_attn_layer_norm": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDDecoderLayer.self_attn_layer_norm", "name": "self_attn_layer_norm", "type": "torch.nn.modules.normalization.LayerNorm"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDEncoder": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["transformers.models.led.modeling_led.LEDPreTrainedModel"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDEncoder", "name": "LEDEncoder", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoder", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDEncoder", "transformers.models.led.modeling_led.LEDPreTrainedModel", "transformers.modeling_utils.PreTrainedModel", "torch.nn.modules.module.Module", "transformers.modeling_utils.ModuleUtilsMixin", "transformers.generation_utils.GenerationMixin", "transformers.utils.hub.PushToHubMixin", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1], "arg_names": ["self", "config", "embed_tokens"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoder.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1], "arg_names": ["self", "config", "embed_tokens"], "arg_types": ["transformers.models.led.modeling_led.LEDEncoder", "transformers.models.led.configuration_led.LEDConfig", {".class": "UnionType", "items": ["torch.nn.modules.sparse.Embedding", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of LEDEncoder", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_merge_to_attention_mask": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["self", "attention_mask", "global_attention_mask"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoder._merge_to_attention_mask", "name": "_merge_to_attention_mask", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["self", "attention_mask", "global_attention_mask"], "arg_types": ["transformers.models.led.modeling_led.LEDEncoder", "torch._tensor.Tensor", "torch._tensor.Tensor"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_merge_to_attention_mask of LEDEncoder", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_pad_to_window_size": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0, 0], "arg_names": ["self", "input_ids", "attention_mask", "inputs_embeds", "pad_token_id"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoder._pad_to_window_size", "name": "_pad_to_window_size", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 0, 0], "arg_names": ["self", "input_ids", "attention_mask", "inputs_embeds", "pad_token_id"], "arg_types": ["transformers.models.led.modeling_led.LEDEncoder", "torch._tensor.Tensor", "torch._tensor.Tensor", "torch._tensor.Tensor", "builtins.int"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_pad_to_window_size of LEDEncoder", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "dropout": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoder.dropout", "name": "dropout", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "embed_positions": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoder.embed_positions", "name": "embed_positions", "type": "transformers.models.led.modeling_led.LEDLearnedPositionalEmbedding"}}, "embed_tokens": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoder.embed_tokens", "name": "embed_tokens", "type": "torch.nn.modules.sparse.Embedding"}}, "forward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "input_ids", "attention_mask", "global_attention_mask", "head_mask", "inputs_embeds", "output_attentions", "output_hidden_states", "return_dict"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoder.forward", "name": "forward", "type": null}}, "gradient_checkpointing": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoder.gradient_checkpointing", "name": "gradient_checkpointing", "type": "builtins.bool"}}, "layerdrop": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoder.layerdrop", "name": "layerdrop", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "layernorm_embedding": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoder.layernorm_embedding", "name": "layernorm_embedding", "type": "torch.nn.modules.normalization.LayerNorm"}}, "layers": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoder.layers", "name": "layers", "type": "torch.nn.modules.container.ModuleList"}}, "max_source_positions": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoder.max_source_positions", "name": "max_source_positions", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "padding_idx": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoder.padding_idx", "name": "padding_idx", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDEncoderAttention": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["torch.nn.modules.module.Module"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDEncoderAttention", "name": "LEDEncoderAttention", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderAttention", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDEncoderAttention", "torch.nn.modules.module.Module", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["self", "config", "layer_id"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderAttention.__init__", "name": "__init__", "type": null}}, "forward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "hidden_states", "attention_mask", "layer_head_mask", "is_index_masked", "is_index_global_attn", "is_global_attn", "output_attentions"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderAttention.forward", "name": "forward", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "hidden_states", "attention_mask", "layer_head_mask", "is_index_masked", "is_index_global_attn", "is_global_attn", "output_attentions"], "arg_types": ["transformers.models.led.modeling_led.LEDEncoderAttention", "torch._tensor.Tensor", {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, "builtins.bool"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "forward of LEDEncoderAttention", "ret_type": {".class": "TupleType", "implicit": false, "items": ["torch._tensor.Tensor", {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._tensor.Tensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "longformer_self_attn": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderAttention.longformer_self_attn", "name": "longformer_self_attn", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "output": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderAttention.output", "name": "output", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDEncoderBaseModelOutput": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["transformers.utils.generic.ModelOutput"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDEncoderBaseModelOutput", "name": "LEDEncoderBaseModelOutput", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderBaseModelOutput", "has_param_spec_type": false, "metaclass_type": "abc.ABCMeta", "metadata": {"dataclass": {"attributes": [{"column": 4, "has_default": false, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1176, "name": "last_hidden_state", "type": "torch._C.FloatTensor"}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1177, "name": "hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1178, "name": "attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1179, "name": "global_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}], "frozen": false}, "dataclass_tag": {}}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDEncoderBaseModelOutput", "transformers.utils.generic.ModelOutput", "collections.OrderedDict", "builtins.dict", "typing.MutableMapping", "typing.Mapping", "typing.Collection", "typing.Reversible", "typing.Iterable", "typing.Container", "builtins.object"], "names": {".class": "SymbolTable", "__dataclass_fields__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.led.modeling_led.LEDEncoderBaseModelOutput.__dataclass_fields__", "name": "__dataclass_fields__", "type": {".class": "Instance", "args": ["builtins.str", {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "dataclasses.Field"}], "type_ref": "builtins.dict"}}, "plugin_generated": true}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1], "arg_names": ["self", "last_hidden_state", "hidden_states", "attentions", "global_attentions"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderBaseModelOutput.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1], "arg_names": ["self", "last_hidden_state", "hidden_states", "attentions", "global_attentions"], "arg_types": ["transformers.models.led.modeling_led.LEDEncoderBaseModelOutput", "torch._C.FloatTensor", {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of LEDEncoderBaseModelOutput", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "plugin_generated": true}, "__init__-redefinition": {".class": "SymbolTableNode", "cross_ref": "transformers.models.led.modeling_led.LEDEncoderBaseModelOutput.__init__", "kind": "Mdef", "plugin_generated": true}, "__match_args__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_ready", "allow_incompatible_override"], "fullname": "transformers.models.led.modeling_led.LEDEncoderBaseModelOutput.__match_args__", "name": "__match_args__", "type": {".class": "TupleType", "implicit": false, "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "last_hidden_state"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "hidden_states"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "attentions"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "global_attentions"}], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}}, "plugin_generated": true}, "__match_args__-redefinition": {".class": "SymbolTableNode", "cross_ref": "transformers.models.led.modeling_led.LEDEncoderBaseModelOutput.__match_args__", "kind": "Mdef", "plugin_generated": true}, "attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDEncoderBaseModelOutput.attentions", "name": "attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "global_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDEncoderBaseModelOutput.global_attentions", "name": "global_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "hidden_states": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDEncoderBaseModelOutput.hidden_states", "name": "hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "last_hidden_state": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "transformers.models.led.modeling_led.LEDEncoderBaseModelOutput.last_hidden_state", "name": "last_hidden_state", "type": "torch._C.FloatTensor"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDEncoderLayer": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["torch.nn.modules.module.Module"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDEncoderLayer", "name": "LEDEncoderLayer", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderLayer", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDEncoderLayer", "torch.nn.modules.module.Module", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["self", "config", "layer_id"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderLayer.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["self", "config", "layer_id"], "arg_types": ["transformers.models.led.modeling_led.LEDEncoderLayer", "transformers.models.led.configuration_led.LEDConfig", "builtins.int"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of LEDEncoderLayer", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "activation_dropout": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderLayer.activation_dropout", "name": "activation_dropout", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "activation_fn": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderLayer.activation_fn", "name": "activation_fn", "type": "torch.nn.modules.module.Module"}}, "dropout": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderLayer.dropout", "name": "dropout", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "embed_dim": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderLayer.embed_dim", "name": "embed_dim", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "fc1": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderLayer.fc1", "name": "fc1", "type": "torch.nn.modules.linear.Linear"}}, "fc2": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderLayer.fc2", "name": "fc2", "type": "torch.nn.modules.linear.Linear"}}, "final_layer_norm": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderLayer.final_layer_norm", "name": "final_layer_norm", "type": "torch.nn.modules.normalization.LayerNorm"}}, "forward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0, 1, 1, 1, 1], "arg_names": ["self", "hidden_states", "attention_mask", "layer_head_mask", "is_index_masked", "is_index_global_attn", "is_global_attn", "output_attentions"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderLayer.forward", "name": "forward", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 0, 1, 1, 1, 1], "arg_names": ["self", "hidden_states", "attention_mask", "layer_head_mask", "is_index_masked", "is_index_global_attn", "is_global_attn", "output_attentions"], "arg_types": ["transformers.models.led.modeling_led.LEDEncoderLayer", "torch._tensor.Tensor", "torch._tensor.Tensor", "torch._tensor.Tensor", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "forward of LEDEncoderLayer", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "self_attn": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderLayer.self_attn", "name": "self_attn", "type": "transformers.models.led.modeling_led.LEDEncoderAttention"}}, "self_attn_layer_norm": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderLayer.self_attn_layer_norm", "name": "self_attn_layer_norm", "type": "torch.nn.modules.normalization.LayerNorm"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDEncoderSelfAttention": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["torch.nn.modules.module.Module"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention", "name": "LEDEncoderSelfAttention", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDEncoderSelfAttention", "torch.nn.modules.module.Module", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["self", "config", "layer_id"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention.__init__", "name": "__init__", "type": null}}, "_chunk": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["hidden_states", "window_overlap"], "flags": ["is_static", "is_decorated"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention._chunk", "name": "_chunk", "type": null}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_staticmethod", "is_ready", "is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention._chunk", "name": "_chunk", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["hidden_states", "window_overlap"], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": true, "is_ellipsis_args": false, "name": "_chunk of LEDEncoderSelfAttention", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "_compute_attn_output_with_global_indices": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0, 0, 0], "arg_names": ["self", "value_vectors", "attn_probs", "max_num_global_attn_indices", "is_index_global_attn_nonzero", "is_local_index_global_attn_nonzero"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention._compute_attn_output_with_global_indices", "name": "_compute_attn_output_with_global_indices", "type": null}}, "_compute_global_attn_output_from_hidden": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0, 0, 0, 0, 0], "arg_names": ["self", "hidden_states", "max_num_global_attn_indices", "layer_head_mask", "is_local_index_global_attn_nonzero", "is_index_global_attn_nonzero", "is_local_index_no_global_attn_nonzero", "is_index_masked"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention._compute_global_attn_output_from_hidden", "name": "_compute_global_attn_output_from_hidden", "type": null}}, "_concat_with_global_key_attn_probs": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0, 0, 0, 0], "arg_names": ["self", "key_vectors", "query_vectors", "max_num_global_attn_indices", "is_index_global_attn_nonzero", "is_local_index_global_attn_nonzero", "is_local_index_no_global_attn_nonzero"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention._concat_with_global_key_attn_probs", "name": "_concat_with_global_key_attn_probs", "type": null}}, "_get_global_attn_indices": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["is_index_global_attn"], "flags": ["is_static", "is_decorated"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention._get_global_attn_indices", "name": "_get_global_attn_indices", "type": null}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_staticmethod", "is_ready", "is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention._get_global_attn_indices", "name": "_get_global_attn_indices", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["is_index_global_attn"], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": true, "is_ellipsis_args": false, "name": "_get_global_attn_indices of LEDEncoderSelfAttention", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "_mask_invalid_locations": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["input_tensor", "affected_seq_len"], "flags": ["is_static", "is_decorated"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention._mask_invalid_locations", "name": "_mask_invalid_locations", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["input_tensor", "affected_seq_len"], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_mask_invalid_locations of LEDEncoderSelfAttention", "ret_type": "torch._tensor.Tensor", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_staticmethod", "is_ready", "is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention._mask_invalid_locations", "name": "_mask_invalid_locations", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["input_tensor", "affected_seq_len"], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_mask_invalid_locations of LEDEncoderSelfAttention", "ret_type": "torch._tensor.Tensor", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "_pad_and_diagonalize": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["chunked_hidden_states"], "flags": ["is_static", "is_decorated"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention._pad_and_diagonalize", "name": "_pad_and_diagonalize", "type": null}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_staticmethod", "is_ready", "is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention._pad_and_diagonalize", "name": "_pad_and_diagonalize", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["chunked_hidden_states"], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": true, "is_ellipsis_args": false, "name": "_pad_and_diagonalize of LEDEncoderSelfAttention", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "_pad_and_transpose_last_two_dims": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["hidden_states_padded", "padding"], "flags": ["is_static", "is_decorated"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention._pad_and_transpose_last_two_dims", "name": "_pad_and_transpose_last_two_dims", "type": null}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_staticmethod", "is_ready", "is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention._pad_and_transpose_last_two_dims", "name": "_pad_and_transpose_last_two_dims", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["hidden_states_padded", "padding"], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": true, "is_ellipsis_args": false, "name": "_pad_and_transpose_last_two_dims of LEDEncoderSelfAttention", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "_sliding_chunks_matmul_attn_probs_value": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0], "arg_names": ["self", "attn_probs", "value", "window_overlap"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention._sliding_chunks_matmul_attn_probs_value", "name": "_sliding_chunks_matmul_attn_probs_value", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 0], "arg_names": ["self", "attn_probs", "value", "window_overlap"], "arg_types": ["transformers.models.led.modeling_led.LEDEncoderSelfAttention", "torch._tensor.Tensor", "torch._tensor.Tensor", "builtins.int"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_sliding_chunks_matmul_attn_probs_value of LEDEncoderSelfAttention", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_sliding_chunks_query_key_matmul": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0], "arg_names": ["self", "query", "key", "window_overlap"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention._sliding_chunks_query_key_matmul", "name": "_sliding_chunks_query_key_matmul", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 0], "arg_names": ["self", "query", "key", "window_overlap"], "arg_types": ["transformers.models.led.modeling_led.LEDEncoderSelfAttention", "torch._tensor.Tensor", "torch._tensor.Tensor", "builtins.int"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_sliding_chunks_query_key_matmul of LEDEncoderSelfAttention", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "dropout": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention.dropout", "name": "dropout", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "embed_dim": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention.embed_dim", "name": "embed_dim", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "forward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "hidden_states", "attention_mask", "layer_head_mask", "is_index_masked", "is_index_global_attn", "is_global_attn", "output_attentions"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention.forward", "name": "forward", "type": null}}, "head_dim": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention.head_dim", "name": "head_dim", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "key": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention.key", "name": "key", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "key_global": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention.key_global", "name": "key_global", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "layer_id": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention.layer_id", "name": "layer_id", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "num_heads": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention.num_heads", "name": "num_heads", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "one_sided_attn_window_size": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention.one_sided_attn_window_size", "name": "one_sided_attn_window_size", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "query": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention.query", "name": "query", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "query_global": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention.query_global", "name": "query_global", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "value": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention.value", "name": "value", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "value_global": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDEncoderSelfAttention.value_global", "name": "value_global", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDForConditionalGeneration": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["transformers.models.led.modeling_led.LEDPreTrainedModel"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration", "name": "LEDForConditionalGeneration", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDForConditionalGeneration", "transformers.models.led.modeling_led.LEDPreTrainedModel", "transformers.modeling_utils.PreTrainedModel", "torch.nn.modules.module.Module", "transformers.modeling_utils.ModuleUtilsMixin", "transformers.generation_utils.GenerationMixin", "transformers.utils.hub.PushToHubMixin", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "config"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "config"], "arg_types": ["transformers.models.led.modeling_led.LEDForConditionalGeneration", "transformers.models.led.configuration_led.LEDConfig"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of LEDForConditionalGeneration", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_keys_to_ignore_on_load_missing": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration._keys_to_ignore_on_load_missing", "name": "_keys_to_ignore_on_load_missing", "type": null}}, "_reorder_cache": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["past", "beam_idx"], "flags": ["is_static", "is_decorated"], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration._reorder_cache", "name": "_reorder_cache", "type": null}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_staticmethod", "is_ready", "is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration._reorder_cache", "name": "_reorder_cache", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["past", "beam_idx"], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": true, "is_ellipsis_args": false, "name": "_reorder_cache of LEDForConditionalGeneration", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "_resize_final_logits_bias": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "new_num_tokens"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration._resize_final_logits_bias", "name": "_resize_final_logits_bias", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "new_num_tokens"], "arg_types": ["transformers.models.led.modeling_led.LEDForConditionalGeneration", "builtins.int"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_resize_final_logits_bias of LEDForConditionalGeneration", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "base_model_prefix": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration.base_model_prefix", "name": "base_model_prefix", "type": "builtins.str"}}, "forward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "input_ids", "attention_mask", "decoder_input_ids", "decoder_attention_mask", "head_mask", "decoder_head_mask", "cross_attn_head_mask", "encoder_outputs", "global_attention_mask", "past_key_values", "inputs_embeds", "decoder_inputs_embeds", "labels", "use_cache", "output_attentions", "output_hidden_states", "return_dict"], "flags": ["is_decorated"], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration.forward", "name": "forward", "type": {".class": "CallableType", "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "input_ids", "attention_mask", "decoder_input_ids", "decoder_attention_mask", "head_mask", "decoder_head_mask", "cross_attn_head_mask", "encoder_outputs", "global_attention_mask", "past_key_values", "inputs_embeds", "decoder_inputs_embeds", "labels", "use_cache", "output_attentions", "output_hidden_states", "return_dict"], "arg_types": ["transformers.models.led.modeling_led.LEDForConditionalGeneration", {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "forward of LEDForConditionalGeneration", "ret_type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._tensor.Tensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput"]}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration.forward", "name": "forward", "type": {".class": "AnyType", "missing_import_name": null, "source_any": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_of_any": 7}}}}, "get_decoder": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration.get_decoder", "name": "get_decoder", "type": null}}, "get_encoder": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration.get_encoder", "name": "get_encoder", "type": null}}, "get_output_embeddings": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration.get_output_embeddings", "name": "get_output_embeddings", "type": null}}, "led": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration.led", "name": "led", "type": "transformers.models.led.modeling_led.LEDModel"}}, "lm_head": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration.lm_head", "name": "lm_head", "type": "torch.nn.modules.linear.Linear"}}, "prepare_decoder_input_ids_from_labels": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "labels"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration.prepare_decoder_input_ids_from_labels", "name": "prepare_decoder_input_ids_from_labels", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "labels"], "arg_types": ["transformers.models.led.modeling_led.LEDForConditionalGeneration", "torch._tensor.Tensor"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "prepare_decoder_input_ids_from_labels of LEDForConditionalGeneration", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "prepare_inputs_for_generation": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 4], "arg_names": ["self", "decoder_input_ids", "past", "attention_mask", "global_attention_mask", "head_mask", "decoder_head_mask", "cross_attn_head_mask", "use_cache", "encoder_outputs", "kwargs"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration.prepare_inputs_for_generation", "name": "prepare_inputs_for_generation", "type": null}}, "resize_token_embeddings": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "new_num_tokens"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration.resize_token_embeddings", "name": "resize_token_embeddings", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "new_num_tokens"], "arg_types": ["transformers.models.led.modeling_led.LEDForConditionalGeneration", "builtins.int"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "resize_token_embeddings of LEDForConditionalGeneration", "ret_type": "torch.nn.modules.sparse.Embedding", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "set_output_embeddings": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "new_embeddings"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDForConditionalGeneration.set_output_embeddings", "name": "set_output_embeddings", "type": null}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDForQuestionAnswering": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["transformers.models.led.modeling_led.LEDPreTrainedModel"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDForQuestionAnswering", "name": "LEDForQuestionAnswering", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDForQuestionAnswering", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDForQuestionAnswering", "transformers.models.led.modeling_led.LEDPreTrainedModel", "transformers.modeling_utils.PreTrainedModel", "torch.nn.modules.module.Module", "transformers.modeling_utils.ModuleUtilsMixin", "transformers.generation_utils.GenerationMixin", "transformers.utils.hub.PushToHubMixin", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "config"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDForQuestionAnswering.__init__", "name": "__init__", "type": null}}, "forward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "input_ids", "attention_mask", "decoder_input_ids", "decoder_attention_mask", "head_mask", "decoder_head_mask", "cross_attn_head_mask", "encoder_outputs", "global_attention_mask", "start_positions", "end_positions", "inputs_embeds", "decoder_inputs_embeds", "use_cache", "output_attentions", "output_hidden_states", "return_dict"], "flags": ["is_decorated"], "fullname": "transformers.models.led.modeling_led.LEDForQuestionAnswering.forward", "name": "forward", "type": {".class": "CallableType", "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "input_ids", "attention_mask", "decoder_input_ids", "decoder_attention_mask", "head_mask", "decoder_head_mask", "cross_attn_head_mask", "encoder_outputs", "global_attention_mask", "start_positions", "end_positions", "inputs_embeds", "decoder_inputs_embeds", "use_cache", "output_attentions", "output_hidden_states", "return_dict"], "arg_types": ["transformers.models.led.modeling_led.LEDForQuestionAnswering", {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "forward of LEDForQuestionAnswering", "ret_type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._tensor.Tensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput"]}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDForQuestionAnswering.forward", "name": "forward", "type": {".class": "AnyType", "missing_import_name": null, "source_any": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_of_any": 7}}}}, "led": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDForQuestionAnswering.led", "name": "led", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "num_labels": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDForQuestionAnswering.num_labels", "name": "num_labels", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "qa_outputs": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDForQuestionAnswering.qa_outputs", "name": "qa_outputs", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDForSequenceClassification": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["transformers.models.led.modeling_led.LEDPreTrainedModel"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDForSequenceClassification", "name": "LEDForSequenceClassification", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDForSequenceClassification", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDForSequenceClassification", "transformers.models.led.modeling_led.LEDPreTrainedModel", "transformers.modeling_utils.PreTrainedModel", "torch.nn.modules.module.Module", "transformers.modeling_utils.ModuleUtilsMixin", "transformers.generation_utils.GenerationMixin", "transformers.utils.hub.PushToHubMixin", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 4], "arg_names": ["self", "config", "kwargs"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDForSequenceClassification.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0, 4], "arg_names": ["self", "config", "kwargs"], "arg_types": ["transformers.models.led.modeling_led.LEDForSequenceClassification", "transformers.models.led.configuration_led.LEDConfig", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of LEDForSequenceClassification", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "classification_head": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDForSequenceClassification.classification_head", "name": "classification_head", "type": "transformers.models.led.modeling_led.LEDClassificationHead"}}, "forward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "input_ids", "attention_mask", "decoder_input_ids", "decoder_attention_mask", "head_mask", "decoder_head_mask", "cross_attn_head_mask", "encoder_outputs", "global_attention_mask", "inputs_embeds", "decoder_inputs_embeds", "labels", "use_cache", "output_attentions", "output_hidden_states", "return_dict"], "flags": ["is_decorated"], "fullname": "transformers.models.led.modeling_led.LEDForSequenceClassification.forward", "name": "forward", "type": {".class": "CallableType", "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "input_ids", "attention_mask", "decoder_input_ids", "decoder_attention_mask", "head_mask", "decoder_head_mask", "cross_attn_head_mask", "encoder_outputs", "global_attention_mask", "inputs_embeds", "decoder_inputs_embeds", "labels", "use_cache", "output_attentions", "output_hidden_states", "return_dict"], "arg_types": ["transformers.models.led.modeling_led.LEDForSequenceClassification", {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "forward of LEDForSequenceClassification", "ret_type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._tensor.Tensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput"]}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDForSequenceClassification.forward", "name": "forward", "type": {".class": "AnyType", "missing_import_name": null, "source_any": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_of_any": 7}}}}, "led": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDForSequenceClassification.led", "name": "led", "type": "transformers.models.led.modeling_led.LEDModel"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDLearnedPositionalEmbedding": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["torch.nn.modules.sparse.Embedding"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDLearnedPositionalEmbedding", "name": "LEDLearnedPositionalEmbedding", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDLearnedPositionalEmbedding", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDLearnedPositionalEmbedding", "torch.nn.modules.sparse.Embedding", "torch.nn.modules.module.Module", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["self", "num_embeddings", "embedding_dim"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDLearnedPositionalEmbedding.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["self", "num_embeddings", "embedding_dim"], "arg_types": ["transformers.models.led.modeling_led.LEDLearnedPositionalEmbedding", "builtins.int", "builtins.int"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of LEDLearnedPositionalEmbedding", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "forward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1], "arg_names": ["self", "input_ids_shape", "past_key_values_length"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDLearnedPositionalEmbedding.forward", "name": "forward", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1], "arg_names": ["self", "input_ids_shape", "past_key_values_length"], "arg_types": ["transformers.models.led.modeling_led.LEDLearnedPositionalEmbedding", "torch._C.Size", "builtins.int"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "forward of LEDLearnedPositionalEmbedding", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDModel": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["transformers.models.led.modeling_led.LEDPreTrainedModel"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDModel", "name": "LEDModel", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDModel", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDModel", "transformers.models.led.modeling_led.LEDPreTrainedModel", "transformers.modeling_utils.PreTrainedModel", "torch.nn.modules.module.Module", "transformers.modeling_utils.ModuleUtilsMixin", "transformers.generation_utils.GenerationMixin", "transformers.utils.hub.PushToHubMixin", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "config"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDModel.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "config"], "arg_types": ["transformers.models.led.modeling_led.LEDModel", "transformers.models.led.configuration_led.LEDConfig"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of LEDModel", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "decoder": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDModel.decoder", "name": "decoder", "type": "transformers.models.led.modeling_led.LEDDecoder"}}, "encoder": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDModel.encoder", "name": "encoder", "type": "transformers.models.led.modeling_led.LEDEncoder"}}, "forward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "input_ids", "attention_mask", "decoder_input_ids", "decoder_attention_mask", "head_mask", "decoder_head_mask", "cross_attn_head_mask", "encoder_outputs", "global_attention_mask", "past_key_values", "inputs_embeds", "decoder_inputs_embeds", "use_cache", "output_attentions", "output_hidden_states", "return_dict"], "flags": ["is_decorated"], "fullname": "transformers.models.led.modeling_led.LEDModel.forward", "name": "forward", "type": {".class": "CallableType", "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "input_ids", "attention_mask", "decoder_input_ids", "decoder_attention_mask", "head_mask", "decoder_head_mask", "cross_attn_head_mask", "encoder_outputs", "global_attention_mask", "past_key_values", "inputs_embeds", "decoder_inputs_embeds", "use_cache", "output_attentions", "output_hidden_states", "return_dict"], "arg_types": ["transformers.models.led.modeling_led.LEDModel", {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.LongTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._tensor.Tensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "forward of LEDModel", "ret_type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._tensor.Tensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput"]}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDModel.forward", "name": "forward", "type": {".class": "AnyType", "missing_import_name": null, "source_any": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_of_any": 7}}}}, "get_decoder": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDModel.get_decoder", "name": "get_decoder", "type": null}}, "get_encoder": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDModel.get_encoder", "name": "get_encoder", "type": null}}, "get_input_embeddings": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDModel.get_input_embeddings", "name": "get_input_embeddings", "type": null}}, "set_input_embeddings": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "value"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDModel.set_input_embeddings", "name": "set_input_embeddings", "type": null}}, "shared": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDModel.shared", "name": "shared", "type": "torch.nn.modules.sparse.Embedding"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDPreTrainedModel": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["transformers.modeling_utils.PreTrainedModel"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDPreTrainedModel", "name": "LEDPreTrainedModel", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDPreTrainedModel", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDPreTrainedModel", "transformers.modeling_utils.PreTrainedModel", "torch.nn.modules.module.Module", "transformers.modeling_utils.ModuleUtilsMixin", "transformers.generation_utils.GenerationMixin", "transformers.utils.hub.PushToHubMixin", "builtins.object"], "names": {".class": "SymbolTable", "_init_weights": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "module"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDPreTrainedModel._init_weights", "name": "_init_weights", "type": null}}, "_set_gradient_checkpointing": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1], "arg_names": ["self", "module", "value"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDPreTrainedModel._set_gradient_checkpointing", "name": "_set_gradient_checkpointing", "type": null}}, "base_model_prefix": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDPreTrainedModel.base_model_prefix", "name": "base_model_prefix", "type": "builtins.str"}}, "config_class": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDPreTrainedModel.config_class", "name": "config_class", "type": null}}, "dummy_inputs": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "transformers.models.led.modeling_led.LEDPreTrainedModel.dummy_inputs", "name": "dummy_inputs", "type": null}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "transformers.models.led.modeling_led.LEDPreTrainedModel.dummy_inputs", "name": "dummy_inputs", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["transformers.models.led.modeling_led.LEDPreTrainedModel"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": true, "is_ellipsis_args": false, "name": "dummy_inputs of LEDPreTrainedModel", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "supports_gradient_checkpointing": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDPreTrainedModel.supports_gradient_checkpointing", "name": "supports_gradient_checkpointing", "type": "builtins.bool"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDSeq2SeqLMOutput": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["transformers.utils.generic.ModelOutput"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput", "name": "LEDSeq2SeqLMOutput", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput", "has_param_spec_type": false, "metaclass_type": "abc.ABCMeta", "metadata": {"dataclass": {"attributes": [{"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1305, "name": "loss", "type": {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1306, "name": "logits", "type": "torch._C.FloatTensor"}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1307, "name": "past_key_values", "type": {".class": "UnionType", "items": [{".class": "Instance", "args": ["torch._C.FloatTensor"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1308, "name": "decoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1309, "name": "decoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1310, "name": "cross_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1311, "name": "encoder_last_hidden_state", "type": {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1312, "name": "encoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1313, "name": "encoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1314, "name": "encoder_global_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}], "frozen": false}, "dataclass_tag": {}}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDSeq2SeqLMOutput", "transformers.utils.generic.ModelOutput", "collections.OrderedDict", "builtins.dict", "typing.MutableMapping", "typing.Mapping", "typing.Collection", "typing.Reversible", "typing.Iterable", "typing.Container", "builtins.object"], "names": {".class": "SymbolTable", "__dataclass_fields__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput.__dataclass_fields__", "name": "__dataclass_fields__", "type": {".class": "Instance", "args": ["builtins.str", {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "dataclasses.Field"}], "type_ref": "builtins.dict"}}, "plugin_generated": true}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "loss", "logits", "past_key_values", "decoder_hidden_states", "decoder_attentions", "cross_attentions", "encoder_last_hidden_state", "encoder_hidden_states", "encoder_attentions", "encoder_global_attentions"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "loss", "logits", "past_key_values", "decoder_hidden_states", "decoder_attentions", "cross_attentions", "encoder_last_hidden_state", "encoder_hidden_states", "encoder_attentions", "encoder_global_attentions"], "arg_types": ["transformers.models.led.modeling_led.LEDSeq2SeqLMOutput", {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, "torch._C.FloatTensor", {".class": "UnionType", "items": [{".class": "Instance", "args": ["torch._C.FloatTensor"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of LEDSeq2SeqLMOutput", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "plugin_generated": true}, "__init__-redefinition": {".class": "SymbolTableNode", "cross_ref": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput.__init__", "kind": "Mdef", "plugin_generated": true}, "__match_args__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_ready", "allow_incompatible_override"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput.__match_args__", "name": "__match_args__", "type": {".class": "TupleType", "implicit": false, "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "loss"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "logits"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "past_key_values"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "decoder_hidden_states"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "decoder_attentions"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "cross_attentions"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_last_hidden_state"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_hidden_states"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_attentions"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_global_attentions"}], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}}, "plugin_generated": true}, "__match_args__-redefinition": {".class": "SymbolTableNode", "cross_ref": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput.__match_args__", "kind": "Mdef", "plugin_generated": true}, "cross_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput.cross_attentions", "name": "cross_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "decoder_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput.decoder_attentions", "name": "decoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "decoder_hidden_states": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput.decoder_hidden_states", "name": "decoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput.encoder_attentions", "name": "encoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_global_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput.encoder_global_attentions", "name": "encoder_global_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_hidden_states": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput.encoder_hidden_states", "name": "encoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_last_hidden_state": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput.encoder_last_hidden_state", "name": "encoder_last_hidden_state", "type": {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}}}, "logits": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput.logits", "name": "logits", "type": "torch._C.FloatTensor"}}, "loss": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput.loss", "name": "loss", "type": {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}}}, "past_key_values": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqLMOutput.past_key_values", "name": "past_key_values", "type": {".class": "UnionType", "items": [{".class": "Instance", "args": ["torch._C.FloatTensor"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDSeq2SeqModelOutput": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["transformers.utils.generic.ModelOutput"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput", "name": "LEDSeq2SeqModelOutput", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput", "has_param_spec_type": false, "metaclass_type": "abc.ABCMeta", "metadata": {"dataclass": {"attributes": [{"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1239, "name": "last_hidden_state", "type": "torch._C.FloatTensor"}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1240, "name": "past_key_values", "type": {".class": "UnionType", "items": [{".class": "Instance", "args": ["torch._C.FloatTensor"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1241, "name": "decoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1242, "name": "decoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1243, "name": "cross_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1244, "name": "encoder_last_hidden_state", "type": {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1245, "name": "encoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1246, "name": "encoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1247, "name": "encoder_global_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}], "frozen": false}, "dataclass_tag": {}}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDSeq2SeqModelOutput", "transformers.utils.generic.ModelOutput", "collections.OrderedDict", "builtins.dict", "typing.MutableMapping", "typing.Mapping", "typing.Collection", "typing.Reversible", "typing.Iterable", "typing.Container", "builtins.object"], "names": {".class": "SymbolTable", "__dataclass_fields__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput.__dataclass_fields__", "name": "__dataclass_fields__", "type": {".class": "Instance", "args": ["builtins.str", {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "dataclasses.Field"}], "type_ref": "builtins.dict"}}, "plugin_generated": true}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "last_hidden_state", "past_key_values", "decoder_hidden_states", "decoder_attentions", "cross_attentions", "encoder_last_hidden_state", "encoder_hidden_states", "encoder_attentions", "encoder_global_attentions"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "last_hidden_state", "past_key_values", "decoder_hidden_states", "decoder_attentions", "cross_attentions", "encoder_last_hidden_state", "encoder_hidden_states", "encoder_attentions", "encoder_global_attentions"], "arg_types": ["transformers.models.led.modeling_led.LEDSeq2SeqModelOutput", "torch._C.FloatTensor", {".class": "UnionType", "items": [{".class": "Instance", "args": ["torch._C.FloatTensor"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of LEDSeq2SeqModelOutput", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "plugin_generated": true}, "__init__-redefinition": {".class": "SymbolTableNode", "cross_ref": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput.__init__", "kind": "Mdef", "plugin_generated": true}, "__match_args__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_ready", "allow_incompatible_override"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput.__match_args__", "name": "__match_args__", "type": {".class": "TupleType", "implicit": false, "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "last_hidden_state"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "past_key_values"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "decoder_hidden_states"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "decoder_attentions"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "cross_attentions"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_last_hidden_state"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_hidden_states"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_attentions"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_global_attentions"}], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}}, "plugin_generated": true}, "__match_args__-redefinition": {".class": "SymbolTableNode", "cross_ref": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput.__match_args__", "kind": "Mdef", "plugin_generated": true}, "cross_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput.cross_attentions", "name": "cross_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "decoder_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput.decoder_attentions", "name": "decoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "decoder_hidden_states": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput.decoder_hidden_states", "name": "decoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput.encoder_attentions", "name": "encoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_global_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput.encoder_global_attentions", "name": "encoder_global_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_hidden_states": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput.encoder_hidden_states", "name": "encoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_last_hidden_state": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput.encoder_last_hidden_state", "name": "encoder_last_hidden_state", "type": {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}}}, "last_hidden_state": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput.last_hidden_state", "name": "last_hidden_state", "type": "torch._C.FloatTensor"}}, "past_key_values": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqModelOutput.past_key_values", "name": "past_key_values", "type": {".class": "UnionType", "items": [{".class": "Instance", "args": ["torch._C.FloatTensor"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDSeq2SeqQuestionAnsweringModelOutput": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["transformers.utils.generic.ModelOutput"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput", "name": "LEDSeq2SeqQuestionAnsweringModelOutput", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput", "has_param_spec_type": false, "metaclass_type": "abc.ABCMeta", "metadata": {"dataclass": {"attributes": [{"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1441, "name": "loss", "type": {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1442, "name": "start_logits", "type": "torch._C.FloatTensor"}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1443, "name": "end_logits", "type": "torch._C.FloatTensor"}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1444, "name": "past_key_values", "type": {".class": "UnionType", "items": [{".class": "Instance", "args": ["torch._C.FloatTensor"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1445, "name": "decoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1446, "name": "decoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1447, "name": "cross_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1448, "name": "encoder_last_hidden_state", "type": {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1449, "name": "encoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1450, "name": "encoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1451, "name": "encoder_global_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}], "frozen": false}, "dataclass_tag": {}}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput", "transformers.utils.generic.ModelOutput", "collections.OrderedDict", "builtins.dict", "typing.MutableMapping", "typing.Mapping", "typing.Collection", "typing.Reversible", "typing.Iterable", "typing.Container", "builtins.object"], "names": {".class": "SymbolTable", "__dataclass_fields__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.__dataclass_fields__", "name": "__dataclass_fields__", "type": {".class": "Instance", "args": ["builtins.str", {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "dataclasses.Field"}], "type_ref": "builtins.dict"}}, "plugin_generated": true}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "loss", "start_logits", "end_logits", "past_key_values", "decoder_hidden_states", "decoder_attentions", "cross_attentions", "encoder_last_hidden_state", "encoder_hidden_states", "encoder_attentions", "encoder_global_attentions"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "loss", "start_logits", "end_logits", "past_key_values", "decoder_hidden_states", "decoder_attentions", "cross_attentions", "encoder_last_hidden_state", "encoder_hidden_states", "encoder_attentions", "encoder_global_attentions"], "arg_types": ["transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput", {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, "torch._C.FloatTensor", "torch._C.FloatTensor", {".class": "UnionType", "items": [{".class": "Instance", "args": ["torch._C.FloatTensor"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of LEDSeq2SeqQuestionAnsweringModelOutput", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "plugin_generated": true}, "__init__-redefinition": {".class": "SymbolTableNode", "cross_ref": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.__init__", "kind": "Mdef", "plugin_generated": true}, "__match_args__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_ready", "allow_incompatible_override"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.__match_args__", "name": "__match_args__", "type": {".class": "TupleType", "implicit": false, "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "loss"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "start_logits"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "end_logits"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "past_key_values"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "decoder_hidden_states"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "decoder_attentions"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "cross_attentions"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_last_hidden_state"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_hidden_states"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_attentions"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_global_attentions"}], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}}, "plugin_generated": true}, "__match_args__-redefinition": {".class": "SymbolTableNode", "cross_ref": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.__match_args__", "kind": "Mdef", "plugin_generated": true}, "cross_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.cross_attentions", "name": "cross_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "decoder_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.decoder_attentions", "name": "decoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "decoder_hidden_states": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.decoder_hidden_states", "name": "decoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.encoder_attentions", "name": "encoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_global_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.encoder_global_attentions", "name": "encoder_global_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_hidden_states": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.encoder_hidden_states", "name": "encoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_last_hidden_state": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.encoder_last_hidden_state", "name": "encoder_last_hidden_state", "type": {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}}}, "end_logits": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.end_logits", "name": "end_logits", "type": "torch._C.FloatTensor"}}, "loss": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.loss", "name": "loss", "type": {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}}}, "past_key_values": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.past_key_values", "name": "past_key_values", "type": {".class": "UnionType", "items": [{".class": "Instance", "args": ["torch._C.FloatTensor"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}}}, "start_logits": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqQuestionAnsweringModelOutput.start_logits", "name": "start_logits", "type": "torch._C.FloatTensor"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LEDSeq2SeqSequenceClassifierOutput": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["transformers.utils.generic.ModelOutput"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput", "name": "LEDSeq2SeqSequenceClassifierOutput", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput", "has_param_spec_type": false, "metaclass_type": "abc.ABCMeta", "metadata": {"dataclass": {"attributes": [{"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1372, "name": "loss", "type": {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1373, "name": "logits", "type": "torch._C.FloatTensor"}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1374, "name": "past_key_values", "type": {".class": "UnionType", "items": [{".class": "Instance", "args": ["torch._C.FloatTensor"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1375, "name": "decoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1376, "name": "decoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1377, "name": "cross_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1378, "name": "encoder_last_hidden_state", "type": {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1379, "name": "encoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1380, "name": "encoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}, {"column": 4, "has_default": true, "is_in_init": true, "is_init_var": false, "kw_only": false, "line": 1381, "name": "encoder_global_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}], "frozen": false}, "dataclass_tag": {}}, "module_name": "transformers.models.led.modeling_led", "mro": ["transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput", "transformers.utils.generic.ModelOutput", "collections.OrderedDict", "builtins.dict", "typing.MutableMapping", "typing.Mapping", "typing.Collection", "typing.Reversible", "typing.Iterable", "typing.Container", "builtins.object"], "names": {".class": "SymbolTable", "__dataclass_fields__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput.__dataclass_fields__", "name": "__dataclass_fields__", "type": {".class": "Instance", "args": ["builtins.str", {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "dataclasses.Field"}], "type_ref": "builtins.dict"}}, "plugin_generated": true}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "loss", "logits", "past_key_values", "decoder_hidden_states", "decoder_attentions", "cross_attentions", "encoder_last_hidden_state", "encoder_hidden_states", "encoder_attentions", "encoder_global_attentions"], "flags": [], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "loss", "logits", "past_key_values", "decoder_hidden_states", "decoder_attentions", "cross_attentions", "encoder_last_hidden_state", "encoder_hidden_states", "encoder_attentions", "encoder_global_attentions"], "arg_types": ["transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput", {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, "torch._C.FloatTensor", {".class": "UnionType", "items": [{".class": "Instance", "args": ["torch._C.FloatTensor"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of LEDSeq2SeqSequenceClassifierOutput", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "plugin_generated": true}, "__init__-redefinition": {".class": "SymbolTableNode", "cross_ref": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput.__init__", "kind": "Mdef", "plugin_generated": true}, "__match_args__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_ready", "allow_incompatible_override"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput.__match_args__", "name": "__match_args__", "type": {".class": "TupleType", "implicit": false, "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "loss"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "logits"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "past_key_values"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "decoder_hidden_states"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "decoder_attentions"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "cross_attentions"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_last_hidden_state"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_hidden_states"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_attentions"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "encoder_global_attentions"}], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}}, "plugin_generated": true}, "__match_args__-redefinition": {".class": "SymbolTableNode", "cross_ref": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput.__match_args__", "kind": "Mdef", "plugin_generated": true}, "cross_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput.cross_attentions", "name": "cross_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "decoder_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput.decoder_attentions", "name": "decoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "decoder_hidden_states": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput.decoder_hidden_states", "name": "decoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput.encoder_attentions", "name": "encoder_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_global_attentions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput.encoder_global_attentions", "name": "encoder_global_attentions", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_hidden_states": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput.encoder_hidden_states", "name": "encoder_hidden_states", "type": {".class": "UnionType", "items": [{".class": "TupleType", "implicit": false, "items": ["torch._C.FloatTensor"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, {".class": "NoneType"}]}}}, "encoder_last_hidden_state": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput.encoder_last_hidden_state", "name": "encoder_last_hidden_state", "type": {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}}}, "logits": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput.logits", "name": "logits", "type": "torch._C.FloatTensor"}}, "loss": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput.loss", "name": "loss", "type": {".class": "UnionType", "items": ["torch._C.FloatTensor", {".class": "NoneType"}]}}}, "past_key_values": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LEDSeq2SeqSequenceClassifierOutput.past_key_values", "name": "past_key_values", "type": {".class": "UnionType", "items": [{".class": "Instance", "args": ["torch._C.FloatTensor"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "LED_GENERATION_EXAMPLE": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LED_GENERATION_EXAMPLE", "name": "LED_GENERATION_EXAMPLE", "type": "builtins.str"}}, "LED_INPUTS_DOCSTRING": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LED_INPUTS_DOCSTRING", "name": "LED_INPUTS_DOCSTRING", "type": "builtins.str"}}, "LED_PRETRAINED_MODEL_ARCHIVE_LIST": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_inferred", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LED_PRETRAINED_MODEL_ARCHIVE_LIST", "name": "LED_PRETRAINED_MODEL_ARCHIVE_LIST", "type": {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}}}, "LED_START_DOCSTRING": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.LED_START_DOCSTRING", "name": "LED_START_DOCSTRING", "type": "builtins.str"}}, "List": {".class": "SymbolTableNode", "cross_ref": "typing.List", "kind": "Gdef"}, "MSELoss": {".class": "SymbolTableNode", "cross_ref": "torch.nn.modules.loss.MSELoss", "kind": "Gdef"}, "ModelOutput": {".class": "SymbolTableNode", "cross_ref": "transformers.utils.generic.ModelOutput", "kind": "Gdef"}, "Optional": {".class": "SymbolTableNode", "cross_ref": "typing.Optional", "kind": "Gdef"}, "PreTrainedModel": {".class": "SymbolTableNode", "cross_ref": "transformers.modeling_utils.PreTrainedModel", "kind": "Gdef"}, "Seq2SeqLMOutput": {".class": "SymbolTableNode", "cross_ref": "transformers.modeling_outputs.Seq2SeqLMOutput", "kind": "Gdef"}, "Seq2SeqModelOutput": {".class": "SymbolTableNode", "cross_ref": "transformers.modeling_outputs.Seq2SeqModelOutput", "kind": "Gdef"}, "Seq2SeqQuestionAnsweringModelOutput": {".class": "SymbolTableNode", "cross_ref": "transformers.modeling_outputs.Seq2SeqQuestionAnsweringModelOutput", "kind": "Gdef"}, "Seq2SeqSequenceClassifierOutput": {".class": "SymbolTableNode", "cross_ref": "transformers.modeling_outputs.Seq2SeqSequenceClassifierOutput", "kind": "Gdef"}, "Tuple": {".class": "SymbolTableNode", "cross_ref": "typing.Tuple", "kind": "Gdef"}, "Union": {".class": "SymbolTableNode", "cross_ref": "typing.Union", "kind": "Gdef"}, "_CHECKPOINT_FOR_DOC": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led._CHECKPOINT_FOR_DOC", "name": "_CHECKPOINT_FOR_DOC", "type": "builtins.str"}}, "_CONFIG_FOR_DOC": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led._CONFIG_FOR_DOC", "name": "_CONFIG_FOR_DOC", "type": "builtins.str"}}, "_TOKENIZER_FOR_DOC": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led._TOKENIZER_FOR_DOC", "name": "_TOKENIZER_FOR_DOC", "type": "builtins.str"}}, "__annotations__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.led.modeling_led.__annotations__", "name": "__annotations__", "type": {".class": "Instance", "args": ["builtins.str", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.dict"}}}, "__doc__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.led.modeling_led.__doc__", "name": "__doc__", "type": "builtins.str"}}, "__file__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.led.modeling_led.__file__", "name": "__file__", "type": "builtins.str"}}, "__name__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.led.modeling_led.__name__", "name": "__name__", "type": "builtins.str"}}, "__package__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.led.modeling_led.__package__", "name": "__package__", "type": "builtins.str"}}, "_expand_mask": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1], "arg_names": ["mask", "dtype", "tgt_len"], "flags": [], "fullname": "transformers.models.led.modeling_led._expand_mask", "name": "_expand_mask", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1], "arg_names": ["mask", "dtype", "tgt_len"], "arg_types": ["torch._tensor.Tensor", "torch._C.dtype", {".class": "UnionType", "items": ["builtins.int", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_expand_mask", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_make_causal_mask": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1], "arg_names": ["input_ids_shape", "dtype", "past_key_values_length"], "flags": [], "fullname": "transformers.models.led.modeling_led._make_causal_mask", "name": "_make_causal_mask", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1], "arg_names": ["input_ids_shape", "dtype", "past_key_values_length"], "arg_types": ["torch._C.Size", "torch._C.dtype", "builtins.int"], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_make_causal_mask", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "add_code_sample_docstrings": {".class": "SymbolTableNode", "cross_ref": "transformers.utils.doc.add_code_sample_docstrings", "kind": "Gdef"}, "add_end_docstrings": {".class": "SymbolTableNode", "cross_ref": "transformers.utils.doc.add_end_docstrings", "kind": "Gdef"}, "add_start_docstrings": {".class": "SymbolTableNode", "cross_ref": "transformers.utils.doc.add_start_docstrings", "kind": "Gdef"}, "add_start_docstrings_to_model_forward": {".class": "SymbolTableNode", "cross_ref": "transformers.utils.doc.add_start_docstrings_to_model_forward", "kind": "Gdef"}, "dataclass": {".class": "SymbolTableNode", "cross_ref": "dataclasses.dataclass", "kind": "Gdef"}, "logger": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_inferred", "has_explicit_value"], "fullname": "transformers.models.led.modeling_led.logger", "name": "logger", "type": "logging.Logger"}}, "logging": {".class": "SymbolTableNode", "cross_ref": "transformers.utils.logging", "kind": "Gdef"}, "math": {".class": "SymbolTableNode", "cross_ref": "math", "kind": "Gdef"}, "nn": {".class": "SymbolTableNode", "cross_ref": "torch.nn", "kind": "Gdef"}, "random": {".class": "SymbolTableNode", "cross_ref": "random", "kind": "Gdef"}, "replace_return_docstrings": {".class": "SymbolTableNode", "cross_ref": "transformers.utils.doc.replace_return_docstrings", "kind": "Gdef"}, "shift_tokens_right": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["input_ids", "pad_token_id", "decoder_start_token_id"], "flags": [], "fullname": "transformers.models.led.modeling_led.shift_tokens_right", "name": "shift_tokens_right", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["input_ids", "pad_token_id", "decoder_start_token_id"], "arg_types": ["torch._tensor.Tensor", "builtins.int", "builtins.int"], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "shift_tokens_right", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "torch": {".class": "SymbolTableNode", "cross_ref": "torch", "kind": "Gdef"}}, "path": "/home/paperspace/.pyenv/versions/3.10.4/lib/python3.10/site-packages/transformers/models/led/modeling_led.py"}