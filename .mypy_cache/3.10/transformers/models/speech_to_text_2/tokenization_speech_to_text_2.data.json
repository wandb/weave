{".class": "MypyFile", "_fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2", "future_import_flags": [], "is_partial_stub_package": false, "is_stub": false, "names": {".class": "SymbolTable", "BPE_TOKEN_MERGES": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.BPE_TOKEN_MERGES", "name": "BPE_TOKEN_MERGES", "type": "builtins.str"}}, "BPE_TOKEN_VOCAB": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.BPE_TOKEN_VOCAB", "name": "BPE_TOKEN_VOCAB", "type": "builtins.str"}}, "Dict": {".class": "SymbolTableNode", "cross_ref": "typing.Dict", "kind": "Gdef"}, "List": {".class": "SymbolTableNode", "cross_ref": "typing.List", "kind": "Gdef"}, "Optional": {".class": "SymbolTableNode", "cross_ref": "typing.Optional", "kind": "Gdef"}, "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_inferred", "has_explicit_value"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES", "name": "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES", "type": {".class": "Instance", "args": ["builtins.str", "builtins.int"], "type_ref": "builtins.dict"}}}, "PRETRAINED_VOCAB_FILES_MAP": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_inferred", "has_explicit_value"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.PRETRAINED_VOCAB_FILES_MAP", "name": "PRETRAINED_VOCAB_FILES_MAP", "type": {".class": "Instance", "args": ["builtins.str", {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}], "type_ref": "builtins.dict"}}}, "PreTrainedTokenizer": {".class": "SymbolTableNode", "cross_ref": "transformers.tokenization_utils.PreTrainedTokenizer", "kind": "Gdef"}, "Speech2Text2Tokenizer": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["transformers.tokenization_utils.PreTrainedTokenizer"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer", "name": "Speech2Text2Tokenizer", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2", "mro": ["transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer", "transformers.tokenization_utils.PreTrainedTokenizer", "transformers.tokenization_utils_base.PreTrainedTokenizerBase", "transformers.tokenization_utils_base.SpecialTokensMixin", "transformers.utils.hub.PushToHubMixin", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1, 4], "arg_names": ["self", "vocab_file", "bos_token", "pad_token", "eos_token", "unk_token", "do_lower_case", "merges_file", "kwargs"], "flags": [], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.__init__", "name": "__init__", "type": null}}, "_convert_id_to_token": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "index"], "flags": [], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer._convert_id_to_token", "name": "_convert_id_to_token", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "index"], "arg_types": ["transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer", "builtins.int"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_convert_id_to_token of Speech2Text2Tokenizer", "ret_type": "builtins.str", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_convert_token_to_id": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "token"], "flags": [], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer._convert_token_to_id", "name": "_convert_token_to_id", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "token"], "arg_types": ["transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_convert_token_to_id of Speech2Text2Tokenizer", "ret_type": "builtins.int", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_tokenize": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "text"], "flags": [], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer._tokenize", "name": "_tokenize", "type": null}}, "bpe": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "token"], "flags": [], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.bpe", "name": "bpe", "type": null}}, "bpe_ranks": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.bpe_ranks", "name": "bpe_ranks", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "cache": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.cache", "name": "cache", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "convert_tokens_to_string": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "tokens"], "flags": [], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.convert_tokens_to_string", "name": "convert_tokens_to_string", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "tokens"], "arg_types": ["transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer", {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "convert_tokens_to_string of Speech2Text2Tokenizer", "ret_type": "builtins.str", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "decoder": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.decoder", "name": "decoder", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "do_lower_case": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.do_lower_case", "name": "do_lower_case", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "encoder": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.encoder", "name": "encoder", "type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}}}, "get_vocab": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": [], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.get_vocab", "name": "get_vocab", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "get_vocab of Speech2Text2Tokenizer", "ret_type": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 4}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 4}], "type_ref": "builtins.dict"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "max_model_input_sizes": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.max_model_input_sizes", "name": "max_model_input_sizes", "type": null}}, "model_input_names": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.model_input_names", "name": "model_input_names", "type": {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}}}, "pretrained_vocab_files_map": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.pretrained_vocab_files_map", "name": "pretrained_vocab_files_map", "type": {".class": "Instance", "args": ["builtins.str", {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}], "type_ref": "builtins.dict"}}}, "save_vocabulary": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1], "arg_names": ["self", "save_directory", "filename_prefix"], "flags": [], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.save_vocabulary", "name": "save_vocabulary", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1], "arg_names": ["self", "save_directory", "filename_prefix"], "arg_types": ["transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer", "builtins.str", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "save_vocabulary of Speech2Text2Tokenizer", "ret_type": {".class": "TupleType", "implicit": false, "items": ["builtins.str"], "partial_fallback": {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.tuple"}}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "vocab_files_names": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_inferred", "has_explicit_value"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.vocab_files_names", "name": "vocab_files_names", "type": {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}}}, "vocab_size": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.vocab_size", "name": "vocab_size", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "vocab_size of Speech2Text2Tokenizer", "ret_type": "builtins.int", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.vocab_size", "name": "vocab_size", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "vocab_size of Speech2Text2Tokenizer", "ret_type": "builtins.int", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "Tuple": {".class": "SymbolTableNode", "cross_ref": "typing.Tuple", "kind": "Gdef"}, "VOCAB_FILES_NAMES": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_inferred", "has_explicit_value"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.VOCAB_FILES_NAMES", "name": "VOCAB_FILES_NAMES", "type": {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}}}, "__annotations__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.__annotations__", "name": "__annotations__", "type": {".class": "Instance", "args": ["builtins.str", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.dict"}}}, "__doc__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.__doc__", "name": "__doc__", "type": "builtins.str"}}, "__file__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.__file__", "name": "__file__", "type": "builtins.str"}}, "__name__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.__name__", "name": "__name__", "type": "builtins.str"}}, "__package__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.__package__", "name": "__package__", "type": "builtins.str"}}, "get_pairs": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["word"], "flags": [], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.get_pairs", "name": "get_pairs", "type": null}}, "json": {".class": "SymbolTableNode", "cross_ref": "json", "kind": "Gdef"}, "logger": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_inferred", "has_explicit_value"], "fullname": "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.logger", "name": "logger", "type": "logging.Logger"}}, "logging": {".class": "SymbolTableNode", "cross_ref": "transformers.utils.logging", "kind": "Gdef"}, "os": {".class": "SymbolTableNode", "cross_ref": "os", "kind": "Gdef"}}, "path": "/home/paperspace/.pyenv/versions/3.10.4/lib/python3.10/site-packages/transformers/models/speech_to_text_2/tokenization_speech_to_text_2.py"}