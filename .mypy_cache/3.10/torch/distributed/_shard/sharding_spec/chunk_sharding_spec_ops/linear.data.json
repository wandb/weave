{".class": "MypyFile", "_fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear", "future_import_flags": [], "is_partial_stub_package": false, "is_stub": false, "names": {".class": "SymbolTable", "ChunkShardingSpec": {".class": "SymbolTableNode", "cross_ref": "torch.distributed._shard.sharding_spec.chunk_sharding_spec.ChunkShardingSpec", "kind": "Gdef"}, "Function": {".class": "SymbolTableNode", "cross_ref": "torch.autograd.function.Function", "kind": "Gdef"}, "List": {".class": "SymbolTableNode", "cross_ref": "typing.List", "kind": "Gdef"}, "ShardedTensor": {".class": "SymbolTableNode", "cross_ref": "torch.distributed._shard.sharded_tensor.api.ShardedTensor", "kind": "Gdef"}, "_BiasTensorNarrow": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["torch.autograd.function.Function"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._BiasTensorNarrow", "name": "_BiasTensorNarrow", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._BiasTensorNarrow", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear", "mro": ["torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._BiasTensorNarrow", "torch.autograd.function.Function", "builtins.object"], "names": {".class": "SymbolTable", "backward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["ctx", "grad_output"], "flags": ["is_static", "is_decorated"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._BiasTensorNarrow.backward", "name": "backward", "type": null}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_staticmethod", "is_ready", "is_inferred"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._BiasTensorNarrow.backward", "name": "backward", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["ctx", "grad_output"], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": true, "is_ellipsis_args": false, "name": "backward of _BiasTensorNarrow", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "forward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0, 0, 0, 0], "arg_names": ["ctx", "world_size", "start_pos", "chunk_size", "weight", "pg", "bias"], "flags": ["is_static", "is_decorated"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._BiasTensorNarrow.forward", "name": "forward", "type": null}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_staticmethod", "is_ready", "is_inferred"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._BiasTensorNarrow.forward", "name": "forward", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 0, 0, 0, 0], "arg_names": ["ctx", "world_size", "start_pos", "chunk_size", "weight", "pg", "bias"], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": true, "is_ellipsis_args": false, "name": "forward of _BiasTensorNarrow", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "_BiasTensorPartial": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["torch.autograd.function.Function"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._BiasTensorPartial", "name": "_BiasTensorPartial", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._BiasTensorPartial", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear", "mro": ["torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._BiasTensorPartial", "torch.autograd.function.Function", "builtins.object"], "names": {".class": "SymbolTable", "backward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["ctx", "grad_output"], "flags": ["is_static", "is_decorated"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._BiasTensorPartial.backward", "name": "backward", "type": null}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_staticmethod", "is_ready", "is_inferred"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._BiasTensorPartial.backward", "name": "backward", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["ctx", "grad_output"], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": true, "is_ellipsis_args": false, "name": "backward of _BiasTensorPartial", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "forward": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["ctx", "world_size", "bias"], "flags": ["is_static", "is_decorated"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._BiasTensorPartial.forward", "name": "forward", "type": null}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_staticmethod", "is_ready", "is_inferred"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._BiasTensorPartial.forward", "name": "forward", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["ctx", "world_size", "bias"], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": true, "is_ellipsis_args": false, "name": "forward of _BiasTensorPartial", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "_PartialTensor": {".class": "SymbolTableNode", "cross_ref": "torch.distributed._shard.partial_tensor._PartialTensor", "kind": "Gdef"}, "__annotations__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear.__annotations__", "name": "__annotations__", "type": {".class": "Instance", "args": ["builtins.str", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.dict"}}}, "__doc__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear.__doc__", "name": "__doc__", "type": "builtins.str"}}, "__file__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear.__file__", "name": "__file__", "type": "builtins.str"}}, "__name__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear.__name__", "name": "__name__", "type": "builtins.str"}}, "__package__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear.__package__", "name": "__package__", "type": "builtins.str"}}, "_handle_col_wise_sharding": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0, 0, 0, 0], "arg_names": ["input", "world_size", "weight", "rank", "local_shard_t", "bias", "pg"], "flags": [], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._handle_col_wise_sharding", "name": "_handle_col_wise_sharding", "type": null}}, "_handle_row_wise_sharding_sharded_tensor": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0, 0, 0], "arg_names": ["input", "world_size", "weight", "local_shard_t", "bias", "pg"], "flags": [], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._handle_row_wise_sharding_sharded_tensor", "name": "_handle_row_wise_sharding_sharded_tensor", "type": null}}, "_handle_row_wise_sharding_tensor": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0, 0, 0, 0], "arg_names": ["input", "world_size", "weight", "rank", "local_shard_t", "bias", "pg"], "flags": [], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._handle_row_wise_sharding_tensor", "name": "_handle_row_wise_sharding_tensor", "type": null}}, "_result_distribute_with_col_rearrange": {".class": "SymbolTableNode", "cross_ref": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops._common._result_distribute_with_col_rearrange", "kind": "Gdef"}, "_validate_linear_op_param": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["args", "kwargs"], "flags": [], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear._validate_linear_op_param", "name": "_validate_linear_op_param", "type": null}}, "all_gather": {".class": "SymbolTableNode", "cross_ref": "torch.distributed.nn.functional.all_gather", "kind": "Gdef"}, "all_to_all_single": {".class": "SymbolTableNode", "cross_ref": "torch.distributed.nn.functional.all_to_all_single", "kind": "Gdef"}, "cast": {".class": "SymbolTableNode", "cross_ref": "typing.cast", "kind": "Gdef"}, "custom_sharding_spec_op": {".class": "SymbolTableNode", "cross_ref": "torch.distributed._shard.sharding_spec.api.custom_sharding_spec_op", "kind": "Gdef"}, "dist": {".class": "SymbolTableNode", "cross_ref": "torch.distributed", "kind": "Gdef"}, "get_chunk_sharding_params": {".class": "SymbolTableNode", "cross_ref": "torch.distributed._shard.sharding_spec._internals.get_chunk_sharding_params", "kind": "Gdef"}, "get_chunked_dim_size": {".class": "SymbolTableNode", "cross_ref": "torch.distributed._shard.sharding_spec._internals.get_chunked_dim_size", "kind": "Gdef"}, "get_split_size": {".class": "SymbolTableNode", "cross_ref": "torch.distributed._shard.sharding_spec._internals.get_split_size", "kind": "Gdef"}, "sharded_linear": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0], "arg_names": ["types", "args", "kwargs", "pg"], "flags": ["is_decorated"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear.sharded_linear", "name": "sharded_linear", "type": null}, "is_overload": false, "var": {".class": "Var", "flags": ["is_ready", "is_inferred"], "fullname": "torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.linear.sharded_linear", "name": "sharded_linear", "type": {".class": "AnyType", "missing_import_name": null, "source_any": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_of_any": 7}}}}, "torch": {".class": "SymbolTableNode", "cross_ref": "torch", "kind": "Gdef"}}, "path": "/home/paperspace/.pyenv/versions/3.10.4/lib/python3.10/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec_ops/linear.py"}