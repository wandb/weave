"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8967],{31309:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>i,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>l});var r=t(85893),a=t(11151);const s={},i="Threads",o={id:"guides/tracking/threads",title:"Threads",description:"With W&B Weave Threads, you can track and analyze multi-turn conversations in your LLM applications. Threads group related calls under a shared thread_id, allowing you to visualize complete sessions and track conversation-level metrics across turns. You can create threads programmatically, and visualize them in the Weave UI.",source:"@site/docs/guides/tracking/threads.md",sourceDirName:"guides/tracking",slug:"/guides/tracking/threads",permalink:"/guides/tracking/threads",draft:!1,unlisted:!1,editUrl:"https://github.com/wandb/weave/blob/master/docs/docs/guides/tracking/threads.md",tags:[],version:"current",lastUpdatedAt:1758042624e3,frontMatter:{},sidebar:"documentationSidebar",previous:{title:"Costs",permalink:"/guides/tracking/costs"},next:{title:"Logging Media",permalink:"/guides/core-types/media"}},d={},l=[{value:"Use cases",id:"use-cases",level:2},{value:"Definitions",id:"definitions",level:2},{value:"Thread",id:"thread",level:3},{value:"Turn",id:"turn",level:3},{value:"Call",id:"call",level:3},{value:"Trace",id:"trace",level:3},{value:"UI overview",id:"ui-overview",level:2},{value:"Threads list view",id:"threads-list-view",level:3},{value:"Threads detail drawer",id:"threads-detail-drawer",level:3},{value:"Chat view behavior",id:"chat-view-behavior",level:3},{value:"What qualifies as a message?",id:"what-qualifies-as-a-message",level:4},{value:"What happens if no messages are present?",id:"what-happens-if-no-messages-are-present",level:4},{value:"Turn and Chat interactions",id:"turn-and-chat-interactions",level:4},{value:"Navigate to and from the trace view",id:"navigate-to-and-from-the-trace-view",level:4},{value:"SDK usage",id:"sdk-usage",level:2},{value:"Basic thread creation",id:"basic-thread-creation",level:3},{value:"Manual agent loop implementation",id:"manual-agent-loop-implementation",level:3},{value:"Manual agent with unbalanced call depth",id:"manual-agent-with-unbalanced-call-depth",level:3},{value:"Resume a previous session",id:"resume-a-previous-session",level:3},{value:"Nested threads",id:"nested-threads",level:3},{value:"API specification",id:"api-specification",level:2},{value:"Endpoint",id:"endpoint",level:2},{value:"Request schema",id:"request-schema",level:3},{value:"Response schema",id:"response-schema",level:3},{value:"Query recent active threads",id:"query-recent-active-threads",level:3},{value:"Query threads by activity level",id:"query-threads-by-activity-level",level:3},{value:"Query recent threads only",id:"query-recent-threads-only",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h1,{id:"threads",children:"Threads"}),"\n",(0,r.jsxs)(n.p,{children:["With W&B Weave ",(0,r.jsx)(n.em,{children:"Threads"}),", you can track and analyze multi-turn conversations in your LLM applications. Threads group related calls under a shared ",(0,r.jsx)(n.code,{children:"thread_id"}),", allowing you to visualize complete sessions and track conversation-level metrics across turns. You can create threads programmatically, and visualize them in the Weave UI."]}),"\n",(0,r.jsx)(n.p,{children:"To get started with Threads, do the following:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Familiarize yourself with the basics of Threads.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#use-cases",children:"Use cases"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#definitions",children:"Definitions"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#ui-overview",children:"The UI experience"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#api-specification",children:"API specification"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Try the code samples, which demonstrate common usage patterns and real-world use cases.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#basic-thread-creation",children:"Basic usage examples"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#manual-agent-loop-implementation",children:"Advanced usage examples"})}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"use-cases",children:"Use cases"}),"\n",(0,r.jsx)(n.p,{children:"Threads are useful when you want to organize and analyze:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Multi-turn conversations"}),"\n",(0,r.jsx)(n.li,{children:"Session-based workflows"}),"\n",(0,r.jsx)(n.li,{children:"Any sequence of related operations."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Threads let you group calls by context, making it easier to understand how your system responds across multiple steps. For example, you can track a single user session, an agent\u2019s chain of decisions, or a complex request that spans infrastructure and business logic layers."}),"\n",(0,r.jsx)(n.p,{children:"By structuring your application with threads and turns, you get cleaner metrics and better visibility in the Weave UI. Instead of seeing every low-level operation, you can focus on the high-level steps that matter."}),"\n",(0,r.jsx)(n.h2,{id:"definitions",children:"Definitions"}),"\n",(0,r.jsx)(n.h3,{id:"thread",children:"Thread"}),"\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.em,{children:"Thread"})," is a logical grouping of related calls that share a common conversational context. A Thread:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Has a unique ",(0,r.jsx)(n.code,{children:"thread_id"})]}),"\n",(0,r.jsxs)(n.li,{children:["Contains one or more ",(0,r.jsx)(n.em,{children:"turns"})]}),"\n",(0,r.jsx)(n.li,{children:"Maintains context across calls"}),"\n",(0,r.jsx)(n.li,{children:"Represent complete user sessions or interaction flows"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"turn",children:"Turn"}),"\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.em,{children:"Turn"})," is a high-level operation within a Thread, displayed in the UI as individual rows in a thread view. Each Turn:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Represents one logical step in a conversation or workflow"}),"\n",(0,r.jsx)(n.li,{children:"Turns are the direct children of a thread context and may include nested lower-level calls (not shown in thread-level stats)."}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"call",children:"Call"}),"\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.em,{children:"Call"})," is any ",(0,r.jsx)(n.code,{children:"@weave.op"}),"-decorated function execution in your application."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"Turn calls"})," are top-level operations that start new turns"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"Nested calls"})," are lower-level operations within a turn"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"trace",children:"Trace"}),"\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.em,{children:"Trace"})," captures the full call stack for a single operation. Threads group traces together that are part of the same logical conversation or session. In other words, a thread is made up of multiple turns, each representing one part in the conversation. For more information on Traces, see the ",(0,r.jsx)(n.a,{href:"/guides/tracking/tracing",children:"Tracing overview"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"ui-overview",children:"UI overview"}),"\n",(0,r.jsxs)(n.p,{children:["In the Weave sidebar, select ",(0,r.jsx)(n.strong,{children:"Threads"})," to access the ",(0,r.jsx)(n.a,{href:"#threads-list-view",children:"Threads list view"}),"."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"The Threads icon in the Weave sidebar",src:t(74055).Z+"",width:"114",height:"126"})}),"\n",(0,r.jsx)(n.h3,{id:"threads-list-view",children:"Threads list view"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Lists recent threads in your project"}),"\n",(0,r.jsx)(n.li,{children:"Columns include number of turns, start time, and last updated"}),"\n",(0,r.jsxs)(n.li,{children:["Click a row to open its ",(0,r.jsx)(n.a,{href:"#threads-detail-drawer",children:"detail drawer"})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"The Threads list view",src:t(31595).Z+"",width:"2914",height:"576"})}),"\n",(0,r.jsx)(n.h3,{id:"threads-detail-drawer",children:"Threads detail drawer"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Click any row to open the detail drawer for that row"}),"\n",(0,r.jsx)(n.li,{children:"Shows all turns within a thread."}),"\n",(0,r.jsx)(n.li,{children:"Turns are listed in the order they started (based on their start time, not by duration or end time)."}),"\n",(0,r.jsx)(n.li,{children:"Includes call-level metadata (latency, inputs, outputs)"}),"\n",(0,r.jsx)(n.li,{children:"Optionally shows message content or structured data if logged"}),"\n",(0,r.jsx)(n.li,{children:"To view the full execution of a turn, you can open it from the thread detail drawer. This lets you drill into all nested operations that occurred during that specific turn."}),"\n",(0,r.jsxs)(n.li,{children:["If a turn includes messages extracted from LLM calls, they will appear in the right-hand chat pane. These messages typically come from calls made by supported integrations (e.g., ",(0,r.jsx)(n.code,{children:"openai.ChatCompletion.create"}),") and must meet specific criteria to display. For more information, see ",(0,r.jsx)(n.a,{href:"#chat-view-behavior",children:"Chat view behavior"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"chat-view-behavior",children:"Chat view behavior"}),"\n",(0,r.jsx)(n.p,{children:"The chat pane displays structured message data extracted from LLM calls made during each turn. This view gives you a conversational-style rendering of the interaction."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Chat view",src:t(85128).Z+"",width:"2912",height:"1512"})}),"\n",(0,r.jsx)(n.h4,{id:"what-qualifies-as-a-message",children:"What qualifies as a message?"}),"\n",(0,r.jsx)(n.p,{children:"Messages are extracted from calls within a turn that represent direct interactions with LLM providers (e.g., sending a prompt and receiving a response). Only calls that are not further nested inside other calls are shown as messages. This avoids duplicating intermediate steps or aggregated internal logic."}),"\n",(0,r.jsx)(n.p,{children:"Typically, messages are emitted by automatically patched third-party SDKs like:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"openai.ChatCompletion.create"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"anthropic.Anthropic.completion"})}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"what-happens-if-no-messages-are-present",children:"What happens if no messages are present?"}),"\n",(0,r.jsx)(n.p,{children:"If a turn doesn't emit any messages, the chat pane will show an empty message section for that turn. However, the chat pane may still include messages from other turns in the same thread."}),"\n",(0,r.jsx)(n.h4,{id:"turn-and-chat-interactions",children:"Turn and Chat interactions"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Clicking a turn scrolls the chat pane to that turn's message location (pinning behavior)."}),"\n",(0,r.jsx)(n.li,{children:"Scrolling the chat pane highlights the corresponding turn in the left-hand list."}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"navigate-to-and-from-the-trace-view",children:"Navigate to and from the trace view"}),"\n",(0,r.jsx)(n.p,{children:"You can open the full trace for a turn by clicking into it."}),"\n",(0,r.jsx)(n.p,{children:"A back button appears in the upper left corner to return to the thread detail view. UI state (like scroll position) is not preserved across the transition."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"The Threads drawer view",src:t(62036).Z+"",width:"2914",height:"1522"})}),"\n",(0,r.jsx)(n.h2,{id:"sdk-usage",children:"SDK usage"}),"\n",(0,r.jsx)(n.p,{children:"Each example in this section demonstrates a different strategy for organizing turns and threads in your application. For most examples, you should provide your own LLM call or system behavior inside the stub functions."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["To track a session or conversation, use the ",(0,r.jsx)(n.code,{children:"weave.thread()"})," context manager."]}),"\n",(0,r.jsxs)(n.li,{children:["Decorate logical operations with ",(0,r.jsx)(n.code,{children:"@weave.op"})," to track them as turns or nested calls."]}),"\n",(0,r.jsxs)(n.li,{children:["If you pass a ",(0,r.jsx)(n.code,{children:"thread_id"}),", Weave uses it to group all operations in that block under the same thread. If you omit the ",(0,r.jsx)(n.code,{children:"thread_id"}),", Weave auto-generates a unique one for you."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["The return value from ",(0,r.jsx)(n.code,{children:"weave.thread()"})," is a ",(0,r.jsx)(n.code,{children:"ThreadContext"})," object with a ",(0,r.jsx)(n.code,{children:"thread_id"})," property, which you can log, reuse, or pass to other systems."]}),"\n",(0,r.jsxs)(n.p,{children:["Nested ",(0,r.jsx)(n.code,{children:"weave.thread()"})," contexts always start a new thread unless the same ",(0,r.jsx)(n.code,{children:"thread_id"})," is reused. Ending a child context does not interrupt or overwrite the parent context. This allows for forked thread structures or layered thread orchestration, depending on your app logic."]}),"\n",(0,r.jsx)(n.h3,{id:"basic-thread-creation",children:"Basic thread creation"}),"\n",(0,r.jsxs)(n.p,{children:["The following code sample demonstrates how to use ",(0,r.jsx)(n.code,{children:"weave.thread()"})," to group one or more operations under a shared ",(0,r.jsx)(n.code,{children:"thread_id"}),". This is the simplest way to start using Threads in your application."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import weave\n\n@weave.op\ndef say_hello(name: str) -> str:\n    return f"Hello, {name}!"\n\n# Start a new thread context\nwith weave.thread() as thread_ctx:\n    print(f"Thread ID: {thread_ctx.thread_id}")\n    say_hello("Bill Nye the Science Guy")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"manual-agent-loop-implementation",children:"Manual agent loop implementation"}),"\n",(0,r.jsxs)(n.p,{children:["This example shows how to manually define a conversational agent using ",(0,r.jsx)(n.code,{children:"@weave.op"})," decorators and ",(0,r.jsx)(n.code,{children:"weave.thread()"})," context management. Each call to ",(0,r.jsx)(n.code,{children:"process_user_message"})," creates a new turn in the thread. You can use this pattern when building your own agent loop and want full control over how context and nesting are handled."]}),"\n",(0,r.jsxs)(n.p,{children:["Use the auto-generated thread ID for short-lived interactions, or pass a custom session ID (like ",(0,r.jsx)(n.code,{children:"user_session_123"}),") to persist thread context across sessions."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import weave\n\nclass ConversationAgent:\n    @weave.op\n    def process_user_message(self, message: str) -> str:\n        """\n        TURN-LEVEL OPERATION: This represents one conversation turn.\n        Only this function will be counted in thread statistics.\n        """\n        # Store user message\n        # Generate AI response through nested calls\n        response = self._generate_response(message)\n        # Store assistant response\n        return response\n\n    @weave.op\n    def _generate_response(self, message: str) -> str:\n        """NESTED CALL: Implementation details, not counted in thread stats."""\n        context = self._retrieve_context(message)     # Another nested call\n        intent = self._classify_intent(message)       # Another nested call\n        response = self._call_llm(message, context)   # LLM call (nested)\n        return self._format_response(response)        # Final nested call\n\n    @weave.op\n    def _retrieve_context(self, message: str) -> str:\n        # Vector DB lookup, knowledge base query, etc.\n        return "retrieved_context"\n\n    @weave.op\n    def _classify_intent(self, message: str) -> str:\n        # Intent classification logic\n        return "general_inquiry"\n\n    @weave.op\n    def _call_llm(self, message: str, context: str) -> str:\n        # OpenAI/Anthropic/etc API call\n        return "llm_response"\n\n    @weave.op\n    def _format_response(self, response: str) -> str:\n        # Response formatting logic\n        return f"Formatted: {response}"\n\n# Usage: Thread context established automatically\nagent = ConversationAgent()\n\n# Establish thread context - each process_user_message call becomes a turn\nwith weave.thread() as thread_ctx:  # Auto-generates thread_id\n    print(f"Thread ID: {thread_ctx.thread_id}")\n\n    # Each call to process_user_message creates 1 turn + multiple nested calls\n    agent.process_user_message("Hello, help with setup")           # Turn 1\n    agent.process_user_message("What languages do you recommend?") # Turn 2\n    agent.process_user_message("Explain Python vs JavaScript")     # Turn 3\n\n# Result: Thread with 3 turns, ~15-20 total calls (including nested)\n\n# Alternative: Use explicit thread_id for session tracking\nsession_id = "user_session_123"\nwith weave.thread(session_id) as thread_ctx:\n    print(f"Session Thread ID: {thread_ctx.thread_id}")  # "user_session_123"\n\n    agent.process_user_message("Continue our previous conversation")  # Turn 1 in this session\n    agent.process_user_message("Can you summarize what we discussed?") # Turn 2 in this session\n'})}),"\n",(0,r.jsx)(n.h3,{id:"manual-agent-with-unbalanced-call-depth",children:"Manual agent with unbalanced call depth"}),"\n",(0,r.jsx)(n.p,{children:"This example demonstrates that turns can be defined at different depths in the call stack depending on how thread context is applied. The sample uses two providers (OpenAI and Anthropic), each with a different call depth before reaching the turn boundary."}),"\n",(0,r.jsxs)(n.p,{children:["All turns share the same ",(0,r.jsx)(n.code,{children:"thread_id"}),", but the turn boundary appears at different levels in the stack depending on the provider logic. This is useful when calls need to be traced differently for different backends, while still grouping them into the same thread."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import weave\nimport random\nimport asyncio\n\nclass OpenAIProvider:\n    """OpenAI branch: 2 levels deep call chain to turn boundary"""\n\n    @weave.op\n    def route_to_openai(self, user_input: str, thread_id: str) -> str:\n        """Level 1: Route and prepare OpenAI request"""\n        # Input validation, routing logic, basic preprocessing\n        print(f"  L1: Routing to OpenAI for: {user_input}")\n\n        # This is the turn boundary - wrap with thread context\n        with weave.thread(thread_id):\n            # Call Level 2 directly - this creates the call chain depth\n            return self.execute_openai_call(user_input)\n\n    @weave.op\n    def execute_openai_call(self, user_input: str) -> str:\n        """Level 2: TURN BOUNDARY - Execute OpenAI API call"""\n        print(f"    L2: Executing OpenAI API call")\n        response = f"OpenAI GPT-4 response: {user_input}"\n        return response\n\n\nclass AnthropicProvider:\n    """Anthropic branch: 3 levels deep call chain to turn boundary"""\n\n    @weave.op\n    def route_to_anthropic(self, user_input: str, thread_id: str) -> str:\n        """Level 1: Route and prepare Anthropic request"""\n        # Input validation, routing logic, provider selection\n        print(f"  L1: Routing to Anthropic for: {user_input}")\n\n        # Call Level 2 - this creates call chain depth\n        return self.authenticate_anthropic(user_input, thread_id)\n\n    @weave.op\n    def authenticate_anthropic(self, user_input: str, thread_id: str) -> str:\n        """Level 2: Handle Anthropic authentication and setup"""\n        print(f"    L2: Authenticating with Anthropic")\n\n        # Authentication, rate limiting, session management\n        auth_token = "anthropic_key_xyz_authenticated"\n\n         # This is the turn boundary - wrap with thread context at Level 3\n        with weave.thread(thread_id):\n            # Call Level 3 - further nesting the call chain\n            return self.execute_anthropic_call(user_input, auth_token)\n\n    @weave.op\n    def execute_anthropic_call(self, user_input: str, auth_token: str) -> str:\n        """Level 3: TURN BOUNDARY - Execute Anthropic API call"""\n        print(f"      L3: Executing Anthropic API call with auth")\n        response = f"Anthropic Claude response (auth: {auth_token[:15]}...): {user_input}"\n        return response\n\n\nclass MultiProviderAgent:\n    """Main agent that routes between providers with different call chain depths"""\n\n    def __init__(self):\n        self.openai_provider = OpenAIProvider()\n        self.anthropic_provider = AnthropicProvider()\n\n    def handle_conversation_turn(self, user_input: str, thread_id: str) -> str:\n        """\n        Route to different providers with imbalanced call chain depths.\n        Thread context is applied at different nesting levels in each chain.\n        """\n        # Randomly choose provider for demonstration\n        use_openai = random.choice([True, False])\n\n        if use_openai:\n            print(f"Choosing OpenAI (2-level call chain)")\n            # OpenAI: Level 1 \u2192 Level 2 (turn boundary)\n            response = self.openai_provider.route_to_openai(user_input, thread_id)\n            return f"[OpenAI Branch] {response}"\n        else:\n            print(f"Choosing Anthropic (3-level call chain)")\n            # Anthropic: Level 1 \u2192 Level 2 \u2192 Level 3 (turn boundary)\n            response = self.anthropic_provider.route_to_anthropic(user_input, thread_id)\n            return f"[Anthropic Branch] {response}"\n\n\nasync def main():\n    agent = MultiProviderAgent()\n    conversation_id = "nested_depth_conversation_999"\n\n    # Multi-turn conversation with different call chain depths\n    conversation_turns = [\n        "What\'s deep learning?",\n        "Explain neural network backpropagation",\n        "How do attention mechanisms work?",\n        "What\'s the transformer architecture?",\n        "Compare CNNs vs RNNs"\n    ]\n\n    print(f"Starting conversation: {conversation_id}")\n\n    for i, user_input in enumerate(conversation_turns, 1):\n        print(f"\\\\n--- Turn {i} ---")\n        print(f"User: {user_input}")\n\n        # Same thread_id used across different call chain depths\n        response = agent.handle_conversation_turn(user_input, conversation_id)\n        print(f"Agent: {response}")\n\nif __name__ == "__main__":\n    asyncio.run(main())\n\n# Expected Result: Single thread with 5 turns\n# - OpenAI turns: thread context at Level 2 in call chain\n#   Call stack: route_to_openai() \u2192 execute_openai_call() \u2190 thread context here\n# - Anthropic turns: thread context at Level 3 in call chain\n#   Call stack: route_to_anthropic() \u2192 authenticate_anthropic() \u2192 execute_anthropic_call() \u2190 thread context here\n# - All turns share thread_id: "nested_depth_conversation_999"\n# - Turn boundaries marked at different call stack depths\n# - Supporting operations in call chain tracked as nested calls, not turns\n'})}),"\n",(0,r.jsx)(n.h3,{id:"resume-a-previous-session",children:"Resume a previous session"}),"\n",(0,r.jsx)(n.p,{children:"Sometimes you need to resume a previously started session and continue adding calls to the same thread. In other cases, you may not be able to resume an existing session and must start a new thread instead."}),"\n",(0,r.jsxs)(n.p,{children:["When implementing optional thread resumption, ",(0,r.jsx)(n.strong,{children:"never"})," leave the ",(0,r.jsx)(n.code,{children:"thread_id"})," parameter as ",(0,r.jsx)(n.code,{children:"None"}),", as this will disable thread grouping entirely. Instead, always provide a valid thread ID. If you need to create a new thread, generate a unique identifier using a function like ",(0,r.jsx)(n.code,{children:"generate_id()"}),"."]}),"\n",(0,r.jsx)(n.admonition,{type:"info",children:(0,r.jsxs)(n.p,{children:["When no ",(0,r.jsx)(n.code,{children:"thread_id"})," is specified, Weave's internal implementation automatically generates a random UUID v7. You can replicate this behavior in your own ",(0,r.jsx)(n.code,{children:"generate_id()"})," function or use any unique string value you prefer."]})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import weave\nimport uuidv7\nimport argparse\n\ndef generate_id():\n    """Generate a unique thread ID using UUID v7."""\n    return str(uuidv7.uuidv7())\n\n@weave.op\ndef load_history(session_id):\n    """Load conversation history for the given session."""\n    # Your implementation here\n    return []\n\n# Parse command line arguments for session resumption\nparser = argparse.ArgumentParser()\nparser.add_argument("--session-id", help="Existing session ID to resume")\nargs = parser.parse_args()\n\n# Determine thread ID: resume existing session or create new one\nif args.session_id:\n    thread_id = args.session_id\n    print(f"Resuming session: {thread_id}")\nelse:\n    thread_id = generate_id()\n    print(f"Starting new session: {thread_id}")\n\n# Establish thread context for tracking calls\nwith weave.thread(thread_id) as thread_ctx:\n    # Load or initialize conversation history\n    history = load_history(thread_id)\n    print(f"Active thread ID: {thread_ctx.thread_id}")\n    \n    # Your application logic here...\n'})}),"\n",(0,r.jsx)(n.h3,{id:"nested-threads",children:"Nested threads"}),"\n",(0,r.jsx)(n.p,{children:"This example illustrates how to structure complex applications using multiple coordinated threads."}),"\n",(0,r.jsxs)(n.p,{children:["Each layer runs in its own thread context, allowing for clean separation of concerns. The parent application thread coordinates these layers by setting up thread IDs using a shared ",(0,r.jsx)(n.code,{children:"ThreadContext"}),". Use this pattern when you want to analyze or monitor different parts of the system independently while still tying them to a shared session."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import weave\nfrom contextlib import contextmanager\nfrom typing import Dict\n\n# Global thread context for coordinating nested threads\nclass ThreadContext:\n    def __init__(self):\n        self.app_thread_id = None\n        self.infra_thread_id = None\n        self.logic_thread_id = None\n\n    def setup_for_request(self, request_id: str):\n        self.app_thread_id = f"app_{request_id}"\n        self.infra_thread_id = f"{self.app_thread_id}_infra"\n        self.logic_thread_id = f"{self.app_thread_id}_logic"\n\n# Global instance\nthread_ctx = ThreadContext()\n\nclass InfrastructureLayer:\n    """Handles all infrastructure operations in a dedicated thread"""\n\n    @weave.op\n    def authenticate_user(self, user_id: str) -> Dict:\n        # Authentication logic...\n        return {"user_id": user_id, "authenticated": True}\n\n    @weave.op\n    def call_payment_gateway(self, amount: float) -> Dict:\n        # Payment processing...\n        return {"status": "approved", "amount": amount}\n\n    @weave.op\n    def update_inventory(self, product_id: str, quantity: int) -> Dict:\n        # Inventory management...\n        return {"product_id": product_id, "updated": True}\n\n    def execute_operations(self, user_id: str, order_data: Dict) -> Dict:\n        """Execute all infrastructure operations in dedicated thread context"""\n        with weave.thread(thread_ctx.infra_thread_id):\n            auth_result = self.authenticate_user(user_id)\n            payment_result = self.call_payment_gateway(order_data["amount"])\n            inventory_result = self.update_inventory(order_data["product_id"], order_data["quantity"])\n\n            return {\n                "auth": auth_result,\n                "payment": payment_result,\n                "inventory": inventory_result\n            }\n\n\nclass BusinessLogicLayer:\n    """Handles business logic in a dedicated thread"""\n\n    @weave.op\n    def validate_order(self, order_data: Dict) -> Dict:\n        # Validation logic...\n        return {"valid": True}\n\n    @weave.op\n    def calculate_pricing(self, order_data: Dict) -> Dict:\n        # Pricing calculations...\n        return {"total": order_data["amount"], "tax": order_data["amount"] * 0.08}\n\n    @weave.op\n    def apply_business_rules(self, order_data: Dict) -> Dict:\n        # Business rules...\n        return {"rules_applied": ["standard_processing"], "priority": "normal"}\n\n    def execute_logic(self, order_data: Dict) -> Dict:\n        """Execute all business logic in dedicated thread context"""\n        with weave.thread(thread_ctx.logic_thread_id):\n            validation = self.validate_order(order_data)\n            pricing = self.calculate_pricing(order_data)\n            rules = self.apply_business_rules(order_data)\n\n            return {"validation": validation, "pricing": pricing, "rules": rules}\n\n\nclass OrderProcessingApp:\n    """Main application orchestrator"""\n\n    def __init__(self):\n        self.infra = InfrastructureLayer()\n        self.business = BusinessLogicLayer()\n\n    @weave.op\n    def process_order(self, user_id: str, order_data: Dict) -> Dict:\n        """Main order processing - becomes a turn in the app thread"""\n\n        # Execute nested operations in their dedicated threads\n        infra_results = self.infra.execute_operations(user_id, order_data)\n        logic_results = self.business.execute_logic(order_data)\n\n        # Final orchestration\n        return {\n            "order_id": f"order_12345",\n            "status": "completed",\n            "infra_results": infra_results,\n            "logic_results": logic_results\n        }\n\n\n# Usage with global thread context coordination\ndef handle_order_request(request_id: str, user_id: str, order_data: Dict):\n    # Setup thread context for this request\n    thread_ctx.setup_for_request(request_id)\n\n    # Execute in app thread context\n    with weave.thread(thread_ctx.app_thread_id):\n        app = OrderProcessingApp()\n        result = app.process_order(user_id, order_data)\n        return result\n\n# Example usage\norder_result = handle_order_request(\n    request_id="req_789",\n    user_id="user_001",\n    order_data={"product_id": "laptop", "quantity": 1, "amount": 1299.99}\n)\n\n# Expected Thread Structure:\n#\n# App Thread: app_req_789\n# \u2514\u2500\u2500 Turn: process_order() \u2190 Main orchestration\n#\n# Infra Thread: app_req_789_infra\n# \u251c\u2500\u2500 Turn: authenticate_user() \u2190 Infrastructure operation 1\n# \u251c\u2500\u2500 Turn: call_payment_gateway() \u2190 Infrastructure operation 2\n# \u2514\u2500\u2500 Turn: update_inventory() \u2190 Infrastructure operation 3\n#\n# Logic Thread: app_req_789_logic\n# \u251c\u2500\u2500 Turn: validate_order() \u2190 Business logic operation 1\n# \u251c\u2500\u2500 Turn: calculate_pricing() \u2190 Business logic operation 2\n# \u2514\u2500\u2500 Turn: apply_business_rules() \u2190 Business logic operation 3\n#\n# Benefits:\n# - Clear separation of concerns across threads\n# - No parameter drilling of thread IDs\n# - Independent monitoring of app/infra/logic layers\n# - Global coordination through thread context\n'})}),"\n",(0,r.jsx)(n.h2,{id:"api-specification",children:"API specification"}),"\n",(0,r.jsx)(n.h2,{id:"endpoint",children:"Endpoint"}),"\n",(0,r.jsxs)(n.p,{children:["Endpoint: ",(0,r.jsx)(n.code,{children:"POST /threads/query"})]}),"\n",(0,r.jsx)(n.h3,{id:"request-schema",children:"Request schema"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class ThreadsQueryReq:\n    project_id: str\n    limit: Optional[int] = None\n    offset: Optional[int] = None\n    sort_by: Optional[list[SortBy]] = None  # Supported fields: thread_id, turn_count, start_time, last_updated\n    sortable_datetime_after: Optional[datetime] = None   # Filter threads by granule optimization\n    sortable_datetime_before: Optional[datetime] = None  # Filter threads by granule optimization\n"})}),"\n",(0,r.jsx)(n.h3,{id:"response-schema",children:"Response schema"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class ThreadSchema:\n    thread_id: str           # Unique identifier for the thread\n    turn_count: int          # Number of turn calls in this thread\n    start_time: datetime     # Earliest start time of turn calls in this thread\n    last_updated: datetime   # Latest end time of turn calls in this thread\n\nclass ThreadsQueryRes:\n    threads: List[ThreadSchema]\n"})}),"\n",(0,r.jsx)(n.h3,{id:"query-recent-active-threads",children:"Query recent active threads"}),"\n",(0,r.jsxs)(n.p,{children:["This example fetches the 50 most recently updated threads. Replace ",(0,r.jsx)(n.code,{children:"my-project"})," with your actual project ID."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Get most recently active threads\nresponse = client.threads_query(ThreadsQueryReq(\n    project_id="my-project",\n    sort_by=[SortBy(field="last_updated", direction="desc")],\n    limit=50\n))\n\nfor thread in response.threads:\n    print(f"Thread {thread.thread_id}: {thread.turn_count} turns, last active {thread.last_updated}")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"query-threads-by-activity-level",children:"Query threads by activity level"}),"\n",(0,r.jsx)(n.p,{children:"This example fetches the 20 most active threads, ordered by number of turns."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Get threads with most activity (most turns)\nresponse = client.threads_query(ThreadsQueryReq(\n    project_id="my-project",\n    sort_by=[SortBy(field="turn_count", direction="desc")],\n    limit=20\n))\n'})}),"\n",(0,r.jsx)(n.h3,{id:"query-recent-threads-only",children:"Query recent threads only"}),"\n",(0,r.jsxs)(n.p,{children:["This example returns threads that started in the past 24 hours. You can change the time window by adjusting the value of ",(0,r.jsx)(n.code,{children:"days"})," in ",(0,r.jsx)(n.code,{children:"timedelta"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from datetime import datetime, timedelta\n\n# Get threads started in the last 24 hours\nyesterday = datetime.now() - timedelta(days=1)\nresponse = client.threads_query(ThreadsQueryReq(\n    project_id="my-project",\n    sortable_datetime_after=yesterday,\n    sort_by=[SortBy(field="start_time", direction="desc")]\n))\n'})})]})}function h(e={}){const{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},85128:(e,n,t)=>{t.d(n,{Z:()=>r});const r=t.p+"assets/images/threads-chat-view-5d6a0909c436a31dcc9c2a5a6b7d05fa.png"},62036:(e,n,t)=>{t.d(n,{Z:()=>r});const r=t.p+"assets/images/threads-drawer-1c3dad4fc61ecd3e4333f1da6923d7ef.png"},31595:(e,n,t)=>{t.d(n,{Z:()=>r});const r=t.p+"assets/images/threads-list-1fddd9fcf52cb94fb2f16a51a7a47441.png"},74055:(e,n,t)=>{t.d(n,{Z:()=>r});const r="data:image/png;base64,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"},11151:(e,n,t)=>{t.d(n,{Z:()=>o,a:()=>i});var r=t(67294);const a={},s=r.createContext(a);function i(e){const n=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);