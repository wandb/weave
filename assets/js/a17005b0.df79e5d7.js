"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7972],{36959:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>c});var a=n(85893),r=n(11151);const s={},i="CrewAI",o={id:"guides/integrations/crewai",title:"CrewAI",description:"CrewAI is a lean, lightning-fast Python framework built entirely from scratch\u2014completely independent of LangChain or other agent frameworks. CrewAI empowers developers with both high-level simplicity (Crews) and precise low-level control (Flows), ideal for creating autonomous AI agents tailored to any scenario. Learn more about CrewAI here.",source:"@site/docs/guides/integrations/crewai.md",sourceDirName:"guides/integrations",slug:"/guides/integrations/crewai",permalink:"/guides/integrations/crewai",draft:!1,unlisted:!1,editUrl:"https://github.com/wandb/weave/blob/master/docs/docs/guides/integrations/crewai.md",tags:[],version:"current",lastUpdatedAt:1749652482e3,frontMatter:{},sidebar:"documentationSidebar",previous:{title:"Instructor",permalink:"/guides/integrations/instructor"},next:{title:"Smolagents",permalink:"/guides/integrations/smolagents"}},l={},c=[{value:"Getting Started with Crew",id:"getting-started-with-crew",level:2},{value:"Track Tools",id:"track-tools",level:2},{value:"Getting Started with Flow",id:"getting-started-with-flow",level:2},{value:"Crew Guardrail - Track your own ops",id:"crew-guardrail---track-your-own-ops",level:2},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",img:"img",p:"p",pre:"pre",...(0,r.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.h1,{id:"crewai",children:"CrewAI"}),"\n",(0,a.jsx)("a",{target:"_blank",href:"https://github.com/wandb/examples/blob/master/weave/docs/quickstart_crewai.ipynb",children:(0,a.jsx)("img",{src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"Open In Colab"})}),"\n",(0,a.jsxs)(t.p,{children:["CrewAI is a lean, lightning-fast Python framework built entirely from scratch\u2014completely independent of LangChain or other agent frameworks. CrewAI empowers developers with both high-level simplicity (",(0,a.jsx)(t.a,{href:"https://docs.crewai.com/guides/crews/first-crew",children:"Crews"}),") and precise low-level control (",(0,a.jsx)(t.a,{href:"https://docs.crewai.com/guides/flows/first-flow",children:"Flows"}),"), ideal for creating autonomous AI agents tailored to any scenario. Learn more about ",(0,a.jsx)(t.a,{href:"https://docs.crewai.com/introduction",children:"CrewAI here"}),"."]}),"\n",(0,a.jsx)(t.p,{children:"When working with AI agents, debugging and monitoring their interactions is crucial. CrewAI applications often consist of multiple agents working together, making it essential to understand how they collaborate and communicate. Weave simplifies this process by automatically capturing traces for your CrewAI applications, enabling you to monitor and analyze your agents' performance and interactions."}),"\n",(0,a.jsx)(t.p,{children:"The integration supports both Crews and Flows."}),"\n",(0,a.jsx)(t.h2,{id:"getting-started-with-crew",children:"Getting Started with Crew"}),"\n",(0,a.jsxs)(t.p,{children:["You need to install CrewAI (",(0,a.jsx)(t.a,{href:"https://docs.crewai.com/installation",children:"more details"}),") and weave to run this example:"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{children:"pip install crewai weave\n"})}),"\n",(0,a.jsxs)(t.p,{children:["Now we will create a CrewAI Crew and trace the execution using Weave. To get started, simply call ",(0,a.jsx)(t.code,{children:"weave.init()"})," at the beginning of your script. The argument in weave.init() is a project name where the traces will be logged."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"import weave\nfrom crewai import Agent, Task, Crew, LLM, Process\n\n# Initialize Weave with your project name\n# highlight-next-line\nweave.init(project_name=\"crewai_demo\")\n\n# Create an LLM with a temperature of 0 to ensure deterministic outputs\nllm = LLM(model=\"gpt-4o-mini\", temperature=0)\n\n# Create agents\nresearcher = Agent(\n    role='Research Analyst',\n    goal='Find and analyze the best investment opportunities',\n    backstory='Expert in financial analysis and market research',\n    llm=llm,\n    verbose=True,\n    allow_delegation=False,\n)\n\nwriter = Agent(\n    role='Report Writer',\n    goal='Write clear and concise investment reports',\n    backstory='Experienced in creating detailed financial reports',\n    llm=llm,\n    verbose=True,\n    allow_delegation=False,\n)\n\n# Create tasks\nresearch_task = Task(\n    description='Deep research on the {topic}',\n    expected_output='Comprehensive market data including key players, market size, and growth trends.',\n    agent=researcher\n)\n\nwriting_task = Task(\n    description='Write a detailed report based on the research',\n    expected_output='The report should be easy to read and understand. Use bullet points where applicable.',\n    agent=writer\n)\n\n# Create a crew\ncrew = Crew(\n    agents=[researcher, writer],\n    tasks=[research_task, writing_task],\n    verbose=True,\n    process=Process.sequential,\n)\n\n# Run the crew\nresult = crew.kickoff(inputs={\"topic\": \"AI in material science\"})\nprint(result)\n"})}),"\n",(0,a.jsx)(t.p,{children:"Weave will track and log all calls made through the CrewAI library, including agent interactions, task executions, and LLM calls. You can view the traces in the Weave web interface."}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.a,{href:"https://wandb.ai/ayut/crewai_demo/weave/traces?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fayut%2Fcrewai_demo%2Fop%2Fcrewai.Crew.kickoff%3A*%22%5D%7D&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c7ac-bd52-7390-95a7-309370e9e058%3FhideTraceTree%3D0&cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D",children:(0,a.jsx)(t.img,{alt:"crew_trace.png",src:n(43442).Z+"",width:"3456",height:"1998"})})}),"\n",(0,a.jsx)(t.admonition,{type:"note",children:(0,a.jsxs)(t.p,{children:["CrewAI provides several methods for better control over the kickoff process: ",(0,a.jsx)(t.code,{children:"kickoff()"}),", ",(0,a.jsx)(t.code,{children:"kickoff_for_each()"}),", ",(0,a.jsx)(t.code,{children:"kickoff_async()"}),", and ",(0,a.jsx)(t.code,{children:"kickoff_for_each_async()"}),". The integration supports logging traces from all these methods."]})}),"\n",(0,a.jsx)(t.h2,{id:"track-tools",children:"Track Tools"}),"\n",(0,a.jsx)(t.p,{children:"CrewAI tools empower agents with capabilities ranging from web searching and data analysis to collaboration and delegating tasks among coworkers. The integration can trace them as well."}),"\n",(0,a.jsx)(t.p,{children:"We will improve the quality of the generated report in the above example by giving it access to a tool that can search the internet and return the most relevant results."}),"\n",(0,a.jsx)(t.p,{children:"Let us first install the extra dependency."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{children:"pip install 'crewai[tools]'\n"})}),"\n",(0,a.jsxs)(t.p,{children:["In this example, we are using the ",(0,a.jsx)(t.code,{children:"SerperDevTool"})," to enable our 'Research Analyst' agent to search relevant information on the internet. Learn more about this tool and API requirements ",(0,a.jsx)(t.a,{href:"https://docs.crewai.com/tools/serperdevtool",children:"here"}),"."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"# .... existing imports ....\nfrom crewai_tools import SerperDevTool\n\n# We provide the agent with the tool.\nresearcher = Agent(\n    role='Research Analyst',\n    goal='Find and analyze the best investment opportunities',\n    backstory='Expert in financial analysis and market research',\n    llm=llm,\n    verbose=True,\n    allow_delegation=False,\n    # highlight-next-line\n    tools=[SerperDevTool()],\n)\n\n# .... existing code ....\n"})}),"\n",(0,a.jsx)(t.p,{children:"Running this Crew with an agent with access to internet produces better and more relevant result. We automatically trace the tool usage as shown in the image below."}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.a,{href:"https://wandb.ai/ayut/crewai_demo/weave/traces?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fayut%2Fcrewai_demo%2Fop%2Fcrewai.Crew.kickoff%3A*%22%5D%7D&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c7c7-0213-7f42-b130-caa93a79316c%3FdescendentCallId%3D0195c7c7-0a16-7f11-8cfd-9dedf1d03b3b&cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D",children:(0,a.jsx)(t.img,{alt:"crew_with_tool_trace.png",src:n(16874).Z+"",width:"3454",height:"1996"})})}),"\n",(0,a.jsx)(t.admonition,{type:"note",children:(0,a.jsxs)(t.p,{children:["The integration automatically patches all the tools available in the ",(0,a.jsx)(t.a,{href:"https://github.com/crewAIInc/crewAI-tools",children:(0,a.jsx)(t.code,{children:"crewAI-tools"})})," repository."]})}),"\n",(0,a.jsx)(t.h2,{id:"getting-started-with-flow",children:"Getting Started with Flow"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'import weave\n# Initialize Weave with your project name\n# highlight-next-line\nweave.init("crewai_demo")\n\nfrom crewai.flow.flow import Flow, listen, router, start\nfrom litellm import completion\n\n\nclass CustomerFeedbackFlow(Flow):\n    model = "gpt-4o-mini"\n\n    @start()\n    def fetch_feedback(self):\n        print("Fetching customer feedback")\n        # In a real-world scenario, this could be replaced by an API call.\n        # For this example, we simulate customer feedback.\n        feedback = (\n            "I had a terrible experience with the product. "\n            "It broke after one use and customer service was unhelpful."\n        )\n        self.state["feedback"] = feedback\n        return feedback\n\n    @router(fetch_feedback)\n    def analyze_feedback(self, feedback):\n        # Use the language model to analyze sentiment\n        prompt = (\n            f"Analyze the sentiment of this customer feedback and "\n            "return only \'positive\' or \'negative\':\\n\\n"\n            f"Feedback: {feedback}"\n        )\n        response = completion(\n            model=self.model,\n            messages=[{"role": "user", "content": prompt}],\n        )\n        sentiment = response["choices"][0]["message"]["content"].strip().lower()\n        # If the response is ambiguous, default to negative\n        if sentiment not in ["positive", "negative"]:\n            sentiment = "negative"\n        return sentiment\n\n    @listen("positive")\n    def handle_positive_feedback(self):\n        # Generate a thank you message for positive feedback\n        prompt = "Generate a thank you message for a customer who provided positive feedback."\n        response = completion(\n            model=self.model,\n            messages=[{"role": "user", "content": prompt}],\n        )\n        thank_you_message = response["choices"][0]["message"]["content"].strip()\n        self.state["response"] = thank_you_message\n        return thank_you_message\n\n    @listen("negative")\n    def handle_negative_feedback(self):\n        # Generate an apology message with a promise to improve service for negative feedback\n        prompt = (\n            "Generate an apology message to a customer who provided negative feedback and offer assistance or a solution."\n        )\n        response = completion(\n            model=self.model,\n            messages=[{"role": "user", "content": prompt}],\n        )\n        apology_message = response["choices"][0]["message"]["content"].strip()\n        self.state["response"] = apology_message\n        return apology_message\n\n# Instantiate and kickoff the flow\nflow = CustomerFeedbackFlow()\nresult = flow.kickoff()\nprint(result)\n'})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.a,{href:"https://wandb.ai/ayut/crewai_demo/weave/traces?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fayut%2Fcrewai_demo%2Fop%2Fcrewai.Flow.kickoff%3A*%22%5D%7D&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c7e3-7a63-7283-bef4-9e0eb2f0eab1&cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D",children:(0,a.jsx)(t.img,{alt:"flow.png",src:n(90617).Z+"",width:"3456",height:"1996"})})}),"\n",(0,a.jsx)(t.admonition,{type:"note",children:(0,a.jsxs)(t.p,{children:["The integration automatically patches the ",(0,a.jsx)(t.code,{children:"Flow.kickoff"})," entry point and all the available decorators -- ",(0,a.jsx)(t.code,{children:"@start"}),", ",(0,a.jsx)(t.code,{children:"@listen"}),", ",(0,a.jsx)(t.code,{children:"@router"}),", ",(0,a.jsx)(t.code,{children:"@or_"})," and ",(0,a.jsx)(t.code,{children:"@and_"}),"."]})}),"\n",(0,a.jsx)(t.h2,{id:"crew-guardrail---track-your-own-ops",children:"Crew Guardrail - Track your own ops"}),"\n",(0,a.jsx)(t.p,{children:"Task guardrails provide a way to validate and transform task outputs before they are passed to the next task. We can use a simple python function to validate the agent's execution on-the-fly."}),"\n",(0,a.jsxs)(t.p,{children:["Wrapping this function with ",(0,a.jsx)(t.code,{children:"@weave.op"})," starts capturing inputs, outputs and app logic so you can debug how data is validated through your agents. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git."]}),"\n",(0,a.jsx)(t.p,{children:"Let's take the example of research analyst and writer. We add a guardrail to validate the length of the generated report."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'# .... existing imports and weave initialization ....\n\n# Decorate your guardrail function with `@weave.op()`\n# highlight-next-line\n@weave.op(name="guardrail-validate_blog_content")\ndef validate_blog_content(result: TaskOutput) -> Tuple[bool, Any]:\n    # Get raw string result\n    result = result.raw\n\n    """Validate blog content meets requirements."""\n    try:\n        # Check word count\n        word_count = len(result.split())\n\n        if word_count > 200:\n            return (False, {\n                "error": "Blog content exceeds 200 words",\n                "code": "WORD_COUNT_ERROR",\n                "context": {"word_count": word_count}\n            })\n\n        # Additional validation logic here\n        return (True, result.strip())\n    except Exception as e:\n        return (False, {\n            "error": "Unexpected error during validation",\n            "code": "SYSTEM_ERROR"\n        })\n\n\n# .... existing agents and research analyst task ....\n\nwriting_task = Task(\n    description=\'Write a detailed report based on the research under 200 words\',\n    expected_output=\'The report should be easy to read and understand. Use bullet points where applicable.\',\n    agent=writer,\n    # highlight-next-line\n    guardrail=validate_blog_content,\n)\n\n# .... existing code to run crew ....\n'})}),"\n",(0,a.jsxs)(t.p,{children:["By simply decorating the guardrail function with ",(0,a.jsx)(t.code,{children:"@weave.op"})," we are able to keep track of the input and output to this function along with execution time, token information if an LLM is used under the hood, code version and more."]}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.a,{href:"https://wandb.ai/ayut/crewai_demo/weave/traces?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fayut%2Fcrewai_demo%2Fop%2Fcrewai.Crew.kickoff%3A*%22%5D%7D&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c838-38cb-71a2-8a15-651ecddf9d89%3FdescendentCallId%3D0195c838-8632-7173-846d-f230e7272c20&cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D",children:(0,a.jsx)(t.img,{alt:"guardrail.png",src:n(13493).Z+"",width:"3456",height:"1994"})})}),"\n",(0,a.jsx)(t.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,a.jsxs)(t.p,{children:["Do let us know what we should improve about this integration. Please open an issue if you encounter one ",(0,a.jsx)(t.a,{href:"https://github.com/wandb/weave/issues/new/choose",children:"here"}),"."]}),"\n",(0,a.jsxs)(t.p,{children:["Learn more about how to build powerful multiagent systems using CrewAI through their ",(0,a.jsx)(t.a,{href:"https://github.com/crewAIInc/crewAI-examples",children:"many examples"})," and ",(0,a.jsx)(t.a,{href:"https://docs.crewai.com/introduction",children:"documentation"}),"."]})]})}function h(e={}){const{wrapper:t}={...(0,r.a)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},43442:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/crew-d62116b8fda917106f979e0a3bfee038.png"},13493:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/crew_with_guardrail-1161b56634f89cf90d06146cacea9edf.png"},16874:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/crew_with_tool-9cbe763c126dfc7f0f3cbdfefe18a273.png"},90617:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/flow-35254b39399d9faa1e7449466b6c3743.png"},11151:(e,t,n)=>{n.d(t,{Z:()=>o,a:()=>i});var a=n(67294);const r={},s=a.createContext(r);function i(e){const t=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),a.createElement(s.Provider,{value:t},e.children)}}}]);