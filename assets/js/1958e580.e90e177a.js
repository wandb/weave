"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8863],{81496:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>s,default:()=>u,frontMatter:()=>o,metadata:()=>r,toc:()=>l});var a=t(85893),i=t(11151);const o={title:"Using HuggingFace Datasets in evaluations with `preprocess_model_input`"},s="Using HuggingFace Datasets in evaluations with preprocess_model_input",r={id:"reference/gen_notebooks/hf_dataset_evals",title:"Using HuggingFace Datasets in evaluations with `preprocess_model_input`",description:"Open in Colab",source:"@site/docs/reference/gen_notebooks/hf_dataset_evals.md",sourceDirName:"reference/gen_notebooks",slug:"/reference/gen_notebooks/hf_dataset_evals",permalink:"/reference/gen_notebooks/hf_dataset_evals",draft:!1,unlisted:!1,editUrl:"https://github.com/wandb/weave/blob/master/docs/docs/reference/gen_notebooks/hf_dataset_evals.md",tags:[],version:"current",lastUpdatedAt:1738860822e3,frontMatter:{title:"Using HuggingFace Datasets in evaluations with `preprocess_model_input`"},sidebar:"notebookSidebar",previous:{title:"Log Feedback from Production",permalink:"/reference/gen_notebooks/feedback_prod"},next:{title:"Log Calls from Existing CSV",permalink:"/reference/gen_notebooks/import_from_csv"}},d={},l=[{value:"Note: This is a temporary workaround",id:"note-this-is-a-temporary-workaround",level:2},{value:"Setup and imports",id:"setup-and-imports",level:2},{value:"Load and prepare HuggingFace dataset",id:"load-and-prepare-huggingface-dataset",level:2},{value:"Define processing and evaluation functions",id:"define-processing-and-evaluation-functions",level:2},{value:"Processing pipeline",id:"processing-pipeline",level:3},{value:"Create and run evaluation",id:"create-and-run-evaluation",level:3}];function c(e){const n={admonition:"admonition",blockquote:"blockquote",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(n.admonition,{title:"This is a notebook",type:"tip",children:[(0,a.jsx)("a",{href:"https://colab.research.google.com/github/wandb/weave/blob/master/docs/./notebooks/hf_dataset_evals.ipynb",target:"_blank",rel:"noopener noreferrer",class:"navbar__item navbar__link button button--secondary button--med margin-right--sm notebook-cta-button",children:(0,a.jsxs)("div",{children:[(0,a.jsx)("img",{src:"https://upload.wikimedia.org/wikipedia/commons/archive/d/d0/20221103151430%21Google_Colaboratory_SVG_Logo.svg",alt:"Open In Colab",height:"20px"}),(0,a.jsx)("div",{children:"Open in Colab"})]})}),(0,a.jsx)("a",{href:"https://github.com/wandb/weave/blob/master/docs/./notebooks/hf_dataset_evals.ipynb",target:"_blank",rel:"noopener noreferrer",class:"navbar__item navbar__link button button--secondary button--med margin-right--sm notebook-cta-button",children:(0,a.jsxs)("div",{children:[(0,a.jsx)("img",{src:"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg",alt:"View in Github",height:"15px"}),(0,a.jsx)("div",{children:"View in Github"})]})})]}),"\n",(0,a.jsxs)(n.h1,{id:"using-huggingface-datasets-in-evaluations-with-preprocess_model_input",children:["Using HuggingFace Datasets in evaluations with ",(0,a.jsx)(n.code,{children:"preprocess_model_input"})]}),"\n",(0,a.jsx)(n.h2,{id:"note-this-is-a-temporary-workaround",children:"Note: This is a temporary workaround"}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:["This guide demonstrates a workaround for using HuggingFace Datasets with Weave evaluations.",(0,a.jsx)("br",{}),(0,a.jsx)("br",{}),"\nWe are actively working on developing more seamless integrations that will simplify this process.",(0,a.jsx)(n.br,{}),"\n","While this approach works, expect improvements and updates in the near future that will make working with external datasets more straightforward."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"setup-and-imports",children:"Setup and imports"}),"\n",(0,a.jsx)(n.p,{children:"First, we initialize Weave and connect to Weights & Biases for tracking experiments."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!pip install datasets wandb weave\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Initialize variables\nHUGGINGFACE_DATASET = "wandb/ragbench-test-sample"\nWANDB_KEY = ""\nWEAVE_TEAM = ""\nWEAVE_PROJECT = ""\n\n# Init weave and required libraries\nimport asyncio\n\nimport nest_asyncio\nimport wandb\nfrom datasets import load_dataset\n\nimport weave\nfrom weave import Evaluation\n\n# Login to wandb and initialize weave\nwandb.login(key=WANDB_KEY)\nclient = weave.init(f"{WEAVE_TEAM}/{WEAVE_PROJECT}")\n\n# Apply nest_asyncio to allow nested event loops (needed for some notebook environments)\nnest_asyncio.apply()\n'})}),"\n",(0,a.jsx)(n.h2,{id:"load-and-prepare-huggingface-dataset",children:"Load and prepare HuggingFace dataset"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"We load a HuggingFace dataset."}),"\n",(0,a.jsx)(n.li,{children:"Create an index mapping to reference the dataset rows."}),"\n",(0,a.jsx)(n.li,{children:"This index approach allows us to maintain references to the original dataset."}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"}),(0,a.jsx)("br",{}),"\nIn the index, we encode the ",(0,a.jsx)(n.code,{children:"hf_hub_name"})," along with the ",(0,a.jsx)(n.code,{children:"hf_id"})," to ensure each row has a unique identifier.",(0,a.jsx)(n.br,{}),"\n","This unique digest value is used for tracking and referencing specific dataset entries during evaluations."]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Load the HuggingFace dataset\nds = load_dataset(HUGGINGFACE_DATASET)\nrow_count = ds["train"].num_rows\n\n# Create an index mapping for the dataset\n# This creates a list of dictionaries with HF dataset indices\n# Example: [{"hf_id": 0}, {"hf_id": 1}, {"hf_id": 2}, ...]\nhf_index = [{"hf_id": i, "hf_hub_name": HUGGINGFACE_DATASET} for i in range(row_count)]\n'})}),"\n",(0,a.jsx)(n.h2,{id:"define-processing-and-evaluation-functions",children:"Define processing and evaluation functions"}),"\n",(0,a.jsx)(n.h3,{id:"processing-pipeline",children:"Processing pipeline"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"preprocess_example"}),": Transforms the index reference into the actual data needed for evaluation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"hf_eval"}),": Defines how to score the model outputs"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"function_to_evaluate"}),": The actual function/model being evaluated"]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'@weave.op()\ndef preprocess_example(example):\n    """\n    Preprocesses each example before evaluation.\n    Args:\n        example: Dict containing hf_id\n    Returns:\n        Dict containing the prompt from the HF dataset\n    """\n    hf_row = ds["train"][example["hf_id"]]\n    return {"prompt": hf_row["question"], "answer": hf_row["response"]}\n\n\n@weave.op()\ndef hf_eval(hf_id: int, output: dict) -> dict:\n    """\n    Scoring function for evaluating model outputs.\n    Args:\n        hf_id: Index in the HF dataset\n        output: The output from the model to evaluate\n    Returns:\n        Dict containing evaluation scores\n    """\n    hf_row = ds["train"][hf_id]\n    return {"scorer_value": True}\n\n\n@weave.op()\ndef function_to_evaluate(prompt: str):\n    """\n    The function that will be evaluated (e.g., your model or pipeline).\n    Args:\n        prompt: Input prompt from the dataset\n    Returns:\n        Dict containing model output\n    """\n    return {"generated_text": "testing "}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"create-and-run-evaluation",children:"Create and run evaluation"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["For each index in hf_index:","\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"preprocess_example"})," gets the corresponding data from the HF dataset."]}),"\n",(0,a.jsxs)(n.li,{children:["The preprocessed data is passed to ",(0,a.jsx)(n.code,{children:"function_to_evaluate"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["The output is scored using ",(0,a.jsx)(n.code,{children:"hf_eval"}),"."]}),"\n",(0,a.jsx)(n.li,{children:"Results are tracked in Weave."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# Create evaluation object\nevaluation = Evaluation(\n    dataset=hf_index,  # Use our index mapping\n    scorers=[hf_eval],  # List of scoring functions\n    preprocess_model_input=preprocess_example,  # Function to prepare inputs\n)\n\n\n# Run evaluation asynchronously\nasync def main():\n    await evaluation.evaluate(function_to_evaluate)\n\n\nasyncio.run(main())\n"})})]})}function u(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},11151:(e,n,t)=>{t.d(n,{Z:()=>r,a:()=>s});var a=t(67294);const i={},o=a.createContext(i);function s(e){const n=a.useContext(o);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);