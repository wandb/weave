"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1022],{5287:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>l});var s=t(85893),a=t(11151);const o={title:"Log Feedback from Production"},i=void 0,r={id:"reference/gen_notebooks/feedback_prod",title:"Log Feedback from Production",description:"Open in Colab",source:"@site/docs/reference/gen_notebooks/feedback_prod.md",sourceDirName:"reference/gen_notebooks",slug:"/reference/gen_notebooks/feedback_prod",permalink:"/reference/gen_notebooks/feedback_prod",draft:!1,unlisted:!1,editUrl:"https://github.com/wandb/weave/blob/master/docs/docs/reference/gen_notebooks/feedback_prod.md",tags:[],version:"current",lastUpdatedAt:1749652482e3,frontMatter:{title:"Log Feedback from Production"},sidebar:"notebookSidebar",previous:{title:"Prompt Optimization",permalink:"/reference/gen_notebooks/dspy_prompt_optimization"},next:{title:"Using HuggingFace Datasets in evaluations with `preprocess_model_input`",permalink:"/reference/gen_notebooks/hf_dataset_evals"}},c={},l=[{value:"Setup",id:"setup",level:2},{value:"Explanation",id:"explanation",level:2},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const n={admonition:"admonition",code:"code",em:"em",h2:"h2",p:"p",pre:"pre",...(0,a.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(n.admonition,{title:"This is a notebook",type:"tip",children:[(0,s.jsx)("a",{href:"https://colab.research.google.com/github/wandb/weave/blob/master/docs/./notebooks/feedback_prod.ipynb",target:"_blank",rel:"noopener noreferrer",class:"navbar__item navbar__link button button--secondary button--med margin-right--sm notebook-cta-button",children:(0,s.jsxs)("div",{children:[(0,s.jsx)("img",{src:"https://upload.wikimedia.org/wikipedia/commons/archive/d/d0/20221103151430%21Google_Colaboratory_SVG_Logo.svg",alt:"Open In Colab",height:"20px"}),(0,s.jsx)("div",{children:"Open in Colab"})]})}),(0,s.jsx)("a",{href:"https://github.com/wandb/weave/blob/master/docs/./notebooks/feedback_prod.ipynb",target:"_blank",rel:"noopener noreferrer",class:"navbar__item navbar__link button button--secondary button--med margin-right--sm notebook-cta-button",children:(0,s.jsxs)("div",{children:[(0,s.jsx)("img",{src:"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg",alt:"View in Github",height:"15px"}),(0,s.jsx)("div",{children:"View in Github"})]})})]}),"\n",(0,s.jsx)(n.p,{children:"It is often hard to automatically evaluate a generated LLM response so, depending on your risk tolerance, you can gather direct user feedback to find areas to improve."}),"\n",(0,s.jsx)(n.p,{children:"In this tutorial, we'll use a custom chatbot as an example app from which to collect user feedback.\nWe'll use Streamlit to build the interface and we'll capture the LLM interactions and feedback in Weave."}),"\n",(0,s.jsx)(n.h2,{id:"setup",children:"Setup"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"!pip install weave openai streamlit wandb\n!pip install set-env-colab-kaggle-dotenv -q # for env var\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Add a .env file with your OpenAI and WandB API keys\nfrom set_env import set_env\n\n_ = set_env("OPENAI_API_KEY")\n_ = set_env("WANDB_API_KEY")\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Next, create a file called ",(0,s.jsx)(n.code,{children:"chatbot.py"})," with the following contents:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# chatbot.py\n\nimport openai\nimport streamlit as st\nimport wandb\nfrom set_env import set_env\n\nimport weave\n\n_ = set_env("OPENAI_API_KEY")\n_ = set_env("WANDB_API_KEY")\n\n# highlight-next-line\nwandb.login()\n\n# highlight-next-line\nweave_client = weave.init("feedback-example")\noai_client = openai.OpenAI()\n\n\ndef init_states():\n    """Set up session_state keys if they don\'t exist yet."""\n    if "messages" not in st.session_state:\n        st.session_state["messages"] = []\n    if "calls" not in st.session_state:\n        st.session_state["calls"] = []\n    if "session_id" not in st.session_state:\n        st.session_state["session_id"] = "123abc"\n\n\n# highlight-next-line\n@weave.op\ndef chat_response(full_history):\n    """\n    Calls the OpenAI API in streaming mode given the entire conversation history so far.\n    full_history is a list of dicts: [{"role":"user"|"assistant","content":...}, ...]\n    """\n    stream = oai_client.chat.completions.create(\n        model="gpt-4", messages=full_history, stream=True\n    )\n    response_text = st.write_stream(stream)\n    return {"response": response_text}\n\n\ndef render_feedback_buttons(call_idx):\n    """Renders thumbs up/down and text feedback for the call."""\n    col1, col2, col3 = st.columns([1, 1, 4])\n\n    # Thumbs up button\n    with col1:\n        if st.button("\ud83d\udc4d", key=f"thumbs_up_{call_idx}"):\n            st.session_state.calls[call_idx].feedback.add_reaction("\ud83d\udc4d")\n            st.success("Thanks for the feedback!")\n\n    # Thumbs down button\n    with col2:\n        if st.button("\ud83d\udc4e", key=f"thumbs_down_{call_idx}"):\n            st.session_state.calls[call_idx].feedback.add_reaction("\ud83d\udc4e")\n            st.success("Thanks for the feedback!")\n\n    # Text feedback\n    with col3:\n        feedback_text = st.text_input("Feedback", key=f"feedback_input_{call_idx}")\n        if st.button("Submit Feedback", key=f"submit_feedback_{call_idx}"):\n            if feedback_text:\n                st.session_state.calls[call_idx].feedback.add_note(feedback_text)\n                st.success("Feedback submitted!")\n\n\ndef display_old_messages():\n    """Displays the conversation stored in st.session_state.messages with feedback buttons"""\n    for idx, message in enumerate(st.session_state.messages):\n        with st.chat_message(message["role"]):\n            st.markdown(message["content"])\n\n            # If it\'s an assistant message, show feedback form\n            if message["role"] == "assistant":\n                # Figure out index of this assistant message in st.session_state.calls\n                assistant_idx = (\n                    len(\n                        [\n                            m\n                            for m in st.session_state.messages[: idx + 1]\n                            if m["role"] == "assistant"\n                        ]\n                    )\n                    - 1\n                )\n                # Render thumbs up/down & text feedback\n                if assistant_idx < len(st.session_state.calls):\n                    render_feedback_buttons(assistant_idx)\n\n\ndef display_chat_prompt():\n    """Displays the chat prompt input box."""\n    if prompt := st.chat_input("Ask me anything!"):\n        # Immediately render new user message\n        with st.chat_message("user"):\n            st.markdown(prompt)\n\n        # Save user message in session\n        st.session_state.messages.append({"role": "user", "content": prompt})\n\n        # Prepare chat history for the API\n        full_history = [\n            {"role": msg["role"], "content": msg["content"]}\n            for msg in st.session_state.messages\n        ]\n\n        with st.chat_message("assistant"):\n            # Attach Weave attributes for tracking of conversation instances\n            with weave.attributes(\n                {"session": st.session_state["session_id"], "env": "prod"}\n            ):\n                # Call the OpenAI API (stream)\n                result, call = chat_response.call(full_history)\n\n                # Store the assistant message\n                st.session_state.messages.append(\n                    {"role": "assistant", "content": result["response"]}\n                )\n\n                # Store the weave call object to link feedback to the specific response\n                st.session_state.calls.append(call)\n\n                # Render feedback buttons for the new message\n                new_assistant_idx = (\n                    len(\n                        [\n                            m\n                            for m in st.session_state.messages\n                            if m["role"] == "assistant"\n                        ]\n                    )\n                    - 1\n                )\n\n                # Render feedback buttons\n                if new_assistant_idx < len(st.session_state.calls):\n                    render_feedback_buttons(new_assistant_idx)\n\n\ndef main():\n    st.title("Chatbot with immediate feedback forms")\n    init_states()\n    display_old_messages()\n    display_chat_prompt()\n\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,s.jsxs)(n.p,{children:["You can run this with ",(0,s.jsx)(n.code,{children:"streamlit run chatbot.py"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"Now, you can interact with this application and click the feedback buttons after each response.\nVisit the Weave UI to see the attached feedback."}),"\n",(0,s.jsx)(n.h2,{id:"explanation",children:"Explanation"}),"\n",(0,s.jsx)(n.p,{children:"If we consider our decorated prediction function as:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import weave\n\nweave.init("feedback-example")\n\n\n# highlight-next-line\n@weave.op\ndef predict(input_data):\n    # Your prediction logic here\n    some_result = "hello world"\n    return some_result\n'})}),"\n",(0,s.jsx)(n.p,{children:"We can use it as usual to deliver some model response to the user:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'with weave.attributes(\n    {"session": "123abc", "env": "prod"}\n):  # attach arbitrary attributes to the call alongside inputs & outputs\n    result = predict(input_data="your data here")  # user question through the App UI\n'})}),"\n",(0,s.jsxs)(n.p,{children:["To attach feedback, you need the ",(0,s.jsx)(n.code,{children:"call"})," object, which is obtained by using the ",(0,s.jsx)(n.code,{children:".call()"})," method ",(0,s.jsx)(n.em,{children:"instead of calling the function as normal"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'result, call = predict.call(input_data="your data here")\n'})}),"\n",(0,s.jsxs)(n.p,{children:["This call object is needed for attaching feedback to the specific response.\nAfter making the call, the output of the operation is available using ",(0,s.jsx)(n.code,{children:"result"})," above."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'call.feedback.add_reaction("\ud83d\udc4d")  # user reaction through the App UI\n'})}),"\n",(0,s.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,s.jsx)(n.p,{children:"In this tutorial, we built a chat UI with Streamlit which had inputs & outputs captured in Weave, alongside \ud83d\udc4d\ud83d\udc4e buttons to capture user feedback."})]})}function h(e={}){const{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},11151:(e,n,t)=>{t.d(n,{Z:()=>r,a:()=>i});var s=t(67294);const a={},o=s.createContext(a);function i(e){const n=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);