"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7411],{20824:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>r,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var i=t(85893),a=t(11151);const o={},r="FAQs",s={id:"guides/tracking/faqs",title:"FAQs",description:"The following page provides answers to common questions about Weave tracing.",source:"@site/docs/guides/tracking/faqs.md",sourceDirName:"guides/tracking",slug:"/guides/tracking/faqs",permalink:"/guides/tracking/faqs",draft:!1,unlisted:!1,editUrl:"https://github.com/wandb/weave/blob/master/docs/docs/guides/tracking/faqs.md",tags:[],version:"current",lastUpdatedAt:1749652482e3,frontMatter:{},sidebar:"documentationSidebar",previous:{title:"Troubleshooting",permalink:"/guides/troubleshooting"}},d={},l=[{value:"What information does Weave capture for a function?",id:"what-information-does-weave-capture-for-a-function",level:2},{value:"How can I disable code capture?",id:"how-can-i-disable-code-capture",level:2},{value:"How can I disable system information capture?",id:"how-can-i-disable-system-information-capture",level:2},{value:"How can I disable client information capture?",id:"how-can-i-disable-client-information-capture",level:2},{value:"How do I render Python datetime values in the UI?",id:"how-do-i-render-python-datetime-values-in-the-ui",level:2},{value:"How do I render Markdown in the UI?",id:"how-do-i-render-markdown-in-the-ui",level:2},{value:"Will Weave affect my function&#39;s execution speed?",id:"will-weave-affect-my-functions-execution-speed",level:2},{value:"How is Weave data ingestion calculated?",id:"how-is-weave-data-ingestion-calculated",level:2},{value:"What is pairwise evaluation and how do I do it?",id:"what-is-pairwise-evaluation-and-how-do-i-do-it",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"faqs",children:"FAQs"}),"\n",(0,i.jsx)(n.p,{children:"The following page provides answers to common questions about Weave tracing."}),"\n",(0,i.jsx)(n.h2,{id:"what-information-does-weave-capture-for-a-function",children:"What information does Weave capture for a function?"}),"\n",(0,i.jsxs)(n.p,{children:["A function can be designated as a Weave ",(0,i.jsx)(n.a,{href:"/guides/tracking/ops",children:"Op"})," either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Code capture"})," - Weave captures a representation of the Op's source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Function name, inputs, and outputs"})," - The name of the function will be captured but can be ",(0,i.jsx)(n.a,{href:"/guides/tracking/tracing/#call-display-name",children:"overridden"}),". A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you ",(0,i.jsx)(n.a,{href:"/guides/tracking/ops#customize-logged-inputs-and-outputs",children:"customize the logging"})," of inputs and outputs - you can specify a function to add/remove/modify what is logged."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Op call hierarchy"}),' - When an Op is called within the context of another Op executing, this relationship is captured, even in cases\nwhere there is an intermediate non-Op function executing. This relationship between Op calls is used to provide a "Trace tree".']}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Execution status and exceptions"})," - Weave tracks whether a function is executing, finished, or errored. If an exception occurs during execution the error message and a stack track is recorded."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"System information"})," - Weave may capture information about which operating system the client is running on including detailed version information."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Client information"})," - Weave may capture information about the Weave client itself, such as the programming language in use and detailed version information for that language and the Weave client library."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Timing"})," - The execution start and end time is captured and also used for latency calculations."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Token usage"})," - In some ",(0,i.jsx)(n.a,{href:"/guides/integrations/",children:"integrations"})," LLM token usage counts may be automatically logged."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"User and run context"})," - Logging is associated with a W&B user account. That will be captured along with any wandb Run context."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Derived information"})," - Weave may compute derived information from the raw information logged, for example a cost estimate may be calculated based on token usage and knowledge of the model used. Weave also aggregates some information over calls."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Additional information you choose"})," - You can choose to log ",(0,i.jsxs)(n.a,{href:"/guides/core-types/models#track-production-calls",children:["custom metadata with ",(0,i.jsx)(n.code,{children:"weave.attributes"})]})," as part of your call or attach ",(0,i.jsx)(n.a,{href:"/guides/tracking/feedback#add-feedback-to-a-call",children:"feedback"})," to a call."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"how-can-i-disable-code-capture",children:"How can I disable code capture?"}),"\n",(0,i.jsxs)(n.p,{children:["You can disable code capture during Weave client initialization: ",(0,i.jsx)(n.code,{children:'weave.init("entity/project", settings={"capture_code": False})'}),".\nYou can also use the ",(0,i.jsx)(n.a,{href:"/guides/core-types/env-vars",children:"environment variable"})," ",(0,i.jsx)(n.code,{children:"WEAVE_CAPTURE_CODE=false"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"how-can-i-disable-system-information-capture",children:"How can I disable system information capture?"}),"\n",(0,i.jsxs)(n.p,{children:["You can disable system information capture during Weave client initialization: ",(0,i.jsx)(n.code,{children:'weave.init("entity/project", settings={"capture_system_info": False})'}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"how-can-i-disable-client-information-capture",children:"How can I disable client information capture?"}),"\n",(0,i.jsxs)(n.p,{children:["You can disable client information capture during Weave client initialization: ",(0,i.jsx)(n.code,{children:'weave.init("entity/project", settings={"capture_client_info": False})'}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"how-do-i-render-python-datetime-values-in-the-ui",children:"How do I render Python datetime values in the UI?"}),"\n",(0,i.jsxs)(n.p,{children:["Use Python\u2019s ",(0,i.jsx)(n.code,{children:"datetime.datetime"})," (with timezone info), and publish the object using ",(0,i.jsx)(n.code,{children:"weave.publish(...)"}),". Weave recognizes this type and renders it as a timestamp."]}),"\n",(0,i.jsx)(n.h2,{id:"how-do-i-render-markdown-in-the-ui",children:"How do I render Markdown in the UI?"}),"\n",(0,i.jsxs)(n.p,{children:["Wrap your string with ",(0,i.jsx)(n.code,{children:"weave.Markdown(...)"})," before saving, and use ",(0,i.jsx)(n.code,{children:"weave.publish(...)"})," to store it. Weave uses the object\u2019s type to determine rendering, and ",(0,i.jsx)(n.code,{children:"weave.Markdown"})," maps to a known UI renderer.  The value will be shown as a formatted Markdown object in the UI. For a full code sample, see ",(0,i.jsx)(n.a,{href:"/guides/tracking/tracing#viewing-calls",children:"Viewing calls"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"will-weave-affect-my-functions-execution-speed",children:"Will Weave affect my function's execution speed?"}),"\n",(0,i.jsx)(n.p,{children:"The overhead of Weave logging is typically negligible compared to making a call to an LLM.\nTo minimize Weave's impact on the speed of your Op's execution, its network activity happens on a background thread.\nWhen your program is exiting it may appear to pause while any remaining enqueued data is logged."}),"\n",(0,i.jsx)(n.h2,{id:"how-is-weave-data-ingestion-calculated",children:"How is Weave data ingestion calculated?"}),"\n",(0,i.jsx)(n.p,{children:'We define ingested bytes as bytes that we receive, process, and store on your behalf. This includes trace metadata, LLM inputs/outputs, and any other information you explicitly log to Weave, but does not include communication overhead (e.g., HTTP headers) or any other data that is not placed in long-term storage. We count bytes as "ingested" only once at the time they are received and stored.'}),"\n",(0,i.jsx)(n.h2,{id:"what-is-pairwise-evaluation-and-how-do-i-do-it",children:"What is pairwise evaluation and how do I do it?"}),"\n",(0,i.jsxs)(n.p,{children:["When ",(0,i.jsx)(n.a,{href:"/guides/evaluation/scorers",children:"scoring"})," models in a Weave ",(0,i.jsx)(n.a,{href:"/guides/core-types/evaluations",children:"evaluation"}),", absolute value metrics (e.g. ",(0,i.jsx)(n.code,{children:"9/10"})," for Model A and ",(0,i.jsx)(n.code,{children:"8/10"})," for Model B) are typically harder to assign than relative ones (e.g. Model A performs better than Model B). ",(0,i.jsx)(n.em,{children:"Pairwise evaluation"})," allows you to compare the outputs of two models by ranking them relative to each other. This approach is particularly useful when you want to determine which model performs better for subjective tasks such as text generation, summarization, or question answering. With pairwise evaluation, you can obtain a relative preference ranking that reveals which model is best for specific inputs."]}),"\n",(0,i.jsx)(n.admonition,{type:"important",children:(0,i.jsx)(n.p,{children:"This approach is a workaround and may change in future releases. We are actively working on a more robust API to support pairwise evaluations. Stay tuned for updates!"})}),"\n",(0,i.jsxs)(n.p,{children:["The following code sample demonstrates how to implement a pairwise evaluation in Weave by creating a ",(0,i.jsx)(n.a,{href:"/guides/evaluation/scorers#class-based-scorers",children:"class-based scorer"})," called ",(0,i.jsx)(n.code,{children:"PreferenceScorer"}),". The ",(0,i.jsx)(n.code,{children:"PreferenceScorer"})," compares two models, ",(0,i.jsx)(n.code,{children:"ModelA"})," and ",(0,i.jsx)(n.code,{children:"ModelB"}),", and returns a relative score of the model outputs based on explicit hints in the input text."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from weave import Model, Evaluation, Scorer, Dataset\nfrom weave.flow.model import ApplyModelError, apply_model_async\n\nclass ModelA(Model):\n    @weave.op\n    def predict(self, input_text: str):\n        if "Prefer model A" in input_text:\n            return {"response": "This is a great answer from Model A"}\n        return {"response": "Meh, whatever"}\n\nclass ModelB(Model):\n    @weave.op\n    def predict(self, input_text: str):\n        if "Prefer model B" in input_text:\n            return {"response": "This is a thoughtful answer from Model B"}\n        return {"response": "I don\'t know"}\n\nclass PreferenceScorer(Scorer):\n    @weave.op\n    async def _get_other_model_output(self, example: dict) -> Any:\n        """Get output from the other model for comparison.\n        Args:\n            example: The input example data to run through the other model\n        Returns:\n            The output from the other model\n        """\n\n        other_model_result = await apply_model_async(\n            self.other_model,\n            example,\n            None,\n        )\n\n        if isinstance(other_model_result, ApplyModelError):\n            return None\n\n        return other_model_result.model_output\n\n    @weave.op\n    async def score(self, output: dict, input_text: str) -> dict:\n        """Compare the output of the primary model with the other model.\n        Args:\n            output (dict): The output from the primary model.\n            input_text (str): The input text used to generate the outputs.\n        Returns:\n            dict: A flat dictionary containing the comparison result and reason.\n        """\n        other_output = await self._get_other_model_output(\n            {"input_text": input_text}\n        )\n        if other_output is None:\n            return {"primary_is_better": False, "reason": "Other model failed"}\n\n        if "Prefer model A" in input_text:\n            primary_is_better = True\n            reason = "Model A gave a great answer"\n        else:\n            primary_is_better = False\n            reason = "Model B is preferred for this type of question"\n\n        return {"primary_is_better": primary_is_better, "reason": reason}\n\ndataset = Dataset(\n    rows=[\n        {"input_text": "Prefer model A: Question 1"},  # Model A wins\n        {"input_text": "Prefer model A: Question 2"},  # Model A wins\n        {"input_text": "Prefer model B: Question 3"},  # Model B wins\n        {"input_text": "Prefer model B: Question 4"},  # Model B wins\n    ]\n)\n\nmodel_a = ModelA()\nmodel_b = ModelB()\npref_scorer = PreferenceScorer(other_model=model_b)\nevaluation = Evaluation(dataset=dataset, scorers=[pref_scorer])\nevaluation.evaluate(model_a)\n'})})]})}function u(e={}){const{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},11151:(e,n,t)=>{t.d(n,{Z:()=>s,a:()=>r});var i=t(67294);const a={},o=i.createContext(a);function r(e){const n=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);