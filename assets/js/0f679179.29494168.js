"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9892],{99675:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>p,frontMatter:()=>l,metadata:()=>c,toc:()=>h});var i=r(85893),t=r(11151),a=r(65488),s=r(85162);const l={},o="W&B Inference",c={id:"guides/integrations/inference",title:"W&B Inference",description:"W&B Inference provides access to leading open-source foundation models via W&B Weave and an OpenAI-compliant API. With W&B Inference, you can:",source:"@site/docs/guides/integrations/inference.md",sourceDirName:"guides/integrations",slug:"/guides/integrations/inference",permalink:"/guides/integrations/inference",draft:!1,unlisted:!1,editUrl:"https://github.com/wandb/weave/blob/master/docs/docs/guides/integrations/inference.md",tags:[],version:"current",lastUpdatedAt:1750805203e3,frontMatter:{},sidebar:"documentationSidebar",previous:{title:"Integrations",permalink:"/guides/integrations/"},next:{title:"Amazon Bedrock",permalink:"/guides/integrations/bedrock"}},d={},h=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Additional prerequisites for using the API via Python",id:"additional-prerequisites-for-using-the-api-via-python",level:3},{value:"API specification",id:"api-specification",level:2},{value:"Endpoint",id:"endpoint",level:3},{value:"Available methods",id:"available-methods",level:3},{value:"Chat completions",id:"chat-completions",level:4},{value:"List supported models",id:"list-supported-models",level:4},{value:"Usage examples",id:"usage-examples",level:2},{value:"Basic example: Trace Llama 3.1 8B with Weave",id:"basic-example-trace-llama-31-8b-with-weave",level:3},{value:"Advanced example: Use Weave Evaluations and Leaderboards with the inference service",id:"advanced-example-use-weave-evaluations-and-leaderboards-with-the-inference-service",level:3},{value:"UI",id:"ui",level:2},{value:"Access the Inference service",id:"access-the-inference-service",level:3},{value:"Direct link",id:"direct-link",level:4},{value:"From the Inference tab",id:"from-the-inference-tab",level:4},{value:"From the Playground tab",id:"from-the-playground-tab",level:4},{value:"Try a model in the Playground",id:"try-a-model-in-the-playground",level:3},{value:"Compare multiple models",id:"compare-multiple-models",level:3},{value:"Access the Compare view from the Inference tab",id:"access-the-compare-view-from-the-inference-tab",level:4},{value:"Access the Compare view from the Playground tab",id:"access-the-compare-view-from-the-playground-tab",level:4},{value:"View billing and usage information",id:"view-billing-and-usage-information",level:3},{value:"Usage information and limits",id:"usage-information-and-limits",level:2},{value:"Geographic restrictions",id:"geographic-restrictions",level:3},{value:"Concurrency limits",id:"concurrency-limits",level:3},{value:"Pricing",id:"pricing",level:3},{value:"API errors",id:"api-errors",level:2}];function u(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"wb-inference",children:"W&B Inference"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.em,{children:"W&B Inference"})," provides access to leading open-source foundation models via W&B Weave and an OpenAI-compliant API. With W&B Inference, you can:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Develop AI applications and agents without signing up for a hosting provider or self-hosting a model."}),"\n",(0,i.jsx)(n.li,{children:"Try the supported models in the W&B Weave Playground."}),"\n"]}),"\n",(0,i.jsxs)(n.admonition,{type:"important",children:[(0,i.jsx)(n.p,{children:"W&B Inference credits are included with Free, Pro, and Academic plans for a limited time. Availability may vary for Enterprise. Once credits are consumed:"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Free accounts must upgrade to a Pro plan to continue using Inference."}),"\n",(0,i.jsx)(n.li,{children:"Pro plan users will be billed for Inference overages on a monthly basis, based on the model-specific pricing."}),"\n"]}),(0,i.jsxs)(n.p,{children:["To learn more, see the ",(0,i.jsx)(n.a,{href:"https://wandb.ai/site/pricing/",children:"pricing page"})," and ",(0,i.jsx)(n.a,{href:"https://wandb.ai/site/pricing/inference",children:"W&B Inference model costs"}),"."]})]}),"\n",(0,i.jsx)(n.p,{children:"Using Weave, you can trace, evaluate, monitor, and iterate on your W&B Inference-powered applications."}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Model"}),(0,i.jsx)(n.th,{children:"Model ID (for API usage)"}),(0,i.jsx)(n.th,{children:"Type(s)"}),(0,i.jsx)(n.th,{children:"Context Window"}),(0,i.jsx)(n.th,{children:"Parameters"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"DeepSeek R1-0528"}),(0,i.jsx)(n.td,{children:"deepseek-ai/DeepSeek-R1-0528"}),(0,i.jsx)(n.td,{children:"Text"}),(0,i.jsx)(n.td,{children:"161K"}),(0,i.jsx)(n.td,{children:"37B - 680B (Active - Total)"}),(0,i.jsx)(n.td,{children:"Optimized for precise reasoning tasks including complex coding, math, and structured document analysis."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"DeepSeek V3-0324"}),(0,i.jsx)(n.td,{children:"deepseek-ai/DeepSeek-V3-0324"}),(0,i.jsx)(n.td,{children:"Text"}),(0,i.jsx)(n.td,{children:"161K"}),(0,i.jsx)(n.td,{children:"37B - 680B (Active - Total)"}),(0,i.jsx)(n.td,{children:"Robust Mixture-of-Experts model tailored for high-complexity language processing and comprehensive document analysis."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Llama 3.1 8B"}),(0,i.jsx)(n.td,{children:"meta-llama/Llama-3.1-8B-Instruct"}),(0,i.jsx)(n.td,{children:"Text"}),(0,i.jsx)(n.td,{children:"128K"}),(0,i.jsx)(n.td,{children:"8B (Total)"}),(0,i.jsx)(n.td,{children:"Efficient conversational model optimized for responsive multilingual chatbot interactions."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Llama 3.3 70B"}),(0,i.jsx)(n.td,{children:"meta-llama/Llama-3.3-70B-Instruct"}),(0,i.jsx)(n.td,{children:"Text"}),(0,i.jsx)(n.td,{children:"128K"}),(0,i.jsx)(n.td,{children:"70B (Total)"}),(0,i.jsx)(n.td,{children:"Multilingual model excelling in conversational tasks, detailed instruction-following, and coding."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Llama 4 Scout"}),(0,i.jsx)(n.td,{children:"meta-llama/Llama-4-Scout-17B-16E-Instruct"}),(0,i.jsx)(n.td,{children:"Text, Vision"}),(0,i.jsx)(n.td,{children:"64K"}),(0,i.jsx)(n.td,{children:"17B - 109B (Active - Total)"}),(0,i.jsx)(n.td,{children:"Multimodal model integrating text and image understanding, ideal for visual tasks and combined analysis."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Phi 4 Mini"}),(0,i.jsx)(n.td,{children:"microsoft/Phi-4-mini-instruct"}),(0,i.jsx)(n.td,{children:"Text"}),(0,i.jsx)(n.td,{children:"128K"}),(0,i.jsx)(n.td,{children:"3.8B (Active - Total)"}),(0,i.jsx)(n.td,{children:"Compact, efficient model ideal for fast responses in resource-constrained environments."})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"This guide provides the following information:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"#prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#additional-prerequisites-for-using-the-api-via-python",children:"Additional prerequisites for using the API via Python"})}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"#api-specification",children:"API specification"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#endpoint",children:"Endpoint"})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"#available-methods",children:"Available methods"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#chat-completions",children:"Chat completions"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#list-supported-models",children:"List supported models"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#usage-examples",children:"Usage examples"})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"#ui",children:"UI"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#access-the-inference-service",children:"Access the Inference service"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#try-a-model-in-the-playground",children:"Try a model in the Playground"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#compare-multiple-models",children:"Compare multiple models"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#view-billing-and-usage-information",children:"View billing and usage information"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#usage-information-and-limits",children:"Usage information and limits "})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#api-errors",children:"API errors"})}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(n.p,{children:"The following prerequisites are required to access the W&B Inference service via the API or the W&B Weave UI."}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["A W&B account. Sign up ",(0,i.jsx)(n.a,{href:"https://app.wandb.ai/login?signup=true&_gl=1*1yze8dp*_ga*ODIxMjU5MTk3LjE3NDk0OTE2NDM.*_ga_GMYDGNGKDT*czE3NDk4NDYxMzgkbzEyJGcwJHQxNzQ5ODQ2MTM4JGo2MCRsMCRoMA..*_ga_JH1SJHJQXJ*czE3NDk4NDU2NTMkbzI1JGcxJHQxNzQ5ODQ2MTQ2JGo0NyRsMCRoMA..*_gcl_au*MTE4ODk1MzY1OC4xNzQ5NDkxNjQzLjk1ODA2MjQwNC4xNzQ5NTgyMTUzLjE3NDk1ODIxNTM.",children:"here"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["A W&B API key. Get your API key at ",(0,i.jsx)(n.a,{href:"https://wandb.ai/authorize",children:"https://wandb.ai/authorize"}),"."]}),"\n",(0,i.jsx)(n.li,{children:"A W&B project."}),"\n",(0,i.jsxs)(n.li,{children:["If you are using the Inference service via Python, see ",(0,i.jsx)(n.a,{href:"#additional-prerequisites-for-using-the-api-via-python",children:"Additional prerequisites for using the API via Python"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"additional-prerequisites-for-using-the-api-via-python",children:"Additional prerequisites for using the API via Python"}),"\n",(0,i.jsxs)(n.p,{children:["To use the Inference API via Python, first complete the general prerequisites. Then, install the ",(0,i.jsx)(n.code,{children:"openai"})," and ",(0,i.jsx)(n.code,{children:"weave"})," libraries in your local environment:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install openai weave\n"})}),"\n",(0,i.jsxs)(n.admonition,{type:"note",children:[(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"weave"})," library is only required if you'll be using Weave to trace your LLM applications. For information on getting started with Weave, see the ",(0,i.jsx)(n.a,{href:"/quickstart",children:"Weave Quickstart"}),"."]}),(0,i.jsxs)(n.p,{children:["For usage examples demonstrating how to use the W&B Inference service with Weave, see the ",(0,i.jsx)(n.a,{href:"#usage-examples",children:"API usage examples"}),"."]})]}),"\n",(0,i.jsx)(n.h2,{id:"api-specification",children:"API specification"}),"\n",(0,i.jsx)(n.p,{children:"The following section provides API specification information and API usage examples."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#endpoint",children:"Endpoint"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#available-methods",children:"Available methods"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#usage-examples",children:"Usage examples"})}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"endpoint",children:"Endpoint"}),"\n",(0,i.jsx)(n.p,{children:"The Inference service can be accessed via the following endpoint:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-plaintext",children:"https://api.inference.wandb.ai/v1\n"})}),"\n",(0,i.jsx)(n.admonition,{type:"important",children:(0,i.jsxs)(n.p,{children:['To access this endpoint, you must have a W&B account with Inference service credits allocated, a valid W&B API key, and a W&B entity (also referred to as "team") and project. In the code samples in this guide, entity (team) and project are referred to as ',(0,i.jsx)(n.code,{children:"<your-team>\\<your-project>"}),"."]})}),"\n",(0,i.jsx)(n.h3,{id:"available-methods",children:"Available methods"}),"\n",(0,i.jsx)(n.p,{children:"The Inference service supports the following API methods:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#chat-completions",children:"Chat completions"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#list-supported-models",children:"List supported models"})}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"chat-completions",children:"Chat completions"}),"\n",(0,i.jsxs)(n.p,{children:["The primary API method available is ",(0,i.jsx)(n.code,{children:"/chat/completions"}),", which supports OpenAI-compatible request formats for sending messages to a supported model and receiving a completion. For usage examples demonstrating how to use the W&B Inference service with Weave, see the ",(0,i.jsx)(n.a,{href:"#usage-examples",children:"API usage examples"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"To create a chat completion, you will need:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["The Inference service base URL ",(0,i.jsx)(n.code,{children:"https://api.inference.wandb.ai/v1"})]}),"\n",(0,i.jsxs)(n.li,{children:["Your W&B API key ",(0,i.jsx)(n.code,{children:"<your-api-key>"})]}),"\n",(0,i.jsxs)(n.li,{children:["Your W&B entity and project names ",(0,i.jsx)(n.code,{children:"<your-team>/<your-project>"})]}),"\n",(0,i.jsxs)(n.li,{children:["The ID for the model you want to use, one of:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"meta-llama/Llama-3.1-8B-Instruct"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"deepseek-ai/DeepSeek-V3-0324"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"meta-llama/Llama-3.3-70B-Instruct"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"deepseek-ai/DeepSeek-R1-0528"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"meta-llama/Llama-4-Scout-17B-16E-Instruct"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"microsoft/Phi-4-mini-instruct"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(a.Z,{groupId:"programming-language",queryString:!0,children:[(0,i.jsx)(s.default,{value:"bash",label:"Bash",default:!0,children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'curl https://api.inference.wandb.ai/v1/chat/completions \\\n  -H "Content-Type: application/json" \\\n  -H "Authorization: Bearer <your-api-key>" \\\n  -H "OpenAI-Project: <your-team>/<your-project>" \\\n  -d \'{\n    "model": "<model-id>",\n    "messages": [\n      { "role": "system", "content": "You are a helpful assistant." },\n      { "role": "user", "content": "Tell me a joke." }\n    ]\n  }\'\n'})})}),(0,i.jsx)(s.default,{value:"python",label:"Python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import openai\n\nclient = openai.OpenAI(\n    # The custom base URL points to W&B Inference\n    base_url=\'https://api.inference.wandb.ai/v1\',\n\n    # Get your API key from https://wandb.ai/authorize\n    # Consider setting it in the environment as OPENAI_API_KEY instead for safety\n    api_key="<your-api-key>",\n\n    # Team and project are required for usage tracking\n    project="<your-team>/<your-project>",\n)\n\n# Replace <model-id> with any of the following values:\n# meta-llama/Llama-3.1-8B-Instruct\n# deepseek-ai/DeepSeek-V3-0324\n# meta-llama/Llama-3.3-70B-Instruct\n# deepseek-ai/DeepSeek-R1-0528\n# meta-llama/Llama-4-Scout-17B-16E-Instruct\n# microsoft/Phi-4-mini-instruct\n\nresponse = client.chat.completions.create(\n    model="<model-id>",\n    messages=[\n        {"role": "system", "content": "<your-system-prompt>"},\n        {"role": "user", "content": "<your-prompt>"}\n    ],\n)\n\nprint(response.choices[0].message.content)\n'})})})]}),"\n",(0,i.jsx)(n.h4,{id:"list-supported-models",children:"List supported models"}),"\n",(0,i.jsx)(n.p,{children:"Use the API to query all currently available models and their IDs. This is useful for selecting models dynamically or inspecting what's available in your environment."}),"\n",(0,i.jsxs)(a.Z,{groupId:"programming-language",queryString:!0,children:[(0,i.jsx)(s.default,{value:"bash",label:"Bash",default:!0,children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'curl https://api.inference.wandb.ai/v1/models \\\n  -H "Content-Type: application/json" \\\n  -H "Authorization: Bearer <your-api-key>" \\\n  -H "OpenAI-Project: <your-team>/<your-project>" \\\n'})})}),(0,i.jsx)(s.default,{value:"python",label:"Python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import openai\n\nclient = openai.OpenAI(\n    base_url="https://api.inference.wandb.ai/v1",\n    api_key="<your-api-key>",\n    project="<your-team>/<your-project>"\n)\n\nresponse = client.models.list()\n\nfor model in response.data:\n    print(model.id)\n'})})})]}),"\n",(0,i.jsx)(n.h2,{id:"usage-examples",children:"Usage examples"}),"\n",(0,i.jsx)(n.p,{children:"This section provides several examples demonstrating how to use W&B Inference with Weave:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#basic-example-trace-llama-31-8b-with-weave",children:"Basic example: Trace Llama 3.1 8B with Weave"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#advanced-example-use-weave-evaluations-and-leaderboards-with-the-inference-service",children:"Advanced example: Use Weave Evaluations and Leaderboards with the inference service"})}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"basic-example-trace-llama-31-8b-with-weave",children:"Basic example: Trace Llama 3.1 8B with Weave"}),"\n",(0,i.jsxs)(n.p,{children:["The following Python code sample shows how to send a prompt to the ",(0,i.jsx)(n.strong,{children:"Llama 3.1 8B"})," model using the W&B Inference API and trace the call in Weave. Tracing lets you capture the full input/output of the LLM call, monitor performance, and analyze results in the Weave UI."]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:["Learn more about ",(0,i.jsx)(n.a,{href:"/guides/tracking/tracing",children:"tracing in Weave"}),"."]})}),"\n",(0,i.jsx)(n.p,{children:"In this example:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["You define a ",(0,i.jsx)(n.code,{children:"@weave.op()"}),"-decorated function, ",(0,i.jsx)(n.code,{children:"run_chat"}),", which makes a chat completion request using the OpenAI-compatible client."]}),"\n",(0,i.jsxs)(n.li,{children:["Your traces are recorded and associated with your W&B entity and project ",(0,i.jsx)(n.code,{children:'project="<your-team>/<your-project>'})]}),"\n",(0,i.jsx)(n.li,{children:"The function is automatically traced by Weave, so its inputs, outputs, latency, and metadata (like model ID) are logged."}),"\n",(0,i.jsxs)(n.li,{children:["The result is printed in the terminal, and the trace appears in your ",(0,i.jsx)(n.strong,{children:"Traces"})," tab at ",(0,i.jsx)(n.a,{href:"https://wandb.ai",children:"https://wandb.ai"})," under the specified project."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["To use this example, you must complete the ",(0,i.jsx)(n.a,{href:"#prerequisites",children:"general prerequisites"})," and ",(0,i.jsx)(n.a,{href:"#additional-prerequisites-for-using-the-api-via-python",children:"Additional prerequisites for using the API via Python"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import weave\nimport openai\n\n# Set the Weave team and project for tracing\nweave.init("<your-team>/<your-project>")\n\nclient = openai.OpenAI(\n    base_url=\'https://api.inference.wandb.ai/v1\',\n\n    # Get your API key from https://wandb.ai/authorize\n    api_key="<your-api-key>",\n\n    # Required for W&B inference usage tracking\n    project="wandb/inference-demo",\n)\n\n# Trace the model call in Weave\n@weave.op()\ndef run_chat():\n    response = client.chat.completions.create(\n        model="meta-llama/Llama-3.1-8B-Instruct",\n        messages=[\n            {"role": "system", "content": "You are a helpful assistant."},\n            {"role": "user", "content": "Tell me a joke."}\n        ],\n    )\n    return response.choices[0].message.content\n\n# Run and log the traced call\noutput = run_chat()\nprint(output)\n'})}),"\n",(0,i.jsxs)(n.p,{children:["Once you run the code sample, you can view the trace in Weave by clicking the link printed in the terminal (e.g. ",(0,i.jsx)(n.code,{children:"https://wandb.ai/<your-team>/<your-project>/r/call/01977f8f-839d-7dda-b0c2-27292ef0e04g"}),"), or:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Navigate to ",(0,i.jsx)(n.a,{href:"https://wandb.ai",children:"https://wandb.ai"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["Select the ",(0,i.jsx)(n.strong,{children:"Traces"})," tab to view your Weave traces."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Next, try the ",(0,i.jsx)(n.a,{href:"#advanced-example-use-weave-evaluations-and-leaderboards-with-the-inference-service",children:"advanced example"}),"."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Traces display",src:r(68435).Z+"",width:"3024",height:"1194"})}),"\n",(0,i.jsx)(n.h3,{id:"advanced-example-use-weave-evaluations-and-leaderboards-with-the-inference-service",children:"Advanced example: Use Weave Evaluations and Leaderboards with the inference service"}),"\n",(0,i.jsxs)(n.p,{children:["In addition to using Weave with the Inference service to ",(0,i.jsx)(n.a,{href:"/guides/tracking/tracing",children:"trace model calls"}),", you can also ",(0,i.jsx)(n.a,{href:"/guides/core-types/evaluations",children:"evaluate performance"}),", and ",(0,i.jsx)(n.a,{href:"/guides/core-types/leaderboards",children:"publish a leaderboard"}),". The following Python code sample compares two models on a simple question\u2013answer dataset."]}),"\n",(0,i.jsxs)(n.p,{children:["To use this example, you must complete the ",(0,i.jsx)(n.a,{href:"#prerequisites",children:"general prerequisites"})," and ",(0,i.jsx)(n.a,{href:"#additional-prerequisites-for-using-the-api-via-python",children:"Additional prerequisites for using the API via Python"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import os\nimport asyncio\nimport openai\nimport weave\nfrom weave.flow import leaderboard\nfrom weave.trace.ref_util import get_ref\n\n# Set the Weave team and project for tracing\nweave.init("<your-team>/<your-project>")\n\ndataset = [\n    {"input": "What is 2 + 2?", "target": "4"},\n    {"input": "Name a primary color.", "target": "red"},\n]\n\n@weave.op\ndef exact_match(target: str, output: str) -> float:\n    return float(target.strip().lower() == output.strip().lower())\n\nclass WBInferenceModel(weave.Model):\n    model: str\n\n    @weave.op\n    def predict(self, prompt: str) -> str:\n        client = openai.OpenAI(\n            base_url="https://api.inference.wandb.ai/v1",\n            # Get your API key from https://wandb.ai/authorize\n            api_key="<your-api-key>",\n            # Required for W&B inference usage tracking\n            project="<your-team>/<your-project>",\n        )\n        resp = client.chat.completions.create(\n            model=self.model,\n            messages=[{"role": "user", "content": prompt}],\n        )\n        return resp.choices[0].message.content\n\nllama = WBInferenceModel(model="meta-llama/Llama-3.1-8B-Instruct")\ndeepseek = WBInferenceModel(model="deepseek-ai/DeepSeek-V3-0324")\n\ndef preprocess_model_input(example):\n    return {"prompt": example["input"]}\n\nevaluation = weave.Evaluation(\n    name="QA",\n    dataset=dataset,\n    scorers=[exact_match],\n    preprocess_model_input=preprocess_model_input,\n)\n\nasync def run_eval():\n    await evaluation.evaluate(llama)\n    await evaluation.evaluate(deepseek)\n\nasyncio.run(run_eval())\n\nspec = leaderboard.Leaderboard(\n    name="Inference Leaderboard",\n    description="Compare models on a QA dataset",\n    columns=[\n        leaderboard.LeaderboardColumn(\n            evaluation_object_ref=get_ref(evaluation).uri(),\n            scorer_name="exact_match",\n            summary_metric_path="mean",\n        )\n    ],\n)\n\nweave.publish(spec)\n'})}),"\n",(0,i.jsxs)(n.p,{children:["After you run the following code sample, navigate to your W&B account at ",(0,i.jsx)(n.a,{href:"https://wandb.ai/",children:"https://wandb.ai/"})," and:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Navigate to the ",(0,i.jsx)(n.strong,{children:"Traces"})," tab to ",(0,i.jsx)(n.a,{href:"/guides/tracking/tracing",children:"view your traces"})]}),"\n",(0,i.jsxs)(n.li,{children:["Navigate to the ",(0,i.jsx)(n.strong,{children:"Evals"})," tab to ",(0,i.jsx)(n.a,{href:"/guides/core-types/evaluations",children:"view your model evaluations"})]}),"\n",(0,i.jsxs)(n.li,{children:["Navigate to the ",(0,i.jsx)(n.strong,{children:"Leaders"})," tab to ",(0,i.jsx)(n.a,{href:"/guides/core-types/leaderboards",children:"view the generated leaderboard"})]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"View your model evaluations",src:r(38371).Z+"",width:"3024",height:"1194"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"View your traces",src:r(24600).Z+"",width:"3024",height:"1194"})}),"\n",(0,i.jsx)(n.h2,{id:"ui",children:"UI"}),"\n",(0,i.jsxs)(n.p,{children:["The following section describes how to use the Inference service from the W&B UI. Before you can access the Inference service via the UI, complete the ",(0,i.jsx)(n.a,{href:"#prerequisites",children:"prerequisites"}),"."]}),"\n",(0,i.jsx)(n.h3,{id:"access-the-inference-service",children:"Access the Inference service"}),"\n",(0,i.jsx)(n.p,{children:"You can access the Inference service via the Weave UI from two different locations:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#direct-link",children:"Direct link"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#from-the-inference-tab",children:"From the Inference tab"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#from-the-playground-tab",children:"From the Playground tab"})}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"direct-link",children:"Direct link"}),"\n",(0,i.jsxs)(n.p,{children:["Navigate to ",(0,i.jsx)(n.a,{href:"https://wandb.ai/inference",children:"https://wandb.ai/inference"}),"."]}),"\n",(0,i.jsx)(n.h4,{id:"from-the-inference-tab",children:"From the Inference tab"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Navigate to your W&B account at ",(0,i.jsx)(n.a,{href:"https://wandb.ai/",children:"https://wandb.ai/"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["From the left sidebar, select ",(0,i.jsx)(n.strong,{children:"Inference"}),". A page with available models and model information displays."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"The Inference tab",src:r(37540).Z+"",width:"2414",height:"1240"})}),"\n",(0,i.jsx)(n.h4,{id:"from-the-playground-tab",children:"From the Playground tab"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["From the left sidebar, select ",(0,i.jsx)(n.strong,{children:"Playground"}),". The Playground chat UI displays."]}),"\n",(0,i.jsxs)(n.li,{children:["From the LLM dropdown list, mouseover ",(0,i.jsx)(n.strong,{children:"W&B Inference"}),". A dropdown with available W&B Inference models displays to the right."]}),"\n",(0,i.jsxs)(n.li,{children:["From the W&B Inference models dropdown, you can:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Click the name of any available model to ",(0,i.jsx)(n.a,{href:"#try-a-model-in-the-playground",children:"try it in the Playground"}),"."]}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#compare-multiple-models",children:"Compare one or more models in the Playground"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"The Inference models dropdown in Playground",src:r(34799).Z+"",width:"3022",height:"1240"})}),"\n",(0,i.jsx)(n.h3,{id:"try-a-model-in-the-playground",children:"Try a model in the Playground"}),"\n",(0,i.jsxs)(n.p,{children:["Once you've ",(0,i.jsx)(n.a,{href:"#access-the-inference-service",children:"selected a model using one of the access options"}),", you can try the model in Playground. The following actions are available:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/guides/tools/playground#customize-settings",children:"Customize model settings and parameters"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/guides/tools/playground#message-controls",children:"Add, retry, edit, and delete messages"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/guides/tools/playground#saved-models",children:"Save and reuse a model with custom settings"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#compare-multiple-models",children:"Compare multiple models"})}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Using an Inference model in the Playground",src:r(81004).Z+"",width:"1706",height:"1240"})}),"\n",(0,i.jsx)(n.h3,{id:"compare-multiple-models",children:"Compare multiple models"}),"\n",(0,i.jsx)(n.p,{children:"You can compare multiple Inference models in the Playground. The Compare view can be accessed from two different locations:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#access-the-compare-view-from-the-inference-tab",children:"Access the Compare view from the Inference tab "})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#access-the-compare-view-from-the-playground-tab",children:"Access the Compare view from the Playground tab"})}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"access-the-compare-view-from-the-inference-tab",children:"Access the Compare view from the Inference tab"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["From the left sidebar, select ",(0,i.jsx)(n.strong,{children:"Inference"}),". A page with available models and model information displays."]}),"\n",(0,i.jsx)(n.li,{children:"To select models for comparison, click anywhere on a model card (except for the model name). The border of the model card is highlighted in blue to indicate the selection."}),"\n",(0,i.jsx)(n.li,{children:"Repeat step 2 for each model you want to compare."}),"\n",(0,i.jsxs)(n.li,{children:["In any of the selected cards, click the ",(0,i.jsx)(n.strong,{children:"Compare N models in the Playground"})," button (",(0,i.jsx)(n.code,{children:"N"})," is the number of models you are comparing. For example, when 3 models are selected, the button displays as ",(0,i.jsx)(n.strong,{children:"Compare 3 models in the Playground"}),"). The comparison view opens."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Now, you can compare models in the Playground, and use any of the features described in ",(0,i.jsx)(n.a,{href:"#try-a-model-in-the-playground",children:"Try a model in the Playground"}),"."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Select multiple models to compare in Playground",src:r(53129).Z+"",width:"2114",height:"1240"})}),"\n",(0,i.jsx)(n.h4,{id:"access-the-compare-view-from-the-playground-tab",children:"Access the Compare view from the Playground tab"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["From the left sidebar, select ",(0,i.jsx)(n.strong,{children:"Playground"}),". The Playground chat UI displays."]}),"\n",(0,i.jsxs)(n.li,{children:["From the LLM dropdown list, mouseover ",(0,i.jsx)(n.strong,{children:"W&B Inference"}),". A dropdown with available W&B Inference models displays to the right."]}),"\n",(0,i.jsxs)(n.li,{children:["From the dropdown, select ",(0,i.jsx)(n.strong,{children:"Compare"}),". The ",(0,i.jsx)(n.strong,{children:"Inference"})," tab displays."]}),"\n",(0,i.jsx)(n.li,{children:"To select models for comparison, click anywhere on a model card (except for the model name). The border of the model card is highlighted in blue to indicate the selection."}),"\n",(0,i.jsx)(n.li,{children:"Repeat step 4 for each model you want to compare."}),"\n",(0,i.jsxs)(n.li,{children:["In any of the selected cards, click the ",(0,i.jsx)(n.strong,{children:"Compare N models in the Playground"})," button (",(0,i.jsx)(n.code,{children:"N"})," is the number of models you are comparing. For example, when 3 models are selected, the button displays as ",(0,i.jsx)(n.strong,{children:"Compare 3 models in the Playground"}),"). The comparison view opens."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Now, you can compare models in the Playground, and use any of the features described in ",(0,i.jsx)(n.a,{href:"#try-a-model-in-the-playground",children:"Try a model in the Playground"}),"."]}),"\n",(0,i.jsx)(n.h3,{id:"view-billing-and-usage-information",children:"View billing and usage information"}),"\n",(0,i.jsx)(n.p,{children:"Organization admins can track current Inference credit balance, usage history, and upcoming billing (if applicable) directly from the W&B UI:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["In the W&B UI, navigate to the W&B ",(0,i.jsx)(n.strong,{children:"Billing"})," page."]}),"\n",(0,i.jsx)(n.li,{children:"In the bottom righthand corner, the Inference billing information card is displayed. From here, you can:"}),"\n"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Click the ",(0,i.jsx)(n.strong,{children:"View usage"})," button in the Inference billing information card to view your usage over time."]}),"\n",(0,i.jsx)(n.li,{children:"If you're on a paid plan, view your upcoming inference charges."}),"\n"]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:["Visit the ",(0,i.jsx)(n.a,{href:"https://wandb.ai/site/pricing/inference",children:"Inference pricing page for a breakdown of per-model pricing"})]})}),"\n",(0,i.jsx)(n.h2,{id:"usage-information-and-limits",children:"Usage information and limits"}),"\n",(0,i.jsx)(n.p,{children:"The following section describes important usage information and limits. Familiarize yourself with this information before using the service."}),"\n",(0,i.jsx)(n.h3,{id:"geographic-restrictions",children:"Geographic restrictions"}),"\n",(0,i.jsxs)(n.p,{children:["The Inference service is only accessible from supported geographic locations. For more information, see the ",(0,i.jsx)(n.a,{href:"https://docs.coreweave.com/docs/policies/terms-of-service/terms-of-use#geographic-restrictions",children:"Terms of Service"}),"."]}),"\n",(0,i.jsx)(n.h3,{id:"concurrency-limits",children:"Concurrency limits"}),"\n",(0,i.jsx)(n.p,{children:"To ensure fair usage and stable performance, the W&B Inference API enforces rate limits at the user and project level. These limits help:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Prevent misuse and protect API stability"}),"\n",(0,i.jsx)(n.li,{children:"Ensure access for all users"}),"\n",(0,i.jsx)(n.li,{children:"Manage infrastructure load effectively"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["If a rate limit is exceeded, the API will return a ",(0,i.jsx)(n.code,{children:"429 Concurrency limit reached for requests"})," response. To resolve this error, reduce the number of concurrent requests."]}),"\n",(0,i.jsx)(n.h3,{id:"pricing",children:"Pricing"}),"\n",(0,i.jsxs)(n.p,{children:["For model pricing information, visit ",(0,i.jsx)(n.a,{href:"http://wandb.com/site/pricing/inference",children:"http://wandb.com/site/pricing/inference"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"api-errors",children:"API errors"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Error Code"}),(0,i.jsx)(n.th,{children:"Message"}),(0,i.jsx)(n.th,{children:"Cause"}),(0,i.jsx)(n.th,{children:"Solution"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"401"}),(0,i.jsx)(n.td,{children:"Invalid Authentication"}),(0,i.jsx)(n.td,{children:"Invalid authentication credentials or your W&B project entity and/or name are incorrect."}),(0,i.jsx)(n.td,{children:"Ensure the correct API key is being used and/or that your W&B project name and entity are correct."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"403"}),(0,i.jsx)(n.td,{children:"Country, region, or territory not supported"}),(0,i.jsx)(n.td,{children:"Accessing the API from an unsupported location."}),(0,i.jsxs)(n.td,{children:["Please see ",(0,i.jsx)(n.a,{href:"#geographic-restrictions",children:"Geographic restrictions"})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"429"}),(0,i.jsx)(n.td,{children:"Concurrency limit reached for requests"}),(0,i.jsx)(n.td,{children:"Too many concurrent requests."}),(0,i.jsx)(n.td,{children:"Reduce the number of concurrent requests."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"429"}),(0,i.jsx)(n.td,{children:"You exceeded your current quota, please check your plan and billing details"}),(0,i.jsx)(n.td,{children:"Out of credits or reached monthly spending cap."}),(0,i.jsx)(n.td,{children:"Purchase more credits or increase your limits."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"500"}),(0,i.jsx)(n.td,{children:"The server had an error while processing your request"}),(0,i.jsx)(n.td,{children:"Internal server error."}),(0,i.jsx)(n.td,{children:"Retry after a brief wait and contact support if it persists."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"503"}),(0,i.jsx)(n.td,{children:"The engine is currently overloaded, please try again later"}),(0,i.jsx)(n.td,{children:"Server is experiencing high traffic."}),(0,i.jsx)(n.td,{children:"Retry your request after a short delay."})]})]})]})]})}function p(e={}){const{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},85162:(e,n,r)=>{r.r(n),r.d(n,{default:()=>s});r(67294);var i=r(90512);const t={tabItem:"tabItem_Ymn6"};var a=r(85893);function s(e){let{children:n,hidden:r,className:s}=e;return(0,a.jsx)("div",{role:"tabpanel",className:(0,i.Z)(t.tabItem,s),hidden:r,children:n})}},65488:(e,n,r)=>{r.d(n,{Z:()=>p});var i=r(67294),t=r(90512),a=r(12466),s=r(70989),l=r(72389);const o={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var c=r(85893);function d(e){let{className:n,block:r,selectedValue:i,selectValue:s,tabValues:l}=e;const d=[],{blockElementScrollPositionUntilNextRender:h}=(0,a.o5)(),u=e=>{const n=e.currentTarget,r=d.indexOf(n),t=l[r].value;t!==i&&(h(n),s(t))},p=e=>{let n=null;switch(e.key){case"Enter":u(e);break;case"ArrowRight":{const r=d.indexOf(e.currentTarget)+1;n=d[r]??d[0];break}case"ArrowLeft":{const r=d.indexOf(e.currentTarget)-1;n=d[r]??d[d.length-1];break}}n?.focus()};return(0,c.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,t.Z)("tabs",{"tabs--block":r},n),children:l.map((e=>{let{value:n,label:r,attributes:a}=e;return(0,c.jsx)("li",{role:"tab",tabIndex:i===n?0:-1,"aria-selected":i===n,ref:e=>d.push(e),onKeyDown:p,onClick:u,...a,className:(0,t.Z)("tabs__item",o.tabItem,a?.className,{"tabs__item--active":i===n}),children:r??n},n)}))})}function h(e){let{lazy:n,children:r,selectedValue:t}=e;const a=(Array.isArray(r)?r:[r]).filter(Boolean);if(n){const e=a.find((e=>e.props.value===t));return e?(0,i.cloneElement)(e,{className:"margin-top--md"}):null}return(0,c.jsx)("div",{className:"margin-top--md",children:a.map(((e,n)=>(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==t})))})}function u(e){const n=(0,s.Y)(e);return(0,c.jsxs)("div",{className:(0,t.Z)("tabs-container",o.tabList),children:[(0,c.jsx)(d,{...n,...e}),(0,c.jsx)(h,{...n,...e})]})}function p(e){const n=(0,l.default)();return(0,c.jsx)(u,{...e,children:(0,s.h)(e.children)},String(n))}},70989:(e,n,r)=>{r.d(n,{Y:()=>p,h:()=>c});var i=r(67294),t=r(16550),a=r(20469),s=r(91980),l=r(67392),o=r(20812);function c(e){return i.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function d(e){const{values:n,children:r}=e;return(0,i.useMemo)((()=>{const e=n??function(e){return c(e).map((e=>{let{props:{value:n,label:r,attributes:i,default:t}}=e;return{value:n,label:r,attributes:i,default:t}}))}(r);return function(e){const n=(0,l.l)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,r])}function h(e){let{value:n,tabValues:r}=e;return r.some((e=>e.value===n))}function u(e){let{queryString:n=!1,groupId:r}=e;const a=(0,t.k6)(),l=function(e){let{queryString:n=!1,groupId:r}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!r)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return r??null}({queryString:n,groupId:r});return[(0,s._X)(l),(0,i.useCallback)((e=>{if(!l)return;const n=new URLSearchParams(a.location.search);n.set(l,e),a.replace({...a.location,search:n.toString()})}),[l,a])]}function p(e){const{defaultValue:n,queryString:r=!1,groupId:t}=e,s=d(e),[l,c]=(0,i.useState)((()=>function(e){let{defaultValue:n,tabValues:r}=e;if(0===r.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!h({value:n,tabValues:r}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${r.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const i=r.find((e=>e.default))??r[0];if(!i)throw new Error("Unexpected error: 0 tabValues");return i.value}({defaultValue:n,tabValues:s}))),[p,m]=u({queryString:r,groupId:t}),[x,f]=function(e){let{groupId:n}=e;const r=function(e){return e?`docusaurus.tab.${e}`:null}(n),[t,a]=(0,o.Nk)(r);return[t,(0,i.useCallback)((e=>{r&&a.set(e)}),[r,a])]}({groupId:t}),j=(()=>{const e=p??x;return h({value:e,tabValues:s})?e:null})();(0,a.Z)((()=>{j&&c(j)}),[j]);return{selectedValue:l,selectValue:(0,i.useCallback)((e=>{if(!h({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);c(e),m(e),f(e)}),[m,f,s]),tabValues:s}}},68435:(e,n,r)=>{r.d(n,{Z:()=>i});const i=r.p+"assets/images/image-786358337a70bc3a2e381b682c9b43a4.png"},38371:(e,n,r)=>{r.d(n,{Z:()=>i});const i=r.p+"assets/images/inference-advanced-evals-29b4ad97521735f82c18c8a111814037.png"},24600:(e,n,r)=>{r.d(n,{Z:()=>i});const i=r.p+"assets/images/inference-advanced-leaderboard-432df73392a9a3e49107d3cc7883782a.png"},53129:(e,n,r)=>{r.d(n,{Z:()=>i});const i=r.p+"assets/images/inference-playground-compare-c6d4df5cece5b287e71ad64e6dcb4aa1.png"},81004:(e,n,r)=>{r.d(n,{Z:()=>i});const i=r.p+"assets/images/inference-playground-single-20e210dd19f1ee1f222fb329a3f0e73c.png"},34799:(e,n,r)=>{r.d(n,{Z:()=>i});const i=r.p+"assets/images/inference-playground-9fa909d61356faa393bc72c07bb6dddc.png"},37540:(e,n,r)=>{r.d(n,{Z:()=>i});const i=r.p+"assets/images/inference-ui-35631339f496504988b4570978eb56da.png"},11151:(e,n,r)=>{r.d(n,{Z:()=>l,a:()=>s});var i=r(67294);const t={},a=i.createContext(t);function s(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);