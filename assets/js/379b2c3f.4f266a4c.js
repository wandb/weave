"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8852],{62720:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>r,contentTitle:()=>i,default:()=>h,frontMatter:()=>a,metadata:()=>l,toc:()=>c});var o=t(85893),s=t(11151);const a={},i="Smolagents",l={id:"guides/integrations/smolagents",title:"Smolagents",description:"All code samples shown on this page are in Python.",source:"@site/docs/guides/integrations/smolagents.md",sourceDirName:"guides/integrations",slug:"/guides/integrations/smolagents",permalink:"/guides/integrations/smolagents",draft:!1,unlisted:!1,editUrl:"https://github.com/wandb/weave/blob/master/docs/docs/guides/integrations/smolagents.md",tags:[],version:"current",lastUpdatedAt:1749652482e3,frontMatter:{},sidebar:"documentationSidebar",previous:{title:"CrewAI",permalink:"/guides/integrations/crewai"},next:{title:"PydanticAI",permalink:"/guides/integrations/pydantic_ai"}},r={},c=[{value:"Overview",id:"overview",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Basic tracing",id:"basic-tracing",level:2},{value:"Tracing custom tools",id:"tracing-custom-tools",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,s.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"smolagents",children:"Smolagents"}),"\n",(0,o.jsx)(n.admonition,{type:"important",children:(0,o.jsx)(n.p,{children:"All code samples shown on this page are in Python."})}),"\n",(0,o.jsxs)(n.p,{children:["This page explains how to integrate ",(0,o.jsx)(n.a,{href:"https://huggingface.co/docs/smolagents/en/index",children:"Smolagents"})," with W&B Weave to track and analyze your agentic applications. You'll learn how to log model inferences, monitor function calls, and organize experiments using Weave's tracing and versioning capabilities. By following the examples provided, you can capture valuable insights, debug your applications efficiently, and compare different model configurations\u2014all within the Weave web interface."]}),"\n",(0,o.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(n.p,{children:"Smolagents is a simple framework that offers minimal abstractions for building powerful agentic applications. It supports multiple LLM providers, such as OpenAI, Hugging Face Transformers, and Anthropic."}),"\n",(0,o.jsxs)(n.p,{children:["Weave automatically captures traces for ",(0,o.jsx)(n.a,{href:"https://huggingface.co/docs/smolagents/en/index",children:"Smolagents"}),". To start tracking, call ",(0,o.jsx)(n.code,{children:"weave.init()"})," and use the library as usual."]}),"\n",(0,o.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["Before you can use Smolagents with Weave, install the required libraries or upgrade to the latest versions. The following command installs or upgrades ",(0,o.jsx)(n.code,{children:"smolagents"}),", ",(0,o.jsx)(n.code,{children:"openai"}),", and ",(0,o.jsx)(n.code,{children:"weave"}),", and suppresses output:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"pip install -U smolagents openai weave -qqq\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Smolagents supports multiple LLM providers, such as OpenAI, Hugging Face Transformers, and Anthropic. Set the API key for your chosen provider by setting the corresponding environment variable:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import os\nimport getpass\n\nos.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API key: ")\n'})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"basic-tracing",children:"Basic tracing"}),"\n",(0,o.jsx)(n.p,{children:"Storing traces of language model applications in a central location is essential during development and production. These traces help with debugging and serve as valuable datasets for improving your application."}),"\n",(0,o.jsxs)(n.p,{children:["Weave automatically captures traces for ",(0,o.jsx)(n.a,{href:"https://huggingface.co/docs/smolagents/en/index",children:"Smolagents"}),". To start tracking, initialize Weave by calling ",(0,o.jsx)(n.code,{children:"weave.init()"}),", then use the library as usual."]}),"\n",(0,o.jsx)(n.p,{children:"The following example demonstrates how to log inference calls to a tool-using LLM agent with Weave. In this scenario:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["You define a language model (OpenAI's ",(0,o.jsx)(n.code,{children:"gpt-4o"}),") using Smolagents' ",(0,o.jsx)(n.code,{children:"OpenAIServerModel"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["You configure a search tool (",(0,o.jsx)(n.code,{children:"DuckDuckGoSearchTool"}),") that the agent can invoke when needed."]}),"\n",(0,o.jsxs)(n.li,{children:["You construct a ",(0,o.jsx)(n.code,{children:"ToolCallingAgent"}),", passing in the tool and model."]}),"\n",(0,o.jsx)(n.li,{children:"You run a query through the agent that triggers the search tool."}),"\n",(0,o.jsx)(n.li,{children:"Weave logs each function and model invocation, making them available for inspection via its web interface."}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import weave\nfrom smolagents import DuckDuckGoSearchTool, OpenAIServerModel, ToolCallingAgent\n\n# Initialize Weave\nweave.init(project_name="smolagents")\n\n# Define your LLM provider supported by Smolagents\nmodel = OpenAIServerModel(model_id="gpt-4o")\n\n# Define a DuckDuckGo web search tool based on your query\nsearch_tool = DuckDuckGoSearchTool()\n\n# Define a tool-calling agent\nagent = ToolCallingAgent(tools=[search_tool], model=model)\nanswer = agent.run(\n    "Get me just the title of the page at url \'https://wandb.ai/geekyrakshit/story-illustration/reports/Building-a-GenAI-assisted-automatic-story-illustrator--Vmlldzo5MTYxNTkw\'?"\n)\n'})}),"\n",(0,o.jsx)(n.p,{children:"Once you run the code sample, navigate to your Weave project dashboard to view the traces."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"Weave logs each inference call, providing details about inputs, outputs, and metadata.",src:t(37654).Z+"",width:"3452",height:"1866"})}),"\n",(0,o.jsx)(n.h2,{id:"tracing-custom-tools",children:"Tracing custom tools"}),"\n",(0,o.jsxs)(n.p,{children:["You can declare custom tools for your agentic workflows by decorating a function with ",(0,o.jsx)(n.code,{children:"@tool"})," from ",(0,o.jsx)(n.code,{children:"smolagents"})," or by inheriting from the ",(0,o.jsx)(n.code,{children:"smolagents.Tool"})," class."]}),"\n",(0,o.jsx)(n.p,{children:"Weave automatically tracks custom tool calls for your Smolagents workflows. The following example shows how to log a custom Smolagents tool call with Weave:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["A custom ",(0,o.jsx)(n.code,{children:"get_weather"})," function is defined and decorated with ",(0,o.jsx)(n.code,{children:"@tool"})," from Smolagents, enabling the agent to invoke it as part of its reasoning process."]}),"\n",(0,o.jsx)(n.li,{children:"The function accepts a location and an optional flag for Celsius output."}),"\n",(0,o.jsxs)(n.li,{children:["A language model is instantiated using ",(0,o.jsx)(n.code,{children:"OpenAIServerModel"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["A ",(0,o.jsx)(n.code,{children:"ToolCallingAgent"})," is created with the custom tool and model."]}),"\n",(0,o.jsxs)(n.li,{children:["When the agent runs the query, it selects and invokes the ",(0,o.jsx)(n.code,{children:"get_weather"})," tool."]}),"\n",(0,o.jsx)(n.li,{children:"Weave logs both the model inference and the custom tool invocation, including arguments and return values."}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from typing import Optional\n\nimport weave\nfrom smolagents import OpenAIServerModel, ToolCallingAgent, tool\n\nweave.init(project_name="smolagents")\n\n@tool\ndef get_weather(location: str, celsius: Optional[bool] = False) -> str:\n    """\n    Get the weather in the next few days for a given location.\n    Args:\n        location: The location.\n        celsius: Whether to use Celsius for temperature.\n    """\n    return f"The weather in {location} is sunny with temperatures around 7\xb0C."\n\nmodel = OpenAIServerModel(model_id="gpt-4o")\nagent = ToolCallingAgent(tools=[get_weather], model=model)\nanswer = agent.run("What is the weather in Tokyo?")\n'})}),"\n",(0,o.jsx)(n.p,{children:"Once you run the code sample, navigate to your Weave project dashboard to view the traces."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"Weave logs each custom tool call.",src:t(74495).Z+"",width:"3452",height:"1866"})})]})}function h(e={}){const{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},74495:(e,n,t)=>{t.d(n,{Z:()=>o});const o=t.p+"assets/images/smolagents-custom-tool-b2515cf00b9504c77b7e937327ce8c30.png"},37654:(e,n,t)=>{t.d(n,{Z:()=>o});const o=t.p+"assets/images/smolagents-trace-deb73b673d6258aa23a3ad0390f2af71.png"},11151:(e,n,t)=>{t.d(n,{Z:()=>l,a:()=>i});var o=t(67294);const s={},a=o.createContext(s);function i(e){const n=o.useContext(a);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),o.createElement(a.Provider,{value:n},e.children)}}}]);