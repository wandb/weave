"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3669],{75559:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>l,default:()=>h,frontMatter:()=>i,metadata:()=>c,toc:()=>u});var a=t(85893),o=t(11151),r=t(65488),s=t(85162);const i={},l="OpenAI",c={id:"guides/integrations/openai",title:"OpenAI",description:"Do you want to experiment with OpenAI models on Weave without any set up? Try the LLM Playground.",source:"@site/docs/guides/integrations/openai.md",sourceDirName:"guides/integrations",slug:"/guides/integrations/openai",permalink:"/guides/integrations/openai",draft:!1,unlisted:!1,editUrl:"https://github.com/wandb/weave/blob/master/docs/docs/guides/integrations/openai.md",tags:[],version:"current",lastUpdatedAt:1739928519e3,frontMatter:{},sidebar:"documentationSidebar",previous:{title:"NVIDIA NIM",permalink:"/guides/integrations/nvidia_nim"},next:{title:"Open Router",permalink:"/guides/integrations/openrouter"}},p={},u=[{value:"Tracing",id:"tracing",level:2},{value:"Track your own ops",id:"track-your-own-ops",level:2},{value:"Create a <code>Model</code> for easier experimentation",id:"create-a-model-for-easier-experimentation",level:2},{value:"Usage Info",id:"usage-info",level:2},{value:"Support for deprecated function calling",id:"support-for-deprecated-function-calling",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",img:"img",p:"p",pre:"pre",...(0,o.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h1,{id:"openai",children:"OpenAI"}),"\n",(0,a.jsx)("a",{target:"_blank",href:"https://colab.research.google.com/github/wandb/examples/blob/master/weave/docs/quickstart_openai.ipynb",children:(0,a.jsx)("img",{src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"Open In Colab"})}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["Do you want to experiment with OpenAI models on Weave without any set up? Try the ",(0,a.jsx)(n.a,{href:"/guides/tools/playground",children:"LLM Playground"}),"."]})}),"\n",(0,a.jsx)(n.h2,{id:"tracing",children:"Tracing"}),"\n",(0,a.jsx)(n.p,{children:"It\u2019s important to store traces of LLM applications in a central database, both during development and in production. You\u2019ll use these traces for debugging and to help build a dataset of tricky examples to evaluate against while improving your application."}),"\n",(0,a.jsxs)(r.Z,{groupId:"programming-language",queryString:!0,children:[(0,a.jsxs)(s.default,{value:"python",label:"Python",default:!0,children:[(0,a.jsxs)(n.p,{children:["Weave can automatically capture traces for the ",(0,a.jsx)(n.a,{href:"https://platform.openai.com/docs/libraries/python-library",children:"openai python library"}),"."]}),(0,a.jsxs)(n.p,{children:["Start capturing by calling ",(0,a.jsx)(n.code,{children:"weave.init(<project-name>)"})," with a project name your choice."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from openai import OpenAI\nimport weave\nclient = OpenAI()\n# highlight-next-line\nweave.init(\'emoji-bot\')\n\nresponse = client.chat.completions.create(\n  model="gpt-4",\n  messages=[\n    {\n      "role": "system",\n      "content": "You are AGI. You will be provided with a message, and your task is to respond using emojis only."\n    },\n    {\n      "role": "user",\n      "content": "How are you?"\n    }\n  ],\n  temperature=0.8,\n  max_tokens=64,\n  top_p=1\n)\n'})})]}),(0,a.jsxs)(s.default,{value:"typescript",label:"TypeScript",children:[(0,a.jsxs)(n.p,{children:["Weave can automatically capture traces for the ",(0,a.jsx)(n.a,{href:"https://platform.openai.com/docs/libraries/node-js-library",children:"openai typescript library"}),"."]}),(0,a.jsxs)(n.p,{children:["Start capturing by calling ",(0,a.jsx)(n.code,{children:"await weave.init(<project-name>)"})," with a project name your choice, and then wrapping your OpenAI client with ",(0,a.jsx)(n.code,{children:"weave.wrapOpenAI"}),"."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"import {OpenAI} from 'openai';\nimport * as weave from 'weave';\n\n// highlight-next-line\nconst client = await weave.init('emoji-bot');\n// highlight-next-line\nconst openai = weave.wrapOpenAI(new OpenAI());\n\nconst response = await openai.chat.completions.create({\n  model: 'gpt-4',\n  messages: [\n    {\n      role: 'system',\n      content:\n        'You are AGI. You will be provided with a message, and your task is to respond using emojis only.',\n    },\n    {\n      role: 'user',\n      content: 'How are you?',\n    },\n  ],\n  temperature: 0.8,\n  max_tokens: 64,\n  top_p: 1,\n});\n"})})]})]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.a,{href:"https://wandb.ai/_scott/emoji-bot/weave/calls",children:(0,a.jsx)(n.img,{alt:"openai.png",src:t(38681).Z+"",width:"2702",height:"1210"})})}),"\n",(0,a.jsx)(n.h2,{id:"track-your-own-ops",children:"Track your own ops"}),"\n",(0,a.jsxs)(r.Z,{groupId:"programming-language",queryString:!0,children:[(0,a.jsxs)(s.default,{value:"python",label:"Python",default:!0,children:[(0,a.jsxs)(n.p,{children:["Wrapping a function with ",(0,a.jsx)(n.code,{children:"@weave.op"})," starts capturing inputs, outputs and app logic so you can debug how data flows through your app. You can deeply nest ops and build a tree of functions that you want to track. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git."]}),(0,a.jsxs)(n.p,{children:["Simply create a function decorated with ",(0,a.jsx)(n.a,{href:"/guides/tracking/ops",children:(0,a.jsx)(n.code,{children:"@weave.op"})})," that calls into ",(0,a.jsx)(n.a,{href:"https://platform.openai.com/docs/reference/python-sdk?lang=python",children:"openai python library"}),"."]}),(0,a.jsx)(n.p,{children:"In the example below, we have 2 functions wrapped with op. This helps us see how intermediate steps, like the retrieval step in a RAG app, are affecting how our app behaves."}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# highlight-next-line\nimport weave\nfrom openai import OpenAI\nimport requests, random\nPROMPT="""Emulate the Pokedex from early Pok\xe9mon episodes. State the name of the Pokemon and then describe it.\n        Your tone is informative yet sassy, blending factual details with a touch of dry humor. Be concise, no more than 3 sentences. """\nPOKEMON = [\'pikachu\', \'charmander\', \'squirtle\', \'bulbasaur\', \'jigglypuff\', \'meowth\', \'eevee\']\nclient = OpenAI()\n\n# highlight-next-line\n@weave.op\ndef get_pokemon_data(pokemon_name):\n    # highlight-next-line\n    # This is a step within your application, like the retrieval step within a RAG app\n    url = f"https://pokeapi.co/api/v2/pokemon/{pokemon_name}"\n    response = requests.get(url)\n    if response.status_code == 200:\n        data = response.json()\n        name = data["name"]\n        types = [t["type"]["name"] for t in data["types"]]\n        species_url = data["species"]["url"]\n        species_response = requests.get(species_url)\n        evolved_from = "Unknown"\n        if species_response.status_code == 200:\n            species_data = species_response.json()\n            if species_data["evolves_from_species"]:\n                evolved_from = species_data["evolves_from_species"]["name"]\n        return {"name": name, "types": types, "evolved_from": evolved_from}\n    else:\n        return None\n\n# highlight-next-line\n@weave.op\ndef pokedex(name: str, prompt: str) -> str:\n    # highlight-next-line\n    # This is your root op that calls out to other ops\n    # highlight-next-line\n    data = get_pokemon_data(name)\n    if not data: return "Error: Unable to fetch data"\n    response = client.chat.completions.create(\n        model="gpt-3.5-turbo",\n        messages=[\n            {"role": "system","content": prompt},\n            {"role": "user", "content": str(data)}\n        ],\n        temperature=0.7,\n        max_tokens=100,\n        top_p=1\n    )\n    return response.choices[0].message.content\n\n# highlight-next-line\nweave.init(\'pokedex-openai\')\n# Get data for a specific Pok\xe9mon\npokemon_data = pokedex(random.choice(POKEMON), PROMPT)\n'})}),(0,a.jsxs)(n.p,{children:["Navigate to Weave and you can click ",(0,a.jsx)(n.code,{children:"get_pokemon_data"})," in the UI to see the inputs & outputs of that step."]})]}),(0,a.jsxs)(s.default,{value:"typescript",label:"TypeScript",children:[(0,a.jsxs)(n.p,{children:["Wrapping a function with ",(0,a.jsx)(n.code,{children:"weave.op"})," starts capturing inputs, outputs and app logic so you can debug how data flows through your app. You can deeply nest ops and build a tree of functions that you want to track. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git."]}),(0,a.jsxs)(n.p,{children:["Simply create a function wrapped with ",(0,a.jsx)(n.a,{href:"/guides/tracking/ops",children:(0,a.jsx)(n.code,{children:"weave.op"})})," that calls into ",(0,a.jsx)(n.a,{href:"https://platform.openai.com/docs/libraries/node-js-library",children:"openai typescript library"}),"."]}),(0,a.jsx)(n.p,{children:"In the example below, we have 2 functions wrapped with op. This helps us see how intermediate steps, like the retrieval step within a RAG app, are affecting how our app behaves."}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"import OpenAI from 'openai';\n// highlight-next-line\nimport * as weave from 'weave';\n\nconst PROMPT = `Emulate the Pokedex from early Pok\xe9mon episodes. State the name of the Pokemon and then describe it.\n        Your tone is informative yet sassy, blending factual details with a touch of dry humor. Be concise, no more than 3 sentences.`;\nconst POKEMON = [\n  'pikachu',\n  'charmander',\n  'squirtle',\n  'bulbasaur',\n  'jigglypuff',\n  'meowth',\n  'eevee',\n];\n\nconst openai = weave.wrapOpenAI(new OpenAI());\n\ninterface PokemonData {\n  name: string;\n  types: string[];\n  evolved_from: string;\n}\n\n// highlight-next-line\nconst getPokemonData = weave.op(async function getPokemonData(\n  pokemonName: string\n): Promise<PokemonData | null> {\n  try {\n    const url = `https://pokeapi.co/api/v2/pokemon/${pokemonName}`;\n    const response = await fetch(url);\n\n    if (response.ok) {\n      const data = await response.json();\n      const name = data.name;\n      const types = data.types.map((t: any) => t.type.name);\n\n      const speciesResponse = await fetch(data.species.url);\n      let evolved_from = 'Unknown';\n\n      if (speciesResponse.ok) {\n        const speciesData = await speciesResponse.json();\n        if (speciesData.evolves_from_species) {\n          evolved_from = speciesData.evolves_from_species.name;\n        }\n      }\n\n      return {name, types, evolved_from};\n    }\n    return null;\n  } catch (error) {\n    return null;\n  }\n});\n\n// highlight-next-line\nconst pokedex = weave.op(async function pokedex(\n  name: string,\n  prompt: string\n): Promise<string> {\n  const data = await getPokemonData(name);\n  if (!data) return 'Error: Unable to fetch data';\n\n  const response = await openai.chat.completions.create({\n    model: 'gpt-3.5-turbo',\n    messages: [\n      {role: 'system', content: prompt},\n      {role: 'user', content: JSON.stringify(data)},\n    ],\n    temperature: 0.7,\n    max_tokens: 100,\n    top_p: 1,\n  });\n\n  return response.choices[0].message.content || '';\n});\n\nasync function main() {\n  await weave.init('pokedex-openai');\n  const randomPokemon = POKEMON[Math.floor(Math.random() * POKEMON.length)];\n  const pokemonData = await pokedex(randomPokemon, PROMPT);\n  console.log(pokemonData);\n}\n\nmain();\n"})})]})]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.a,{href:"https://wandb.ai/_scott/pokedex-openai/weave",children:(0,a.jsx)(n.img,{alt:"openai-pokedex.png",src:t(13610).Z+"",width:"2704",height:"1562"})})}),"\n",(0,a.jsxs)(n.h2,{id:"create-a-model-for-easier-experimentation",children:["Create a ",(0,a.jsx)(n.code,{children:"Model"})," for easier experimentation"]}),"\n",(0,a.jsxs)(r.Z,{groupId:"programming-language",queryString:!0,children:[(0,a.jsxs)(s.default,{value:"python",label:"Python",default:!0,children:[(0,a.jsxs)(n.p,{children:["Organizing experimentation is difficult when there are many moving pieces. By using the ",(0,a.jsx)(n.a,{href:"/guides/core-types/models",children:(0,a.jsx)(n.code,{children:"Model"})})," class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app."]}),(0,a.jsxs)(n.p,{children:["In addition to versioning code and capturing inputs/outputs, ",(0,a.jsx)(n.a,{href:"/guides/core-types/models",children:(0,a.jsx)(n.code,{children:"Model"})}),"s capture structured parameters that control your application\u2019s behavior, making it easy to find what parameters worked best. You can also use Weave Models with ",(0,a.jsx)(n.code,{children:"serve"}),", and ",(0,a.jsx)(n.a,{href:"/guides/core-types/evaluations",children:(0,a.jsx)(n.code,{children:"Evaluation"})}),"s."]}),(0,a.jsxs)(n.p,{children:["In the example below, you can experiment with ",(0,a.jsx)(n.code,{children:"model"})," and ",(0,a.jsx)(n.code,{children:"system_message"}),". Every time you change one of these, you'll get a new ",(0,a.jsx)(n.em,{children:"version"})," of ",(0,a.jsx)(n.code,{children:"GrammarCorrectorModel"}),"."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import weave\nfrom openai import OpenAI\n\nweave.init(\'grammar-openai\')\n\nclass GrammarCorrectorModel(weave.Model): # Change to `weave.Model`\n  model: str\n  system_message: str\n\n  @weave.op()\n  def predict(self, user_input): # Change to `predict`\n    client = OpenAI()\n    response = client.chat.completions.create(\n      model=self.model,\n      messages=[\n          {\n              "role": "system",\n              "content": self.system_message\n          },\n          {\n              "role": "user",\n              "content": user_input\n          }\n          ],\n          temperature=0,\n    )\n    return response.choices[0].message.content\n\n\ncorrector = GrammarCorrectorModel(\n    model="gpt-3.5-turbo-1106",\n    system_message = "You are a grammar checker, correct the following user input.")\nresult = corrector.predict("That was so easy, it was a piece of pie!")\nprint(result)\n'})}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.a,{href:"https://wandb.ai/_scott/grammar-openai/weave/calls",children:(0,a.jsx)(n.img,{alt:"openai-model.png",src:t(60043).Z+"",width:"3146",height:"904"})})})]}),(0,a.jsx)(s.default,{value:"typescript",label:"TypeScript",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-plaintext",children:"This feature is not available in TypeScript yet.  Stay tuned!\n"})})})]}),"\n",(0,a.jsx)(n.h2,{id:"usage-info",children:"Usage Info"}),"\n",(0,a.jsxs)(n.p,{children:["The OpenAI calls return usage info as a default when ",(0,a.jsx)(n.code,{children:"stream=False"}),". Weave will track this usage info and log it to weave to render token counts and cost of the call."]}),"\n",(0,a.jsxs)(n.p,{children:["In case you set ",(0,a.jsx)(n.code,{children:"stream=True"}),", we will automatically patch the call execution with ",(0,a.jsx)(n.code,{children:'stream_options={"include_usage": True}'})," argument. This will return the usage info in the last chunk to be rendered in the UI. As a user, the stream iterator will not contain this info."]}),"\n",(0,a.jsxs)(n.p,{children:["If you explicitly set ",(0,a.jsx)(n.code,{children:"stream=True"})," and ",(0,a.jsx)(n.code,{children:'stream_options={"include_usage": True}'}),", the returned stream object will contain the usage info. If you don't want to track the usage info you need to explicitly set ",(0,a.jsx)(n.code,{children:'stream_options={"include_usage": False}'}),"."]}),"\n",(0,a.jsx)(n.h2,{id:"support-for-deprecated-function-calling",children:"Support for deprecated function calling"}),"\n",(0,a.jsxs)(n.p,{children:["OpenAI deprecated the ",(0,a.jsx)(n.code,{children:"functions"})," argument in favor of ",(0,a.jsx)(n.code,{children:"tool_calls"}),". Since frameworks like Langchain, LlamaIndex, etc., still support this argument our OpenAI weave integration will trace if you pass list of function schemas to ",(0,a.jsx)(n.code,{children:"functions"})," argument."]})]})}function h(e={}){const{wrapper:n}={...(0,o.a)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},85162:(e,n,t)=>{t.r(n),t.d(n,{default:()=>s});t(67294);var a=t(90512);const o={tabItem:"tabItem_Ymn6"};var r=t(85893);function s(e){let{children:n,hidden:t,className:s}=e;return(0,r.jsx)("div",{role:"tabpanel",className:(0,a.Z)(o.tabItem,s),hidden:t,children:n})}},65488:(e,n,t)=>{t.d(n,{Z:()=>h});var a=t(67294),o=t(90512),r=t(12466),s=t(70989),i=t(72389);const l={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var c=t(85893);function p(e){let{className:n,block:t,selectedValue:a,selectValue:s,tabValues:i}=e;const p=[],{blockElementScrollPositionUntilNextRender:u}=(0,r.o5)(),d=e=>{const n=e.currentTarget,t=p.indexOf(n),o=i[t].value;o!==a&&(u(n),s(o))},h=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const t=p.indexOf(e.currentTarget)+1;n=p[t]??p[0];break}case"ArrowLeft":{const t=p.indexOf(e.currentTarget)-1;n=p[t]??p[p.length-1];break}}n?.focus()};return(0,c.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.Z)("tabs",{"tabs--block":t},n),children:i.map((e=>{let{value:n,label:t,attributes:r}=e;return(0,c.jsx)("li",{role:"tab",tabIndex:a===n?0:-1,"aria-selected":a===n,ref:e=>p.push(e),onKeyDown:h,onClick:d,...r,className:(0,o.Z)("tabs__item",l.tabItem,r?.className,{"tabs__item--active":a===n}),children:t??n},n)}))})}function u(e){let{lazy:n,children:t,selectedValue:o}=e;const r=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=r.find((e=>e.props.value===o));return e?(0,a.cloneElement)(e,{className:"margin-top--md"}):null}return(0,c.jsx)("div",{className:"margin-top--md",children:r.map(((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==o})))})}function d(e){const n=(0,s.Y)(e);return(0,c.jsxs)("div",{className:(0,o.Z)("tabs-container",l.tabList),children:[(0,c.jsx)(p,{...n,...e}),(0,c.jsx)(u,{...n,...e})]})}function h(e){const n=(0,i.default)();return(0,c.jsx)(d,{...e,children:(0,s.h)(e.children)},String(n))}},70989:(e,n,t)=>{t.d(n,{Y:()=>h,h:()=>c});var a=t(67294),o=t(16550),r=t(20469),s=t(91980),i=t(67392),l=t(20812);function c(e){return a.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function p(e){const{values:n,children:t}=e;return(0,a.useMemo)((()=>{const e=n??function(e){return c(e).map((e=>{let{props:{value:n,label:t,attributes:a,default:o}}=e;return{value:n,label:t,attributes:a,default:o}}))}(t);return function(e){const n=(0,i.l)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function u(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function d(e){let{queryString:n=!1,groupId:t}=e;const r=(0,o.k6)(),i=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,s._X)(i),(0,a.useCallback)((e=>{if(!i)return;const n=new URLSearchParams(r.location.search);n.set(i,e),r.replace({...r.location,search:n.toString()})}),[i,r])]}function h(e){const{defaultValue:n,queryString:t=!1,groupId:o}=e,s=p(e),[i,c]=(0,a.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!u({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const a=t.find((e=>e.default))??t[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:n,tabValues:s}))),[h,m]=d({queryString:t,groupId:o}),[g,f]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[o,r]=(0,l.Nk)(t);return[o,(0,a.useCallback)((e=>{t&&r.set(e)}),[t,r])]}({groupId:o}),y=(()=>{const e=h??g;return u({value:e,tabValues:s})?e:null})();(0,r.Z)((()=>{y&&c(y)}),[y]);return{selectedValue:i,selectValue:(0,a.useCallback)((e=>{if(!u({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);c(e),m(e),f(e)}),[m,f,s]),tabValues:s}}},60043:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/openai-model-5255ed680d313b124b583ec73e1446b7.png"},13610:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/openai-pokedex-1f8a19ae9d4a27f56961822bd4d20125.png"},38681:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/openai-3d16f489ef9afe0b50ee6b83f9b3b2f2.png"},11151:(e,n,t)=>{t.d(n,{Z:()=>i,a:()=>s});var a=t(67294);const o={},r=a.createContext(o);function s(e){const n=a.useContext(r);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),a.createElement(r.Provider,{value:n},e.children)}}}]);