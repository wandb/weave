"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2085],{84588:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>a,toc:()=>c});var r=i(85893),t=i(11151);const s={},o="Integrations",a={id:"guides/integrations/index",title:"Integrations",description:"Weave provides automatic implicit patching for all supported integrations by default:",source:"@site/docs/guides/integrations/index.md",sourceDirName:"guides/integrations",slug:"/guides/integrations/",permalink:"/guides/integrations/",draft:!1,unlisted:!1,editUrl:"https://github.com/wandb/weave/blob/master/docs/docs/guides/integrations/index.md",tags:[],version:"current",lastUpdatedAt:1758042624e3,frontMatter:{},sidebar:"documentationSidebar",previous:{title:"Evaluation Playground",permalink:"/guides/tools/evaluation_playground"},next:{title:"Saved Views",permalink:"/guides/tools/saved-views"}},l={},c=[{value:"LLM Providers",id:"llm-providers",level:2},{value:"Frameworks",id:"frameworks",level:2},{value:"Protocols",id:"protocols",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h1,{id:"integrations",children:"Integrations"}),"\n",(0,r.jsxs)(n.admonition,{title:"Integration Tracking",type:"info",children:[(0,r.jsxs)(n.p,{children:["Weave provides ",(0,r.jsx)(n.strong,{children:"automatic implicit patching"})," for all supported integrations by default:"]}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Implicit Patching (Automatic):"})," Libraries are automatically patched regardless of when they are imported."]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Option 1: Import before weave.init()\nimport openai\nimport weave\nweave.init('my-project')  # OpenAI is automatically patched!\n\n# Option 2: Import after weave.init()\nimport weave\nweave.init('my-project')\nimport anthropic  # Automatically patched via import hook!\n"})}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Disabling Implicit Patching:"})," You can disable automatic patching if you prefer explicit control."]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import weave\n\n# Option 1: Via settings parameter\nweave.init('my-project', settings={'implicitly_patch_integrations': False})\n\n# Option 2: Via environment variable\n# Set WEAVE_IMPLICITLY_PATCH_INTEGRATIONS=false before running your script\n\n# With implicit patching disabled, you must explicitly patch integrations\nimport openai\nweave.patch_openai()  # Now required for OpenAI tracing\n"})}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Explicit Patching (Manual):"})," You can explicitly patch integrations for fine-grained control."]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import weave\nweave.init('my-project')\nweave.integrations.patch_openai()  # Enable OpenAI tracing\nweave.integrations.patch_anthropic()  # Enable Anthropic tracing\n"})})]}),"\n",(0,r.jsx)(n.p,{children:"W&B Weave provides logging integrations for popular LLM providers and orchestration frameworks. These integrations allow you to seamlessly trace calls made through various libraries, enhancing your ability to monitor and analyze your AI applications."}),"\n",(0,r.jsx)(n.h2,{id:"llm-providers",children:"LLM Providers"}),"\n",(0,r.jsx)(n.p,{children:"LLM providers are the vendors that offer access to large language models for generating predictions. Weave integrates with these providers to log and trace the interactions with their APIs:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"https://docs.wandb.ai/guides/inference/",children:"W&B Inference Service"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/bedrock",children:"Amazon Bedrock"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/anthropic",children:"Anthropic"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/cerebras",children:"Cerebras"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/cohere",children:"Cohere"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/google",children:"Google"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/groq",children:"Groq"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/huggingface",children:"Hugging Face Hub"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/litellm",children:"LiteLLM"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/azure",children:"Microsoft Azure"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/mistral",children:"MistralAI"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/nvidia_nim",children:"NVIDIA NIM"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/openai",children:"OpenAI"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/openrouter",children:"Open Router"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/together_ai",children:"Together AI"})})}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/local_models",children:"Local Models"})}),": For when you're running models on your own infrastructure."]}),"\n",(0,r.jsx)(n.h2,{id:"frameworks",children:"Frameworks"}),"\n",(0,r.jsx)(n.p,{children:"Frameworks help orchestrate the actual execution pipelines in AI applications. They provide tools and abstractions for building complex workflows. Weave integrates with these frameworks to trace the entire pipeline:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/openai_agents",children:"OpenAI Agents SDK"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/langchain",children:"LangChain"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/llamaindex",children:"LlamaIndex"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/dspy",children:"DSPy"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/instructor",children:"Instructor"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/crewai",children:"CrewAI"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/smolagents",children:"Smolagents"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/pydantic_ai",children:"PydanticAI"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/google_adk",children:"Google Agent Development Kit (ADK)"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/autogen",children:"AutoGen"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/verdict",children:"Verdict"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/js",children:"TypeScript SDK"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/agno",children:"Agno"})})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/koog",children:"Koog"})})}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"protocols",children:"Protocols"}),"\n",(0,r.jsx)(n.p,{children:"Weave integrates with standardized protocols that enable communication between AI applications and their supporting services:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/guides/integrations/mcp",children:"Model Context Protocol (MCP)"})})}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Choose an integration from the lists above to learn more about how to use Weave with your preferred LLM provider, framework, or protocol. Whether you're directly accessing LLM APIs, building complex pipelines, or using standardized protocols, Weave provides the tools to trace and analyze your AI applications effectively."})]})}function h(e={}){const{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},11151:(e,n,i)=>{i.d(n,{Z:()=>a,a:()=>o});var r=i(67294);const t={},s=r.createContext(t);function o(e){const n=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);