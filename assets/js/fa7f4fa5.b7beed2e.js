"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1927],{54913:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>r,contentTitle:()=>s,default:()=>h,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var a=t(85893),o=t(11151);const i={title:"Integrating with Weave - Production Dashboard"},s="Integrating with Weave: Production Dashboard",l={id:"reference/gen_notebooks/online_monitoring",title:"Integrating with Weave - Production Dashboard",description:"Open in Colab",source:"@site/docs/reference/gen_notebooks/online_monitoring.md",sourceDirName:"reference/gen_notebooks",slug:"/reference/gen_notebooks/online_monitoring",permalink:"/reference/gen_notebooks/online_monitoring",draft:!1,unlisted:!1,editUrl:"https://github.com/wandb/weave/blob/master/docs/docs/reference/gen_notebooks/online_monitoring.md",tags:[],version:"current",lastUpdatedAt:1749652482e3,frontMatter:{title:"Integrating with Weave - Production Dashboard"},sidebar:"notebookSidebar",previous:{title:"ocr-pipeline",permalink:"/reference/gen_notebooks/ocr-pipeline"},next:{title:"Handling and Redacting PII",permalink:"/reference/gen_notebooks/pii"}},r={},c=[{value:"2.1 Initializing Weave Client and Defining Costs",id:"21-initializing-weave-client-and-defining-costs",level:2},{value:"2.2 Fetching Calls Data from Weave",id:"22-fetching-calls-data-from-weave",level:2},{value:"2.2.1 Fetching Data call-by-call",id:"221-fetching-data-call-by-call",level:3},{value:"2.2.2 Using high-level APIs",id:"222-using-high-level-apis",level:3},{value:"2.4 Gathering inputs and generating visualizations",id:"24-gathering-inputs-and-generating-visualizations",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(n.admonition,{title:"This is a notebook",type:"tip",children:[(0,a.jsx)("a",{href:"https://colab.research.google.com/github/wandb/weave/blob/master/docs/./notebooks/online_monitoring.ipynb",target:"_blank",rel:"noopener noreferrer",class:"navbar__item navbar__link button button--secondary button--med margin-right--sm notebook-cta-button",children:(0,a.jsxs)("div",{children:[(0,a.jsx)("img",{src:"https://upload.wikimedia.org/wikipedia/commons/archive/d/d0/20221103151430%21Google_Colaboratory_SVG_Logo.svg",alt:"Open In Colab",height:"20px"}),(0,a.jsx)("div",{children:"Open in Colab"})]})}),(0,a.jsx)("a",{href:"https://github.com/wandb/weave/blob/master/docs/./notebooks/online_monitoring.ipynb",target:"_blank",rel:"noopener noreferrer",class:"navbar__item navbar__link button button--secondary button--med margin-right--sm notebook-cta-button",children:(0,a.jsxs)("div",{children:[(0,a.jsx)("img",{src:"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg",alt:"View in Github",height:"15px"}),(0,a.jsx)("div",{children:"View in Github"})]})})]}),"\n",(0,a.jsx)(n.h1,{id:"integrating-with-weave-production-dashboard",children:"Integrating with Weave: Production Dashboard"}),"\n",(0,a.jsx)(n.p,{children:"The GenAI tooling landscape is rapidly evolving - new frameworks, tools, and applications are emerging all the time. Weave aims to be a one-stop-shop for all your GenAI monitoring and evaluation needs. This also means that sometimes it is necessary to integrate with existing platforms or extend Weave to fit the specific needs of your project or organization."}),"\n",(0,a.jsx)(n.p,{children:"In this cookbook, we'll demonstrate how to leverage Weave's powerful APIs and functions to create a custom dashboard for production monitoring as an extension to the Traces view in Weave. We'll focus on:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Fetching traces, costs, feedback, and other metrics from Weave"}),"\n",(0,a.jsx)(n.li,{children:"Creating aggregate views for user feedback and cost distribution"}),"\n",(0,a.jsx)(n.li,{children:"Creating visualizations for token usage and latency over time"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["You can try out the dashboard with your own Weave project by installing streamlit and running ",(0,a.jsx)(n.a,{href:"https://github.com/NiWaRe/agent-dev-collection",children:"this production dashboard script"}),"!"]}),"\n",(0,a.jsx)("img",{src:"https://github.com/NiWaRe/knowledge-worker-weave/blob/master/screenshots/dashboard_weave_preview.jpg?raw=true",width:"1000",alt:"Example Production Dashboard with Weave"}),"\n",(0,a.jsx)(n.h1,{id:"1-setup",children:"1. Setup"}),"\n",(0,a.jsx)(n.p,{children:"To follow along this tutorial you'll only need to install the following packages:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!pip install streamlit pandas plotly weave\n"})}),"\n",(0,a.jsx)(n.h1,{id:"2-implementation",children:"2. Implementation"}),"\n",(0,a.jsx)(n.h2,{id:"21-initializing-weave-client-and-defining-costs",children:"2.1 Initializing Weave Client and Defining Costs"}),"\n",(0,a.jsx)(n.p,{children:"First, we'll set up a function to initialize the Weave client and add costs for each model."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"We have included the standard costs for many standard models but we also make it easy to add your own custom costs and custom models. In the following we'll show how to add custom costs for a few models and use the standard costs for the rest."}),"\n",(0,a.jsxs)(n.li,{children:["The costs are calculate based on the tracked tokens for each call in Weave. For many LLM vendor libraries, we will automatically track the token usage, but it is also possible to return custom token counts for any call. See this cookbook on how to define the token count and cost calculation for a custom model - ",(0,a.jsx)(n.a,{href:"https://weave-docs.wandb.ai/reference/gen_notebooks/custom_model_cost#setting-up-a-model-with-weave",children:"custom cost cookbook"}),"."]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'PROJECT_NAME = "wandb-smle/weave-cookboook-demo"\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import weave\n\nMODEL_NAMES = [\n    # model name, prompt cost, completion cost\n    ("gpt-4o-2024-05-13", 0.03, 0.06),\n    ("gpt-4o-mini-2024-07-18", 0.03, 0.06),\n    ("gemini/gemini-1.5-flash", 0.00025, 0.0005),\n    ("gpt-4o-mini", 0.03, 0.06),\n    ("gpt-4-turbo", 0.03, 0.06),\n    ("claude-3-haiku-20240307", 0.01, 0.03),\n    ("gpt-4o", 0.03, 0.06),\n]\n\n\ndef init_weave_client(project_name):\n    try:\n        client = weave.init(project_name)\n        for model, prompt_cost, completion_cost in MODEL_NAMES:\n            client.add_cost(\n                llm_id=model,\n                prompt_token_cost=prompt_cost,\n                completion_token_cost=completion_cost,\n            )\n    except Exception as e:\n        print(f"Failed to initialize Weave client for project \'{project_name}\': {e}")\n        return None\n    else:\n        return client\n\n\nclient = init_weave_client(PROJECT_NAME)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"22-fetching-calls-data-from-weave",children:"2.2 Fetching Calls Data from Weave"}),"\n",(0,a.jsx)(n.p,{children:"In order to fetch call data from Weave, we have two options:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Fetching Data call-by-call"}),"\n",(0,a.jsx)(n.li,{children:"Using high-level APIs"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"221-fetching-data-call-by-call",children:"2.2.1 Fetching Data call-by-call"}),"\n",(0,a.jsxs)(n.p,{children:["The first option to access data from Weave is to retrieve a list of filtered calls and extract the wanted data call-by-call. For that we can use the ",(0,a.jsx)(n.code,{children:"calls_query_stream"})," API to fetch the calls data from Weave:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"calls_query_stream"})," API: This API allows us to fetch the calls data from Weave."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"filter"})," dictionary: This dictionary contains the filter parameters to fetch the calls data - see ",(0,a.jsx)(n.a,{href:"https://weave-docs.wandb.ai/reference/python-sdk/weave/trace_server/weave.trace_server.trace_server_interface/#class-callschema",children:"here"})," for more details."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"expand_columns"})," list: This list contains the columns to expand in the calls data."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"sort_by"})," list: This list contains the sorting parameters for the calls data."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"include_costs"})," boolean: This boolean indicates whether to include the costs in the calls data."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"include_feedback"})," boolean: This boolean indicates whether to include the feedback in the calls data."]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import itertools\nfrom datetime import datetime, timedelta\n\nimport pandas as pd\n\n\ndef fetch_calls(client, project_id, start_time, trace_roots_only, limit):\n    filter_params = {\n        "project_id": project_id,\n        "filter": {"started_at": start_time, "trace_roots_only": trace_roots_only},\n        "expand_columns": ["inputs.example", "inputs.model"],\n        "sort_by": [{"field": "started_at", "direction": "desc"}],\n        "include_costs": True,\n        "include_feedback": True,\n    }\n    try:\n        calls_stream = client.server.calls_query_stream(filter_params)\n        calls = list(\n            itertools.islice(calls_stream, limit)\n        )  # limit the number of calls to fetch if too many\n        print(f"Fetched {len(calls)} calls.")\n    except Exception as e:\n        print(f"Error fetching calls: {e}")\n        return []\n    else:\n        return calls\n\n\ncalls = fetch_calls(client, PROJECT_NAME, datetime.now() - timedelta(days=1), True, 100)\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# the raw data is a list of Call objects\npd.DataFrame([call.dict() for call in calls]).head(3)\n"})}),"\n",(0,a.jsx)(n.p,{children:"Processing the calls is very easy with the return from Weave - we'll extract the relevant information and store it in a list of dictionaries. We'll then convert the list of dictionaries to a pandas DataFrame and return it."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import json\nfrom datetime import datetime\n\nimport pandas as pd\n\n\ndef process_calls(calls):\n    records = []\n    for call in calls:\n        feedback = call.summary.get("weave", {}).get("feedback", [])\n        thumbs_up = sum(\n            1\n            for item in feedback\n            if isinstance(item, dict) and item.get("payload", {}).get("emoji") == "\ud83d\udc4d"\n        )\n        thumbs_down = sum(\n            1\n            for item in feedback\n            if isinstance(item, dict) and item.get("payload", {}).get("emoji") == "\ud83d\udc4e"\n        )\n        latency = call.summary.get("weave", {}).get("latency_ms", 0)\n\n        records.append(\n            {\n                "Call ID": call.id,\n                "Trace ID": call.trace_id,  # this is a unique ID for the trace that can be used to retrieve it\n                "Display Name": call.display_name,  # this is an optional name you can set in the UI or programatically\n                "Latency (ms)": latency,\n                "Thumbs Up": thumbs_up,\n                "Thumbs Down": thumbs_down,\n                "Started At": pd.to_datetime(getattr(call, "started_at", datetime.min)),\n                "Inputs": json.dumps(call.inputs, default=str),\n                "Outputs": json.dumps(call.output, default=str),\n            }\n        )\n    return pd.DataFrame(records)\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"df_calls = process_calls(calls)\ndf_calls.head(3)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"222-using-high-level-apis",children:"2.2.2 Using high-level APIs"}),"\n",(0,a.jsxs)(n.p,{children:["Instead of goin through every call Weave also provides high-level APIs to directly access model costs, feedback, and other metrics.\nFor example, for the cost, we'll use the ",(0,a.jsx)(n.code,{children:"query_costs"})," API to fetch the costs of all used LLMs using in project:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Use cost API to get costs\ncosts = client.query_costs()\ndf_costs = pd.DataFrame([cost.dict() for cost in costs])\ndf_costs["total_cost"] = (\n    df_costs["prompt_token_cost"] + df_costs["completion_token_cost"]\n)\n\n# only show the first row for every unqiue llm_id\ndf_costs\n'})}),"\n",(0,a.jsx)(n.h2,{id:"24-gathering-inputs-and-generating-visualizations",children:"2.4 Gathering inputs and generating visualizations"}),"\n",(0,a.jsxs)(n.p,{children:["Next, we can generate the visualizations using plotly. This is the most basic dashboard, but you can customize it as you like! For a more complex example, check out a Streamlit example ",(0,a.jsx)(n.a,{href:"https://github.com/NiWaRe/knowledge-worker-weave/blob/master/prod_dashboard.py",children:"here"}),"."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import plotly.express as px\nimport plotly.graph_objects as go\n\n\ndef plot_feedback_pie_chart(thumbs_up, thumbs_down):\n    fig = go.Figure(\n        data=[\n            go.Pie(\n                labels=["Thumbs Up", "Thumbs Down"],\n                values=[thumbs_up, thumbs_down],\n                marker={"colors": ["#66b3ff", "#ff9999"]},\n                hole=0.3,\n            )\n        ]\n    )\n    fig.update_traces(textinfo="percent+label", hoverinfo="label+percent")\n    fig.update_layout(showlegend=False, title="Feedback Summary")\n    return fig\n\n\ndef plot_model_cost_distribution(df):\n    fig = px.bar(\n        df,\n        x="llm_id",\n        y="total_cost",\n        color="llm_id",\n        title="Cost Distribution by Model",\n    )\n    fig.update_layout(xaxis_title="Model", yaxis_title="Cost (USD)")\n    return fig\n\n\n# See the source code for all the plots\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'plot_feedback_pie_chart(df_calls["Thumbs Up"].sum(), df_calls["Thumbs Down"].sum())\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"plot_model_cost_distribution(df_costs)\n"})}),"\n",(0,a.jsx)(n.h1,{id:"conclusion",children:"Conclusion"}),"\n",(0,a.jsx)(n.p,{children:"In this cookbook, we demonstrated how to create a custom production monitoring dashboard using Weave's APIs and functions. Weave currently focuses on fast integrations for easy input of data as well as extraction of the data for custom processes."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Data Input:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Framework-agnostic tracing with ",(0,a.jsx)(n.a,{href:"https://weave-docs.wandb.ai/quickstart#2-log-a-trace-to-a-new-project",children:"@weave-op()"})," decorator and the possibility to import calls from CSV (see related ",(0,a.jsx)(n.a,{href:"https://weave-docs.wandb.ai/reference/gen_notebooks/import_from_csv",children:"import cookbook"}),")"]}),"\n",(0,a.jsxs)(n.li,{children:["Service API endpoints to log to Weave from for various programming frameworks and languages, see ",(0,a.jsx)(n.a,{href:"https://weave-docs.wandb.ai/reference/service-api/call-start-call-start-post",children:"here"})," for more details."]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Data Output:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Easy download of the data in CSV, TSV, JSONL, JSON formats - see ",(0,a.jsx)(n.a,{href:"https://weave-docs.wandb.ai/guides/tracking/tracing#querying--exporting-calls",children:"here"})," for more details."]}),"\n",(0,a.jsxs)(n.li,{children:['Easy export using programmatic access to the data - see "Use Python" section in the export panel as described in this cookbook. See ',(0,a.jsx)(n.a,{href:"https://weave-docs.wandb.ai/guides/tracking/tracing#querying--exporting-calls",children:"here"})," for more details."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["This custom dashboard extends Weave's native Traces view, allowing for tailored monitoring of LLM applications in production. If you're interested in viewing a more complex dashboard, check out a Streamlit example where you can add your own Weave project URL ",(0,a.jsx)(n.a,{href:"https://github.com/NiWaRe/agent-dev-collection",children:"in this repo"}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,o.a)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},11151:(e,n,t)=>{t.d(n,{Z:()=>l,a:()=>s});var a=t(67294);const o={},i=a.createContext(o);function s(e){const n=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),a.createElement(i.Provider,{value:n},e.children)}}}]);