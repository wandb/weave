"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7729],{97061:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>t,default:()=>h,frontMatter:()=>r,metadata:()=>l,toc:()=>c});var s=i(85893),a=i(11151);const r={},t="Troubleshooting",l={id:"guides/troubleshooting",title:"Troubleshooting",description:"This page provides solutions and guidance for common issues you may encounter. As we continue to expand this guide, more troubleshooting topics will be added to address a broader range of scenarios.",source:"@site/docs/guides/troubleshooting.md",sourceDirName:"guides",slug:"/guides/troubleshooting",permalink:"/guides/troubleshooting",draft:!1,unlisted:!1,editUrl:"https://github.com/wandb/weave/blob/master/docs/docs/guides/troubleshooting.md",tags:[],version:"current",lastUpdatedAt:1749652482e3,frontMatter:{},sidebar:"documentationSidebar",previous:{title:"Environment variables",permalink:"/guides/core-types/env-vars"},next:{title:"FAQs",permalink:"/guides/tracking/faqs"}},o={},c=[{value:"Trace pages load slowly",id:"trace-pages-load-slowly",level:2},{value:"Adjust via the UI (recommended)",id:"adjust-via-the-ui-recommended",level:3},{value:"Use query parameters",id:"use-query-parameters",level:3},{value:"Server response caching",id:"server-response-caching",level:2},{value:"When to use caching",id:"when-to-use-caching",level:3},{value:"How to enable caching",id:"how-to-enable-caching",level:3},{value:"Caching behavior",id:"caching-behavior",level:3},{value:"Cache size and storage details",id:"cache-size-and-storage-details",level:3},{value:"Trace data is truncated",id:"trace-data-is-truncated",level:2},{value:"Long eval clean up times",id:"long-eval-clean-up-times",level:2},{value:"Flushing",id:"flushing",level:3},{value:"Increasing client parallelism",id:"increasing-client-parallelism",level:3},{value:"OS errors",id:"os-errors",level:2},{value:"<code>[Errno 24]: Too many open files</code>",id:"errno-24-too-many-open-files",level:3}];function d(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsx)(n.p,{children:"This page provides solutions and guidance for common issues you may encounter. As we continue to expand this guide, more troubleshooting topics will be added to address a broader range of scenarios."}),"\n",(0,s.jsx)(n.admonition,{type:"tip",children:(0,s.jsxs)(n.p,{children:["Do you have Weave troubleshooting advice to share with the community? Click ",(0,s.jsx)(n.strong,{children:"Edit this page"})," at the bottom of this guide to contribute directly by submitting a pull request."]})}),"\n",(0,s.jsx)(n.h2,{id:"trace-pages-load-slowly",children:"Trace pages load slowly"}),"\n",(0,s.jsxs)(n.p,{children:["If trace pages are loading slowly, reduce the number of rows displayed to improve load time. The default value is ",(0,s.jsx)(n.code,{children:"50"}),". You can either reduce the number of rows via the UI, or using query parameters."]}),"\n",(0,s.jsx)(n.h3,{id:"adjust-via-the-ui-recommended",children:"Adjust via the UI (recommended)"}),"\n",(0,s.jsxs)(n.p,{children:["Use the ",(0,s.jsx)(n.strong,{children:"Per page"})," control at the bottom-right of the Traces page to adjust the number of rows displayed. In addition to the default of ",(0,s.jsx)(n.code,{children:"50"}),", you can also set to ",(0,s.jsx)(n.code,{children:"10"}),", ",(0,s.jsx)(n.code,{children:"25"}),", or ",(0,s.jsx)(n.code,{children:"100"}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"use-query-parameters",children:"Use query parameters"}),"\n",(0,s.jsxs)(n.p,{children:["If you prefer a manual approach, you can modify the ",(0,s.jsx)(n.code,{children:"pageSize"})," query parameter in your query URL to a value less than the maximum of ",(0,s.jsx)(n.code,{children:"100"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"server-response-caching",children:"Server response caching"}),"\n",(0,s.jsx)(n.p,{children:"Weave provides server response caching to improve performance when making repeated queries or working with limited network bandwidth. While currently disabled by default, this feature is expected to become the default behavior in a future release."}),"\n",(0,s.jsx)(n.h3,{id:"when-to-use-caching",children:"When to use caching"}),"\n",(0,s.jsx)(n.p,{children:"Server response caching is particularly beneficial when:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"You frequently run the same queries"}),"\n",(0,s.jsx)(n.li,{children:"You have limited network bandwidth"}),"\n",(0,s.jsx)(n.li,{children:"You're working in an environment with high latency"}),"\n",(0,s.jsx)(n.li,{children:"You're developing offline and want to cache responses for later use"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"This feature is especially useful when running repeated evaluations on a dataset, as it allows caching the dataset between runs."}),"\n",(0,s.jsx)(n.h3,{id:"how-to-enable-caching",children:"How to enable caching"}),"\n",(0,s.jsx)(n.p,{children:"To enable caching, you can set the following environment variables:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Enable server response caching\nexport WEAVE_USE_SERVER_CACHE=true\n\n# Set cache size limit (default is 1GB)\nexport WEAVE_SERVER_CACHE_SIZE_LIMIT=1000000000\n\n# Set cache directory (optional, defaults to temporary directory)\nexport WEAVE_SERVER_CACHE_DIR=/path/to/cache\n"})}),"\n",(0,s.jsx)(n.h3,{id:"caching-behavior",children:"Caching behavior"}),"\n",(0,s.jsx)(n.p,{children:"Technically, this feature will cache idempotent requests against the server. Specifically, we cache:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"obj_read"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"table_query"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"table_query_stats"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"refs_read_batch"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"file_content_read"})}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"cache-size-and-storage-details",children:"Cache size and storage details"}),"\n",(0,s.jsxs)(n.p,{children:["The cache size is controlled by ",(0,s.jsx)(n.code,{children:"WEAVE_SERVER_CACHE_SIZE_LIMIT"})," (in bytes). The actual disk space used consists of three components:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"A constant 32KB checksum file"}),"\n",(0,s.jsx)(n.li,{children:"A Write-Ahead Log (WAL) file up to ~4MB per running client (automatically removed when the program exits)"}),"\n",(0,s.jsxs)(n.li,{children:["The main database file, which is at least 32KB and at most ",(0,s.jsx)(n.code,{children:"WEAVE_SERVER_CACHE_SIZE_LIMIT"})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Total disk space used:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"While running >= 32KB + ~4MB + cache size"}),"\n",(0,s.jsx)(n.li,{children:"After exit >= 32KB + cache size"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"For example, with the a 5MB cache limit:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"While running: ~9MB maximum"}),"\n",(0,s.jsx)(n.li,{children:"After exit: ~5MB maximum"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"trace-data-is-truncated",children:"Trace data is truncated"}),"\n",(0,s.jsx)(n.p,{children:"Sometimes, large trace data is partially cut off in the Weave UI. This problem occurs because default trace output is a raw, custom Python object that Weave doesn\u2019t know how to serialize."}),"\n",(0,s.jsx)(n.p,{children:"To ensure that large trace data isn't cut off, define a dictionary of strings to return all trace data."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import weave\n\nclass MyObj:\n    def __init__(self, x: int):\n        self.x = x\n\n    def __repr__(self):\n        return f"MyObj(x={self.x})"\n\n    def to_dict(self):\n        return {"x": self.x}\n\n@weave.op()\ndef make_my_obj():\n    x = "s" * 10_000\n    return MyObj(x)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"long-eval-clean-up-times",children:"Long eval clean up times"}),"\n",(0,s.jsx)(n.p,{children:"The following two methods should be used together in order to improve performance when running evaluations with large datasets."}),"\n",(0,s.jsx)(n.h3,{id:"flushing",children:"Flushing"}),"\n",(0,s.jsxs)(n.p,{children:["When running evaluations with large datasets, you may experience a long period of time before program execution, while the dataset is being uploaded in background threads. This generally occurs when main thread execution finished before background cleanup is complete. Calling ",(0,s.jsx)(n.code,{children:"client.flush()"})," will force all background tasks to be processed in the main thread, ensuring parallel processing during main thread execution. This can improve performance when user code completes before data has been uploaded to the server."]}),"\n",(0,s.jsx)(n.p,{children:"Example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'client = weave.init("fast-upload")\n\n# ... evaluation setup\nresult = evaluation.Evaluate(dataset_id="my_dataset_id")\n\nclient.flush()\n'})}),"\n",(0,s.jsx)(n.h3,{id:"increasing-client-parallelism",children:"Increasing client parallelism"}),"\n",(0,s.jsx)(n.p,{children:"Client parallelism is automatically determined based on the environment, but can be set manually using the following environment variable:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"WEAVE_CLIENT_PARALLELISM"}),": The number of threads available for parallel processing. Increasing this number will increase the number of threads available for parallel processing, potentially improving the performance of background tasks like dataset uploads."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["This can also be set programmatically using the ",(0,s.jsx)(n.code,{children:"settings"})," argument to ",(0,s.jsx)(n.code,{children:"weave.init()"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'client = weave.init("fast-upload", settings={"client_parallelism": 100})\n'})}),"\n",(0,s.jsx)(n.h2,{id:"os-errors",children:"OS errors"}),"\n",(0,s.jsx)(n.h3,{id:"errno-24-too-many-open-files",children:(0,s.jsx)(n.code,{children:"[Errno 24]: Too many open files"})}),"\n",(0,s.jsxs)(n.p,{children:["This error occurs when the number of open files exceeds the limit set by your operating system. In Weave, this may happen because you're working with large image datasets. Weave uses ",(0,s.jsx)(n.code,{children:"PIL"})," for image processing, which keeps file descriptors open for the duration of the program."]}),"\n",(0,s.jsxs)(n.p,{children:["To resolve this issue, increase the system limit for open files to ",(0,s.jsx)(n.code,{children:"65,536"})," using ",(0,s.jsx)(n.code,{children:"ulimit"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ulimit -n 65536\n"})})]})}function h(e={}){const{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},11151:(e,n,i)=>{i.d(n,{Z:()=>l,a:()=>t});var s=i(67294);const a={},r=s.createContext(a);function t(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);