"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4947],{89527:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>m,frontMatter:()=>s,metadata:()=>u,toc:()=>c});var t=a(85893),r=a(11151),o=a(65488),i=a(85162);const s={},l="Logging media",u={id:"guides/core-types/media",title:"Logging media",description:"Weave supports logging and displaying video, images, and audio.",source:"@site/docs/guides/core-types/media.md",sourceDirName:"guides/core-types",slug:"/guides/core-types/media",permalink:"/guides/core-types/media",draft:!1,unlisted:!1,editUrl:"https://github.com/wandb/weave/blob/master/docs/docs/guides/core-types/media.md",tags:[],version:"current",lastUpdatedAt:1749652482e3,frontMatter:{},sidebar:"documentationSidebar",previous:{title:"Costs",permalink:"/guides/tracking/costs"},next:{title:"Playground",permalink:"/guides/tools/playground"}},d={},c=[{value:"Video",id:"video",level:2},{value:"Images",id:"images",level:2},{value:"Audio",id:"audio",level:2}];function p(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",img:"img",p:"p",pre:"pre",...(0,r.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"logging-media",children:"Logging media"}),"\n",(0,t.jsx)(n.p,{children:"Weave supports logging and displaying video, images, and audio."}),"\n",(0,t.jsx)(n.h2,{id:"video",children:"Video"}),"\n",(0,t.jsxs)(n.p,{children:["Weave automatically logs videos using ",(0,t.jsx)(n.a,{href:"https://zulko.github.io/moviepy/",children:(0,t.jsx)(n.code,{children:"moviepy"})}),". This allows you to pass video inputs and outputs to traced functions, and Weave will automatically handle uploading and storing video data."]}),"\n",(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsx)(n.p,{children:"Video support is currently only available in Python."})}),"\n",(0,t.jsxs)(n.p,{children:["For usage information, see ",(0,t.jsx)(n.a,{href:"../tracking/video",children:"Video Support"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"images",children:"Images"}),"\n",(0,t.jsxs)(n.p,{children:["Logging type: ",(0,t.jsx)(n.code,{children:"PIL.Image.Image"}),"."]}),"\n",(0,t.jsx)(n.admonition,{type:"important",children:(0,t.jsxs)(n.p,{children:["Base64-encoded image strings (e.g., ",(0,t.jsx)(n.code,{children:"data:image/jpeg;base64,..."}),") are technically supported but discouraged. They can cause performance issues and should only be used if absolutely necessary (e.g., for integration with specific APIs)."]})}),"\n",(0,t.jsx)(n.p,{children:"The following example shows how to log an image generated via the OpenAI DALL-E API:"}),"\n",(0,t.jsxs)(o.Z,{groupId:"programming-language",queryString:!0,children:[(0,t.jsx)(i.default,{value:"python",label:"Python",default:!0,children:(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import weave\nfrom openai import OpenAI\nimport requests\nfrom PIL import Image\n\nweave.init(\'image-example\')\nclient = OpenAI()\n\n@weave.op\ndef generate_image(prompt: str) -> Image:\n    response = client.images.generate(\n        model="dall-e-3",\n        prompt=prompt,\n        size="1024x1024",\n        quality="standard",\n        n=1,\n    )\n    image_url = response.data[0].url\n    image_response = requests.get(image_url, stream=True)\n    image = Image.open(image_response.raw)\n\n    # return a PIL.Image.Image object to be logged as an image\n    return image\n\ngenerate_image("a cat with a pumpkin hat")\n'})})}),(0,t.jsx)(i.default,{value:"typescript",label:"TypeScript",children:(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"import {OpenAI} from 'openai';\nimport * as weave from 'weave';\n\nasync function main() {\n    const client = await weave.init('image-example');\n    const openai = new OpenAI();\n\n    const generateImage = weave.op(async (prompt: string) => {\n        const response = await openai.images.generate({\n            model: 'dall-e-3',\n            prompt: prompt,\n            size: '1024x1024',\n            quality: 'standard',\n            n: 1,\n        });\n        const imageUrl = response.data[0].url;\n        const imgResponse = await fetch(imageUrl);\n        const data = Buffer.from(await imgResponse.arrayBuffer());\n\n        return weave.weaveImage({data});\n    });\n\n    generateImage('a cat with a pumpkin hat');\n}\n\nmain();\n"})})})]}),"\n",(0,t.jsx)(n.p,{children:"This image is logged to Weave and automatically displayed in the UI."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Screenshot of pumpkin cat trace view",src:a(46026).Z+"",width:"3456",height:"1614"})}),"\n",(0,t.jsx)(n.h2,{id:"audio",children:"Audio"}),"\n",(0,t.jsxs)(n.p,{children:["Logging type: ",(0,t.jsx)(n.code,{children:"wave.Wave_read"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"The following example shows how to log an audio file using OpenAI's speech generation API."}),"\n",(0,t.jsxs)(o.Z,{groupId:"programming-language",queryString:!0,children:[(0,t.jsx)(i.default,{value:"python",label:"Python",default:!0,children:(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import weave\nfrom openai import OpenAI\nimport wave\n\nweave.init("audio-example")\nclient = OpenAI()\n\n\n@weave.op\ndef make_audio_file_streaming(text: str) -> wave.Wave_read:\n    with client.audio.speech.with_streaming_response.create(\n        model="tts-1",\n        voice="alloy",\n        input=text,\n        response_format="wav",\n    ) as res:\n        res.stream_to_file("output.wav")\n\n    # return a wave.Wave_read object to be logged as audio\n    return wave.open("output.wav")\n\nmake_audio_file_streaming("Hello, how are you?")\n'})})}),(0,t.jsx)(i.default,{value:"typescript",label:"TypeScript",children:(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"import {OpenAI} from 'openai';\nimport * as weave from 'weave';\n\nasync function main() {\n    await weave.init('audio-example');\n    const openai = new OpenAI();\n\n    const makeAudioFileStreaming = weave.op(async function audio(text: string) {\n        const response = await openai.audio.speech.create({\n            model: 'tts-1',\n            voice: 'alloy',\n            input: text,\n            response_format: 'wav',\n        });\n\n        const chunks: Uint8Array[] = [];\n        for await (const chunk of response.body) {\n            chunks.push(chunk);\n        }\n        return weave.weaveAudio({data: Buffer.concat(chunks)});\n    });\n\n    await makeAudioFileStreaming('Hello, how are you?');\n}\n\nmain();\n"})})})]}),"\n",(0,t.jsx)(n.p,{children:"This audio is logged to Weave and automatically displayed in the UI, along with an audio player. In the audio player, you can view and download the raw audio waveform."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Screenshot of audio trace view",src:a(81325).Z+"",width:"3456",height:"1240"})}),"\n",(0,t.jsx)(n.admonition,{type:"tip",children:(0,t.jsxs)(n.p,{children:["Try our cookbook for ",(0,t.jsx)(n.a,{href:"/reference/gen_notebooks/audio_with_weave",children:"Audio Logging"})," or ",(0,t.jsx)("a",{href:"https://colab.research.google.com/github/wandb/weave/blob/master/docs/./notebooks/audio_with_weave.ipynb",target:"_blank",rel:"noopener noreferrer",class:"navbar__item navbar__link button button--secondary button--med margin-right--sm notebook-cta-button",children:(0,t.jsxs)("div",{children:[(0,t.jsx)("img",{src:"https://upload.wikimedia.org/wikipedia/commons/archive/d/d0/20221103151430%21Google_Colaboratory_SVG_Logo.svg",alt:"Open In Colab",height:"20px"}),(0,t.jsx)("div",{children:"Open in Colab"})]})}),". The cookbook also includes an advanced example of a Real Time Audio API based assistant integrated with Weave."]})})]})}function m(e={}){const{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}},85162:(e,n,a)=>{a.r(n),a.d(n,{default:()=>i});a(67294);var t=a(90512);const r={tabItem:"tabItem_Ymn6"};var o=a(85893);function i(e){let{children:n,hidden:a,className:i}=e;return(0,o.jsx)("div",{role:"tabpanel",className:(0,t.Z)(r.tabItem,i),hidden:a,children:n})}},65488:(e,n,a)=>{a.d(n,{Z:()=>m});var t=a(67294),r=a(90512),o=a(12466),i=a(70989),s=a(72389);const l={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var u=a(85893);function d(e){let{className:n,block:a,selectedValue:t,selectValue:i,tabValues:s}=e;const d=[],{blockElementScrollPositionUntilNextRender:c}=(0,o.o5)(),p=e=>{const n=e.currentTarget,a=d.indexOf(n),r=s[a].value;r!==t&&(c(n),i(r))},m=e=>{let n=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":{const a=d.indexOf(e.currentTarget)+1;n=d[a]??d[0];break}case"ArrowLeft":{const a=d.indexOf(e.currentTarget)-1;n=d[a]??d[d.length-1];break}}n?.focus()};return(0,u.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.Z)("tabs",{"tabs--block":a},n),children:s.map((e=>{let{value:n,label:a,attributes:o}=e;return(0,u.jsx)("li",{role:"tab",tabIndex:t===n?0:-1,"aria-selected":t===n,ref:e=>d.push(e),onKeyDown:m,onClick:p,...o,className:(0,r.Z)("tabs__item",l.tabItem,o?.className,{"tabs__item--active":t===n}),children:a??n},n)}))})}function c(e){let{lazy:n,children:a,selectedValue:r}=e;const o=(Array.isArray(a)?a:[a]).filter(Boolean);if(n){const e=o.find((e=>e.props.value===r));return e?(0,t.cloneElement)(e,{className:"margin-top--md"}):null}return(0,u.jsx)("div",{className:"margin-top--md",children:o.map(((e,n)=>(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==r})))})}function p(e){const n=(0,i.Y)(e);return(0,u.jsxs)("div",{className:(0,r.Z)("tabs-container",l.tabList),children:[(0,u.jsx)(d,{...n,...e}),(0,u.jsx)(c,{...n,...e})]})}function m(e){const n=(0,s.default)();return(0,u.jsx)(p,{...e,children:(0,i.h)(e.children)},String(n))}},70989:(e,n,a)=>{a.d(n,{Y:()=>m,h:()=>u});var t=a(67294),r=a(16550),o=a(20469),i=a(91980),s=a(67392),l=a(20812);function u(e){return t.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,t.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function d(e){const{values:n,children:a}=e;return(0,t.useMemo)((()=>{const e=n??function(e){return u(e).map((e=>{let{props:{value:n,label:a,attributes:t,default:r}}=e;return{value:n,label:a,attributes:t,default:r}}))}(a);return function(e){const n=(0,s.l)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,a])}function c(e){let{value:n,tabValues:a}=e;return a.some((e=>e.value===n))}function p(e){let{queryString:n=!1,groupId:a}=e;const o=(0,r.k6)(),s=function(e){let{queryString:n=!1,groupId:a}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!a)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return a??null}({queryString:n,groupId:a});return[(0,i._X)(s),(0,t.useCallback)((e=>{if(!s)return;const n=new URLSearchParams(o.location.search);n.set(s,e),o.replace({...o.location,search:n.toString()})}),[s,o])]}function m(e){const{defaultValue:n,queryString:a=!1,groupId:r}=e,i=d(e),[s,u]=(0,t.useState)((()=>function(e){let{defaultValue:n,tabValues:a}=e;if(0===a.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!c({value:n,tabValues:a}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${a.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const t=a.find((e=>e.default))??a[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:i}))),[m,g]=p({queryString:a,groupId:r}),[h,f]=function(e){let{groupId:n}=e;const a=function(e){return e?`docusaurus.tab.${e}`:null}(n),[r,o]=(0,l.Nk)(a);return[r,(0,t.useCallback)((e=>{a&&o.set(e)}),[a,o])]}({groupId:r}),v=(()=>{const e=m??h;return c({value:e,tabValues:i})?e:null})();(0,o.Z)((()=>{v&&u(v)}),[v]);return{selectedValue:s,selectValue:(0,t.useCallback)((e=>{if(!c({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);u(e),g(e),f(e)}),[g,f,i]),tabValues:i}}},81325:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/audio-trace-89376da798b679352916b3649673e102.png"},46026:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/cat-pumpkin-trace-97fc2edd89fddc5a9e6b5ff24e65feae.png"},11151:(e,n,a)=>{a.d(n,{Z:()=>s,a:()=>i});var t=a(67294);const r={},o=t.createContext(r);function i(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);