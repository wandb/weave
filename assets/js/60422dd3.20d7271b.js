"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6316],{69350:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>t,contentTitle:()=>d,default:()=>h,frontMatter:()=>l,metadata:()=>o,toc:()=>a});var s=i(85893),r=i(11151);const l={},d="Playground",o={id:"guides/tools/playground",title:"Playground",description:"Evaluating LLM prompts and responses is challenging. The Weave Playground is designed to simplify the process of iterating on LLM prompts and responses, making it easier to experiment with different models and prompts. With features like prompt editing, message retrying, and model comparison, Playground helps you to quickly test and improve your LLM applications. Playground currently supports models from OpenAI, Anthropic, Google, Groq, Amazon Bedrock, and Microsoft Azure, as well as custom providers.",source:"@site/docs/guides/tools/playground.md",sourceDirName:"guides/tools",slug:"/guides/tools/playground",permalink:"/guides/tools/playground",draft:!1,unlisted:!1,editUrl:"https://github.com/wandb/weave/blob/master/docs/docs/guides/tools/playground.md",tags:[],version:"current",lastUpdatedAt:1749652482e3,frontMatter:{},sidebar:"documentationSidebar",previous:{title:"Logging Media",permalink:"/guides/core-types/media"},next:{title:"Integrations",permalink:"/guides/integrations/"}},t={},a=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Add provider credentials and information",id:"add-provider-credentials-and-information",level:3},{value:"Access the Playground",id:"access-the-playground",level:3},{value:"Select an LLM",id:"select-an-llm",level:2},{value:"Amazon Bedrock",id:"amazon-bedrock",level:3},{value:"Anthropic",id:"anthropic",level:3},{value:"Azure",id:"azure",level:3},{value:"Google",id:"google",level:3},{value:"Groq",id:"groq",level:3},{value:"OpenAI",id:"openai",level:3},{value:"X.AI",id:"xai",level:3},{value:"Deepseek",id:"deepseek",level:3},{value:"Customize settings",id:"customize-settings",level:2},{value:"Adjust LLM parameters",id:"adjust-llm-parameters",level:3},{value:"Add a function",id:"add-a-function",level:3},{value:"Adjust the number of trials",id:"adjust-the-number-of-trials",level:3},{value:"Message controls",id:"message-controls",level:2},{value:"Retry, edit, and delete messages",id:"retry-edit-and-delete-messages",level:3},{value:"Add a new message",id:"add-a-new-message",level:3},{value:"Compare LLMs",id:"compare-llms",level:2},{value:"Custom providers",id:"custom-providers",level:2},{value:"Add a custom provider",id:"add-a-custom-provider",level:3},{value:"Edit a custom provider",id:"edit-a-custom-provider",level:3},{value:"Remove a custom provider",id:"remove-a-custom-provider",level:3},{value:"Use ngrok with Ollama",id:"use-ngrok-with-ollama",level:3},{value:"Saved models",id:"saved-models",level:2},{value:"Save a model",id:"save-a-model",level:3},{value:"Use a saved model",id:"use-a-saved-model",level:3},{value:"Update a saved model",id:"update-a-saved-model",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"playground",children:"Playground"}),"\n",(0,s.jsxs)(n.p,{children:["Evaluating LLM prompts and responses is challenging. The Weave Playground is designed to simplify the process of iterating on LLM prompts and responses, making it easier to experiment with different models and prompts. With features like prompt editing, message retrying, and model comparison, Playground helps you to quickly test and improve your LLM applications. Playground currently supports models from OpenAI, Anthropic, Google, Groq, Amazon Bedrock, and Microsoft Azure, as well as ",(0,s.jsx)(n.a,{href:"#add-a-custom-provider",children:"custom providers"}),"."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Quick access:"})," Open the Playground from the W&B sidebar for a fresh session or from the Call page to test an existing project."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Message controls:"})," Edit, retry, or delete messages directly within the chat."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Flexible messaging:"})," Add new messages as either user or system inputs, and send them to the LLM."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Customizable settings:"})," Configure your preferred LLM provider and adjust model settings."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Multi-LLM support:"})," Switch between models, with team-level API key management."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Compare models:"})," Compare how different models respond to prompts."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Custom providers:"})," Test OpenAI compatible API endpoints for custom models."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Saved models:"})," Create and configure a reusable model preset for your workflow"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Get started with the Playground to optimize your LLM interactions and streamline your prompt engineering process and LLM application development."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"#prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#add-provider-credentials-and-information",children:"Add provider credentials and information"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#access-the-playground",children:"Access the Playground"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#select-an-llm",children:"Select an LLM"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#customize-settings",children:"Customize settings"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#add-retry-edit-and-delete-messages",children:"Message controls"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#compare-llms",children:"Compare LLMs"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#custom-providers",children:"Custom providers"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#saved-models",children:"Saved models"})}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(n.p,{children:["Before you can use Playground, you must ",(0,s.jsx)(n.a,{href:"#add-provider-credentials-and-information",children:"add provider credentials"}),", and ",(0,s.jsx)(n.a,{href:"#access-the-playground",children:"open the Playground UI"}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"add-provider-credentials-and-information",children:"Add provider credentials and information"}),"\n",(0,s.jsx)(n.p,{children:"Playground currently supports models from OpenAI, Anthropic, Google, Groq, Amazon Bedrock, and Microsoft Azure. To use one of the available models, add the appropriate information to your team secrets in W&B settings."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["OpenAI: ",(0,s.jsx)(n.code,{children:"OPENAI_API_KEY"})]}),"\n",(0,s.jsxs)(n.li,{children:["Anthropic: ",(0,s.jsx)(n.code,{children:"ANTHROPIC_API_KEY"})]}),"\n",(0,s.jsxs)(n.li,{children:["Google: ",(0,s.jsx)(n.code,{children:"GEMINI_API_KEY"})]}),"\n",(0,s.jsxs)(n.li,{children:["Groq: ",(0,s.jsx)(n.code,{children:"GROQ_API_KEY"})]}),"\n",(0,s.jsxs)(n.li,{children:["Amazon Bedrock:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"AWS_ACCESS_KEY_ID"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"AWS_SECRET_ACCESS_KEY"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"AWS_REGION_NAME"})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["Azure:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"AZURE_API_KEY"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"AZURE_API_BASE"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"AZURE_API_VERSION"})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["X.AI:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"XAI_API_KEY"})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["Deepseek","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"DEEPSEEK_API_KEY"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"access-the-playground",children:"Access the Playground"}),"\n",(0,s.jsx)(n.p,{children:"There are two ways to access the Playground:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"Open a fresh Playground page with a simple system prompt"}),": In the sidebar, select ",(0,s.jsx)(n.strong,{children:"Playground"}),". Playground opens in the same tab."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"Open Playground for a specific call"}),":","\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["In the sidebar, select the ",(0,s.jsx)(n.strong,{children:"Traces"})," tab. A list of traces displays."]}),"\n",(0,s.jsx)(n.li,{children:"In the list of traces, click the name of the call that you want to view. The call's details page opens."}),"\n",(0,s.jsxs)(n.li,{children:["Click ",(0,s.jsx)(n.strong,{children:"Open chat in playground"}),". Playground opens in a new tab."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Screenshot of Open in Playground button",src:i(61961).Z+"",width:"2582",height:"1732"})}),"\n",(0,s.jsx)(n.h2,{id:"select-an-llm",children:"Select an LLM"}),"\n",(0,s.jsx)(n.p,{children:"You can switch the LLM using the dropdown menu in the top left. The available models from various providers are listed below:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#amazon-bedrock",children:"Amazon Bedrock"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#anthropic",children:"Anthropic"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#azure",children:"Azure"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#google",children:"Google"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#groq",children:"Groq"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#openai",children:"OpenAI"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#xai",children:"X.AI"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#deepseek",children:"Deepseek"})}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"amazon-bedrock",children:(0,s.jsx)(n.a,{href:"/guides/integrations/bedrock",children:"Amazon Bedrock"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"ai21.j2-mid-v1"}),"\n",(0,s.jsx)(n.li,{children:"ai21.j2-ultra-v1"}),"\n",(0,s.jsx)(n.li,{children:"amazon.nova-micro-v1:0"}),"\n",(0,s.jsx)(n.li,{children:"amazon.nova-lite-v1:0"}),"\n",(0,s.jsx)(n.li,{children:"amazon.nova-pro-v1:0"}),"\n",(0,s.jsx)(n.li,{children:"amazon.titan-text-lite-v1"}),"\n",(0,s.jsx)(n.li,{children:"amazon.titan-text-express-v1"}),"\n",(0,s.jsx)(n.li,{children:"mistral.mistral-7b-instruct-v0:2"}),"\n",(0,s.jsx)(n.li,{children:"mistral.mixtral-8x7b-instruct-v0:1"}),"\n",(0,s.jsx)(n.li,{children:"mistral.mistral-large-2402-v1:0"}),"\n",(0,s.jsx)(n.li,{children:"mistral.mistral-large-2407-v1:0"}),"\n",(0,s.jsx)(n.li,{children:"anthropic.claude-3-sonnet-20240229-v1:0"}),"\n",(0,s.jsx)(n.li,{children:"anthropic.claude-3-5-sonnet-20240620-v1:0"}),"\n",(0,s.jsx)(n.li,{children:"anthropic.claude-3-haiku-20240307-v1:0"}),"\n",(0,s.jsx)(n.li,{children:"anthropic.claude-3-opus-20240229-v1:0"}),"\n",(0,s.jsx)(n.li,{children:"anthropic.claude-v2"}),"\n",(0,s.jsx)(n.li,{children:"anthropic.claude-v2:1"}),"\n",(0,s.jsx)(n.li,{children:"anthropic.claude-instant-v1"}),"\n",(0,s.jsx)(n.li,{children:"cohere.command-text-v14"}),"\n",(0,s.jsx)(n.li,{children:"cohere.command-light-text-v14"}),"\n",(0,s.jsx)(n.li,{children:"cohere.command-r-plus-v1:0"}),"\n",(0,s.jsx)(n.li,{children:"cohere.command-r-v1:0"}),"\n",(0,s.jsx)(n.li,{children:"meta.llama2-13b-chat-v1"}),"\n",(0,s.jsx)(n.li,{children:"meta.llama2-70b-chat-v1"}),"\n",(0,s.jsx)(n.li,{children:"meta.llama3-8b-instruct-v1:0"}),"\n",(0,s.jsx)(n.li,{children:"meta.llama3-70b-instruct-v1:0"}),"\n",(0,s.jsx)(n.li,{children:"meta.llama3-1-8b-instruct-v1:0"}),"\n",(0,s.jsx)(n.li,{children:"meta.llama3-1-70b-instruct-v1:0"}),"\n",(0,s.jsx)(n.li,{children:"meta.llama3-1-405b-instruct-v1:0"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"anthropic",children:(0,s.jsx)(n.a,{href:"/guides/integrations/anthropic",children:"Anthropic"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"claude-3-7-sonnet-20250219"}),"\n",(0,s.jsx)(n.li,{children:"claude-3-5-sonnet-20240620"}),"\n",(0,s.jsx)(n.li,{children:"claude-3-5-sonnet-20241022"}),"\n",(0,s.jsx)(n.li,{children:"claude-3-haiku-20240307"}),"\n",(0,s.jsx)(n.li,{children:"claude-3-opus-20240229"}),"\n",(0,s.jsx)(n.li,{children:"claude-3-sonnet-20240229"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"azure",children:(0,s.jsx)(n.a,{href:"/guides/integrations/azure",children:"Azure"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"azure/o1-mini"}),"\n",(0,s.jsx)(n.li,{children:"azure/o1-mini-2024-09-12"}),"\n",(0,s.jsx)(n.li,{children:"azure/o1"}),"\n",(0,s.jsx)(n.li,{children:"azure/o1-preview"}),"\n",(0,s.jsx)(n.li,{children:"azure/o1-preview-2024-09-12"}),"\n",(0,s.jsx)(n.li,{children:"azure/gpt-4o"}),"\n",(0,s.jsx)(n.li,{children:"azure/gpt-4o-2024-08-06"}),"\n",(0,s.jsx)(n.li,{children:"azure/gpt-4o-2024-11-20"}),"\n",(0,s.jsx)(n.li,{children:"azure/gpt-4o-2024-05-13"}),"\n",(0,s.jsx)(n.li,{children:"azure/gpt-4o-mini"}),"\n",(0,s.jsx)(n.li,{children:"azure/gpt-4o-mini-2024-07-18"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"google",children:(0,s.jsx)(n.a,{href:"/guides/integrations/google",children:"Google"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"gemini/gemini-2.5-pro-preview-03-25"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-2.0-pro-exp-02-05"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-2.0-flash-exp"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-2.0-flash-001"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-2.0-flash-thinking-exp"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-2.0-flash-thinking-exp-01-21"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-2.0-flash"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-2.0-flash-lite"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-2.0-flash-lite-preview-02-05"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-1.5-flash-001"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-1.5-flash-002"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-1.5-flash-8b-exp-0827"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-1.5-flash-8b-exp-0924"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-1.5-flash-latest"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-1.5-flash"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-1.5-pro-001"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-1.5-pro-002"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-1.5-pro-latest"}),"\n",(0,s.jsx)(n.li,{children:"gemini/gemini-1.5-pro"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"groq",children:(0,s.jsx)(n.a,{href:"/guides/integrations/groq",children:"Groq"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"groq/deepseek-r1-distill-llama-70b"}),"\n",(0,s.jsx)(n.li,{children:"groq/llama-3.3-70b-versatile"}),"\n",(0,s.jsx)(n.li,{children:"groq/llama-3.3-70b-specdec"}),"\n",(0,s.jsx)(n.li,{children:"groq/llama-3.2-1b-preview"}),"\n",(0,s.jsx)(n.li,{children:"groq/llama-3.2-3b-preview"}),"\n",(0,s.jsx)(n.li,{children:"groq/llama-3.2-11b-vision-preview"}),"\n",(0,s.jsx)(n.li,{children:"groq/llama-3.2-90b-vision-preview"}),"\n",(0,s.jsx)(n.li,{children:"groq/llama-3.1-8b-instant"}),"\n",(0,s.jsx)(n.li,{children:"groq/llama3-70b-8192"}),"\n",(0,s.jsx)(n.li,{children:"groq/llama3-8b-8192"}),"\n",(0,s.jsx)(n.li,{children:"groq/gemma2-9b-it"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"openai",children:(0,s.jsx)(n.a,{href:"/guides/integrations/openai",children:"OpenAI"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"gpt-4.1-mini-2025-04-14"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4.1-mini"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4.1-2025-04-14"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4.1"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4.1-nano-2025-04-14"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4.1-nano"}),"\n",(0,s.jsx)(n.li,{children:"o4-mini-2025-04-16"}),"\n",(0,s.jsx)(n.li,{children:"o4-mini"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4.5-preview-2025-02-27"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4.5-preview"}),"\n",(0,s.jsx)(n.li,{children:"o3-2025-04-16"}),"\n",(0,s.jsx)(n.li,{children:"o3"}),"\n",(0,s.jsx)(n.li,{children:"o3-mini-2025-01-31"}),"\n",(0,s.jsx)(n.li,{children:"o3-mini"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4o-mini"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4o-2024-05-13"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4o-2024-08-06"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4o-mini-2024-07-18"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4o"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4o-2024-11-20"}),"\n",(0,s.jsx)(n.li,{children:"o1-mini-2024-09-12"}),"\n",(0,s.jsx)(n.li,{children:"o1-mini"}),"\n",(0,s.jsx)(n.li,{children:"o1-preview-2024-09-12"}),"\n",(0,s.jsx)(n.li,{children:"o1-preview"}),"\n",(0,s.jsx)(n.li,{children:"o1-2024-12-17"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4-1106-preview"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4-32k-0314"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4-turbo-2024-04-09"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4-turbo-preview"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4-turbo"}),"\n",(0,s.jsx)(n.li,{children:"gpt-4"}),"\n",(0,s.jsx)(n.li,{children:"gpt-3.5-turbo-0125"}),"\n",(0,s.jsx)(n.li,{children:"gpt-3.5-turbo-1106"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"xai",children:"X.AI"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"xai/grok-3-beta"}),"\n",(0,s.jsx)(n.li,{children:"xai/grok-3-fast-beta"}),"\n",(0,s.jsx)(n.li,{children:"xai/grok-3-fast-latest"}),"\n",(0,s.jsx)(n.li,{children:"xai/grok-3-mini-beta"}),"\n",(0,s.jsx)(n.li,{children:"xai/grok-3-mini-fast-beta"}),"\n",(0,s.jsx)(n.li,{children:"xai/grok-3-mini-fast-latest"}),"\n",(0,s.jsx)(n.li,{children:"xai/grok-beta"}),"\n",(0,s.jsx)(n.li,{children:"xai/grok-2-1212"}),"\n",(0,s.jsx)(n.li,{children:"xai/grok-2"}),"\n",(0,s.jsx)(n.li,{children:"xai/grok-2-latest"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"deepseek",children:"Deepseek"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"deepseek/deepseek-reasoner"}),"\n",(0,s.jsx)(n.li,{children:"deepseek/deepseek-chat"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"customize-settings",children:"Customize settings"}),"\n",(0,s.jsx)(n.h3,{id:"adjust-llm-parameters",children:"Adjust LLM parameters"}),"\n",(0,s.jsx)(n.p,{children:"You can experiment with different parameter values for your selected model. To adjust parameters, do the following:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["In the upper right corner of the Playground UI, click ",(0,s.jsx)(n.strong,{children:"Chat settings"})," to open the parameter settings dropdown."]}),"\n",(0,s.jsxs)(n.li,{children:["In the dropdown, adjust parameters as desired. You can also toggle Weave call tracking on or off, and ",(0,s.jsx)(n.a,{href:"#add-a-function",children:"add a function"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Click ",(0,s.jsx)(n.strong,{children:"Chat settings"})," to close the dropdown and save your changes."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Screenshot of Playground settings",src:i(35394).Z+"",width:"2584",height:"1326"})}),"\n",(0,s.jsx)(n.h3,{id:"add-a-function",children:"Add a function"}),"\n",(0,s.jsx)(n.p,{children:"You can test how different models use functions based on input it receives from the user. To add a function for testing in Playground, do the following:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["In the upper right corner of the Playground UI, click ",(0,s.jsx)(n.strong,{children:"Chat settings"})," to open the parameter settings dropdown."]}),"\n",(0,s.jsxs)(n.li,{children:["In the dropdown, click ",(0,s.jsx)(n.strong,{children:"+ Add function"}),"."]}),"\n",(0,s.jsx)(n.li,{children:"In the pop-up, add your function information."}),"\n",(0,s.jsxs)(n.li,{children:["To save your changes and close the function pop-up, click the ",(0,s.jsx)(n.strong,{children:"x"})," in the upper right corner."]}),"\n",(0,s.jsxs)(n.li,{children:["Click ",(0,s.jsx)(n.strong,{children:"Chat settings"})," to close the settings dropdown and save your changes."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"adjust-the-number-of-trials",children:"Adjust the number of trials"}),"\n",(0,s.jsxs)(n.p,{children:["Playground allows you to generate multiple outputs for the same input by setting the number of trials. The default setting is ",(0,s.jsx)(n.code,{children:"1"}),". To adjust the number of trials, do the following:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"In the Playground UI, open the settings sidebar if it is not already open."}),"\n",(0,s.jsxs)(n.li,{children:["Adjust the ",(0,s.jsx)(n.strong,{children:"Number of trials"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"message-controls",children:"Message controls"}),"\n",(0,s.jsx)(n.h3,{id:"retry-edit-and-delete-messages",children:"Retry, edit, and delete messages"}),"\n",(0,s.jsxs)(n.p,{children:["With Playground, you can retry, edit, and delete messages. To use this feature, hover over the message you want to edit, retry, or delete. Three buttons display: ",(0,s.jsx)(n.strong,{children:"Delete"}),", ",(0,s.jsx)(n.strong,{children:"Edit"}),", and ",(0,s.jsx)(n.strong,{children:"Retry"}),"."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Delete"}),": Remove the message from the chat."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Edit"}),": Modify the message content."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Retry"}),": Delete all subsequent messages and retry the chat from the selected message."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.img,{alt:"Screenshot of Playground message buttons",src:i(83353).Z+"",width:"1716",height:"626"}),"\n",(0,s.jsx)(n.img,{alt:"Screenshot of Playground editing",src:i(88155).Z+"",width:"1668",height:"762"})]}),"\n",(0,s.jsx)(n.h3,{id:"add-a-new-message",children:"Add a new message"}),"\n",(0,s.jsx)(n.p,{children:"To add a new message to the chat, do the following:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["In the chat box, select one of the available roles (",(0,s.jsx)(n.strong,{children:"Assistant"})," or ",(0,s.jsx)(n.strong,{children:"User"}),")"]}),"\n",(0,s.jsxs)(n.li,{children:["Click ",(0,s.jsx)(n.strong,{children:"+ Add"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["To send a new message to the LLM, click the ",(0,s.jsx)(n.strong,{children:"Send"})," button. Alternatively, press the ",(0,s.jsx)(n.strong,{children:"Command"})," and ",(0,s.jsx)(n.strong,{children:"Enter"})," keys."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Screenshot of Playground sending a message",src:i(44737).Z+"",width:"1788",height:"364"})}),"\n",(0,s.jsx)(n.h2,{id:"compare-llms",children:"Compare LLMs"}),"\n",(0,s.jsx)(n.p,{children:"Playground allows you to compare LLMs. To perform a comparison, do the following:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["In the Playground UI, click ",(0,s.jsx)(n.strong,{children:"Compare"}),". A second chat opens next to the original chat."]}),"\n",(0,s.jsxs)(n.li,{children:["In the second chat, you can:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#select-an-llm",children:"Select the LLM to compare"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#adjust-llm-parameters",children:"Adjust parameters"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#add-a-function",children:"Add functions"})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["In the message box, enter a message that you want to test with both models and press ",(0,s.jsx)(n.strong,{children:"Send"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"custom-providers",children:"Custom providers"}),"\n",(0,s.jsx)(n.h3,{id:"add-a-custom-provider",children:"Add a custom provider"}),"\n",(0,s.jsxs)(n.p,{children:["In addition to the ",(0,s.jsx)(n.a,{href:"#select-an-llm",children:"supported providers"}),", you can use the Playground to test OpenAI compatible API endpoints for custom models. Examples include:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Older versions of supported model providers"}),"\n",(0,s.jsx)(n.li,{children:"Local models"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"To add a custom provider to the Playground, do the following:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["In the upper left corner of the Playground UI, click the ",(0,s.jsx)(n.strong,{children:"Select a model"})," dropdown."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Select ",(0,s.jsx)(n.strong,{children:"+ Add AI provider"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"In the pop-up modal, enter the provider information:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"Provider name"}),": For example, ",(0,s.jsx)(n.code,{children:"openai"})," or ",(0,s.jsx)(n.code,{children:"ollama"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"API key"}),": For example, an OpenAI API key."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"Base URL"}),": For example, ",(0,s.jsx)(n.code,{children:"https://api.openai.com/v1/"})," or a ngrok URL ",(0,s.jsx)(n.code,{children:"https://e452-2600-1700-45f0-3e10-2d3f-796b-d6f2-8ba7.ngrok-free.app"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"Headers"})," (optional): You can add multiple header keys and values."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"Models"}),": You can add multiple models for one provider. For example, ",(0,s.jsx)(n.code,{children:"deepseek-r1"})," and ",(0,s.jsx)(n.code,{children:"qwq"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"Max tokens"})," (optional): For each model, you can specify the max tokens that the model can generate in a response."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Once you've entered your provider information, click ",(0,s.jsx)(n.strong,{children:"Add provider"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Select your new provider and available model(s) from the ",(0,s.jsx)(n.strong,{children:"Select a model"})," dropdown in the upper left corner of the Playground UI."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"important",children:(0,s.jsxs)(n.p,{children:["Because of CORS restrictions, you can't call localhost or 127.0.0.1 URLs directly from the Playground. If you're running a local model server (such as Ollama), use a tunneling service like ngrok to expose it securely. For details, see ",(0,s.jsx)(n.a,{href:"#use-ngrok-with-ollama",children:"Use ngrok with Ollama"}),"."]})}),"\n",(0,s.jsxs)(n.p,{children:["Now, you can test the custom provider model(s) using standard Playground features. You can also ",(0,s.jsx)(n.a,{href:"#edit-a-custom-provider",children:"edit"})," or ",(0,s.jsx)(n.a,{href:"#remove-a-custom-provider",children:"remove"})," the custom provider."]}),"\n",(0,s.jsx)(n.h3,{id:"edit-a-custom-provider",children:"Edit a custom provider"}),"\n",(0,s.jsxs)(n.p,{children:["To edit information for a ",(0,s.jsx)(n.a,{href:"#add-a-custom-provider",children:"previously created custom provider"}),", do the following:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["In the Weave sidebar, navigate to ",(0,s.jsx)(n.strong,{children:"Overview"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["From the top navigation menu, select ",(0,s.jsx)(n.strong,{children:"AI Providers"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["In the ",(0,s.jsx)(n.strong,{children:"Custom providers"})," table, find the custom provider you want to update."]}),"\n",(0,s.jsxs)(n.li,{children:["In the ",(0,s.jsx)(n.strong,{children:"Last Updated"})," column of the entry for your custom provider, click the edit button (the pencil icon)."]}),"\n",(0,s.jsx)(n.li,{children:"In the pop-up modal, edit the provider information."}),"\n",(0,s.jsxs)(n.li,{children:["Click ",(0,s.jsx)(n.strong,{children:"Save"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"remove-a-custom-provider",children:"Remove a custom provider"}),"\n",(0,s.jsxs)(n.p,{children:["To remove a ",(0,s.jsx)(n.a,{href:"#add-a-custom-provider",children:"previously created custom provider"}),", do the following:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["In the Weave sidebar, navigate to ",(0,s.jsx)(n.strong,{children:"Overview"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["From the top navigation menu, select ",(0,s.jsx)(n.strong,{children:"AI Providers"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["In the ",(0,s.jsx)(n.strong,{children:"Custom providers"})," table, find the custom provider you want to update."]}),"\n",(0,s.jsxs)(n.li,{children:["In the ",(0,s.jsx)(n.strong,{children:"Last Updated"})," column of the entry for your custom provider, click the delete button (the trashcan icon)."]}),"\n",(0,s.jsx)(n.li,{children:"In the pop-up modal, confirm that you want to delete the provider. This action cannot be undone."}),"\n",(0,s.jsxs)(n.li,{children:["Click ",(0,s.jsx)(n.strong,{children:"Delete"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"use-ngrok-with-ollama",children:"Use ngrok with Ollama"}),"\n",(0,s.jsx)(n.p,{children:"To test a locally running Ollama model in the Playground, use ngrok to create a temporary public URL that bypasses CORS restrictions."}),"\n",(0,s.jsx)(n.p,{children:"To set it up, do the following:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://ngrok.com/docs/getting-started/#step-1-install",children:"Install ngrok"})," for your operating system."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Start your Ollama model:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ollama run <model>\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"In a separate terminal, create an ngrok tunnel with the required CORS headers:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'ngrok http 11434 --response-header-add "Access-Control-Allow-Origin: *" --host-header rewrite\n'})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["After ngrok starts, it will display a public URL, such as ",(0,s.jsx)(n.code,{children:"https://xxxx-xxxx.ngrok-free.app"}),". Use this URL as the base URL when you add Ollama as a custom provider in the Playground."]}),"\n",(0,s.jsx)(n.p,{children:"The following diagram illustrates the data flow between your local environment, the ngrok proxy, and the W&B cloud services:"}),"\n",(0,s.jsx)(n.mermaid,{value:"flowchart LR\n    %% Style definitions\n    classDef clientMachine fill:#FFD95CCC,stroke:#454B52,stroke-width:2px\n    classDef proxy fill:#00CDDBCC,stroke:#454B52,stroke-width:2px\n    classDef wandbCloud fill:#DE72FFCC,stroke:#454B52,stroke-width:2px\n    classDef publicCloud fill:#FFCBADCC,stroke:#454B52,stroke-width:2px\n\n    %% Subgraphs\n    subgraph Client_Machine\n        browser[Browser]\n        llm_local[Local LLM Provider]\n    end\n\n    subgraph Proxy\n        ngrok[Ngrok Proxy]\n    end\n\n    subgraph WandB_Cloud\n        trace_server[Trace Server]\n    end\n\n    subgraph Public_Cloud\n        llm_cloud[Public LLM Provider]\n    end\n\n    %% Apply styles to subgraphs\n    class Client_Machine clientMachine\n    class Proxy proxy\n    class WandB_Cloud wandbCloud\n    class Public_Cloud publicCloud\n\n    %% Current Data Flow\n    browser --\x3e|Sends chat request| trace_server\n    trace_server --\x3e|Uses Public LLM| llm_cloud\n    trace_server --\x3e|Uses Local LLM| ngrok\n    ngrok --\x3e|Forwards to| llm_local\n    llm_cloud --\x3e|Returns response| trace_server\n    llm_local --\x3e|Returns response| ngrok\n    ngrok --\x3e|Forwards to| trace_server\n    trace_server --\x3e|Returns response| browser\n\n    %% Future Possible Connection\n    browser -.->|Future: Call local LLM directly| llm_local\n\n    %% Link styles\n    linkStyle default stroke:#454B52,stroke-width:2px\n    linkStyle 8 stroke:#454B52,stroke-width:2px,stroke-dasharray:5"}),"\n",(0,s.jsx)(n.h2,{id:"saved-models",children:"Saved models"}),"\n",(0,s.jsx)(n.h3,{id:"save-a-model",children:"Save a model"}),"\n",(0,s.jsx)(n.p,{children:"You can create and configure a reusable model preset for your workflow. Saving a model lets you quickly load it with your preferred settings, parameters, and function hooks."}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"From the LLM dropdown, select a provider."}),"\n",(0,s.jsx)(n.li,{children:"From the provider list, select a model."}),"\n",(0,s.jsxs)(n.li,{children:["In the upper right corner of the Playground UI, click ",(0,s.jsx)(n.strong,{children:"Chat settings"})," to open the chat settings window."]}),"\n",(0,s.jsxs)(n.li,{children:["In the chat settings window:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["In the ",(0,s.jsx)(n.strong,{children:"Model Name"})," field, enter a name for your saved model."]}),"\n",(0,s.jsxs)(n.li,{children:["Adjust parameters as desired. You can also toggle Weave call tracking on or off, and ",(0,s.jsx)(n.a,{href:"#add-a-function",children:"add a function"}),"."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["Click ",(0,s.jsx)(n.strong,{children:"Publish Model"}),". The model is saved and accesible from ",(0,s.jsx)(n.strong,{children:"Saved Models"})," in the LLM dropdown. You can now ",(0,s.jsx)(n.a,{href:"#use-a-saved-model",children:"use"})," and ",(0,s.jsx)(n.a,{href:"#update-a-saved-model",children:"update"})," the saved model."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Saving a model in the Playground",src:i(5418).Z+"",width:"2140",height:"1310"})}),"\n",(0,s.jsx)(n.h3,{id:"use-a-saved-model",children:"Use a saved model"}),"\n",(0,s.jsxs)(n.p,{children:["Quickly switch to a previously ",(0,s.jsx)(n.a,{href:"#save-a-model",children:"saved model"})," to maintain consistency across experiments or sessions. This allows you to pick up right where you left off."]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["From the LLM dropdown, select ",(0,s.jsx)(n.strong,{children:"Saved Models"}),"."]}),"\n",(0,s.jsx)(n.li,{children:"From the list of saved models, click the saved model you want to load. The model loads and is ready for use in the Playground."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"The LLM dropdown, with Saved Models selected",src:i(52512).Z+"",width:"1480",height:"948"})}),"\n",(0,s.jsx)(n.h3,{id:"update-a-saved-model",children:"Update a saved model"}),"\n",(0,s.jsxs)(n.p,{children:["Edit an existing ",(0,s.jsx)(n.a,{href:"#save-a-model",children:"saved model"})," to fine-tune parameters or refresh its configuration. This ensures your saved models evolve alongside your use cases."]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["From the LLM dropdown, select ",(0,s.jsx)(n.strong,{children:"Saved Models"}),"."]}),"\n",(0,s.jsx)(n.li,{children:"From the list of saved models, click the saved model you want to update."}),"\n",(0,s.jsxs)(n.li,{children:["In the upper right corner of the Playground UI, click ",(0,s.jsx)(n.strong,{children:"Chat settings"})," to open the chat settings window."]}),"\n",(0,s.jsxs)(n.li,{children:["In the chat settings window, adjust parameters as desired. You can also toggle Weave call tracking on or off, and ",(0,s.jsx)(n.a,{href:"#add-a-function",children:"add a function"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Click ",(0,s.jsx)(n.strong,{children:"Update model"}),". The model is updated and accesible from ",(0,s.jsx)(n.strong,{children:"Saved Models"})," in the LLM dropdown."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},61961:(e,n,i)=>{i.d(n,{Z:()=>s});const s=i.p+"assets/images/open_chat_in_playground-805b1401f1420257a1eb4573846b38db.png"},44737:(e,n,i)=>{i.d(n,{Z:()=>s});const s=i.p+"assets/images/playground_chat_input-ea91ef8df856725937e5a0dcb1bfad20.png"},83353:(e,n,i)=>{i.d(n,{Z:()=>s});const s=i.p+"assets/images/playground_message_buttons-445507d84c440dfd8d81f7f57f15b7ce.png"},88155:(e,n,i)=>{i.d(n,{Z:()=>s});const s=i.p+"assets/images/playground_message_editor-3fb64862ac8887ace05575836f3125dc.png"},35394:(e,n,i)=>{i.d(n,{Z:()=>s});const s=i.p+"assets/images/playground_settings-dd2e072754145147fa56a74d4b882b85.png"},5418:(e,n,i)=>{i.d(n,{Z:()=>s});const s=i.p+"assets/images/saved-model-00315f7190276fff202cc44816ce5cdb.png"},52512:(e,n,i)=>{i.d(n,{Z:()=>s});const s=i.p+"assets/images/saved-models-dropdown-d1ed4cc8b334638fcbf3e4c411d03f3a.png"},11151:(e,n,i)=>{i.d(n,{Z:()=>o,a:()=>d});var s=i(67294);const r={},l=s.createContext(r);function d(e){const n=s.useContext(l);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:d(e.components),s.createElement(l.Provider,{value:n},e.children)}}}]);