"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2705],{99416:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>d,frontMatter:()=>i,metadata:()=>p,toc:()=>u});var r=t(85893),s=t(11151),a=t(65488),o=t(85162);const i={},l="Prompts",p={id:"guides/core-types/prompts",title:"Prompts",description:"Creating, evaluating, and refining prompts is a core activity for AI engineers.",source:"@site/docs/guides/core-types/prompts.md",sourceDirName:"guides/core-types",slug:"/guides/core-types/prompts",permalink:"/guides/core-types/prompts",draft:!1,unlisted:!1,editUrl:"https://github.com/wandb/weave/blob/master/docs/docs/guides/core-types/prompts.md",tags:[],version:"current",lastUpdatedAt:1758102239e3,frontMatter:{},sidebar:"documentationSidebar",previous:{title:"Models",permalink:"/guides/core-types/models"},next:{title:"Objects",permalink:"/guides/tracking/objects"}},c={},u=[{value:"StringPrompt",id:"stringprompt",level:2},{value:"MessagesPrompt",id:"messagesprompt",level:2},{value:"Parameterizing prompts",id:"parameterizing-prompts",level:2},{value:"View and Compare Prompt Versions",id:"view-prompts",level:2}];function m(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,s.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h1,{id:"prompts",children:"Prompts"}),"\n",(0,r.jsx)(n.p,{children:"Creating, evaluating, and refining prompts is a core activity for AI engineers.\nSmall changes to a prompt can have big impacts on your application's behavior.\nW&B Weave lets you create prompts, save and retrieve them, and evolve them over time."}),"\n",(0,r.jsxs)(n.p,{children:["Weave is unopinionated about how a Prompt is constructed. If your needs are simple, you can use our built-in ",(0,r.jsx)(n.code,{children:"weave.StringPrompt"})," or ",(0,r.jsx)(n.code,{children:"weave.MessagesPrompt"})," classes. If your needs are more complex, you can subclass those or our base class ",(0,r.jsx)(n.code,{children:"weave.Prompt"})," and override the\n",(0,r.jsx)(n.code,{children:"format"})," method."]}),"\n",(0,r.jsxs)(n.p,{children:["When you publish one of these objects with ",(0,r.jsx)(n.code,{children:"weave.publish"}),", it appears in your Weave project on the ",(0,r.jsx)(n.a,{href:"#view-prompts",children:"Prompts page"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"stringprompt",children:"StringPrompt"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"StringPrompt"})," logs single-string prompts that you might use for system messages, user queries, or any standalone text input to an LLM. We recommend using ",(0,r.jsx)(n.code,{children:"StringPrompt"})," to manage individual prompt strings that don't require the complexity of multi-message conversations."]}),"\n",(0,r.jsxs)(a.Z,{groupId:"programming-language",queryString:!0,children:[(0,r.jsx)(o.default,{value:"python",label:"Python",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import weave\nweave.init(\'intro-example\')\n\n# highlight-next-line\nsystem_prompt = weave.StringPrompt("You speak like a pirate")\n# highlight-next-line\nweave.publish(system_prompt, name="pirate_prompt")\n\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model="gpt-4o",\n  messages=[\n    {\n      "role": "system",\n      # highlight-next-line\n      "content": system_prompt.format()\n    },\n    {\n      "role": "user",\n      "content": "Explain general relativity in one paragraph."\n    }\n  ],\n)\n'})})}),(0,r.jsx)(o.default,{value:"typescript",label:"TypeScript",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"import * as weave from 'weave';\nimport OpenAI from 'openai';\n\nasync function main() {\n  // weave.init returns a client instance\n  const weaveClient = await weave.init('wandb/prompt-examples');\n\n  const systemPrompt = new weave.StringPrompt({\n    content: 'You speak like a pirate',\n    name: 'your-prompt',\n    description: 'A helpful description of your prompt',\n  });\n  \n  // Use the client returned from init\n  await weaveClient.publish(systemPrompt, 'pirate_prompt');\n\n  // Wrap OpenAI client to track calls in Weave\n  const client = weave.wrapOpenAI(new OpenAI());\n\n  const response = await client.chat.completions.create({\n    model: \"gpt-4o\",\n    messages: [\n      {\n        role: \"system\",\n        content: systemPrompt.content\n      },\n      {\n        role: \"user\",\n        content: \"Explain general relativity in one paragraph.\"\n      }\n    ],\n  });\n}\n\nmain();\n"})})})]}),"\n",(0,r.jsx)(n.h2,{id:"messagesprompt",children:"MessagesPrompt"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"MessagesPrompt"}),' allows you to log multi-turn conversations and chat-based prompts. It stores an array of message objects (with roles like "system", "user", and "assistant") that represent a complete conversation flow. We recommend using this for chat-based LLMs where you need to maintain context across multiple messages, define specific conversation patterns, or create reusable conversation templates.']}),"\n",(0,r.jsxs)(a.Z,{groupId:"programming-language",queryString:!0,children:[(0,r.jsx)(o.default,{value:"python",label:"Python",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import weave\nweave.init(\'intro-example\')\n\n# highlight-next-line\nprompt = weave.MessagesPrompt([\n    {\n        "role": "system",\n        "content": "You are a stegosaurus, but don\'t be too obvious about it."\n    },\n    {\n        "role": "user",\n        "content": "What\'s good to eat around here?"\n    }\n])\nweave.publish(prompt, name="dino_prompt")\n\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model="gpt-4o",\n  # highlight-next-line\n  messages=prompt.format(),\n)\n'})})}),(0,r.jsx)(o.default,{value:"typescript",label:"TypeScript",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:'import * as weave from \'weave\';\nimport OpenAI from \'openai\';\n\nasync function main() {\n  // weave.init returns a client instance\n  const weaveClient = await weave.init(\'wandb/prompt-examples\');\n\n  const prompt = new weave.MessagesPrompt({\n    messages: [\n      {\n        "role": "system",\n        "content": "You are a stegosaurus, but don\'t be too obvious about it."\n      },\n      {\n        "role": "user",\n        "content": "What\'s good to eat around here?"\n      }\n    ],\n  });\n  \n  // Use the client returned from init\n  await weaveClient.publish(prompt, \'dino_prompt\');\n\n  // Wrap OpenAI client to track calls in Weave\n  const client = weave.wrapOpenAI(new OpenAI());\n\n  const response = await client.chat.completions.create({\n    model: "gpt-4o",\n    messages: prompt.messages,\n  });\n}\n\nmain();\n'})})})]}),"\n",(0,r.jsx)(n.h2,{id:"parameterizing-prompts",children:"Parameterizing prompts"}),"\n",(0,r.jsxs)(n.p,{children:["Both ",(0,r.jsx)(n.code,{children:"StringPrompt"})," and ",(0,r.jsx)(n.code,{children:"MessagesPrompt"})," support dynamic content through parameterization. This allows you to create flexible, reusable prompt templates with placeholders (using ",(0,r.jsx)(n.code,{children:"{variable}"})," syntax) that can be filled with different values at runtime. This is useful for building scalable applications where prompts need to adapt to different inputs, user data, or contexts while maintaining a consistent structure. The ",(0,r.jsx)(n.code,{children:"format()"})," method accepts key-value pairs to replace these placeholders with actual values."]}),"\n",(0,r.jsxs)(a.Z,{groupId:"programming-language",queryString:!0,children:[(0,r.jsx)(o.default,{value:"python",label:"Python",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import weave\nweave.init(\'intro-example\')\n\n# highlight-next-line\nprompt = weave.StringPrompt("Solve the equation {equation}")\nweave.publish(prompt, name="calculator_prompt")\n\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model="gpt-4o",\n  messages=[\n    {\n      "role": "user",\n      # highlight-next-line\n      "content": prompt.format(equation="1 + 1 = ?")\n    }\n  ],\n)\n'})})}),(0,r.jsx)(o.default,{value:"typescript",label:"TypeScript",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"import * as weave from 'weave';\nimport OpenAI from 'openai';\n\nasync function main() {\n  // weave.init returns a client instance\n  const weaveClient = await weave.init('wandb/prompt-examples');\n\n  // highlight-next-line\n  const prompt = new weave.StringPrompt({\n    content: 'Solve the equation {equation}',\n  });\n  \n  // Use the client returned from init\n  await weaveClient.publish(prompt, 'calculator_prompt');\n\n  // Wrap OpenAI client to track calls in Weave\n  const client = weave.wrapOpenAI(new OpenAI());\n\n  const response = await client.chat.completions.create({\n    model: \"gpt-4o\",\n    messages: [\n      {\n        role: \"user\",\n        // highlight-next-line\n        content: prompt.format({ equation: \"1 + 1 = ?\" })\n      }\n    ],\n  });\n}\n\nmain();\n"})})})]}),"\n",(0,r.jsxs)(n.p,{children:["This also works with ",(0,r.jsx)(n.code,{children:"MessagesPrompt"}),"."]}),"\n",(0,r.jsxs)(a.Z,{groupId:"programming-language",queryString:!0,children:[(0,r.jsx)(o.default,{value:"python",label:"Python",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import weave\nweave.init(\'intro-example\')\n\n# highlight-next-line\nprompt = weave.MessagesPrompt([\n{\n    "role": "system",\n    "content": "You will be provided with a description of a scene and your task is to provide a single word that best describes an associated emotion."\n},\n{\n    "role": "user",\n    "content": "{scene}"\n}\n])\nweave.publish(prompt, name="emotion_prompt")\n\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model="gpt-4o",\n  # highlight-next-line\n  messages=prompt.format(scene="A dog is lying on a dock next to a fisherman."),\n)\n'})})}),(0,r.jsx)(o.default,{value:"typescript",label:"TypeScript",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:'import * as weave from \'weave\';\nimport OpenAI from \'openai\';\n\nasync function main() {\n  // weave.init returns a client instance\n  const weaveClient = await weave.init(\'wandb/prompt-examples\');\n\n  // highlight-next-line\n  const prompt = new weave.MessagesPrompt({\n    messages: [\n      {\n        "role": "system",\n        "content": "You will be provided with a description of a scene and your task is to provide a single word that best describes an associated emotion."\n      },\n      {\n        "role": "user",\n        "content": "{scene}"\n      }\n    ]\n  });\n  \n  // Use the client returned from init\n  await weaveClient.publish(prompt, \'emotion_prompt\');\n\n  // Wrap OpenAI client to track calls in Weave\n  const client = weave.wrapOpenAI(new OpenAI());\n\n  const response = await client.chat.completions.create({\n    model: "gpt-4o",\n    // highlight-next-line\n    messages: prompt.format({ scene: "A dog is lying on a dock next to a fisherman." }),\n  });\n}\n\nmain();\n'})})})]}),"\n",(0,r.jsx)(n.h2,{id:"view-prompts",children:"View and Compare Prompt Versions"}),"\n",(0,r.jsx)(n.p,{children:"Weave automatically tracks every version of your prompts, creating a complete history of how your prompts evolve. This versioning system is crucial for prompt engineering workflows, allowing you to experiment safely, track what changes improved or hurt performance, and easily roll back to previous versions if needed. Each time you publish a prompt with the same name but different content, Weave creates a new version while preserving all previous versions."}),"\n",(0,r.jsx)(n.p,{children:"To view versions of the prompt in the UI:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Open your project in the UI and click the ",(0,r.jsx)(n.strong,{children:"Assets"})," button in the left menu. This opens the Assets page."]}),"\n",(0,r.jsxs)(n.li,{children:["From the Assets page, click ",(0,r.jsx)(n.strong,{children:"Prompts"}),". This opens the Prompts page where your project's prompts are listed."]}),"\n",(0,r.jsxs)(n.li,{children:["Under the ",(0,r.jsx)(n.strong,{children:"Versions"})," column, click ",(0,r.jsx)(n.strong,{children:"(x) Versions"})," for the prompt you want to view. This opens a list of prompt versions."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Screenshot of viewing a prompt object",src:t(63824).Z+"",width:"2268",height:"608"})}),"\n",(0,r.jsxs)(n.ol,{start:"4",children:["\n",(0,r.jsxs)(n.li,{children:["(Optional) You can compare versions of prompts by clicking the checkboxes beside the listed prompts and then clicking the ",(0,r.jsx)(n.strong,{children:"Compare"})," button. This allows you to see the diff between your prompts."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Screenshot of prompt comparison",src:t(19116).Z+"",width:"3144",height:"1290"})})]})}function d(e={}){const{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(m,{...e})}):m(e)}},85162:(e,n,t)=>{t.r(n),t.d(n,{default:()=>o});t(67294);var r=t(90512);const s={tabItem:"tabItem_Ymn6"};var a=t(85893);function o(e){let{children:n,hidden:t,className:o}=e;return(0,a.jsx)("div",{role:"tabpanel",className:(0,r.Z)(s.tabItem,o),hidden:t,children:n})}},65488:(e,n,t)=>{t.d(n,{Z:()=>d});var r=t(67294),s=t(90512),a=t(12466),o=t(70989),i=t(72389);const l={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var p=t(85893);function c(e){let{className:n,block:t,selectedValue:r,selectValue:o,tabValues:i}=e;const c=[],{blockElementScrollPositionUntilNextRender:u}=(0,a.o5)(),m=e=>{const n=e.currentTarget,t=c.indexOf(n),s=i[t].value;s!==r&&(u(n),o(s))},d=e=>{let n=null;switch(e.key){case"Enter":m(e);break;case"ArrowRight":{const t=c.indexOf(e.currentTarget)+1;n=c[t]??c[0];break}case"ArrowLeft":{const t=c.indexOf(e.currentTarget)-1;n=c[t]??c[c.length-1];break}}n?.focus()};return(0,p.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.Z)("tabs",{"tabs--block":t},n),children:i.map((e=>{let{value:n,label:t,attributes:a}=e;return(0,p.jsx)("li",{role:"tab",tabIndex:r===n?0:-1,"aria-selected":r===n,ref:e=>c.push(e),onKeyDown:d,onClick:m,...a,className:(0,s.Z)("tabs__item",l.tabItem,a?.className,{"tabs__item--active":r===n}),children:t??n},n)}))})}function u(e){let{lazy:n,children:t,selectedValue:s}=e;const a=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=a.find((e=>e.props.value===s));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return(0,p.jsx)("div",{className:"margin-top--md",children:a.map(((e,n)=>(0,r.cloneElement)(e,{key:n,hidden:e.props.value!==s})))})}function m(e){const n=(0,o.Y)(e);return(0,p.jsxs)("div",{className:(0,s.Z)("tabs-container",l.tabList),children:[(0,p.jsx)(c,{...n,...e}),(0,p.jsx)(u,{...n,...e})]})}function d(e){const n=(0,i.default)();return(0,p.jsx)(m,{...e,children:(0,o.h)(e.children)},String(n))}},70989:(e,n,t)=>{t.d(n,{Y:()=>d,h:()=>p});var r=t(67294),s=t(16550),a=t(20469),o=t(91980),i=t(67392),l=t(20812);function p(e){return r.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function c(e){const{values:n,children:t}=e;return(0,r.useMemo)((()=>{const e=n??function(e){return p(e).map((e=>{let{props:{value:n,label:t,attributes:r,default:s}}=e;return{value:n,label:t,attributes:r,default:s}}))}(t);return function(e){const n=(0,i.l)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function u(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function m(e){let{queryString:n=!1,groupId:t}=e;const a=(0,s.k6)(),i=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,o._X)(i),(0,r.useCallback)((e=>{if(!i)return;const n=new URLSearchParams(a.location.search);n.set(i,e),a.replace({...a.location,search:n.toString()})}),[i,a])]}function d(e){const{defaultValue:n,queryString:t=!1,groupId:s}=e,o=c(e),[i,p]=(0,r.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!u({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const r=t.find((e=>e.default))??t[0];if(!r)throw new Error("Unexpected error: 0 tabValues");return r.value}({defaultValue:n,tabValues:o}))),[d,h]=m({queryString:t,groupId:s}),[g,v]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[s,a]=(0,l.Nk)(t);return[s,(0,r.useCallback)((e=>{t&&a.set(e)}),[t,a])]}({groupId:s}),f=(()=>{const e=d??g;return u({value:e,tabValues:o})?e:null})();(0,a.Z)((()=>{f&&p(f)}),[f]);return{selectedValue:i,selectValue:(0,r.useCallback)((e=>{if(!u({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);p(e),h(e),v(e)}),[h,v,o]),tabValues:o}}},19116:(e,n,t)=>{t.d(n,{Z:()=>r});const r=t.p+"assets/images/prompt-comparison-6b3933739f42884f17336b83ea516f54.png"},63824:(e,n,t)=>{t.d(n,{Z:()=>r});const r=t.p+"assets/images/prompt-object-3bc9df1f0594af7988605112cdf8a0c3.png"},11151:(e,n,t)=>{t.d(n,{Z:()=>i,a:()=>o});var r=t(67294);const s={},a=r.createContext(s);function o(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);