{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import anthropic\n",
    "import weave\n",
    "from datetime import datetime, timezone\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "import requests\n",
    "import io\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "load_dotenv()\n",
    "# Setup\n",
    "weave.init(\"summarization-chain-of-density-cookbook\")\n",
    "anthropic_client = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ArxivPaper model\n",
    "class ArxivPaper(BaseModel):\n",
    "    entry_id: str\n",
    "    updated: datetime\n",
    "    published: datetime\n",
    "    title: str\n",
    "    authors: list[str]\n",
    "    summary: str\n",
    "    pdf_url: str\n",
    "\n",
    "# Create sample ArxivPaper\n",
    "arxiv_paper = ArxivPaper(\n",
    "    entry_id=\"http://arxiv.org/abs/2406.04744v1\",\n",
    "    updated=datetime(2024, 6, 7, 8, 43, 7, tzinfo=timezone.utc),\n",
    "    published=datetime(2024, 6, 7, 8, 43, 7, tzinfo=timezone.utc),\n",
    "    title=\"CRAG -- Comprehensive RAG Benchmark\",\n",
    "    authors=[\"Xiao Yang\", \"Kai Sun\", \"Hao Xin\"],  # Truncated for brevity\n",
    "    summary=\"Retrieval-Augmented Generation (RAG) has recently emerged as a promising solution...\",  # Truncated\n",
    "    pdf_url=\"https://arxiv.org/pdf/2406.04744\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op()\n",
    "def load_pdf(pdf_url: str) -> str:\n",
    "    # Download the PDF\n",
    "    response = requests.get(pdf_url)\n",
    "    pdf_file = io.BytesIO(response.content)\n",
    "    \n",
    "    # Read the PDF\n",
    "    pdf_reader = PdfReader(pdf_file)\n",
    "    \n",
    "    # Extract text from all pages\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain of Density Summarization\n",
    "@weave.op()\n",
    "def summarize_current_summary(document: str, instruction: str, current_summary: str = \"\", iteration: int = 1, model: str = \"claude-3-sonnet-20240229\"):\n",
    "    prompt = f\"\"\"\n",
    "    Document: {document}\n",
    "    Current summary: {current_summary}\n",
    "    Instruction to focus on: {instruction}\n",
    "    Iteration: {iteration}\n",
    "\n",
    "    Generate an increasingly concise, entity-dense, and highly technical summary from the provided document that specifically addresses the given instruction.\n",
    "    \"\"\"\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=4096,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.content[0].text\n",
    "\n",
    "@weave.op()\n",
    "def iterative_density_summarization(document: str, instruction: str, current_summary: str, density_iterations: int, model: str = \"claude-3-sonnet-20240229\"):\n",
    "    iteration_summaries = []\n",
    "    for iteration in range(1, density_iterations + 1):\n",
    "        current_summary = summarize_current_summary(document, instruction, current_summary, iteration, model)\n",
    "        iteration_summaries.append(current_summary)\n",
    "    return current_summary, iteration_summaries\n",
    "\n",
    "@weave.op()\n",
    "def final_summary(instruction: str, current_summary: str, model: str = \"claude-3-sonnet-20240229\"):\n",
    "    prompt = f\"\"\"\n",
    "    Given this summary: {current_summary}\n",
    "    And this instruction to focus on: {instruction}\n",
    "    Create an extremely dense, final summary that captures all key technical information in the most concise form possible, while specifically addressing the given instruction.\n",
    "    \"\"\"\n",
    "    return anthropic_client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=4096,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    ).content[0].text\n",
    "\n",
    "@weave.op()\n",
    "def chain_of_density_summarization(document: str, instruction: str, current_summary: str = \"\", model: str = \"claude-3-sonnet-20240229\", density_iterations: int = 2):\n",
    "    current_summary, iteration_summaries = iterative_density_summarization(document, instruction, current_summary, density_iterations, model)\n",
    "    final_summary_text = final_summary(instruction, current_summary, model)\n",
    "    return {\n",
    "        \"final_summary\": final_summary_text,\n",
    "        \"accumulated_summary\": current_summary,\n",
    "        \"iteration_summaries\": iteration_summaries,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weave Model\n",
    "class ArxivChainOfDensityPipeline(weave.Model):\n",
    "    model: str = \"claude-3-sonnet-20240229\"\n",
    "    density_iterations: int = 3\n",
    "\n",
    "    @weave.op()\n",
    "    def predict(self, paper: ArxivPaper, instruction: str) -> dict:\n",
    "        text = load_pdf(paper[\"pdf_url\"])\n",
    "        result = chain_of_density_summarization(text, instruction, model=self.model, density_iterations=self.density_iterations)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "@weave.op()\n",
    "def evaluate_summary(summary: str, instruction: str, model: str = \"claude-3-sonnet-20240229\") -> dict:\n",
    "    prompt = f\"\"\"\n",
    "    Summary: {summary}\n",
    "    Instruction: {instruction}\n",
    "\n",
    "    Evaluate the summary based on the following criteria:\n",
    "    1. Relevance (1-5): How well does the summary address the given instruction?\n",
    "    2. Conciseness (1-5): How concise is the summary while retaining key information?\n",
    "    3. Technical Accuracy (1-5): How accurately does the summary convey technical details?\n",
    "\n",
    "    Your response MUST be in the following JSON format:\n",
    "    {{\n",
    "        \"relevance\": {{\n",
    "            \"score\": <int>,\n",
    "            \"explanation\": \"<string>\"\n",
    "        }},\n",
    "        \"conciseness\": {{\n",
    "            \"score\": <int>,\n",
    "            \"explanation\": \"<string>\"\n",
    "        }},\n",
    "        \"technical_accuracy\": {{\n",
    "            \"score\": <int>,\n",
    "            \"explanation\": \"<string>\"\n",
    "        }}\n",
    "    }}\n",
    "\n",
    "    Ensure that the scores are integers between 1 and 5, and that the explanations are concise.\n",
    "    \"\"\"\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=1000,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    print(response.content[0].text)\n",
    "    \n",
    "    eval_dict = json.loads(response.content[0].text)\n",
    "    \n",
    "    return {\n",
    "        \"relevance\": eval_dict['relevance']['score'],\n",
    "        \"conciseness\": eval_dict['conciseness']['score'],\n",
    "        \"technical_accuracy\": eval_dict['technical_accuracy']['score'],\n",
    "        \"average_score\": sum(eval_dict[k]['score'] for k in eval_dict) / 3,\n",
    "        \"evaluation_text\": response.content[0].text\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Weave Dataset\n",
    "dataset = weave.Dataset(\n",
    "    name=\"arxiv_papers\",\n",
    "    rows=[\n",
    "        {\n",
    "            \"paper\": arxiv_paper,\n",
    "            \"instruction\": \"What was the approach to experimenting with different data mixtures?\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "weave.publish(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scorer function\n",
    "@weave.op()\n",
    "def quality_scorer(instruction: str, model_output: dict) -> dict:\n",
    "    result = evaluate_summary(model_output[\"final_summary\"], instruction)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "evaluation = weave.Evaluation(dataset=dataset, scorers=[quality_scorer])\n",
    "arxiv_chain_of_density_pipeline = ArxivChainOfDensityPipeline()\n",
    "results = await evaluation.evaluate(arxiv_chain_of_density_pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
