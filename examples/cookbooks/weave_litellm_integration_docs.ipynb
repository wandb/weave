{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wandb/weave/blob/master/examples/cookbooks/weave_litellm_integration_docs.ipynb)\n",
    "<!--- @wandbcode{weave-litellm-integration} -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wandb weave litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0HDOemIDzQa"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import userdata\n",
    "    import os\n",
    "    os.environ[\"WANDB_API_KEY\"] = userdata.get(\"WANDB_API_KEY\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get(\"ANTHROPIC_API_KEY\")\n",
    "except:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tuWG-pChG3fq"
   },
   "outputs": [],
   "source": [
    "project = \"weave_litellm_integration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4C_7MQmV8f_"
   },
   "outputs": [],
   "source": [
    "import litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUg9-Ug0JE30"
   },
   "outputs": [],
   "source": [
    "import weave\n",
    "weave.init(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwnbcjuLFPSC"
   },
   "outputs": [],
   "source": [
    "response = litellm.completion(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Translate 'Hello, how are you?' to French\"}],\n",
    "    max_tokens=1024\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCdDGp5yDlPL"
   },
   "outputs": [],
   "source": [
    "response = litellm.completion(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Translate 'Hello, how are you?' to French\"}],\n",
    "    max_tokens=1024\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSHcQiqVEc4o"
   },
   "outputs": [],
   "source": [
    "@weave.op()\n",
    "def translate(text: str, target_language: str, model: str) -> str:\n",
    "    response = litellm.completion(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Translate '{text}' to {target_language}\"}],\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(translate(\"Hello, how are you?\", \"French\", \"gpt-3.5-turbo\"))\n",
    "print(translate(\"Hello, how are you?\", \"Spanish\", \"claude-3-5-sonnet-20240620\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yq1QlgZXFaaV"
   },
   "outputs": [],
   "source": [
    "class TranslatorModel(weave.Model):\n",
    "    model: str\n",
    "    temperature: float\n",
    "\n",
    "    @weave.op()\n",
    "    def predict(self, text: str, target_language: str):\n",
    "        response = litellm.completion(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are a translator. Translate the given text to {target_language}.\"},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ],\n",
    "            max_tokens=1024,\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "# Create instances with different models\n",
    "gpt_translator = TranslatorModel(model=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "claude_translator = TranslatorModel(model=\"claude-3-5-sonnet-20240620\", temperature=0.1)\n",
    "\n",
    "# Use different models for translation\n",
    "english_text = \"Hello, how are you today?\"\n",
    "\n",
    "print(\"GPT-3.5 Translation to French:\")\n",
    "print(gpt_translator.predict(english_text, \"French\"))\n",
    "\n",
    "print(\"\\nClaude-3.5-Sonnet Translation to Spanish:\")\n",
    "print(claude_translator.predict(english_text, \"Spanish\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdlrxqcBmM_u"
   },
   "outputs": [],
   "source": [
    "claude_translator = TranslatorModel(model=\"claude-3-5-sonnet-20240620\", temperature=0.1)\n",
    "print(claude_translator.predict(english_text, \"Spanish\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBKTo8XnFq6m"
   },
   "outputs": [],
   "source": [
    "response = litellm.completion(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Translate 'Hello, how are you?' to French\"}],\n",
    "    functions=[\n",
    "        {\n",
    "            \"name\": \"translate\",\n",
    "            \"description\": \"Translate text to a specified language\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"text\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The text to translate\",\n",
    "                    },\n",
    "                    \"target_language\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The language to translate to\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"text\", \"target_language\"],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.function_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0ehhh_0mB_2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
