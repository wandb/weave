{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weave/examples/blob/master/examples/cookbooks/weave_litellm_integration_docs.ipynb)\n",
        "<!--- @wandbcode{weave-litellm-integration} -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wandb weave litellm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s0HDOemIDzQa"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import userdata\n",
        "    import os\n",
        "    os.environ[\"WANDB_API_KEY\"] = userdata.get(\"WANDB_API_KEY\")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "    os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get(\"ANTHROPIC_API_KEY\")\n",
        "except:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tuWG-pChG3fq"
      },
      "outputs": [],
      "source": [
        "project = \"weave_litellm_integration\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "R4C_7MQmV8f_"
      },
      "outputs": [],
      "source": [
        "import litellm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JUg9-Ug0JE30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged in as Weights & Biases user: a-sh0ts.\n",
            "View Weave data at https://wandb.ai/a-sh0ts/litellm_weave_integration/weave\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<weave.weave_client.WeaveClient at 0x10c6c2f10>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import weave\n",
        "weave.init(project)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rwnbcjuLFPSC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🍩 https://wandb.ai/a-sh0ts/litellm_weave_integration/r/call/87b74fc6-511a-4a3c-a4a2-80192c5c954a\n",
            "Bonjour, comment vas-tu ?\n"
          ]
        }
      ],
      "source": [
        "response = litellm.completion(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Translate 'Hello, how are you?' to French\"}],\n",
        "    max_tokens=1024\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vCdDGp5yDlPL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🍩 https://wandb.ai/a-sh0ts/litellm_weave_integration/r/call/3b79d7ca-e435-4ed1-b8a0-c35853d5d5f2\n",
            "The French translation of \"Hello, how are you?\" is:\n",
            "\n",
            "\"Bonjour, comment allez-vous?\"\n",
            "\n",
            "This is the formal way of asking. If you want a more informal version, you could say:\n",
            "\n",
            "\"Salut, ça va?\"\n"
          ]
        }
      ],
      "source": [
        "response = litellm.completion(\n",
        "    model=\"claude-3-5-sonnet-20240620\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Translate 'Hello, how are you?' to French\"}],\n",
        "    max_tokens=1024\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cSHcQiqVEc4o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🍩 https://wandb.ai/a-sh0ts/litellm_weave_integration/r/call/155100ed-cd80-4790-aa22-a8635a923b16\n",
            "Bonjour, comment vas-tu ?\n",
            "🍩 https://wandb.ai/a-sh0ts/litellm_weave_integration/r/call/6acab84e-7227-44ae-999f-58f30f276b84\n",
            "The Spanish translation of \"Hello, how are you?\" is:\n",
            "\n",
            "\"Hola, ¿cómo estás?\"\n",
            "\n",
            "This is the informal version, which you would use with friends, family, or people you're familiar with. If you need a more formal version, you could say:\n",
            "\n",
            "\"Hola, ¿cómo está usted?\"\n",
            "\n",
            "Both versions mean the same thing, but the second one is more polite and used in formal situations or when addressing someone older or in a position of authority.\n"
          ]
        }
      ],
      "source": [
        "@weave.op()\n",
        "def translate(text: str, target_language: str, model: str) -> str:\n",
        "    response = litellm.completion(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": f\"Translate '{text}' to {target_language}\"}],\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "print(translate(\"Hello, how are you?\", \"French\", \"gpt-3.5-turbo\"))\n",
        "print(translate(\"Hello, how are you?\", \"Spanish\", \"claude-3-5-sonnet-20240620\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Yq1QlgZXFaaV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT-3.5 Translation to French:\n",
            "ModelResponse(id='chatcmpl-9imYE3ZGUe3xBu8a0DCSQfHvJvwtL', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Bonjour, comment vas-tu aujourd'hui ?\", role='assistant'))], created=1720460090, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=9, prompt_tokens=30, total_tokens=39))\n",
            "Bonjour, comment vas-tu aujourd'hui ?\n",
            "<class 'str'>\n",
            "🍩 https://wandb.ai/a-sh0ts/litellm_weave_integration/r/call/4b4a459b-1eaf-4366-b280-83ba47bc3e91\n",
            "Bonjour, comment vas-tu aujourd'hui ?\n",
            "\n",
            "Claude-3.5-Sonnet Translation to Spanish:\n",
            "ModelResponse(id='chatcmpl-6aec83c8-3a4c-426b-8ab7-4275c69a11a5', choices=[Choices(finish_reason='stop', index=0, message=Message(content='Hola, ¿cómo estás hoy?', role='assistant', tool_calls=[]))], created=1720460093, model='claude-3-5-sonnet-20240620', object='chat.completion', system_fingerprint=None, usage=Usage(prompt_tokens=27, completion_tokens=17, total_tokens=44))\n",
            "Hola, ¿cómo estás hoy?\n",
            "<class 'str'>\n",
            "🍩 https://wandb.ai/a-sh0ts/litellm_weave_integration/r/call/7f706d2c-ad24-4a61-b115-2d98472f819b\n",
            "Hola, ¿cómo estás hoy?\n"
          ]
        }
      ],
      "source": [
        "class TranslatorModel(weave.Model):\n",
        "    model: str\n",
        "    temperature: float\n",
        "\n",
        "    @weave.op()\n",
        "    def predict(self, text: str, target_language: str):\n",
        "        response = litellm.completion(\n",
        "            model=self.model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": f\"You are a translator. Translate the given text to {target_language}.\"},\n",
        "                {\"role\": \"user\", \"content\": text}\n",
        "            ],\n",
        "            max_tokens=1024,\n",
        "            temperature=self.temperature\n",
        "        )\n",
        "        print(response)\n",
        "        print(response.choices[0].message.content)\n",
        "        print(type(response.choices[0].message.content))\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "# Create instances with different models\n",
        "gpt_translator = TranslatorModel(model=\"gpt-3.5-turbo\", temperature=0.3)\n",
        "claude_translator = TranslatorModel(model=\"claude-3-5-sonnet-20240620\", temperature=0.1)\n",
        "\n",
        "\n",
        "# Use different models for translation\n",
        "english_text = \"Hello, how are you today?\"\n",
        "\n",
        "print(\"GPT-3.5 Translation to French:\")\n",
        "print(gpt_translator.predict(english_text, \"French\"))\n",
        "\n",
        "print(\"\\nClaude-3.5-Sonnet Translation to Spanish:\")\n",
        "print(claude_translator.predict(english_text, \"Spanish\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XdlrxqcBmM_u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ModelResponse(id='chatcmpl-33e030a8-4c59-4a2f-915e-4cbcb520cea4', choices=[Choices(finish_reason='stop', index=0, message=Message(content='Hola, ¿cómo estás hoy?', role='assistant', tool_calls=[]))], created=1720460095, model='claude-3-5-sonnet-20240620', object='chat.completion', system_fingerprint=None, usage=Usage(prompt_tokens=27, completion_tokens=17, total_tokens=44))\n",
            "Hola, ¿cómo estás hoy?\n",
            "<class 'str'>\n",
            "🍩 https://wandb.ai/a-sh0ts/litellm_weave_integration/r/call/ca153155-f956-4c9b-ab40-fa1edd27c384\n",
            "Hola, ¿cómo estás hoy?\n"
          ]
        }
      ],
      "source": [
        "claude_translator = TranslatorModel(model=\"claude-3-5-sonnet-20240620\", temperature=0.1)\n",
        "print(claude_translator.predict(english_text, \"Spanish\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BBKTo8XnFq6m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🍩 https://wandb.ai/a-sh0ts/litellm_weave_integration/r/call/b849c29e-6965-4d28-a0a5-a78d798483ea\n",
            "FunctionCall(arguments='{\"text\":\"Hello, how are you?\",\"target_language\":\"fr\"}', name='translate')\n"
          ]
        }
      ],
      "source": [
        "response = litellm.completion(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Translate 'Hello, how are you?' to French\"}],\n",
        "    functions=[\n",
        "        {\n",
        "            \"name\": \"translate\",\n",
        "            \"description\": \"Translate text to a specified language\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"text\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The text to translate\",\n",
        "                    },\n",
        "                    \"target_language\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The language to translate to\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"text\", \"target_language\"],\n",
        "            },\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.function_call)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0ehhh_0mB_2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
