{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Traces\n",
    "\n",
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "Weave is a toolkit for developing AI-powered applications.\n",
    "\n",
    "Weave traces let you automatically capture the inputs, outputs, and internal structure of your Python functions‚Äîespecially useful when working with LLMs. By decorating a function with `@weave.op`, Weave records a rich trace of how your function runs, including any nested operations or external API calls. This makes it easy to debug, understand, and visualize how your code is interacting with language models, all from within your notebook.\n",
    "\n",
    "To get started, complete the prerequisites. Then, define a function with the `@weave.op` decorator to track LLM calls, run it on an example input, and Weave will automatically capture and visualize the trace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McE7cuqSxMiP"
   },
   "source": [
    "## üêù Logging your first trace\n",
    "\n",
    "In this example, we're using W&B Inference. [Learn more](https://docs.wandb.ai/inference) about our inference API.\\\n",
    "Using another provider? [We support all major clients and frameworks](https://docs.wandb.ai/weave/guides/integrations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56XteuP7s7sm"
   },
   "outputs": [],
   "source": [
    "# Ensure your dependencies are installed with:\n",
    "!pip install openai weave\n",
    "\n",
    "# Find your wandb API key at: https://wandb.ai/authorize\n",
    "# Ensure that your wandb API key is available at:\n",
    "# os.environ['WANDB_API_KEY'] = \"<your_wandb_api_key>\"\n",
    "\n",
    "import os\n",
    "import weave\n",
    "from openai import OpenAI\n",
    "\n",
    "# Setup your wandb project (team name / project name) üêù\n",
    "WANDB_ENTITY_PROJECT = \"my-team-name/my-project-name\"\n",
    "\n",
    "# Find your wandb API key at: https://wandb.ai/authorize\n",
    "weave.init(WANDB_ENTITY_PROJECT) # üêù\n",
    "\n",
    "@weave.op() # üêù Decorator to track requests\n",
    "def create_completion(message: str) -> str:\n",
    "  client = OpenAI(\n",
    "      base_url='https://api.inference.wandb.ai/v1',\n",
    "      api_key=os.environ['WANDB_API_KEY'], # üîë Your wandb API key\n",
    "      project=WANDB_ENTITY_PROJECT,\n",
    "  )\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"OpenPipe/Qwen3-14B-Instruct\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "          {\"role\": \"user\", \"content\": message}\n",
    "      ],\n",
    "  )\n",
    "  return response.choices[0].message.content\n",
    "message = \"Tell me a joke.\"\n",
    "create_completion(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üêù Running your first evaluation (using OpenAI)\n",
    "\n",
    "Your can find your OpenAI API keys here: https://platform.openai.com/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure your dependencies are installed with:\n",
    "!pip install openai weave\n",
    "\n",
    "# Find your OpenAI API key at: https://platform.openai.com/api-keys\n",
    "# Ensure that your OpenAI API key is available at:\n",
    "# os.environ['OPENAI_API_KEY'] = \"<your_openai_api_key>\"\n",
    "\n",
    "import os\n",
    "import weave\n",
    "from openai import OpenAI\n",
    "\n",
    "# Setup your wandb project (team name / project name) üêù\n",
    "WANDB_ENTITY_PROJECT = \"my-team-name/my-project-name\"\n",
    "\n",
    "# Find your wandb API key at: https://wandb.ai/authorize\n",
    "weave.init(WANDB_ENTITY_PROJECT) # üêù\n",
    "\n",
    "@weave.op() # üêù Decorator to track requests\n",
    "def create_completion(message: str) -> str:\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "message = \"Tell me a joke.\"\n",
    "create_completion(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGqeyYMmw7Hl"
   },
   "source": [
    "## üöÄ Looking for more examples?\n",
    "- Check out the [Quickstart guide](https://weave-docs.wandb.ai/quickstart).\n",
    "- Learn more about [advanced tracing topics](https://weave-docs.wandb.ai/tutorial-tracing_2).\n",
    "- Learn more about [tracing in Weave](https://weave-docs.wandb.ai/guides/tracking/tracing)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
