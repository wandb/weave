{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Weave Library\n",
    "# (note: this will become `pip install weave` soon - this is a temp dev state)\n",
    "# !pip uninstall weave -y >/dev/null 2>&1\n",
    "# !pip install git+https://github.com/wandb/weave@master -U -qqq >/dev/null 2>&1\n",
    "# !echo \"Installed Weave!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with W&B\n",
    "# (note: we can eliminate this step import in the future)\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Weave\n",
    "# (note: we can eliminate the `weaveflow` import in future)\n",
    "\n",
    "import weave\n",
    "from weave import weaveflow\n",
    "client = weave.init(\"wf_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with OpenAI\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "@weave.op()\n",
    "def simple_openai_complete(message: str, model: str, system_prompt: str) -> str:\n",
    "  completion = OpenAI().chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system_prompt},\n",
    "      {\"role\": \"user\", \"content\": message}\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  return completion.choices[0].message.content\n",
    "\n",
    "@weave.op()\n",
    "def lookup_docs(user_message: str) -> list[str]:\n",
    "  docs = simple_openai_complete(\n",
    "      f\"Query: {user_message}\",\n",
    "      \"gpt-3.5-turbo\",\n",
    "      \"Please act like a vector database, returning up to 3 documents that relate to a query. Feel free to be creative, make up names & details, etc... - as if you have access to relevant documents containing critical information. Do not include docuemnt titles, just content. You must format your response as a JSON.load-able array of strings.\"\n",
    "  )\n",
    "  try:\n",
    "    json_res = json.loads(docs)\n",
    "    res = []\n",
    "    for item in json_res:\n",
    "        res.append(\"\" + item)\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    return []\n",
    "\n",
    "  return res\n",
    "\n",
    "@weave.type()\n",
    "class GptRagModel:\n",
    "  base_model: str\n",
    "  system_prompt: str\n",
    "\n",
    "  @weave.op()\n",
    "  def predict(self, input: str) -> str:\n",
    "    docs = lookup_docs(input)\n",
    "    prompt = f\"Given the following documents, please formulate a short, consise answer.\\n Documents: {','.join(docs)}.\\n\\n Query: {input}.\"\n",
    "    res = simple_openai_complete(prompt, self.base_model, self.system_prompt)\n",
    "    return res\n",
    "\n",
    "@weave.type()\n",
    "class SimpleDataset:\n",
    "  examples: list[str]\n",
    "\n",
    "@weave.op()\n",
    "def brevity_score(example:str, prediction:str) -> float:\n",
    "    # returns a dict of scores\n",
    "    return 1 / (1 + len(prediction))\n",
    "\n",
    "@weave.op()\n",
    "def relevance_score(example:str, prediction:str) -> int:\n",
    "    # returns a dict of scores\n",
    "    return int(simple_openai_complete(\n",
    "        f\"Prompt:{example}.\\nAnswer:{prediction}.\\nScore:\",\n",
    "        \"gpt-3.5-turbo\",\n",
    "        \"Score relevance of the output to the input. Emit ONLY a number between 0 and 9 inclusive. Nothing else\"\n",
    "    ))\n",
    "\n",
    "@weave.op()\n",
    "def score(example:str, prediction:str) -> dict:\n",
    "    # returns a dict of scores\n",
    "    return {\n",
    "        'brevity': brevity_score(example, prediction),\n",
    "        'relevance': relevance_score(example, prediction),\n",
    "    }\n",
    "\n",
    "@weave.op()\n",
    "def eval_iter(model: GptRagModel, example: str) -> dict:\n",
    "    return score(example, model.predict(example))\n",
    "\n",
    "@weave.op()\n",
    "def aggregate_scores(score_dicts) -> float:\n",
    "    return sum([\n",
    "        score_dict['brevity'] * score_dict['relevance']\n",
    "        for score_dict in score_dicts\n",
    "    ]) / len(score_dicts)\n",
    "\n",
    "@weave.op()\n",
    "def evaluate(model: GptRagModel, dataset: SimpleDataset):\n",
    "    scores = []\n",
    "    for example in dataset.examples:\n",
    "        score_dict = eval_iter(model, example)\n",
    "        scores.append(score_dict)\n",
    "    score_agg = aggregate_scores(scores)\n",
    "    return score_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    GptRagModel(\"gpt-3.5-turbo\", \"You are a helpful assistant.\"),\n",
    "    GptRagModel(\"gpt-3.5-turbo\", \"You are a very bored, sarcastic assistant.\"),\n",
    "    GptRagModel(\"gpt-3.5-turbo\", \"You are a evil, unhelpful assistant.\")\n",
    "]\n",
    "\n",
    "dataset = SimpleDataset([\n",
    "    \"What is the square root of pi?\",\n",
    "    \"Describe inception, not the movie, the concept.\",\n",
    "    \"How much is Apple worth today?\"\n",
    "])\n",
    "\n",
    "for model in models:\n",
    "  evaluate(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wandb-weave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
