{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openai Proxy Quickstart\n",
    "> A simple tool to capture metadata about your interactions with the OpenAI API.  Currently supports ChatCompletion endpoint, including streaming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "All you need to do is:\n",
    "1. Change your openai api key to the format `{wandb_api_key}:{openai_api_key}`; and\n",
    "2. Change your openai api base url to `https://wandb.ai/proxy/openai/v1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_base = \"https://api.wandb.ai/proxy/openai/v1\"\n",
    "openai.api_key = f\"{wandb_api_key}:{openai_api_key}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start logging\n",
    "You can use your existing API calls as-is, now with extra logging!\n",
    "\n",
    "By default, this will log to `{your_entity}/proxy/openai`, where the project is `proxy` and the table name is `openai`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenAI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=256,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke about gradients!\"}],\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl \"https://api.wandb.ai/proxy/openai/v1/chat/completions\" \\\n",
    "-H \"Authorization: Bearer $WANDB_API_KEY:$OPENAI_API_KEY\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\n",
    "     \"model\": \"gpt-3.5-turbo\",\n",
    "     \"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke about loss functions!\"}],\n",
    "     \"temperature\": 0.7\n",
    "   }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Optionally specify headers to determine where you want your data to be created.\n",
    "\n",
    "| Header | Description | Example | Default |\n",
    "| --- | --- | --- | --- |\n",
    "| `X-Wandb-Entity` | W&B entity name | `wandb` | Your default entity |\n",
    "| `X-Wandb-Project` | W&B project name | `examples` | `monitoring` |\n",
    "| `X-Wandb-Stream` | StreamTable name | `openai-chat-test` | `openai` |\n",
    "\n",
    "By default, proxy data will show up in `{your_entity}/proxy/openai`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced configuration\n",
    "1. Optionally add custom attributes to your table with the `X-Wandb-Attribute-` prefix.  For example, adding the header `X-Wandb-Attribute-Foo: bar` will add a column `Foo` with the value `bar` to your table.\n",
    "2. Optionally add the `X-Wandb-Client-Id` header if you want to further group related requests together.  By default, each request will have its own unique Client ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenAI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=256,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke about gradients as if you were Shakespeare\"}],\n",
    "    headers={\n",
    "        \"X-Wandb-Entity\": \"andrew\",\n",
    "        \"X-Wandb-Project\": \"examples\",\n",
    "        \"X-Wandb-Stream\": \"openai-chat-test\",\n",
    "        \"X-Wandb-Client-Id\": \"Shakespearean-Gradients-001\",\n",
    "        \"X-Wandb-Attribute-Persona\": \"Shakespeare\",\n",
    "    }\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use with CURL\n",
    "Note: We use the `X-OpenAI-Client-User-Agent` header to determine that your request is intended for OpenAI.  You can use a valid user agent, or just `{}` as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl \"https://api.wandb.ai/proxy/openai/v1/chat/completions\" \\\n",
    "-H \"Authorization: Bearer $WANDB_API_KEY:$OPENAI_API_KEY\" \\\n",
    "-H \"X-Wandb-Entity: wandb\" \\\n",
    "-H \"X-Wandb-Project: examples\" \\\n",
    "-H \"X-Wandb-Stream: openai-chat-test\" \\\n",
    "-H \"X-Wandb-Client-Id: Shakespearean-Gradients-001\" \\\n",
    "-H \"X-Wandb-Attribute-Persona: Shakespeare\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\n",
    "     \"model\": \"gpt-3.5-turbo\",\n",
    "     \"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke about loss functions!\"}],\n",
    "     \"temperature\": 0.7\n",
    "   }'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
