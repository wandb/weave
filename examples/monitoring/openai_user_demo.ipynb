{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ccfdbc",
   "metadata": {},
   "source": [
    "# OpenAI LLM Monitoring with W&B Weave\n",
    "\n",
    "Use the W&B OpenAI integration to monitor OpenAI API calls and understand how your projects and teams are leveraging LLMs.\n",
    "This example notebook will generate links to Weave Boards: LLM usage monitoring dashboards which you can explore and customize from the UI.\n",
    " \n",
    "* dynamically query and derive insights from the logs of all your OpenAI API calls\n",
    "* iterate visually to slice, aggregate, and explore your data; customize panels to focus on interesting patterns\n",
    "* rename Boards to save your progress and publish them to share with your team\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/wandb/weave/master/docs/assets/full_board_view.png\">\n",
    "\n",
    "# Step 0: Setup\n",
    "\n",
    "Install dependencies, login to W&B so you can save and share your work, and authenticate with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8107732a-fb90-45f8-8377-6381bd28475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not already installed\n",
    "!pip install -qqq weave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d21f68-7945-4a10-bb78-a921809790ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "import weave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c26c3-393d-45a0-84a8-b277c42e4724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e91f9c-0640-4346-8c4a-e5f35256afe6",
   "metadata": {},
   "source": [
    "# Step 1: Configure data streaming\n",
    "\n",
    "Configure how W&B stores all the work related to your current monitoring project.\n",
    "* required: set WB_ENTITY to your wandb username or team name\n",
    "* optional: rename the WB_PROJECT, the top-level directory for this work\n",
    "* optional: rename the STREAM_NAME, the record table which stores the logs of OpenAI API calls as they stream in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75400a-0614-4af5-9945-48fa1cd93934",
   "metadata": {},
   "outputs": [],
   "source": [
    "WB_ENTITY = \n",
    "WB_PROJECT = \"llmon\"\n",
    "STREAM_NAME = \"openai_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6e2af-ab8d-4041-a5ce-de6f645c3fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying a single model for simplicity\n",
    "OPENAI_MODEL = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26402897-4f73-4dd6-9314-2a1c60638e4d",
   "metadata": {},
   "source": [
    "## init_monitor()\n",
    "\n",
    "To start monitoring OpenAI API usage, call `init_monitor(<stream>)`, where `<stream>` has the form `<wandb_team_or_user>/<wandb_project>/<stream_name>`. The stream records and stores all the OpenAI API calls.\n",
    "\n",
    "Running this cell will print out a link to view the current project in the Weave UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b2070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weave.monitoring import openai, init_monitor\n",
    "m = init_monitor(f\"{WB_ENTITY}/{WB_PROJECT}/{STREAM_NAME}\")\n",
    "\n",
    "# prefill with some sample logs\n",
    "r = openai.ChatCompletion.create(model=OPENAI_MODEL, messages=[{\"role\": \"user\", \"content\": \"hello world!\"}])\n",
    "r = openai.ChatCompletion.create(model=OPENAI_MODEL, messages=[{\"role\": \"user\", \"content\": \"what is 2+2?\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb51abb4",
   "metadata": {},
   "source": [
    "# Step 1: Preview monitoring dashboard\n",
    "\n",
    "Click on the link above to preview the data stream, then click \"OpenAI Monitor Board\" in the right sidebar to create a Weave Board for this data stream.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/wandb/weave/master/docs/assets/short_board_attempt.gif\" width=75%>\n",
    "\n",
    "\n",
    "# Step 2: Explore & understand your LLM usage\n",
    "\n",
    "We illustrate a few ways you could track OpenAI API calls. There are many more possibilities depending on your use case.\n",
    "To visualize your work in real-time, you can:\n",
    "* keep the Board open in a separate tab and refresh to view the latest data\n",
    "* optionaly rename the Board for easier reference and \"Publish\" it to share a link with others\n",
    "* find previously saved Boards by navigating to the relevant W&B entity and W&B project name from weave.wandb.ai\n",
    "\n",
    "To save your work, rename the board by clicking on the autogenerated name at the top of the page. To share your board, click \"Publish\" in the top right (also supports renaming)\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/wandb/weave/master/docs/assets/publish_board_short.gif\" width=75%>\n",
    "\n",
    "## 2.0 Log a prompt and its completion\n",
    "\n",
    "Monitor a ChatCompletion request and print the corresponding response, extracting only the text of the completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e711d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(model=OPENAI_MODEL, messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"What is the meaning of life, the universe, and everything?\"},\n",
    "    ])\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace8f71-3e50-444b-89e0-a8a619a9e0a8",
   "metadata": {},
   "source": [
    "## 2.1 Track relevant parameters as attributes\n",
    "\n",
    "Factor out parameters of interest and track them as attributes on the logged record.\n",
    "Here we track the \"system prompt\" separately from the \"prompt template\" and the \"equation\" parameter. This time we'll print the full structured response from the ChatCompletion call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7930e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"you always write in bullet points\"\n",
    "prompt_template = 'solve the following equation step by step: {equation}'\n",
    "params = {'equation': '4 * (3 - 1)'}\n",
    "openai.ChatCompletion.create(model=OPENAI_MODEL,\n",
    "                             messages=[\n",
    "                                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                                    {\"role\": \"user\", \"content\": prompt_template.format(**params)},\n",
    "                                ],\n",
    "                             # you can add additional attributes to the logged record\n",
    "                             # see the monitor_api notebook for more examples\n",
    "                             monitor_attributes={\n",
    "                                 'system_prompt': system_prompt,\n",
    "                                 'prompt_template': prompt_template,\n",
    "                                 'params': params\n",
    "                             })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450dc210-3526-4f6e-a05a-df15ebf8d398",
   "metadata": {},
   "source": [
    "## 2.2 Log an ongoing stream of messages\n",
    "\n",
    "Monitor a stream of messages and log the result as a single record. Note: tokens are not counted in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b423df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weave.monitoring.openai import message_from_stream\n",
    "r = openai.ChatCompletion.create(model=OPENAI_MODEL, messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a robot and only speak in robot, like beep bloop bop.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a 50-word story.\"},\n",
    "    ], stream=True)\n",
    "for s in message_from_stream(r):\n",
    "    print(s, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81945b3c-310e-404b-aea7-a47c6760db2e",
   "metadata": {},
   "source": [
    "## 2.3 Structure prompt engineering experiments\n",
    "\n",
    "Here we compare a few toy options for the system prompt, user question, and intended audience. Try your own experiments and see if any interesting insights emerge as you explore in the Board and group by different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde1485-8d5f-4b25-a878-0c9de719dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_math(system_prompt, prompt_template, params):\n",
    "    openai.ChatCompletion.create(model=OPENAI_MODEL,\n",
    "                             messages=[\n",
    "                                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                                    {\"role\": \"user\", \"content\": prompt_template.format(**params)},\n",
    "                                ],\n",
    "                             # you can add additional attributes to the logged record\n",
    "                             # see the monitor_api notebook for more examples\n",
    "                             monitor_attributes={\n",
    "                                 'system_prompt': system_prompt,\n",
    "                                 'prompt_template': prompt_template,\n",
    "                                 'params': params\n",
    "                             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d73400-835e-4e8d-b985-a812cf11b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to substitute your own prompts :)\n",
    "system_prompts = [\"you're extremely flowery and poetic\", \"you're very direct and precise\", \"balance brevity with insight\"]\n",
    "prompt_template = 'explain the solution of the following to a {audience}: {equation}'\n",
    "equations = ['x^2 + 4x + 9 = 0', '15 * (2 - 6) / 4']\n",
    "audience = [\"new student\", \"math genius\"]\n",
    "\n",
    "for system_prompt in system_prompts:\n",
    "    for equation in equations:\n",
    "        for person in audience:\n",
    "            params = {\"equation\" : equation, \"audience\" : person}\n",
    "            explain_math(system_prompt, prompt_template, params) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
