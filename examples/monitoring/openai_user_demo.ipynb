{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ccfdbc",
   "metadata": {},
   "source": [
    "# OpenAI LLM Monitoring\n",
    "\n",
    "Use the W&B OpenAI integration to monitor API calls and understand how your projects and teams are leveraging LLMs.\n",
    "\n",
    "# Step 0: Setup\n",
    "\n",
    "* authenticate with OpenAI\n",
    "* login to W&B so you can save and share your work\n",
    "* install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f177b-60f6-421f-b46b-66596bea720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"sk-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2822d2-5b03-48a0-8c77-105383caf96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai as openai_access; openai_access.api_key=OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d21f68-7945-4a10-bb78-a921809790ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8107732a-fb90-45f8-8377-6381bd28475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "weave.use_frontend_devmode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e91f9c-0640-4346-8c4a-e5f35256afe6",
   "metadata": {},
   "source": [
    "# Step 1: Configure data streaming\n",
    "\n",
    "Configure how W&B stores all the work related to your current monitoring project.\n",
    "* required: set WB_ENTITY to your wandb username or team name\n",
    "* optional: rename the WB_PROJECT, the top-level directory where this work is stored & organized\n",
    "* optional: rename the STREAM_NAME, the record table which stores the individual calls as they stream in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75400a-0614-4af5-9945-48fa1cd93934",
   "metadata": {},
   "outputs": [],
   "source": [
    "WB_ENTITY = \n",
    "WB_PROJECT = \"llmon\"\n",
    "STREAM_NAME = \"openai_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6e2af-ab8d-4041-a5ce-de6f645c3fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying a single model for simplicity\n",
    "OPENAI_MODEL = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26402897-4f73-4dd6-9314-2a1c60638e4d",
   "metadata": {},
   "source": [
    "## init_monitor()\n",
    "\n",
    "To start monitoring OpenAI API usage, call `init_monitor(<stream>)`, where `<stream>` has the form `<wandb_team_or_user>/<wandb_project>/<stream_name>`. The stream records and stores all the OpenAI API calls.\n",
    "\n",
    "Running this cell will print out a link to view the current project in the Weave UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b2070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weave.monitoring import openai, init_monitor\n",
    "m = init_monitor(f\"{WB_ENTITY}/{WB_PROJECT}/{STREAM_NAME}\")\n",
    "\n",
    "# Do an initial request, otherwise we don't have a type on which to recommend the OpenAI board!\n",
    "# We need at least 2 requests for the Board to work, otherwise we get divide by zero errors.\n",
    "# TODO: fix this onboarding issue\n",
    "r = openai.ChatCompletion.create(model=OPENAI_MODEL, messages=[{\"role\": \"user\", \"content\": f\"hello world!\"}])\n",
    "r = openai.ChatCompletion.create(model=OPENAI_MODEL, messages=[{\"role\": \"user\", \"content\": f\"what is 2+2?\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb51abb4",
   "metadata": {},
   "source": [
    "# Step 1: Preview monitoring dashboard\n",
    "\n",
    "Click on the link above to preview the data stream, then click \"OpenAI Monitoring Board\" in the lower right to create a Weave Board for this data stream.\n",
    "\n",
    "# Step 2: Explore & understand your LLM usage\n",
    "\n",
    "We illustrate a few ways you could track OpenAI API calls. There are many more possibilities depending on your use case. You can keep the Board open in a separate tab, refresh to view the latest data, and optionaly rename it for easier reference and sharing with others.\n",
    "\n",
    "## Basic prompt and completion\n",
    "\n",
    "Monitor a ChatCompletion request and print the corresponding response, extracting only the text of the completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e711d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(model=OPENAI_MODEL, messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"what is the meaning of life, the universe, and everything?\"},\n",
    "    ])\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace8f71-3e50-444b-89e0-a8a619a9e0a8",
   "metadata": {},
   "source": [
    "## Track relevant parameters as attributes\n",
    "\n",
    "Factor out relevant parameters and track them as attributes on the logged record.\n",
    "Here we track the \"system prompt\" separately from the \"prompt_template\" and \"equation\" parameter. This time we'll print the full structured response from the ChatCompletion call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7930e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"you always write in bullet points\"\n",
    "prompt_template = 'solve the following equation step by step: {equation}'\n",
    "params = {'equation': '4 * (3 - 1)'}\n",
    "openai.ChatCompletion.create(model=OPENAI_MODEL,\n",
    "                             messages=[\n",
    "                                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                                    {\"role\": \"user\", \"content\": prompt_template.format(**params)},\n",
    "                                ],\n",
    "                             # you can add additional attributes to the logged record\n",
    "                             # see the monitor_api notebook for more examples\n",
    "                             monitor_attributes={\n",
    "                                 'system_prompt': system_prompt,\n",
    "                                 'prompt_template': prompt,\n",
    "                                 'params': params\n",
    "                             })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450dc210-3526-4f6e-a05a-df15ebf8d398",
   "metadata": {},
   "source": [
    "## Streaming requests\n",
    "\n",
    "Monitor a stream of messages and log the result as a single record. Note: tokens are not counted in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b423df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weave.monitoring.openai import message_from_stream\n",
    "r = openai.ChatCompletion.create(model=OPENAI_MODEL, messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a robot and only speak in robot, like beep bloop bop.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a 50-word story.\"},\n",
    "    ], stream=True)\n",
    "for s in message_from_stream(r):\n",
    "    print(s, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81945b3c-310e-404b-aea7-a47c6760db2e",
   "metadata": {},
   "source": [
    "## Structure prompt engineering experiments\n",
    "\n",
    "Here we compare a few toy options for the system prompt, user question, and intended audience. See if any interesting insights emerge as you explore in the Board and group by different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde1485-8d5f-4b25-a878-0c9de719dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_math(system_prompt, prompt_template, params):\n",
    "    openai.ChatCompletion.create(model=OPENAI_MODEL,\n",
    "                             messages=[\n",
    "                                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                                    {\"role\": \"user\", \"content\": prompt_template.format(**params)},\n",
    "                                ],\n",
    "                             # you can add additional attributes to the logged record\n",
    "                             # see the monitor_api notebook for more examples\n",
    "                             monitor_attributes={\n",
    "                                 'system_prompt': system_prompt,\n",
    "                                 'prompt_template': prompt,\n",
    "                                 'params': params\n",
    "                             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d73400-835e-4e8d-b985-a812cf11b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompts = [\"you're extremely flowery and poetic\", \"you're very direct and precise\", \"balance brevity with deep insight\"]\n",
    "prompt_template = 'explain the solution of the following to a {audience}: {equation}'\n",
    "\n",
    "equations = ['x^2 + 4x + 9 = 0', 'x^2 + 2x - 32 = 0']\n",
    "audience = [\"new student\", \"math genius\"]\n",
    "\n",
    "for system_prompt in system_prompts:\n",
    "    for equation in equations:\n",
    "        for person in audience:\n",
    "            params = {\"equation\" : equation, \"audience\" : person}\n",
    "            explain_math(system_prompt, prompt_template, params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c26c3-393d-45a0-84a8-b277c42e4724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# better way to set up OpenAI authentication\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
