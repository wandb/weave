{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openai Proxy Quickstart\n",
    "> A simple tool to capture metadata about your interactions with the OpenAI API.  Currently supports ChatCompletion endpoint, including streaming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "All you need to do is:\n",
    "1. Change your openai api key to the format `{wandb_api_key}:{openai_api_key}`; and\n",
    "2. Change your openai api base url to `https://wandb.ai/proxy/openai/v1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_base = \"https://api.wandb.ai/proxy/openai/v1\"\n",
    "openai.api_key = f\"{wandb_api_key}:{openai_api_key}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start logging\n",
    "You can use your existing API calls as-is, now with extra logging!\n",
    "\n",
    "By default, this will log to `{your_entity}/monitoring/openai`, where the project is `monitoring` and the table name is `openai`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenAI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke about gradients!\"}],\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl \"https://api.wandb.ai/proxy/openai/v1/chat/completions\" \\\n",
    "-H \"Authorization: Bearer $WANDB_API_KEY:$OPENAI_API_KEY\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\n",
    "     \"model\": \"gpt-3.5-turbo\",\n",
    "     \"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke about loss functions!\"}]\n",
    "   }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Optionally specify headers to determine where you want your data to be created.\n",
    "\n",
    "| Header | Description | Default |\n",
    "| --- | --- | --- |\n",
    "| `X-Wandb-Entity` | W&B entity name | Your default entity |\n",
    "| `X-Wandb-Project` | W&B project name | `monitoring` |\n",
    "| `X-Wandb-Stream` | StreamTable name | `openai` |\n",
    "\n",
    "By default, proxy data will show up in `{your_entity}/monitoring/openai`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced configuration\n",
    "1. Optionally add custom attributes to your table with the `X-Wandb-Attribute-` prefix.  For example, adding the header `X-Wandb-Attribute-Foo: bar` will add a column `Foo` with the value `bar` to your table.\n",
    "2. Optionally add the `X-Wandb-Client-Id` header if you want to further group related requests together.  By default, each request will have its own unique Client ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenAI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke about gradients as if you were Shakespeare\"}],\n",
    "    headers={\n",
    "        \"X-Wandb-Entity\": \"your-entity\",\n",
    "        \"X-Wandb-Project\": \"your-project\",\n",
    "        \"X-Wandb-Stream\": \"your-stream\",\n",
    "        \"X-Wandb-Client-Id\": \"Shakespearean-Gradients-001\",\n",
    "        \"X-Wandb-Attribute-Persona\": \"Shakespeare\",\n",
    "    }\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use with CURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl \"https://api.wandb.ai/proxy/openai/v1/chat/completions\" \\\n",
    "-H \"Authorization: Bearer $WANDB_API_KEY:$OPENAI_API_KEY\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-H \"X-Wandb-Entity: your-entity\" \\\n",
    "-H \"X-Wandb-Project: your-project\" \\\n",
    "-H \"X-Wandb-Stream: your-stream\" \\\n",
    "-H \"X-Wandb-Client-Id: Shakespearean-Gradients-001\" \\\n",
    "-H \"X-Wandb-Attribute-Persona: Shakespeare\" \\\n",
    "-d '{\n",
    "     \"model\": \"gpt-3.5-turbo\",\n",
    "     \"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke about loss functions!\"}]\n",
    "   }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Use Proxy with Weave SDK\n",
    "You can use this proxy with the Weave SDK to log out to a personal streamtable and a proxy-configured streamtable simultaneously.  This can be useful for admins who want to monitor API calls in their organization.\n",
    "- Users specify a personal table path with `init_monitor(entity/project/table)`.  Any `ChatCompletion.create` calls with automatically log to this table.\n",
    "- Then, if the `openai.api_base` and `openai.api_key` are set to proxy format, the above calls will also log the proxy-configured table.\n",
    "\n",
    "NOTE: This currently does not work with streaming `ChatCompletion`, but we hope to support it soon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weave.monitoring import openai as openaimon\n",
    "from weave.monitoring import init_monitor\n",
    "\n",
    "m = init_monitor(\"personal-entity/personal-project/personal-stream\")\n",
    "\n",
    "openai.api_base = \"https://api.wandb.ai/proxy/openai/v1\"\n",
    "openai.api_key = f\"{wandb_api_key}:{openai_api_key}\"\n",
    "\n",
    "OPENAI_MODEL = 'gpt-3.5-turbo'\n",
    "\n",
    "r = openaimon.ChatCompletion.create(model=OPENAI_MODEL, messages=[{\"role\": \"user\", \"content\": f\"hello world!\"}])\n",
    "r = openaimon.ChatCompletion.create(model=OPENAI_MODEL, messages=[{\"role\": \"user\", \"content\": f\"what is 2+2?\"}])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
