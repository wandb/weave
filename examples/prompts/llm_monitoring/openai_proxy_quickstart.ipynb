{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/wandb/weave/blob/master/examples/prompts/llm_monitoring/openai_proxy_quickstart.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "**Note:** you will need an [OpenAI API key](https://platform.openai.com/account/api-keys) to run this colab.\n",
    "\n",
    "# Openai Proxy Quickstart\n",
    "\n",
    "A simple tool to capture metadata about your interactions with the OpenAI API.  Currently supports ChatCompletion endpoint, including streaming.\n",
    "\n",
    "# Step 0: Setup\n",
    "Install dependencies, authenticate with OpenAI and W&B via API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: `weave` and `tiktoken` are not required for the proxy,\n",
    "# but are used in the last cell example\n",
    "\n",
    "!pip install -qqq openai weave tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authenticate with OpenAI\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authenticate with W&B\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "if os.getenv(\"WANDB_API_KEY\") is None:\n",
    "  os.environ[\"WANDB_API_KEY\"] = getpass(\"Paste your W&B API key from: https://wandb.ai/authorize\\n\")\n",
    "print(\"W&B API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Update OpenAI API key and base url\n",
    "\n",
    "All you need to do is:\n",
    "1. Change your OpenAI API key to the format `{wandb_api_key}:{openai_api_key}`; and\n",
    "2. Change your OpenAI API base url to `https://proxy.wandb.ai/proxy/openai/v1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_base = \"https://proxy.wandb.ai/proxy/openai/v1\"\n",
    "openai.api_key = f\"{wandb_api_key}:{openai_api_key}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Start logging!\n",
    "\n",
    "You can use your existing API calls as-is, now with extra logging!\n",
    "\n",
    "By default, these logs will be saved in a StreamTable named `{your_entity}/monitoring/openai`, where the project is `monitoring` and the table name is `openai`. `your_entity` will match the default entity associated with your [W&B API key](wandb.ai/authorize). You can optionally set this field to any different wandb username or team name to which you have login access.\n",
    "# Visualize your logs in an interactive Weave Board\n",
    "\n",
    "**View your logs at [https://weave.wandb.ai/browse/wandb](https://weave.wandb.ai/browse/wandb)/{your_entity}/monitoring/table/openai**.\n",
    "\n",
    "Click on \"+ New board from template\" on the right hand side to open an interactive Weave Board. This Board will automatically monitor OpenAI API usage and visualize key metrics like cost and latency across all your calls. You can also extend this board with custom analysis, filter/sort/group by attributes of interest, and share your visualizations and insights with your team.\n",
    "\n",
    "# Examples of logging methods\n",
    "\n",
    "There are a few different ways to call OpenAI with the proxy shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Using OpenAI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke about gradients!\"}],\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Using CURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl \"https://proxy.wandb.ai/proxy/openai/v1/chat/completions\" \\\n",
    "-H \"Authorization: Bearer $WANDB_API_KEY:$OPENAI_API_KEY\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\n",
    "     \"model\": \"gpt-3.5-turbo\",\n",
    "     \"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke about loss functions!\"}]\n",
    "   }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional configuration\n",
    "Optionally specify headers to determine where you want your data to be created.\n",
    "\n",
    "| Header | Description | Default |\n",
    "| --- | --- | --- |\n",
    "| `X-Wandb-Entity` | W&B entity name | Your default entity |\n",
    "| `X-Wandb-Project` | W&B project name | `monitoring` |\n",
    "| `X-Wandb-Stream` | StreamTable name | `openai` |\n",
    "\n",
    "By default, proxy data will show up in `{your_entity}/monitoring/openai`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced configuration\n",
    "1. Optionally add custom attributes to your table with the `X-Wandb-Attribute-` prefix.  For example, adding the header `X-Wandb-Attribute-Foo: bar` will add a column `Foo` with the value `bar` to your table.\n",
    "2. Optionally add the `X-Wandb-Client-Id` header if you want to further group related requests together.  By default, each request will have its own unique Client ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "WB_ENTITY = # set to your wandb username or team name\n",
    "WB_PROJECT = \"weave\" # top-level directory for this work\n",
    "STREAM_NAME = \"openai_logs\" # record table which stores the logs of OpenAI API calls as they stream in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Using OpenAI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke about gradients as if you were Shakespeare\"}],\n",
    "    headers={\n",
    "        \"X-Wandb-Entity\": WB_ENTITY,\n",
    "        \"X-Wandb-Project\": WB_PROJECT,\n",
    "        \"X-Wandb-Stream\": STREAM_NAME,\n",
    "        \"X-Wandb-Client-Id\": \"Shakespearean-Gradients-001\",\n",
    "        \"X-Wandb-Attribute-Persona\": \"Shakespeare\",\n",
    "    }\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Using CURL\n",
    "\n",
    "**Note:** Replace WB_ENTITY, WB_PROJECT, and STREAM_NAME with explicit strings below to specify where to store the logs.\n",
    "You will likely get an authentication error if you don't do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl \"https://proxy.wandb.ai/proxy/openai/v1/chat/completions\" \\\n",
    "-H \"Authorization: Bearer $WANDB_API_KEY:$OPENAI_API_KEY\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-H \"X-Wandb-Entity: WB_ENTITY\" \\\n",
    "-H \"X-Wandb-Project: WB_PROJECT\" \\\n",
    "-H \"X-Wandb-Stream: STREAM_NAME\" \\\n",
    "-H \"X-Wandb-Client-Id: Shakespearean-Gradients-001\" \\\n",
    "-H \"X-Wandb-Attribute-Persona: Shakespeare\" \\\n",
    "-d '{\n",
    "     \"model\": \"gpt-3.5-turbo\",\n",
    "     \"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke about loss functions!\"}]\n",
    "   }'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
