{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "957b839e-ae72-4608-8f17-454e95c6c76c",
   "metadata": {},
   "source": [
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/wandb/weave/blob/master/examples/prompts/trace_debugging/trace_quickstart_langchain.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# Debug LLMs with W&B Trace and LangChain\n",
    "\n",
    "Use W&B Trace with LangChain to\n",
    "* trace and visualize all the intermediate processing steps of your LLM calls\n",
    "* debug and diagnose errors in particular prompts or chain configurations\n",
    "* quickly find more effective prompts and LLM chains for your specific use case\n",
    "\n",
    "Follow the steps below to build your own interactive Weave Board for tracing and debugging LangChain calls. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/wandb/weave/master/docs/assets/traces_debug_board.png\">\n",
    "\n",
    "[Play with a live version of this Weave Board â†’](http://wandb.me/traces-board)\n",
    "\n",
    "# Step 0: Setup\n",
    "\n",
    "Install dependencies, authenticate with OpenAI, and login to W&B so you can save and share your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de23014-21d9-4f48-8541-636c5d741410",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qqq weave wandb openai langchain==0.0.295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005fc98a-ef8d-46d0-9774-a8bbc5cc93bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb27a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1be6b-27e4-41f9-97b3-1c188352286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import weave\n",
    "from weave.legacy.weave.monitoring.langchain import WeaveTracer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca215666-16a7-4dc5-8354-4c7b30f83d44",
   "metadata": {},
   "source": [
    "# Step 1: Configure data streaming and storage in W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92d9e5e-17ef-4bc3-a7ec-9d321fd1a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "WB_PROJECT = \"traces\" # top-level directory for this work\n",
    "WB_STREAM = \"lc_traces_stream\" # record table which stores the logs of LangChain calls\n",
    "WB_ENTITY = \"\" # optional: wandb username or team name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971d6cdf-e10c-481b-8625-b512f2e4e006",
   "metadata": {},
   "source": [
    "**Note**: The WB_ENTITY will match the default entity associated with your [W&B API key](wandb.ai/authorize). You can optionally set WB_ENTITY to a different wandb username or team name. Log in to W&B and navigate to [the Home Page](https://wandb.ai/home) to see any other valid options for your WB_ENTITY under your \"Profile\" and \"Teams\" in the left sidebar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9fa217-2e3a-48ac-b057-6a9e7b2aaf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit or add your own!\n",
    "sample_math_questions = [\n",
    "   'What is the sum of 5 and 7?',\n",
    "   'What is the binomial distribution of x?', # intentionally error, x is undefined\n",
    "   'What is the area of a circle with a radius of 5?',\n",
    "   'What is the value of y in the equation y = 2x + 1 when x = 3?',\n",
    "   'What is the equation of the line that passes through the points (2, 4) and (3, 6)?',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1801036-39fa-4022-b971-2d1497ffce56",
   "metadata": {},
   "source": [
    "# Step 2: Add a WeaveTracer as a callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea66fe-d6f7-4273-8ba8-754d8ce5dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n",
    "\n",
    "# store all traces in the StreamTable we configured above\n",
    "tracer = WeaveTracer(f\"{WB_ENTITY}/{WB_PROJECT}/{WB_STREAM}\")\n",
    "\n",
    "for question in sample_math_questions:\n",
    "    try:\n",
    "        # add WeaveTracer as a callback to monitor & log all calls\n",
    "        print(agent.run(question, callbacks=[tracer]))\n",
    "    except Exception as e:\n",
    "        print(\"Caught Exception:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0ac3c2-8566-4517-bbf9-cd380e5697f2",
   "metadata": {},
   "source": [
    "# Step 3: Create and customize a Trace Debugging Board\n",
    "\n",
    "Click on the \"View data at:\" link above to view your data stream in Weave.\n",
    "\n",
    "You can click on \"+ New board from template\" on the right to create a Trace Debug Board, which enables:\n",
    "* key LLM tuning metrics at a glance: latency and success vs failure, for each call and as a distribution\n",
    "* complete view of call details: inputs, outputs, status, timestamp, etc&mdash;also available for downtream queries & analaysis\n",
    "* interactive W&B Trace view: a color-coded flow chart of every step of an LLM chain, with full metadata, model details, and similar span views updating in sync with every selected span\n",
    "* monitor & analyze from the automatic Board; customize & publish the Board for streamlined collaboration with your team\n",
    "\n",
    "# Next steps\n",
    "\n",
    "Use the Board to dive into the details of your chains!\n",
    "For UI instructions, see this [guide](https://docs.wandb.ai/guides/prompts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0457f4a-b37f-417e-962e-095094ac3dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some more questions in case you'd like to explore other traces\n",
    "additional_sample_questions = [\n",
    "    \"If a ball that weighs 100 grams is dropped from a height of 500 meters, what is its velocity when it hits the ground?\",\n",
    "    \"Find the derivative of the natural log of x base 2 and multiply that by pi\",\n",
    "    \"What is the prime factorization of 1273?\",\n",
    "    \"How many roots does x^2 + 2x + 4 = 0 have?\",\n",
    "    \"Find the integral of x squared from 0 to 3\",\n",
    "    \"What is the sin of 0.47 radians, divided by the cube root of 27?\"\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
