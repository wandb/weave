# ðŸ”† W&B Prompts Feedback Sprint - Oct 2nd - Oct 22nd ðŸ”† 

Built on our new fully OSS library, weave, the W&B Engineering team want your feedback on how our new LLM tools, LLM Monitoring and Traces-v2, can be tailored to your specific use cases!

The Feedback Sprint closes Sunday, October 22nd 2023, [click here](https://wandb.ai/site/monitoring?utm_source=weave-github&utm_medium=github&utm_campaign=prompts-feedback-sprint&utm_term=prompts-feedback-sprint-sep23) to participate and be in for a chance to win some W&B swag.

<div align="center">
  <img src="../../docs/assets/mini_prodmon_overview.gif" width="65%">
</div>

## How to participate
Join the W&B Prompts Feedback Sprint for a chance to win some W&B swag by [signing up here](https://wandb.ai/site/monitoring?utm_source=weave-github&utm_medium=github&utm_campaign=prompts-feedback-sprint&utm_term=prompts-feedback-sprint-sep23)

### Give feedback, win swag
We'll select 10 people who provide the team feedback on W&B Prompts. To chat with and give feedback to the W&B Engineering team you have 2 options:

**Discord**
- Join the W&B Discord - https://wandb.me/discord
- Head to the `#prompts-feedback` channel to share your thoughts with our Engineering team!

**Github**
- If you prefer github, you can open an issue [in the weave repository here](https://github.com/wandb/weave/issues) and add the tag `prompts-feedback` to your issue.

We're looking forward to hearing from you and we're excited to shape the future of LLM developer tools with you!

## W&B Prompts
W&B Prompts is our latest LLM offering and comprises so far of LLM Monitoring and Traces:

- **[LLM Monitoring](https://github.com/wandb/weave/tree/master/examples/prompts/llm_monitoring) â†’** The central observability and governance platform for all LLM-related activities, including:
    - Centrally monitor all LLM activities in real time including throughput, token usage, cost, latency, errors
    - Track end-to-end LLM inputs & outputs across distributed systems
    - Centrally secure and govern all LLM workloads with LLM API Gateway

- **[Traces-v2](https://github.com/wandb/weave/tree/master/examples/prompts/trace_debugging) â†’** Visualize and inspect the execution flow of your LLM chains and agents, analyze the inputs, intermediate results and output. Upgraded to run run on weave for more functionality including being able to view the all inputs + outputs of a selected span type.

