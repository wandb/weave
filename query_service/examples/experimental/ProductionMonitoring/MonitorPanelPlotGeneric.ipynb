{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f7512dfa",
      "metadata": {},
      "source": [
        "# Model monitoring dashboard example\n",
        "\n",
        "This notebook currently requires the plotly library to be installed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80506dea",
      "metadata": {},
      "outputs": [],
      "source": [
        "import weave\n",
        "from weave.legacy.scripts import syndata_mon"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8519889f",
      "metadata": {},
      "source": [
        "## Create synthetic data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eba21e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "#preds = syndata_mon.random_predictions(10)\n",
        "\n",
        "#predictions = weave.save(preds, 'predictions')\n",
        "#len(preds.column('prompt').to_pylist_raw())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8934efcf",
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import tiktoken\n",
        "import faiss\n",
        "import numpy as np\n",
        "from tenacity import (\n",
        "    before_sleep_log,\n",
        "    retry,\n",
        "    retry_if_exception_type,\n",
        "    stop_after_attempt,\n",
        "    wait_exponential,\n",
        ")\n",
        "import openai\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']\n",
        "\n",
        "# OpenAI API functions\n",
        "retry_openai_decorator = retry(\n",
        "        reraise=True,\n",
        "        stop=stop_after_attempt(4),\n",
        "        wait=wait_exponential(multiplier=1, min=4, max=10),\n",
        "        retry=(\n",
        "            retry_if_exception_type(openai.error.Timeout)\n",
        "            | retry_if_exception_type(openai.error.APIError)\n",
        "            | retry_if_exception_type(openai.error.APIConnectionError)\n",
        "            | retry_if_exception_type(openai.error.RateLimitError)\n",
        "            | retry_if_exception_type(openai.error.ServiceUnavailableError)\n",
        "        ),\n",
        "        before_sleep=before_sleep_log(logger, logging.WARNING),\n",
        "    )\n",
        "\n",
        "@retry_openai_decorator\n",
        "def openai_embed(model, input):\n",
        "    return openai.Embedding.create(input = input, model=model)\n",
        "\n",
        "@retry_openai_decorator\n",
        "def openai_chatcompletion(model, messages):\n",
        "    return openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\", # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
        "        messages = messages\n",
        "    )\n",
        "\n",
        "# Helper to efficiently embed a set of documents using the OpenAI embedding API\n",
        "# This is from langchain\n",
        "\n",
        "embedding_ctx_length = 8191\n",
        "OPENAI_EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "chunk_size = 1000\n",
        "\n",
        "from typing import List\n",
        "\n",
        "def embed_texts(texts: List[str], embedding_model: str) -> List[List[float]]:\n",
        "    embeddings: List[List[float]] = [[] for _ in range(len(texts))]\n",
        "    tokens = []\n",
        "    indices = []\n",
        "    encoding = tiktoken.model.encoding_for_model(embedding_model)\n",
        "    for i, text in enumerate(texts):\n",
        "        if embedding_model.endswith(\"001\"):\n",
        "            # See: https://github.com/openai/openai-python/issues/418#issuecomment-1525939500\n",
        "            # replace newlines, which can negatively affect performance.\n",
        "            text = text.replace(\"\\n\", \" \")\n",
        "        token = encoding.encode(\n",
        "            text,\n",
        "            disallowed_special=\"all\",\n",
        "        )\n",
        "        for j in range(0, len(token), embedding_ctx_length):\n",
        "            tokens += [token[j : j + embedding_ctx_length]]\n",
        "            indices += [i]\n",
        "\n",
        "    batched_embeddings = []\n",
        "    _chunk_size = chunk_size\n",
        "    for i in range(0, len(tokens), _chunk_size):\n",
        "        response = openai_embed(\n",
        "            embedding_model,\n",
        "            input=tokens[i : i + _chunk_size],\n",
        "        )\n",
        "        batched_embeddings += [r[\"embedding\"] for r in response[\"data\"]]\n",
        "\n",
        "    results: List[List[List[float]]] = [[] for _ in range(len(texts))]\n",
        "    num_tokens_in_batch: List[List[int]] = [[] for _ in range(len(texts))]\n",
        "    for i in range(len(indices)):\n",
        "        results[indices[i]].append(batched_embeddings[i])\n",
        "        num_tokens_in_batch[indices[i]].append(len(tokens[i]))\n",
        "\n",
        "    for i in range(len(texts)):\n",
        "        _result = results[i]\n",
        "        if len(_result) == 0:\n",
        "            average = embed_with_retry(\n",
        "                embedding_model,\n",
        "                input=\"\",\n",
        "            )[\"data\"][0][\"embedding\"]\n",
        "        else:\n",
        "            average = np.average(\n",
        "                _result, axis=0, weights=num_tokens_in_batch[i]\n",
        "            )\n",
        "        embeddings[i] = (average / np.linalg.norm(average)).tolist()\n",
        "\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab2debd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas\n",
        "data = pandas.read_csv('/Users/shawn/datasets/wandb_export_2023-06-03T15_01_20.066-07_00.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c084173",
      "metadata": {},
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eef1fb56",
      "metadata": {},
      "outputs": [],
      "source": [
        "embeddings = embed_texts(data['question'][:100], OPENAI_EMBEDDING_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45c9bcf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from weave.legacy.weave.ecosystem import umap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a1f09d",
      "metadata": {},
      "outputs": [],
      "source": [
        "umap.umap_projection(embeddings, {})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0781ddcd",
      "metadata": {},
      "outputs": [],
      "source": [
        "len(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c190e190",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Dimension reduction and clustering libraries\n",
        "import umap\n",
        "import hdbscan\n",
        "import sklearn.cluster as cluster\n",
        "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16e52ec2",
      "metadata": {},
      "outputs": [],
      "source": [
        "standard_embedding = umap.UMAP(random_state=42).fit_transform(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c28defdb",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], s=0.1, cmap='Spectral');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e59fd77",
      "metadata": {},
      "outputs": [],
      "source": [
        "clusterable_embedding = umap.UMAP(\n",
        "    n_neighbors=30,\n",
        "    min_dist=0.0,\n",
        "    n_components=2,\n",
        "    random_state=42,\n",
        ").fit_transform(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d571528d",
      "metadata": {},
      "outputs": [],
      "source": [
        "clusterable_embedding.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c568b42a",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], s=0.1, cmap='Spectral');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf0920f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = hdbscan.HDBSCAN(\n",
        "    min_samples=10,\n",
        "    min_cluster_size=50,\n",
        ").fit_predict(clusterable_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead20089",
      "metadata": {},
      "outputs": [],
      "source": [
        "#labels\n",
        "np.unique(labels, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32d4fabe",
      "metadata": {},
      "outputs": [],
      "source": [
        "clustered = (labels >= 0)\n",
        "plt.scatter(standard_embedding[~clustered, 0],\n",
        "            standard_embedding[~clustered, 1],\n",
        "            color=(0.5, 0.5, 0.5),\n",
        "            s=0.1,\n",
        "            alpha=0.5)\n",
        "plt.scatter(standard_embedding[clustered, 0],\n",
        "            standard_embedding[clustered, 1],\n",
        "            c=labels[clustered],\n",
        "            s=0.1,\n",
        "            cmap='Spectral');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "289f1c42",
      "metadata": {},
      "outputs": [],
      "source": [
        "data['embedding_x'] = standard_embedding[:,0]\n",
        "data['embedding_y'] = standard_embedding[:,1]\n",
        "data['cluster_id'] = labels.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aafaa6f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "weave.show(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdd59e39",
      "metadata": {},
      "source": [
        "## Create a Weave Board for the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22be0bd4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from weave.legacy.weave.panels_py import panel_autoboard\n",
        "\n",
        "panel_autoboard.auto_panels(predictions)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
