{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "039f298a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import weave\n",
        "weave.use_frontend_devmode()\n",
        "from weave.legacy.weave.ops_arrow.list_ import dataframe_to_arrow\n",
        "from weave.legacy.weave.ecosystem import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e0d6245",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from faker import Faker\n",
        "from datetime import timedelta, time\n",
        "\n",
        "# Generate the version schedule\n",
        "def generate_version_schedule(start_date, end_date):\n",
        "    current_date = start_date\n",
        "    versions = ['1.0']\n",
        "    version_schedule = {}\n",
        "    while current_date <= end_date:\n",
        "        date_versions = []\n",
        "        for version in versions:\n",
        "            service_percent = random.uniform(0, 1)\n",
        "            date_versions.append((version, service_percent))\n",
        "\n",
        "        version_schedule[current_date.date()] = date_versions\n",
        "        current_date += timedelta(days=1)\n",
        "        if random.random() < 0.10:  # 5% chance to introduce a new version each day\n",
        "            new_version = f'{float(versions[-1])+0.1:.1f}'\n",
        "            versions.append(new_version)\n",
        "        if len(versions) > 1 and random.random() < 0.10:\n",
        "            versions.pop(0)\n",
        "    return version_schedule\n",
        "\n",
        "# Generate the latency schedule\n",
        "def generate_latency_schedule(start_date, end_date):\n",
        "    latency_schedule = {}\n",
        "    for current_date in pd.date_range(start_date, end_date):\n",
        "        base_latency = random.uniform(0.1, 1)\n",
        "        day_factor = random.uniform(0.5, 1.5)\n",
        "        month_factor = random.uniform(0.5, 1.5)\n",
        "        latency = base_latency * day_factor * month_factor\n",
        "        latency_schedule[current_date.date()] = latency\n",
        "    return latency_schedule\n",
        "\n",
        "# Generate the cost schedule\n",
        "def generate_cost_schedule(start_date, end_date, cost_change_date):\n",
        "    cost_schedule = {}\n",
        "    current_date = start_date\n",
        "    cost_per_token = 0.01\n",
        "    while current_date <= end_date:\n",
        "        if current_date >= cost_change_date:\n",
        "            cost_per_token = 0.005\n",
        "        cost_schedule[current_date.date()] = cost_per_token\n",
        "        current_date += timedelta(days=1)\n",
        "    return cost_schedule\n",
        "\n",
        "def generate_user_usage_schedule(start_date, end_date, users):\n",
        "    user_usage_schedule = []\n",
        "    for user in users:\n",
        "        current_date = start_date + timedelta(days=random.randrange(90))\n",
        "        while current_date <= end_date:\n",
        "            usage_periods = random.randint(1, 30)\n",
        "            for _ in range(usage_periods):\n",
        "                period_length_timedelta = timedelta(hours=random.randint(1, 24 * 7))\n",
        "                rate = random.uniform(0.1, 10)\n",
        "                user_usage_schedule.append((current_date, user, period_length_timedelta, rate))\n",
        "                current_date += period_length_timedelta  # Increment current_date\n",
        "                if current_date > end_date:\n",
        "                    break\n",
        "    return user_usage_schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d6a0318",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define our fake users\n",
        "fake = Faker()\n",
        "users = [fake.user_name() for _ in range(100)]\n",
        "\n",
        "# Read the file and generate prompts\n",
        "with open('/Users/shawn/Downloads/t8.shakespeare.txt', 'r') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "# Define the time range\n",
        "start_date = pd.to_datetime('2023-01-01', utc=True)\n",
        "end_date = pd.to_datetime('2023-03-31', utc=True)\n",
        "cost_change_date = pd.to_datetime('2023-02-15', utc=True)\n",
        "\n",
        "# Generate the schedules\n",
        "version_schedule = generate_version_schedule(start_date, end_date)\n",
        "latency_schedule = generate_latency_schedule(start_date, end_date)\n",
        "cost_schedule = generate_cost_schedule(start_date, end_date, cost_change_date)\n",
        "user_usage_schedule = generate_user_usage_schedule(start_date, end_date, users)\n",
        "\n",
        "# Helper function to generate a random completion\n",
        "def generate_completion(prompt):\n",
        "    words = prompt.split()\n",
        "    completion = ' '.join(random.choices(words, k=int(len(words)* (random.random() + 0.1) * 10)))\n",
        "    return completion\n",
        "\n",
        "#latency_schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a672c782",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tqdm\n",
        "data = []\n",
        "for usage in tqdm.tqdm(user_usage_schedule):\n",
        "    usage_date, user, usage_period, rate = usage\n",
        "    \n",
        "    end_date = usage_date + usage_period\n",
        "    increment = timedelta(hours=rate)\n",
        "    \n",
        "    while usage_date < end_date:\n",
        "        # Find the version that was active during this usage\n",
        "        if usage_date.date() not in version_schedule:\n",
        "            break\n",
        "        active_versions = version_schedule[usage_date.date()]\n",
        "        #active_versions = [(version, percent) for date, version, percent in version_schedule if date.date() == usage_date.date()]\n",
        "        # Normalize the service percentages\n",
        "        total_percent = sum([percent for version, percent in active_versions])\n",
        "        if total_percent == 0:\n",
        "            continue\n",
        "        normalized_percentages = [percent / total_percent for version, percent in active_versions]\n",
        "\n",
        "        version = np.random.choice([v for v, p in active_versions], p=normalized_percentages)\n",
        "         \n",
        "        # Find the cost during this usage\n",
        "        cost_per_token = cost_schedule[usage_date.date()]\n",
        "        \n",
        "        # Find the average latency during this usage\n",
        "        latency = latency_schedule[usage_date.date()]\n",
        "        latency *= (0.9 + random.random() *.2)\n",
        "        \n",
        "        prompt = ' '.join(random.sample(lines, 10))  # Increase prompt size\n",
        "        completion = generate_completion(prompt)\n",
        "        prompt_tokens = len(prompt.split())\n",
        "        completion_tokens = len(completion.split())\n",
        "        api_cost = (prompt_tokens + completion_tokens) * cost_per_token\n",
        "\n",
        "        data.append([usage_date, user, version, prompt, completion, \n",
        "                     prompt_tokens, completion_tokens, api_cost, latency])\n",
        "        \n",
        "        usage_date += increment\n",
        "\n",
        "df = pd.DataFrame(data, columns=['timestamp', 'username', 'model_version', 'prompt', 'completion', \n",
        "                                 'prompt_tokens', 'completion_tokens', 'api_cost', 'latency'])\n",
        "\n",
        "predictions = weave.save(dataframe_to_arrow(df), 'predictions')\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57fc86e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = weave.legacy.weave.ops.get(\"local-artifact:///predictions:latest/obj\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8049b6dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "weave.legacy.weave.panels.Board(\n",
        "    vars={\n",
        "        'all_preds': predictions,\n",
        "        'x_max': weave.legacy.weave.ops.date_parse(str(end_date)),\n",
        "        'x_min': lambda x_max: x_max - weave.legacy.weave.ops.days(5),\n",
        "        'predictions': lambda x_min: predictions.filter(lambda pred: pred['timestamp'] > x_min)\n",
        "    },\n",
        "    panels=[\n",
        "        weave.legacy.weave.panels.BoardPanel(\n",
        "            lambda predictions, x_min, x_max: wandb.TimeSeries(\n",
        "                            predictions,\n",
        "                            x=lambda item: item[\"timestamp\"],\n",
        "                            label=lambda item: item[\"model_version\"],\n",
        "                            agg=lambda preds: preds.count(),\n",
        "                            min_x=x_min,\n",
        "                            max_x=x_max,\n",
        "                            mark=\"bar\",\n",
        "                            axis_labels={\"y\": \"num_preds\"},\n",
        "                        ),\n",
        "            layout=weave.legacy.weave.panels.BoardPanelLayout(x=0, y=0, w=12, h=6)\n",
        "        ),\n",
        "        weave.legacy.weave.panels.BoardPanel(\n",
        "            lambda predictions, x_min, x_max: wandb.TimeSeries(\n",
        "                            predictions,\n",
        "                            x=lambda item: item[\"timestamp\"],\n",
        "                            label=lambda item: item[\"username\"],\n",
        "                            agg=lambda preds: preds.count(),\n",
        "                            min_x=x_min,\n",
        "                            max_x=x_max,\n",
        "                            mark=\"bar\",\n",
        "                            axis_labels={\"y\": \"num_preds\"},\n",
        "                        ),\n",
        "            layout=weave.legacy.weave.panels.BoardPanelLayout(x=12, y=0, w=12, h=6)\n",
        "        ),\n",
        "        weave.legacy.weave.panels.BoardPanel(\n",
        "            lambda predictions, x_min, x_max: wandb.TimeSeries(\n",
        "                            predictions,\n",
        "                            x=lambda item: item[\"timestamp\"],\n",
        "                            #label=lambda item: item[\"model_version\"],\n",
        "                            agg=lambda preds: preds[\"api_cost\"].sum(),\n",
        "                            min_x=x_min,\n",
        "                            max_x=x_max,\n",
        "                            mark=\"line\",\n",
        "                            axis_labels={\"y\": \"api_cost\"},\n",
        "                        ),\n",
        "            layout=weave.legacy.weave.panels.BoardPanelLayout(x=0, y=6, w=8, h=6)\n",
        "        ),\n",
        "        weave.legacy.weave.panels.BoardPanel(\n",
        "            lambda predictions, x_min, x_max: wandb.TimeSeries(\n",
        "                            predictions,\n",
        "                            x=lambda item: item[\"timestamp\"],\n",
        "                            #label=lambda item: item[\"model_version\"],\n",
        "                            agg=lambda preds: preds[\"prompt_tokens\"].sum() + preds['completion_tokens'].sum(),\n",
        "                            min_x=x_min,\n",
        "                            max_x=x_max,\n",
        "                            mark=\"line\",\n",
        "                            axis_labels={\"y\": \"total_tokens\"},\n",
        "                        ),\n",
        "            layout=weave.legacy.weave.panels.BoardPanelLayout(x=8, y=6, w=8, h=6)\n",
        "        ),\n",
        "        weave.legacy.weave.panels.BoardPanel(\n",
        "            lambda predictions, x_min, x_max: wandb.TimeSeries(\n",
        "                            predictions,\n",
        "                            x=lambda item: item[\"timestamp\"],\n",
        "                            #label=lambda item: item[\"model_version\"],\n",
        "                            agg=lambda preds: preds[\"latency\"].avg(),\n",
        "                            min_x=x_min,\n",
        "                            max_x=x_max,\n",
        "                            mark=\"line\",\n",
        "                            axis_labels={\"y\": \"avg_latency\"},\n",
        "                        ),\n",
        "            layout=weave.legacy.weave.panels.BoardPanelLayout(x=16, y=6, w=8, h=6)\n",
        "        ),\n",
        "        weave.legacy.weave.panels.BoardPanel(\n",
        "            lambda predictions, x_min, x_max: wandb.Distribution(\n",
        "                predictions,\n",
        "                value_fn=lambda pred: pred['api_cost'],\n",
        "                bin_size=0.2\n",
        "            ),\n",
        "            layout=weave.legacy.weave.panels.BoardPanelLayout(x=0, y=12, w=8, h=6)\n",
        "        ),\n",
        "        weave.legacy.weave.panels.BoardPanel(\n",
        "            lambda predictions, x_min, x_max: wandb.Distribution(\n",
        "                predictions,\n",
        "                value_fn=lambda pred: pred['prompt_tokens'] + pred['completion_tokens'],\n",
        "                bin_size=25\n",
        "            ),\n",
        "            layout=weave.legacy.weave.panels.BoardPanelLayout(x=8, y=12, w=8, h=6)\n",
        "        ),\n",
        "        weave.legacy.weave.panels.BoardPanel(\n",
        "            lambda predictions, x_min, x_max: wandb.Distribution(\n",
        "                predictions,\n",
        "                value_fn=lambda pred: pred['latency'],\n",
        "                bin_size=0.05\n",
        "            ),\n",
        "            layout=weave.legacy.weave.panels.BoardPanelLayout(x=16, y=12, w=8, h=6)\n",
        "        ),\n",
        "        weave.legacy.weave.panels.BoardPanel(\n",
        "            lambda predictions: predictions,\n",
        "            layout=weave.legacy.weave.panels.BoardPanelLayout(x=0, y=18, w=24, h=12)\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
