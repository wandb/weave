{
  "models": [
    {
      "provider": "coreweave",
      "id": "cw_deepseek-ai_DeepSeek-R1",
      "idPlayground": "cw_deepseek-ai_DeepSeek-R1",
      "idHuggingFace": "deepseek-ai/DeepSeek-R1",
      "label": "DeepSeek R1",
      "status": "hosted",
      "descriptionShort": "A high-performance transformer model optimized for complex reasoning and long-form tasks across diverse domains.",
      "descriptionMedium": "DeepSeek R1 is a high-performing open-source language model developed with a focus on deep reasoning and long-context understanding. It delivers strong results on benchmarks involving logical tasks, code generation, and complex multi-turn dialogue. Built with a transformer architecture and trained on diverse public datasets, it's designed to support research and real-world applications alike. While not as multimodal as newer models, its long context window and consistent performance make it a solid choice for document understanding, chain-of-thought prompting, and retrieval-augmented workflows.",
      "launchDate": "2025-01-01T00:00:00Z",
      "contextWindow": 128000,
      "priceCentsPerBillionTokensInput": 15000,
      "priceCentsPerBillionTokensOutput": 139000,
      "apiStyle": "chat",
      "modalities": ["Text"],
      "likesHuggingFace": 12287,
      "downloadsHuggingFace": 708851
    },
    {
      "provider": "coreweave",
      "id": "cw_meta-llama_Llama-3.3-70B-Instruct",
      "idPlayground": "cw_meta-llama_Llama-3.3-70B-Instruct",
      "idHuggingFace": "meta-llama/Llama-3.3-70B-Instruct",
      "label": "Llama 3.3 70B",
      "status": "hosted",
      "descriptionShort": "Meta's flagship open model for 2024, LLaMA 3.3 excels at general-purpose and multilingual tasks with strong benchmark performance.",
      "descriptionMedium": "Llama 3.3 70B represents Meta's latest advancement in open-source language models, offering exceptional performance across a wide range of tasks. With its 70 billion parameters, it demonstrates remarkable capabilities in multilingual understanding, code generation, and complex reasoning. The model's architecture incorporates recent advances in transformer design, enabling efficient processing of long contexts while maintaining high accuracy. Its strong performance on standard benchmarks and real-world applications makes it particularly suitable for enterprise use cases, research, and development of specialized applications.",
      "launchDate": "2024-12-01T00:00:00Z",
      "contextWindow": 128000,
      "priceCentsPerBillionTokensInput": 16000,
      "priceCentsPerBillionTokensOutput": 139000,
      "apiStyle": "chat",
      "modalities": ["Text"],
      "likesHuggingFace": 2339,
      "downloadsHuggingFace": 667747
    },
    {
      "provider": "coreweave",
      "id": "cw_mistralai_Mistral-Small-3.1-24B-Instruct-2503",
      "idPlayground": "cw_mistralai_Mistral-Small-3.1-24B-Instruct-2503",
      "idHuggingFace": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
      "label": "Mistral Small 3.1",
      "status": "hosted",
      "descriptionShort": "A lightweight, multimodal model designed for general tasks, offering efficient inference across both text and vision inputs.",
      "descriptionMedium": "Mistral Small 3.1 represents a significant advancement in efficient multimodal AI, combining text and vision capabilities in a compact 24B parameter package. The model leverages innovative architectural choices to maintain high performance while reducing computational requirements. Its multimodal capabilities enable it to process and understand both textual and visual inputs, making it particularly effective for tasks requiring cross-modal understanding. The model's efficiency makes it well-suited for real-time applications, edge deployment, and scenarios where resource constraints are a consideration.",
      "launchDate": "2025-03-01T00:00:00Z",
      "contextWindow": 128000,
      "priceCentsPerBillionTokensInput": 17000,
      "priceCentsPerBillionTokensOutput": 139000,
      "apiStyle": "chat",
      "modalities": ["Text", "Vision"],
      "likesHuggingFace": 1253,
      "downloadsHuggingFace": 116727
    },
    {
      "provider": "coreweave",
      "id": "cw_meta-llama_Llama-4-Scout-17B-16E-Instruct",
      "idPlayground": "cw_meta-llama_Llama-4-Scout-17B-16E-Instruct",
      "idHuggingFace": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "label": "Llama 4 Scout",
      "status": "hosted",
      "descriptionShort": "A cutting-edge text and vision model from Meta, Scout is built for deep multimodal understanding and general task execution.",
      "descriptionMedium": "Llama 4 Scout represents Meta's latest foray into multimodal AI, combining advanced language understanding with sophisticated vision capabilities. The model's architecture is specifically designed to excel at tasks requiring deep integration of visual and textual information. With its 17B parameters and 16 expert layers, it achieves a remarkable balance between performance and efficiency. The model demonstrates particular strength in visual reasoning, image understanding, and tasks requiring cross-modal alignment. Its design makes it ideal for applications in computer vision, visual question answering, and complex multimodal interactions.",
      "launchDate": "2025-04-01T00:00:00Z",
      "contextWindow": 10000000,
      "priceCentsPerBillionTokensInput": 18000,
      "priceCentsPerBillionTokensOutput": 139000,
      "apiStyle": "chat",
      "modalities": ["Text", "Vision"],
      "likesHuggingFace": 928,
      "downloadsHuggingFace": 299060
    },
    {
      "provider": "coreweave",
      "id": "cw_Qwen_QwQ-32B",
      "idPlayground": "cw_Qwen_QwQ-32B",
      "idHuggingFace": "Qwen/QwQ-32B",
      "label": "Qwen QwQ 32B",
      "status": "hosted",
      "descriptionShort": "Qwen QwQ is a reasoning-focused model built for high-performance use cases, particularly in structured and logic-heavy domains.",
      "descriptionMedium": "Qwen QwQ 32B is a specialized language model developed with a strong emphasis on logical reasoning and structured problem-solving. The model's architecture incorporates advanced attention mechanisms and specialized training techniques to enhance its capabilities in mathematical reasoning, logical deduction, and complex problem decomposition. With 32 billion parameters, it achieves impressive performance on tasks requiring step-by-step reasoning, mathematical operations, and structured data processing. The model is particularly effective for applications in scientific computing, data analysis, and tasks requiring precise logical operations.",
      "launchDate": "2025-03-01T00:00:00Z",
      "contextWindow": 131000,
      "priceCentsPerBillionTokensInput": 19000,
      "priceCentsPerBillionTokensOutput": 139000,
      "apiStyle": "chat",
      "modalities": ["Text"],
      "likesHuggingFace": 2767,
      "downloadsHuggingFace": 318949
    },
    {
      "provider": "coreweave",
      "id": "cw_microsoft_Phi-4-mini-instruct",
      "idPlayground": "cw_microsoft_Phi-4-mini-instruct",
      "idHuggingFace": "microsoft/Phi-4-mini-instruct",
      "label": "Phi 4 Mini",
      "status": "hosted",
      "descriptionShort": "A compact and capable model from Microsoft, Phi 4 Mini is ideal for general-purpose language tasks where speed and size matter.",
      "descriptionMedium": "Phi 4 Mini represents Microsoft's approach to efficient language modeling, delivering strong performance in a compact package. The model incorporates innovative architectural choices and training techniques to maximize capabilities while minimizing resource requirements. Despite its smaller size, it maintains impressive performance across a wide range of language tasks, including text generation, summarization, and question answering. Its efficiency makes it particularly suitable for deployment in resource-constrained environments, real-time applications, and scenarios where rapid inference is crucial. The model's design prioritizes practical utility while maintaining high quality outputs.",
      "launchDate": "2025-02-01T00:00:00Z",
      "contextWindow": 16000,
      "priceCentsPerBillionTokensInput": 20000,
      "priceCentsPerBillionTokensOutput": 139000,
      "apiStyle": "chat",
      "modalities": ["Text"],
      "likesHuggingFace": 489,
      "downloadsHuggingFace": 358111
    },
    {
      "provider": "coreweave",
      "id": "cw_meta-llama_Llama-4-Maverick-17B-128E-Instruct-FP8",
      "idPlayground": "cw_meta-llama_Llama-4-Maverick-17B-128E-Instruct-FP8",
      "idHuggingFace": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "label": "Llama 4 Maverick",
      "status": "hosted",
      "descriptionShort": "Maverick extends the LLaMA 4 family with vision capabilities, making it a versatile choice for multimodal general-purpose applications.",
      "descriptionMedium": "Llama 4 Maverick represents a significant advancement in Meta's multimodal AI capabilities, combining sophisticated language understanding with advanced vision processing. The model's architecture features 128 expert layers optimized for FP8 precision, enabling efficient processing of both visual and textual information. Its design emphasizes the seamless integration of visual and language understanding, making it particularly effective for tasks requiring deep multimodal comprehension. The model excels in visual reasoning, image understanding, and complex multimodal interactions, while maintaining efficient inference through its optimized architecture.",
      "launchDate": "2025-04-01T00:00:00Z",
      "contextWindow": 1000000,
      "priceCentsPerBillionTokensInput": 21000,
      "priceCentsPerBillionTokensOutput": 139000,
      "apiStyle": "chat",
      "modalities": ["Text", "Vision"],
      "likesHuggingFace": 113,
      "downloadsHuggingFace": 48325
    },
    {
      "provider": "coreweave",
      "id": "cw_Qwen_Qwen2.5-VL-7B-Instruct",
      "idPlayground": "cw_Qwen_Qwen2.5-VL-7B-Instruct",
      "idHuggingFace": "Qwen/Qwen2.5-VL-7B-Instruct",
      "label": "Qwen 2.5 VL 7B",
      "status": "hosted",
      "descriptionShort": "An efficient text and vision model from Alibaba, Qwen 2.5 VL is tuned for coding, general-purpose reasoning, and image understanding.",
      "descriptionMedium": "Qwen 2.5 VL 7B is Alibaba's latest multimodal model, combining efficient language processing with sophisticated vision capabilities in a compact 7B parameter package. The model is specifically optimized for coding tasks, visual reasoning, and general-purpose applications. Its architecture enables effective processing of both code and natural language, making it particularly suitable for software development and technical documentation tasks. The model's vision capabilities are tuned for precise image understanding and visual reasoning, while its efficient design makes it practical for deployment in various production environments.",
      "launchDate": "2025-01-01T00:00:00Z",
      "contextWindow": 32000,
      "priceCentsPerBillionTokensInput": 22000,
      "priceCentsPerBillionTokensOutput": 139000,
      "apiStyle": "chat",
      "modalities": ["Text", "Vision"],
      "likesHuggingFace": 926,
      "downloadsHuggingFace": 2647737
    },
    {
      "provider": "coreweave",
      "id": "cw_ibm-granite_granite-3.3-8b-instruct",
      "idPlayground": "cw_ibm-granite_granite-3.3-8b-instruct",
      "idHuggingFace": "ibm-granite/granite-3.3-8b-instruct",
      "label": "Granite 3.3 8B",
      "status": "hosted",
      "descriptionShort": "Granite is an open, generalist model with a strong focus on reasoning, designed for transparency and broad utility across domains.",
      "descriptionMedium": "Granite 3.3 8B represents IBM's commitment to open, transparent AI development, offering a versatile language model with strong reasoning capabilities. The model's architecture emphasizes interpretability and reliability, making it particularly suitable for enterprise applications where transparency is crucial. Despite its compact 8B parameter size, it delivers robust performance across a wide range of tasks, with particular strength in logical reasoning and structured problem-solving. The model's design prioritizes practical utility while maintaining high standards of accuracy and reliability, making it well-suited for business applications, research, and development of specialized AI solutions.",
      "launchDate": "2025-04-01T00:00:00Z",
      "contextWindow": 128000,
      "priceCentsPerBillionTokensInput": 23000,
      "priceCentsPerBillionTokensOutput": 139000,
      "apiStyle": "chat",
      "modalities": ["Text"],
      "likesHuggingFace": 81,
      "downloadsHuggingFace": 52663
    },
    {
      "provider": "coreweave",
      "id": "cw_BAAI_bge-m3",
      "idHuggingFace": "BAAI/bge-m3",
      "label": "BGE M3",
      "status": "hosted",
      "descriptionShort": "A state-of-the-art embedding model tailored for retrieval-augmented generation (RAG), providing dense, high-quality vector outputs.",
      "descriptionMedium": "BGE M3 represents a significant advancement in embedding technology, specifically optimized for retrieval-augmented generation (RAG) applications. The model's architecture is designed to produce high-quality, dense vector representations that capture semantic meaning with exceptional precision. Its specialized training process enables it to excel at tasks requiring semantic similarity matching, information retrieval, and knowledge grounding. The model's outputs are particularly well-suited for building efficient search systems, knowledge bases, and RAG pipelines, where accurate semantic understanding is crucial for performance.",
      "launchDate": "2024-01-01T00:00:00Z",
      "contextWindow": 8000,
      "priceCentsPerBillionTokensInput": 24000,
      "priceCentsPerBillionTokensOutput": 139000,
      "apiStyle": "embedding",
      "modalities": ["Embedding"],
      "likesHuggingFace": 2084,
      "downloadsHuggingFace": 3590321
    }
  ]
}
