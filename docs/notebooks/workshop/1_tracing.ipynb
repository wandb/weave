{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aa8d1bc",
   "metadata": {},
   "source": [
    "# ğŸ Weave Workshop: Build, Track, and Evaluate LLM Applications\n",
    "\n",
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "Welcome to the Weave workshop! In this hands-on session, you'll learn how to use Weave to develop, debug, and evaluate AI-powered applications.\n",
    "\n",
    "**What you'll learn:**\n",
    "- ğŸ” **Trace & Debug**: Track every LLM call, see inputs/outputs, and debug issues\n",
    "- ğŸ“Š **Evaluate**: Build rigorous evaluations with multiple scoring functions\n",
    "- ğŸƒ **Compare**: Run A/B tests and compare different approaches\n",
    "- ğŸ“ˆ **Monitor**: Track costs, latency, and performance metrics\n",
    "- ğŸ¯ **Iterate**: Use data-driven insights to improve your application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbfa532",
   "metadata": {},
   "source": [
    "## ğŸ”‘ Prerequisites\n",
    "\n",
    "Before we begin, let's set up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c118d894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "ğŸ“ Setting up API keys...\n",
      "âœ… W&B authentication will be handled automatically by Weave\n",
      "   (Optional: You can set WANDB_API_KEY env variable if you prefer)\n",
      "\n",
      "ğŸ¤– OpenAI Setup:\n",
      "âœ… OpenAI API key found in environment\n",
      "\n",
      "---\n",
      "ğŸ Initializing Weave...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: Logged in as Weights & Biases user: timssweeney.\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: View Weave data at https://wandb.ai/timssweeney/weave-workshop/weave\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install wandb weave openai pydantic nest_asyncio opentelemetry-exporter-otlp 'weave[video_support]' -qqq\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "from typing import Any\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import weave\n",
    "\n",
    "# ğŸ”‘ Setup your API keys\n",
    "print(\"ğŸ“ Setting up API keys...\")\n",
    "\n",
    "# Weights & Biases will automatically prompt if needed\n",
    "# It checks: 1) WANDB_API_KEY env var, 2) ~/.netrc, 3) prompts user\n",
    "print(\"âœ… W&B authentication will be handled automatically by Weave\")\n",
    "print(\"   (Optional: You can set WANDB_API_KEY env variable if you prefer)\")\n",
    "\n",
    "# OpenAI requires manual setup\n",
    "print(\"\\nğŸ¤– OpenAI Setup:\")\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\n",
    "        \"You can generate your OpenAI API key here: https://platform.openai.com/api-keys\"\n",
    "    )\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "else:\n",
    "    print(\"âœ… OpenAI API key found in environment\")\n",
    "\n",
    "print(\"\\n---\")\n",
    "\n",
    "# ğŸ  Initialize your W&B project\n",
    "print(\"ğŸ Initializing Weave...\")\n",
    "weave_client = weave.init(\"weave-workshop\")  # ğŸ Your W&B project name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e12b2a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## ğŸ” Part 1: Tracing & Debugging with Weave\n",
    "\n",
    "Let's start by building a simple LLM application and see how Weave automatically tracks everything.\n",
    "\n",
    "Note: We're using `gpt-4o-mini` which supports structured outputs while being cost-effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004c5be6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Analysis complete!\n",
      "Customer: Sarah Johnson\n",
      "Sentiment: negative\n",
      "\n",
      "ğŸ” Check the Weave UI to see the trace!\n"
     ]
    }
   ],
   "source": [
    "# Define our data structure\n",
    "class CustomerEmail(BaseModel):\n",
    "    customer_name: str\n",
    "    product: str\n",
    "    issue: str\n",
    "    sentiment: str = Field(description=\"positive, neutral, or negative\")\n",
    "\n",
    "\n",
    "# ğŸ Track functions with @weave.op\n",
    "@weave.op\n",
    "def analyze_customer_email(email: str) -> CustomerEmail:\n",
    "    \"\"\"Analyze a customer support email and extract key information.\"\"\"\n",
    "    client = OpenAI()\n",
    "\n",
    "    # ğŸ¯ Note: OpenAI calls are automatically traced by Weave!\n",
    "    # Weave automatically integrates with dozens of popular libraries including:\n",
    "    # OpenAI, Anthropic, LangChain, LlamaIndex, HuggingFace, and more\n",
    "    # See full list: https://weave-docs.wandb.ai/guides/integrations/\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",  # Using mini model for cost efficiency\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Extract customer name, product, issue, and sentiment.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": email,\n",
    "            },\n",
    "        ],\n",
    "        response_format=CustomerEmail,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.parsed\n",
    "\n",
    "\n",
    "# Let's test it!\n",
    "test_email = \"\"\"\n",
    "Hi Support,\n",
    "\n",
    "I'm really frustrated! My new ProWidget 3000 stopped working after just 2 days.\n",
    "The screen went completely black and won't turn on no matter what I try.\n",
    "\n",
    "Please help!\n",
    "Sarah Johnson\n",
    "\"\"\"\n",
    "\n",
    "# ğŸ¯ Run the function - Weave will automatically track this call\n",
    "result = analyze_customer_email(test_email)\n",
    "print(\"âœ… Analysis complete!\")\n",
    "print(f\"Customer: {result.customer_name}\")\n",
    "print(f\"Sentiment: {result.sentiment}\")\n",
    "print(\"\\nğŸ” Check the Weave UI to see the trace!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a830342",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### ğŸ› Part 1.1: Debugging with Call Traces\n",
    "\n",
    "Weave tracks nested function calls, making debugging easy. Let's build a more complex example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ca6be",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“§ Original length: 195, Cleaned length: 191\n",
      "\n",
      "ğŸ« Ticket processed!\n",
      "Urgency: high\n",
      "Needs immediate attention: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/0197066b-97c2-7be1-918c-843b0bcb2322\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/0197066b-9c14-7e43-81db-53b2667f125b\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/0197066b-a04d-7a71-81fc-a073d863592c\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/0197066b-a066-7330-a5b7-bc498b4ae407\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/0197066b-d734-7ee3-aab8-dfc11ab19ac8\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/0197066b-eec9-76a1-97c1-07e38e50a312\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/0197066b-f810-7960-959a-48d2b956bc04\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/0197066f-5ac3-71c2-96ec-bb00d274d85a\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/0197066f-8f6c-7162-ad23-be005b48b70c\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/0197066f-aa36-7a83-a7bf-ebd9c607bcb0\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: Task failed: ValueError: Failed to write video file with error: No 'fps' (frames per second) attribute specified for function write_videofile and the clip has no 'fps' attribute. Either provide e.g. fps=24 in the arguments of the function, or define the clip's fps with `clip.fps=24`\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/0197066f-b41b-7473-90b5-10d7323e7920\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/01970673-a5c5-7472-be0e-7efe231ce296\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/01970673-aab9-7601-a479-30d9aacbd45b\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/01970673-aab8-7161-ab8e-524f25df00e7\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/01970676-b5f7-7a53-a8aa-6957f5f896d4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/timssweeney/weave-workshop/r/call/01970673-aab8-7161-ab8e-522e4aa54c09\n"
     ]
    }
   ],
   "source": [
    "@weave.op\n",
    "def preprocess_email(email: str) -> str:\n",
    "    \"\"\"Clean and standardize email text.\"\"\"\n",
    "    # Remove extra whitespace\n",
    "    cleaned = \" \".join(email.split())\n",
    "    # Add some metadata for debugging\n",
    "    print(f\"ğŸ“§ Original length: {len(email)}, Cleaned length: {len(cleaned)}\")\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def classify_urgency(email: str, sentiment: str) -> str:\n",
    "    \"\"\"Determine urgency level based on content and sentiment.\"\"\"\n",
    "    urgent_keywords = [\n",
    "        \"urgent\",\n",
    "        \"asap\",\n",
    "        \"immediately\",\n",
    "        \"frustrated\",\n",
    "        \"broken\",\n",
    "        \"stopped working\",\n",
    "    ]\n",
    "\n",
    "    # Check for urgent keywords\n",
    "    email_lower = email.lower()\n",
    "    has_urgent_keywords = any(keyword in email_lower for keyword in urgent_keywords)\n",
    "\n",
    "    if sentiment == \"negative\" and has_urgent_keywords:\n",
    "        return \"high\"\n",
    "    elif sentiment == \"negative\" or has_urgent_keywords:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"low\"\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def process_support_ticket(email: str) -> dict[str, Any]:\n",
    "    \"\"\"Complete support ticket processing pipeline.\"\"\"\n",
    "    # Step 1: Clean the email\n",
    "    cleaned_email = preprocess_email(email)\n",
    "\n",
    "    # Step 2: Analyze the email\n",
    "    analysis = analyze_customer_email(cleaned_email)\n",
    "\n",
    "    # Step 3: Determine urgency\n",
    "    urgency = classify_urgency(cleaned_email, analysis.sentiment)\n",
    "\n",
    "    # Return complete ticket info\n",
    "    return {\n",
    "        \"customer_name\": analysis.customer_name,\n",
    "        \"product\": analysis.product,\n",
    "        \"issue\": analysis.issue,\n",
    "        \"sentiment\": analysis.sentiment,\n",
    "        \"urgency\": urgency,\n",
    "        \"needs_immediate_attention\": urgency == \"high\",\n",
    "    }\n",
    "\n",
    "\n",
    "# ğŸ¯ Run the pipeline - see the nested traces in Weave!\n",
    "ticket = process_support_ticket(test_email)\n",
    "print(\"\\nğŸ« Ticket processed!\")\n",
    "print(f\"Urgency: {ticket['urgency']}\")\n",
    "print(f\"Needs immediate attention: {ticket['needs_immediate_attention']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddafb70",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### ğŸ Part 1.2: Exception Tracking\n",
    "\n",
    "Weave automatically tracks exceptions in nested function calls, making debugging easy.\n",
    "Let's see how exceptions flow through parent and child operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "513ca38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ Testing exception tracking in nested operations...\n",
      "âŒ Failed to process item 1: Data too short!\n",
      "âŒ Failed to process item 2: Found 'error' in data: This contains error word\n",
      "âŒ Failed to process item 4: Data too short!\n",
      "\n",
      "ğŸ“Š Results:\n",
      "âœ… Successful: 2\n",
      "âŒ Failed: 3\n",
      "\n",
      "ğŸ’¡ Check the Weave UI to see:\n",
      "  - Parent operation (safe_processor) shows all child calls\n",
      "  - Failed child operations (risky_operation) are highlighted in red\n",
      "  - Full exception details and stack traces\n",
      "  - How exceptions flow from child to parent operations\n"
     ]
    }
   ],
   "source": [
    "@weave.op\n",
    "def risky_operation(data: str) -> str:\n",
    "    \"\"\"A child operation that might fail.\"\"\"\n",
    "    if \"error\" in data.lower():\n",
    "        raise ValueError(f\"Found 'error' in data: {data}\")\n",
    "    if len(data) < 5:\n",
    "        raise ValueError(\"Data too short!\")\n",
    "    return f\"Processed: {data}\"\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def safe_processor(inputs: list[str]) -> dict[str, Any]:\n",
    "    \"\"\"A parent operation that handles child failures gracefully.\"\"\"\n",
    "    results = {\"successful\": [], \"failed\": []}\n",
    "\n",
    "    for i, data in enumerate(inputs):\n",
    "        try:\n",
    "            # Call the risky child operation\n",
    "            processed = risky_operation(data)\n",
    "            results[\"successful\"].append(\n",
    "                {\"index\": i, \"data\": data, \"result\": processed}\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Catch and log the exception\n",
    "            results[\"failed\"].append({\"index\": i, \"data\": data, \"error\": str(e)})\n",
    "            print(f\"âŒ Failed to process item {i}: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Test with mixed data - some will succeed, some will fail\n",
    "test_data = [\n",
    "    \"Valid data here\",  # âœ… Will succeed\n",
    "    \"err\",  # âŒ Too short\n",
    "    \"This contains error word\",  # âŒ Contains 'error'\n",
    "    \"Another good input\",  # âœ… Will succeed\n",
    "    \"bad\",  # âŒ Too short\n",
    "]\n",
    "\n",
    "print(\"ğŸ Testing exception tracking in nested operations...\")\n",
    "result = safe_processor(test_data)\n",
    "\n",
    "print(\"\\nğŸ“Š Results:\")\n",
    "print(f\"âœ… Successful: {len(result['successful'])}\")\n",
    "print(f\"âŒ Failed: {len(result['failed'])}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Check the Weave UI to see:\")\n",
    "print(\"  - Parent operation (safe_processor) shows all child calls\")\n",
    "print(\"  - Failed child operations (risky_operation) are highlighted in red\")\n",
    "print(\"  - Full exception details and stack traces\")\n",
    "print(\"  - How exceptions flow from child to parent operations\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84f353c",
   "metadata": {},
   "source": [
    "### ğŸ¬ Part 1.3: Media Support & Multimodal Tracing\n",
    "\n",
    "Weave can automatically trace and log various media types including images, videos, audio, and PDFs.\n",
    "This is especially useful for multimodal AI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17529f13",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¬ Testing Weave's media support...\n",
      "\n",
      "ğŸ“¸ Generating image...\n",
      "âœ… Generated image: (1024, 1024)\n",
      "\n",
      "ğŸ” Analyzing image with GPT-4 Vision...\n",
      "ğŸ¤– Analysis: The image depicts a cute, futuristic robot sitting on an open book, surrounded by holographic displays showcasing data and graphics in a digital environment filled with binary code.\n",
      "\n",
      "ğŸµ Generating audio...\n",
      "âœ… Generated audio file\n",
      "\n",
      "ğŸ¬ Creating video...\n",
      "âœ… Generated video clip\n",
      "\n",
      "ğŸ’¡ Check the Weave UI to see:\n",
      "  - ğŸ“¸ Images displayed with thumbnails and full-size view\n",
      "  - ğŸµ Audio files with built-in audio player and waveform\n",
      "  - ğŸ¬ Video clips with video player (if moviepy available)\n",
      "  - ğŸ”— All media automatically linked to their function calls\n",
      "  - ğŸ“Š Media metadata (dimensions, duration, file size, etc.)\n",
      "\n",
      "ğŸ¯ Key Benefits:\n",
      "  - No manual upload needed - Weave handles everything automatically\n",
      "  - Media is preserved with full context of the function call\n",
      "  - Easy to debug multimodal AI applications\n",
      "  - Share results with team members through Weave UI\n"
     ]
    }
   ],
   "source": [
    "# Let's demonstrate media support with different types\n",
    "import requests\n",
    "from PIL import Image\n",
    "import wave\n",
    "import base64\n",
    "\n",
    "# ğŸ“¸ Image Support - Weave automatically logs PIL.Image objects\n",
    "@weave.op\n",
    "def generate_sample_image() -> Image.Image:\n",
    "    \"\"\"Generate a sample image using OpenAI DALL-E API.\"\"\"\n",
    "    client = OpenAI()\n",
    "    \n",
    "    response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=\"A cute robot learning about data science, digital art style\",\n",
    "        size=\"1024x1024\",\n",
    "        quality=\"standard\",\n",
    "        n=1,\n",
    "    )\n",
    "    \n",
    "    # Download and return as PIL Image - Weave will automatically log this!\n",
    "    image_url = response.data[0].url\n",
    "    image_response = requests.get(image_url, stream=True)\n",
    "    image = Image.open(image_response.raw)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# ğŸµ Audio Support - Weave automatically logs wave.Wave_read objects  \n",
    "@weave.op\n",
    "def generate_sample_audio(text: str) -> wave.Wave_read:\n",
    "    \"\"\"Generate audio using OpenAI's text-to-speech API.\"\"\"\n",
    "    client = OpenAI()\n",
    "    \n",
    "    with client.audio.speech.with_streaming_response.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"alloy\", \n",
    "        input=text,\n",
    "        response_format=\"wav\",\n",
    "    ) as response:\n",
    "        response.stream_to_file(\"sample_audio.wav\")\n",
    "    \n",
    "    # Return wave file - Weave will automatically log this with audio player!\n",
    "    return wave.open(\"sample_audio.wav\", \"rb\")\n",
    "\n",
    "# ğŸ¬ Video Support - Weave automatically logs moviepy video clips\n",
    "@weave.op  \n",
    "def create_sample_video():\n",
    "    \"\"\"Create a simple video clip using moviepy.\"\"\"\n",
    "    try:\n",
    "        from moviepy.editor import ColorClip, TextClip, CompositeVideoClip\n",
    "        \n",
    "        # Create a simple video: colored background with text\n",
    "        background = ColorClip(size=(640, 480), color=(100, 150, 200), duration=3)\n",
    "        \n",
    "        # Add text overlay\n",
    "        # text_clip = TextClip(\"Hello from Weave!\", \n",
    "        #                    fontsize=50, \n",
    "        #                    color='white',\n",
    "        #                    font='Arial-Bold').set_duration(3).set_position('center')\n",
    "        \n",
    "        # Composite the video\n",
    "        video = CompositeVideoClip([background])\n",
    "        \n",
    "        # Return video clip - Weave will automatically log this!\n",
    "        return video\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"ğŸ“¹ MoviePy not installed. Install with: pip install moviepy\")\n",
    "        return \"Video creation skipped - moviepy not available\"\n",
    "\n",
    "# ğŸ–¼ï¸ Multimodal Analysis - Combining image and text\n",
    "@weave.op\n",
    "def analyze_image_with_gpt4_vision(image: Image.Image, question: str) -> str:\n",
    "    \"\"\"Analyze an image using GPT-4 Vision.\"\"\"\n",
    "    client = OpenAI()\n",
    "    \n",
    "    # Convert PIL image to base64 for API\n",
    "    import io\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format='PNG')\n",
    "    image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # Supports vision\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": question},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{image_base64}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=300\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# ğŸ¯ Let's test the media support!\n",
    "print(\"ğŸ¬ Testing Weave's media support...\")\n",
    "\n",
    "# Test image generation and analysis\n",
    "print(\"\\nğŸ“¸ Generating image...\")\n",
    "sample_image = generate_sample_image()\n",
    "print(f\"âœ… Generated image: {sample_image.size}\")\n",
    "\n",
    "print(\"\\nğŸ” Analyzing image with GPT-4 Vision...\")\n",
    "analysis = analyze_image_with_gpt4_vision(\n",
    "    sample_image, \n",
    "    \"What do you see in this image? Describe it in one sentence.\"\n",
    ")\n",
    "print(f\"ğŸ¤– Analysis: {analysis}\")\n",
    "\n",
    "# Test audio generation\n",
    "print(\"\\nğŸµ Generating audio...\")\n",
    "sample_audio = generate_sample_audio(\"Welcome to the Weave workshop! This audio will be automatically logged.\")\n",
    "print(\"âœ… Generated audio file\")\n",
    "\n",
    "# Test video creation (if moviepy is available)\n",
    "print(\"\\nğŸ¬ Creating video...\")\n",
    "sample_video = create_sample_video()\n",
    "if isinstance(sample_video, str):\n",
    "    print(f\"âš ï¸ {sample_video}\")\n",
    "else:\n",
    "    print(\"âœ… Generated video clip\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Check the Weave UI to see:\")\n",
    "print(\"  - ğŸ“¸ Images displayed with thumbnails and full-size view\")\n",
    "print(\"  - ğŸµ Audio files with built-in audio player and waveform\")\n",
    "print(\"  - ğŸ¬ Video clips with video player (if moviepy available)\")\n",
    "print(\"  - ğŸ”— All media automatically linked to their function calls\")\n",
    "print(\"  - ğŸ“Š Media metadata (dimensions, duration, file size, etc.)\")\n",
    "\n",
    "print(\"\\nğŸ¯ Key Benefits:\")\n",
    "print(\"  - No manual upload needed - Weave handles everything automatically\")\n",
    "print(\"  - Media is preserved with full context of the function call\")\n",
    "print(\"  - Easy to debug multimodal AI applications\")\n",
    "print(\"  - Share results with team members through Weave UI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af695e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<moviepy.video.compositing.CompositeVideoClip.CompositeVideoClip at 0x15bd93500>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from moviepy.editor import ColorClip, TextClip, CompositeVideoClip\n",
    "\n",
    "# Create a simple video: colored background with text\n",
    "background = ColorClip(size=(640, 480), color=(100, 150, 200), duration=3)\n",
    "\n",
    "# # Add text overlay\n",
    "# text_clip = TextClip(\"Hello from Weave!\", \n",
    "#                     fontsize=50, \n",
    "#                     color='white',\n",
    "#                     font='Arial-Bold').set_duration(3).set_position('center')\n",
    "\n",
    "# # Composite the video\n",
    "video = CompositeVideoClip([background])\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b7057b",
   "metadata": {},
   "source": [
    "### ğŸ”’ Part 1.4: Custom Serialization\n",
    "\n",
    "Control what gets logged and how with Weave's serialization features.\n",
    "Use `postprocess_inputs` and `postprocess_output` to customize what data gets stored.\n",
    "Perfect for PII redaction, large object handling, sensitive data filtering, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33a0c314",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ Testing custom serialization and privacy controls...\n",
      "\n",
      "ğŸ“§ Testing PII redaction...\n",
      "âœ… PII redacted in logs (check Weave UI)\n",
      "\n",
      "ğŸ“¦ Testing large object handling...\n",
      "âœ… Large objects summarized: {'processed_count': 1000, 'metadata_length': 2800, 'summary': 'Processed 1000 items'}\n",
      "\n",
      "ğŸ” Testing sensitive config filtering...\n",
      "âœ… Sensitive config filtered: {'endpoint': 'https://api.example.com', 'configured': True, 'auth_method': 'token'}\n",
      "\n",
      "ğŸ”„ Testing data transformation...\n",
      "âœ… Data transformed for logging: {'status': 'completed', 'config_keys': ['debug', 'timeout'], 'user_data_processed': True}\n",
      "\n",
      "ğŸ’¡ Check the Weave UI to see:\n",
      "  - ğŸ”’ PII automatically redacted in input/output logs\n",
      "  - ğŸ“¦ Large objects summarized instead of fully logged\n",
      "  - ğŸ” Sensitive configuration keys hidden\n",
      "  - ğŸ”„ Complex objects transformed to readable summaries\n",
      "  - ğŸ“Š Enhanced metadata added to outputs\n",
      "\n",
      "ğŸ¯ Key Benefits:\n",
      "  - Protect sensitive data while maintaining observability\n",
      "  - Keep logs manageable by summarizing large objects\n",
      "  - Customize logging format for better readability\n",
      "  - Maintain compliance with privacy regulations\n",
      "  - Debug effectively without exposing secrets\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import Any, Dict\n",
    "\n",
    "# ğŸ”’ Example 1: PII Redaction\n",
    "def redact_pii_inputs(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Redact PII from inputs before logging.\"\"\"\n",
    "    processed = inputs.copy()\n",
    "    \n",
    "    if \"email_content\" in processed:\n",
    "        text = processed[\"email_content\"]\n",
    "        # Redact email addresses\n",
    "        text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '<EMAIL>', text)\n",
    "        # Redact phone numbers\n",
    "        text = re.sub(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b', '<PHONE>', text)\n",
    "        # Redact SSN\n",
    "        text = re.sub(r'\\b\\d{3}-\\d{2}-\\d{4}\\b', '<SSN>', text)\n",
    "        processed[\"email_content\"] = text\n",
    "    \n",
    "    return processed\n",
    "\n",
    "def redact_pii_output(output: Any) -> Any:\n",
    "    \"\"\"Redact PII from outputs before logging.\"\"\"\n",
    "    if hasattr(output, 'customer_name'):\n",
    "        # Create a copy and redact the name\n",
    "        output_dict = output.dict() if hasattr(output, 'dict') else output\n",
    "        if isinstance(output_dict, dict) and 'customer_name' in output_dict:\n",
    "            output_dict['customer_name'] = '<CUSTOMER_NAME>'\n",
    "        return output_dict\n",
    "    return output\n",
    "\n",
    "@weave.op(\n",
    "    postprocess_inputs=redact_pii_inputs,\n",
    "    postprocess_output=redact_pii_output\n",
    ")\n",
    "def analyze_sensitive_email(email_content: str) -> CustomerEmail:\n",
    "    \"\"\"Analyze email while protecting PII in logs.\"\"\"\n",
    "    return analyze_customer_email(email_content)\n",
    "\n",
    "# ğŸ“¦ Example 2: Large Object Handling\n",
    "def summarize_large_inputs(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Summarize large objects to avoid logging huge data.\"\"\"\n",
    "    processed = inputs.copy()\n",
    "    \n",
    "    for key, value in processed.items():\n",
    "        if isinstance(value, (list, tuple)) and len(value) > 10:\n",
    "            # Only log first/last few items for large lists\n",
    "            processed[key] = {\n",
    "                \"type\": f\"{type(value).__name__}\",\n",
    "                \"length\": len(value),\n",
    "                \"sample_start\": value[:3],\n",
    "                \"sample_end\": value[-3:],\n",
    "                \"note\": \"Large object truncated for logging\"\n",
    "            }\n",
    "        elif isinstance(value, str) and len(value) > 1000:\n",
    "            # Truncate very long strings\n",
    "            processed[key] = {\n",
    "                \"type\": \"string\",\n",
    "                \"length\": len(value),\n",
    "                \"preview\": value[:200] + \"...\",\n",
    "                \"note\": \"Long string truncated for logging\"\n",
    "            }\n",
    "    \n",
    "    return processed\n",
    "\n",
    "@weave.op(postprocess_inputs=summarize_large_inputs)\n",
    "def process_large_dataset(data_list: list, metadata: str) -> dict:\n",
    "    \"\"\"Process large datasets while keeping logs manageable.\"\"\"\n",
    "    return {\n",
    "        \"processed_count\": len(data_list),\n",
    "        \"metadata_length\": len(metadata),\n",
    "        \"summary\": f\"Processed {len(data_list)} items\"\n",
    "    }\n",
    "\n",
    "# ğŸ¯ Example 3: Sensitive Configuration Filtering\n",
    "def filter_sensitive_config(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Remove sensitive configuration from logs.\"\"\"\n",
    "    processed = inputs.copy()\n",
    "    \n",
    "    # List of sensitive keys to redact\n",
    "    sensitive_keys = ['api_key', 'password', 'secret', 'token', 'private_key']\n",
    "    \n",
    "    for key in list(processed.keys()):\n",
    "        if any(sensitive in key.lower() for sensitive in sensitive_keys):\n",
    "            processed[key] = '<REDACTED>'\n",
    "        elif isinstance(processed[key], dict):\n",
    "            # Recursively filter nested dictionaries\n",
    "            processed[key] = filter_sensitive_config({'nested': processed[key]})['nested']\n",
    "    \n",
    "    return processed\n",
    "\n",
    "@weave.op(postprocess_inputs=filter_sensitive_config)\n",
    "def configure_api_client(api_key: str, endpoint: str, secret_token: str) -> dict:\n",
    "    \"\"\"Configure API client while hiding sensitive data in logs.\"\"\"\n",
    "    return {\n",
    "        \"endpoint\": endpoint,\n",
    "        \"configured\": True,\n",
    "        \"auth_method\": \"token\"\n",
    "    }\n",
    "\n",
    "# ğŸ”„ Example 4: Data Transformation for Logging\n",
    "def transform_for_logging(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Transform data to a more readable format for logs.\"\"\"\n",
    "    processed = inputs.copy()\n",
    "    \n",
    "    # Convert complex objects to readable summaries\n",
    "    for key, value in processed.items():\n",
    "        if hasattr(value, '__dict__'):\n",
    "            # Convert objects to their string representation\n",
    "            processed[key] = {\n",
    "                \"type\": type(value).__name__,\n",
    "                \"summary\": str(value)[:100],\n",
    "                \"attributes\": list(vars(value).keys()) if hasattr(value, '__dict__') else []\n",
    "            }\n",
    "    \n",
    "    return processed\n",
    "\n",
    "def enhance_output_logging(output: Any) -> Any:\n",
    "    \"\"\"Add metadata to output for better logging.\"\"\"\n",
    "    if isinstance(output, dict):\n",
    "        enhanced = output.copy()\n",
    "        enhanced[\"_logged_at\"] = \"workshop_demo\"\n",
    "        enhanced[\"_output_type\"] = \"processed_result\"\n",
    "        return enhanced\n",
    "    return output\n",
    "\n",
    "@weave.op(\n",
    "    postprocess_inputs=transform_for_logging,\n",
    "    postprocess_output=enhance_output_logging\n",
    ")\n",
    "def complex_data_processor(user_object: Any, config: dict) -> dict:\n",
    "    \"\"\"Process complex data with enhanced logging.\"\"\"\n",
    "    return {\n",
    "        \"status\": \"completed\",\n",
    "        \"config_keys\": list(config.keys()) if isinstance(config, dict) else [],\n",
    "        \"user_data_processed\": True\n",
    "    }\n",
    "\n",
    "# ğŸ§ª Let's test all the serialization controls!\n",
    "print(\"ğŸ”’ Testing custom serialization and privacy controls...\")\n",
    "\n",
    "# Test 1: PII Redaction\n",
    "print(\"\\nğŸ“§ Testing PII redaction...\")\n",
    "sensitive_email = \"\"\"\n",
    "Hi Support,\n",
    "My name is John Smith and my email is john.smith@company.com.\n",
    "My phone number is 555-123-4567 and SSN is 123-45-6789.\n",
    "Please help with my ProWidget issue!\n",
    "\"\"\"\n",
    "\n",
    "result1 = analyze_sensitive_email(sensitive_email)\n",
    "print(\"âœ… PII redacted in logs (check Weave UI)\")\n",
    "\n",
    "# Test 2: Large Object Handling  \n",
    "print(\"\\nğŸ“¦ Testing large object handling...\")\n",
    "large_data = list(range(1000))  # Large list\n",
    "long_text = \"This is a very long string. \" * 100  # Long string\n",
    "\n",
    "result2 = process_large_dataset(large_data, long_text)\n",
    "print(f\"âœ… Large objects summarized: {result2}\")\n",
    "\n",
    "# Test 3: Sensitive Configuration\n",
    "print(\"\\nğŸ” Testing sensitive config filtering...\")\n",
    "result3 = configure_api_client(\n",
    "    api_key=\"secret_key_12345\",\n",
    "    endpoint=\"https://api.example.com\",\n",
    "    secret_token=\"super_secret_token\"\n",
    ")\n",
    "print(f\"âœ… Sensitive config filtered: {result3}\")\n",
    "\n",
    "# Test 4: Data Transformation\n",
    "print(\"\\nğŸ”„ Testing data transformation...\")\n",
    "class SampleObject:\n",
    "    def __init__(self):\n",
    "        self.name = \"test\"\n",
    "        self.value = 42\n",
    "\n",
    "sample_obj = SampleObject()\n",
    "sample_config = {\"debug\": True, \"timeout\": 30}\n",
    "\n",
    "result4 = complex_data_processor(sample_obj, sample_config)\n",
    "print(f\"âœ… Data transformed for logging: {result4}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Check the Weave UI to see:\")\n",
    "print(\"  - ğŸ”’ PII automatically redacted in input/output logs\")\n",
    "print(\"  - ğŸ“¦ Large objects summarized instead of fully logged\")\n",
    "print(\"  - ğŸ” Sensitive configuration keys hidden\")\n",
    "print(\"  - ğŸ”„ Complex objects transformed to readable summaries\")\n",
    "print(\"  - ğŸ“Š Enhanced metadata added to outputs\")\n",
    "\n",
    "print(\"\\nğŸ¯ Key Benefits:\")\n",
    "print(\"  - Protect sensitive data while maintaining observability\")\n",
    "print(\"  - Keep logs manageable by summarizing large objects\")\n",
    "print(\"  - Customize logging format for better readability\")\n",
    "print(\"  - Maintain compliance with privacy regulations\")\n",
    "print(\"  - Debug effectively without exposing secrets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aa03a0",
   "metadata": {},
   "source": [
    "### ğŸ”— Part 1.5: OpenTelemetry Integration\n",
    "\n",
    "Weave supports OpenTelemetry (OTEL) traces, allowing you to integrate with existing observability infrastructure.\n",
    "Send OTLP-formatted traces directly to Weave alongside your native Weave traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74f9f042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Testing OpenTelemetry integration with Weave...\n",
      "ğŸ“ OTEL Setup (demo mode - would need real credentials):\n",
      "  - Endpoint: https://trace.wandb.ai/otel/v1/traces\n",
      "  - Headers: Authorization + project_id\n",
      "  - Format: OTLP (OpenTelemetry Protocol)\n",
      "\n",
      "ğŸ¯ Benefits of OTEL + Weave:\n",
      "  - ğŸ“Š Unified observability across your entire stack\n",
      "  - ğŸ”„ Correlate Weave AI traces with infrastructure traces\n",
      "  - ğŸ¢ Enterprise-ready observability standards\n",
      "  - ğŸ”— Connect with existing monitoring tools (Jaeger, Zipkin, etc.)\n",
      "\n",
      "âœ… Weave trace: Weave processed: workshop example\n",
      "\n",
      "ğŸ’¡ In the Weave UI, you would see:\n",
      "  - Native Weave traces with full AI context\n",
      "  - OTEL traces with custom spans and attributes\n",
      "  - Unified timeline showing both trace types\n",
      "  - Ability to correlate AI operations with system performance\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "# ğŸ”— Configure OTEL to send traces to Weave\n",
    "def setup_otel_for_weave(project_name: str = \"weave-workshop\"):\n",
    "    \"\"\"Set up OpenTelemetry to send traces to Weave.\"\"\"\n",
    "    \n",
    "    # Weave OTEL endpoint\n",
    "    PROJECT_ID = f\"timssweeney/{project_name}\"  # Replace with your entity\n",
    "    OTEL_ENDPOINT = \"https://trace.wandb.ai/otel/v1/traces\"\n",
    "    \n",
    "    # Authentication (in real usage, get from environment)\n",
    "    WANDB_API_KEY = os.environ.get(\"WANDB_API_KEY\", \"502b7a882a9cf2e5c40e162c515ab2c88f7258e9\")\n",
    "    auth = base64.b64encode(f\"api:{WANDB_API_KEY}\".encode()).decode()\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Basic {auth}\",\n",
    "        \"project_id\": PROJECT_ID,\n",
    "    }\n",
    "    \n",
    "    # Create tracer provider\n",
    "    tracer_provider = trace_sdk.TracerProvider()\n",
    "    \n",
    "    # Configure OTLP exporter for Weave\n",
    "    exporter = OTLPSpanExporter(\n",
    "        endpoint=OTEL_ENDPOINT,\n",
    "        headers=headers,\n",
    "    )\n",
    "    \n",
    "    tracer_provider.add_span_processor(SimpleSpanProcessor(exporter))\n",
    "    trace.set_tracer_provider(tracer_provider)\n",
    "    \n",
    "    return trace.get_tracer(__name__)\n",
    "\n",
    "# ğŸ¯ Example: Mixed Weave + OTEL tracing\n",
    "@weave.op\n",
    "def weave_function(data: str) -> str:\n",
    "    \"\"\"A function traced by Weave.\"\"\"\n",
    "    return f\"Weave processed: {data}\"\n",
    "\n",
    "def otel_function(tracer, data: str) -> str:\n",
    "    \"\"\"A function traced by OpenTelemetry.\"\"\"\n",
    "    with tracer.start_as_current_span(\"otel_processing\") as span:\n",
    "        span.set_attribute(\"input.data\", data)\n",
    "        span.set_attribute(\"processing.type\", \"otel\")\n",
    "        \n",
    "        result = f\"OTEL processed: {data}\"\n",
    "        span.set_attribute(\"output.result\", result)\n",
    "        return result\n",
    "\n",
    "\n",
    "tracer = setup_otel_for_weave()\n",
    "otel_function(tracer, \"Hello from OTEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6560e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
