{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c9b481b",
   "metadata": {},
   "source": [
    "# Part 1: Tracing & Debugging with Weave\n",
    "\n",
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "Learn how to use Weave's automatic tracing capabilities to debug and monitor LLM applications.\n",
    "\n",
    "**In this section:**\n",
    "- ðŸ” **Function Tracing**: Automatically track function calls with `@weave.op`\n",
    "- ðŸ› **Nested Debugging**: Debug complex pipelines with call traces\n",
    "- âš ï¸ **Exception Tracking**: Monitor and debug failures\n",
    "- ðŸ–¼ï¸ **Media Support**: Trace multimodal applications with images and audio\n",
    "- ðŸ”’ **Custom Serialization**: Control what data gets logged\n",
    "- ðŸ”— **OpenTelemetry**: Integrate with existing observability tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44c52d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install dependencies and configure API keys.\n",
    "\n",
    "OpenAI API key can be found at https://platform.openai.com/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install wandb weave openai pydantic nest_asyncio opentelemetry-exporter-otlp 'weave[video_support]' set-env-colab-kaggle-dotenv -qqq\n",
    "\n",
    "import os\n",
    "from typing import Any\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from set_env import set_env\n",
    "\n",
    "import weave\n",
    "\n",
    "# Setup API keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize Weave - this creates your project and starts tracing\n",
    "weave_client = weave.init(\"weave-workshop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822a5ab4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## ðŸ” Part 1: Function Tracing\n",
    "\n",
    "Let's start by building a simple LLM application and see how Weave automatically tracks everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71713c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our data structure\n",
    "class CustomerEmail(BaseModel):\n",
    "    customer_name: str\n",
    "    product: str\n",
    "    issue: str\n",
    "    sentiment: str = Field(description=\"positive, neutral, or negative\")\n",
    "\n",
    "\n",
    "# ðŸŽ¯ Track functions with @weave.op\n",
    "@weave.op\n",
    "def analyze_customer_email(email: str) -> CustomerEmail:\n",
    "    \"\"\"Analyze a customer support email and extract key information.\"\"\"\n",
    "    client = OpenAI()\n",
    "\n",
    "    # ðŸ”¥ OpenAI calls are automatically traced by Weave!\n",
    "    # Weave integrates with dozens of popular AI libraries out of the box\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",  # Using mini model for cost efficiency\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Extract customer name, product, issue, and sentiment.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": email,\n",
    "            },\n",
    "        ],\n",
    "        response_format=CustomerEmail,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.parsed\n",
    "\n",
    "\n",
    "# Test the function\n",
    "test_email = \"\"\"\n",
    "Hi Support,\n",
    "\n",
    "I'm really frustrated! My new ProWidget 3000 stopped working after just 2 days.\n",
    "The screen went black and won't turn on no matter what I try.\n",
    "\n",
    "Please help!\n",
    "Sarah Johnson\n",
    "\"\"\"\n",
    "\n",
    "# ðŸš€ Run the function - Weave automatically tracks this call\n",
    "result = analyze_customer_email(test_email)\n",
    "print(f\"Customer: {result.customer_name}\")\n",
    "print(f\"Sentiment: {result.sentiment}\")\n",
    "print(\"âœ… Check the Weave UI to see the trace!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e7db36",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### ðŸ› Part 1.1: Nested Debugging\n",
    "\n",
    "Weave tracks nested function calls, making debugging easy. Let's build a more complex pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aaaba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op\n",
    "def preprocess_email(email: str) -> str:\n",
    "    \"\"\"Clean and standardize email text.\"\"\"\n",
    "    # Remove extra whitespace and normalize formatting\n",
    "    cleaned = \" \".join(email.split())\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def classify_urgency(email: str, sentiment: str) -> str:\n",
    "    \"\"\"Determine urgency level based on content and sentiment.\"\"\"\n",
    "    urgent_keywords = [\n",
    "        \"urgent\",\n",
    "        \"asap\",\n",
    "        \"immediately\",\n",
    "        \"frustrated\",\n",
    "        \"broken\",\n",
    "        \"stopped working\",\n",
    "    ]\n",
    "\n",
    "    # Check for urgent keywords in the email\n",
    "    email_lower = email.lower()\n",
    "    has_urgent_keywords = any(keyword in email_lower for keyword in urgent_keywords)\n",
    "\n",
    "    # Combine sentiment and keywords to determine urgency\n",
    "    if sentiment == \"negative\" and has_urgent_keywords:\n",
    "        return \"high\"\n",
    "    elif sentiment == \"negative\" or has_urgent_keywords:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"low\"\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def process_support_ticket(email: str) -> dict[str, Any]:\n",
    "    \"\"\"Complete support ticket processing pipeline.\"\"\"\n",
    "    # Step 1: Clean the email\n",
    "    cleaned_email = preprocess_email(email)\n",
    "\n",
    "    # Step 2: Analyze the email content\n",
    "    analysis = analyze_customer_email(cleaned_email)\n",
    "\n",
    "    # Step 3: Determine urgency level\n",
    "    urgency = classify_urgency(cleaned_email, analysis.sentiment)\n",
    "\n",
    "    # Return complete ticket information\n",
    "    return {\n",
    "        \"customer_name\": analysis.customer_name,\n",
    "        \"product\": analysis.product,\n",
    "        \"issue\": analysis.issue,\n",
    "        \"sentiment\": analysis.sentiment,\n",
    "        \"urgency\": urgency,\n",
    "        \"needs_immediate_attention\": urgency == \"high\",\n",
    "    }\n",
    "\n",
    "\n",
    "# ðŸ”— Run the pipeline - see the nested traces in Weave!\n",
    "ticket = process_support_ticket(test_email)\n",
    "print(f\"Urgency: {ticket['urgency']}\")\n",
    "print(f\"Needs immediate attention: {ticket['needs_immediate_attention']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4526b841",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### âš ï¸ Part 1.2: Exception Tracking\n",
    "\n",
    "Weave automatically tracks exceptions in nested function calls, making debugging easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbcd5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op\n",
    "def risky_operation(data: str) -> str:\n",
    "    \"\"\"A child operation that might fail.\"\"\"\n",
    "    if \"error\" in data.lower():\n",
    "        raise ValueError(f\"Found 'error' in data: {data}\")\n",
    "    if len(data) < 5:\n",
    "        raise ValueError(\"Data too short!\")\n",
    "    return f\"Processed: {data}\"\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def safe_processor(inputs: list[str]) -> dict[str, Any]:\n",
    "    \"\"\"A parent operation that handles child failures gracefully.\"\"\"\n",
    "    results = {\"successful\": [], \"failed\": []}\n",
    "\n",
    "    for i, data in enumerate(inputs):\n",
    "        try:\n",
    "            # Call the risky child operation\n",
    "            processed = risky_operation(data)\n",
    "            results[\"successful\"].append(\n",
    "                {\"index\": i, \"data\": data, \"result\": processed}\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Catch and log the exception - Weave tracks this!\n",
    "            results[\"failed\"].append({\"index\": i, \"data\": data, \"error\": str(e)})\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Test with mixed data - some will succeed, some will fail\n",
    "test_data = [\n",
    "    \"Valid data here\",  # âœ… Will succeed\n",
    "    \"err\",  # âŒ Too short\n",
    "    \"This contains error word\",  # âŒ Contains 'error'\n",
    "    \"Another good input\",  # âœ… Will succeed\n",
    "    \"bad\",  # âŒ Too short\n",
    "]\n",
    "\n",
    "result = safe_processor(test_data)\n",
    "print(f\"âœ… Successful: {len(result['successful'])}\")\n",
    "print(f\"âŒ Failed: {len(result['failed'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8f2845",
   "metadata": {},
   "source": [
    "### ðŸ–¼ï¸ Part 1.3: Media Support\n",
    "\n",
    "Weave automatically traces and logs various media types including images, videos, and audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6c0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import wave\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# ðŸ“¸ Image Support - Weave automatically logs PIL.Image objects\n",
    "@weave.op\n",
    "def generate_sample_image() -> Image.Image:\n",
    "    \"\"\"Generate a sample image using OpenAI DALL-E API.\"\"\"\n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=\"A cute robot learning about data science, digital art style\",\n",
    "        size=\"1024x1024\",\n",
    "        quality=\"standard\",\n",
    "        n=1,\n",
    "    )\n",
    "\n",
    "    # Download and return as PIL Image - Weave will automatically log this!\n",
    "    image_url = response.data[0].url\n",
    "    image_response = requests.get(image_url, stream=True)\n",
    "    image = Image.open(image_response.raw)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "# ðŸŽµ Audio Support - Weave automatically logs wave.Wave_read objects\n",
    "@weave.op\n",
    "def generate_sample_audio(text: str) -> wave.Wave_read:\n",
    "    \"\"\"Generate audio using OpenAI's text-to-speech API.\"\"\"\n",
    "    client = OpenAI()\n",
    "\n",
    "    with client.audio.speech.with_streaming_response.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"alloy\",\n",
    "        input=text,\n",
    "        response_format=\"wav\",\n",
    "    ) as response:\n",
    "        response.stream_to_file(\"sample_audio.wav\")\n",
    "\n",
    "    # Return wave file - Weave will automatically log this with audio player!\n",
    "    return wave.open(\"sample_audio.wav\", \"rb\")\n",
    "\n",
    "\n",
    "# ðŸŽ¬ Video Support - Weave automatically logs moviepy video clips\n",
    "@weave.op\n",
    "def create_sample_video():\n",
    "    \"\"\"Create a simple color-changing video using moviepy.\"\"\"\n",
    "    try:\n",
    "        from moviepy.editor import ColorClip, VideoFileClip, concatenate_videoclips\n",
    "\n",
    "        # Create a sequence of colored clips that change over time\n",
    "        colors = [\n",
    "            (255, 100, 100),  # Red\n",
    "            (100, 255, 100),  # Green\n",
    "            (100, 100, 255),  # Blue\n",
    "            (255, 255, 100),  # Yellow\n",
    "            (255, 100, 255),  # Magenta\n",
    "        ]\n",
    "\n",
    "        # Create individual color clips (each 0.6 seconds)\n",
    "        clips = []\n",
    "        for color in colors:\n",
    "            clip = ColorClip(size=(640, 480), color=color, duration=0.6)\n",
    "            clips.append(clip)\n",
    "\n",
    "        # Concatenate all clips into one video\n",
    "        video = concatenate_videoclips(clips)\n",
    "\n",
    "        # Return video clip - Weave will automatically log this!\n",
    "        video_path = \"./sample_video.mp4\"\n",
    "        video.write_videofile(video_path, fps=24)\n",
    "        return VideoFileClip(video_path, has_mask=False, audio=True)\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"ðŸ“¹ MoviePy not installed. Install with: pip install moviepy\")\n",
    "        return \"Video creation skipped - moviepy not available\"\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ“¹ Video creation failed: {str(e)}\")\n",
    "        return \"Video creation skipped - error occurred\"\n",
    "\n",
    "\n",
    "# ðŸ” Multimodal Analysis - Combining image and text\n",
    "@weave.op\n",
    "def analyze_image_with_gpt4_vision(image: Image.Image, question: str) -> str:\n",
    "    \"\"\"Analyze an image using GPT-4 Vision.\"\"\"\n",
    "    client = OpenAI()\n",
    "\n",
    "    # Convert PIL image to base64 for API\n",
    "    import io\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format=\"PNG\")\n",
    "    image_base64 = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # Supports vision\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": question},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"},\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=300,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# Generate and analyze media\n",
    "sample_image = generate_sample_image()\n",
    "print(f\"ðŸ“¸ Generated image: {sample_image.size}\")\n",
    "\n",
    "analysis = analyze_image_with_gpt4_vision(\n",
    "    sample_image, \"What do you see in this image? Describe it in one sentence.\"\n",
    ")\n",
    "print(f\"ðŸ¤– Analysis: {analysis}\")\n",
    "\n",
    "sample_audio = generate_sample_audio(\n",
    "    \"Welcome to the Weave workshop! This audio will be automatically logged.\"\n",
    ")\n",
    "print(\"ðŸŽµ Generated audio file\")\n",
    "\n",
    "sample_video = create_sample_video()\n",
    "print(\"ðŸŽ¬ Generated video clip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cddbbe",
   "metadata": {},
   "source": [
    "### ðŸ”’ Part 1.4: Custom Serialization\n",
    "\n",
    "Control what gets logged with custom serialization functions.\n",
    "Perfect for PII redaction, large object handling, and sensitive data filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Any, Dict\n",
    "\n",
    "\n",
    "# ðŸ” Example 1: PII Redaction\n",
    "def redact_pii_inputs(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Redact PII from inputs before logging.\"\"\"\n",
    "    processed = inputs.copy()\n",
    "\n",
    "    if \"email_content\" in processed:\n",
    "        text = processed[\"email_content\"]\n",
    "        # Redact email addresses\n",
    "        text = re.sub(\n",
    "            r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\", \"<EMAIL>\", text\n",
    "        )\n",
    "        # Redact phone numbers\n",
    "        text = re.sub(r\"\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b\", \"<PHONE>\", text)\n",
    "        # Redact SSN\n",
    "        text = re.sub(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\", \"<SSN>\", text)\n",
    "        processed[\"email_content\"] = text\n",
    "\n",
    "    return processed\n",
    "\n",
    "\n",
    "def redact_pii_output(output: Any) -> Any:\n",
    "    \"\"\"Redact PII from outputs before logging.\"\"\"\n",
    "    if hasattr(output, \"customer_name\"):\n",
    "        # Create a copy and redact the name\n",
    "        output_dict = output.model_dump() if hasattr(output, \"dict\") else output\n",
    "        if isinstance(output_dict, dict) and \"customer_name\" in output_dict:\n",
    "            output_dict[\"customer_name\"] = \"<CUSTOMER_NAME>\"\n",
    "        return output_dict\n",
    "    return output\n",
    "\n",
    "\n",
    "@weave.op(postprocess_inputs=redact_pii_inputs, postprocess_output=redact_pii_output)\n",
    "def analyze_sensitive_email(email_content: str) -> CustomerEmail:\n",
    "    \"\"\"Analyze email while protecting PII in logs.\"\"\"\n",
    "    return analyze_customer_email(email_content)\n",
    "\n",
    "\n",
    "# ðŸ“¦ Example 2: Large Object Handling\n",
    "def summarize_large_inputs(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Summarize large objects to avoid logging huge data.\"\"\"\n",
    "    processed = inputs.copy()\n",
    "\n",
    "    for key, value in processed.items():\n",
    "        if isinstance(value, (list, tuple)) and len(value) > 10:\n",
    "            # Only log first/last few items for large lists\n",
    "            processed[key] = {\n",
    "                \"type\": f\"{type(value).__name__}\",\n",
    "                \"length\": len(value),\n",
    "                \"sample_start\": value[:3],\n",
    "                \"sample_end\": value[-3:],\n",
    "                \"note\": \"Large object truncated for logging\",\n",
    "            }\n",
    "        elif isinstance(value, str) and len(value) > 1000:\n",
    "            # Truncate very long strings\n",
    "            processed[key] = {\n",
    "                \"type\": \"string\",\n",
    "                \"length\": len(value),\n",
    "                \"preview\": value[:200] + \"...\",\n",
    "                \"note\": \"Long string truncated for logging\",\n",
    "            }\n",
    "\n",
    "    return processed\n",
    "\n",
    "\n",
    "@weave.op(postprocess_inputs=summarize_large_inputs)\n",
    "def process_large_dataset(data_list: list, metadata: str) -> dict:\n",
    "    \"\"\"Process large datasets while keeping logs manageable.\"\"\"\n",
    "    return {\n",
    "        \"processed_count\": len(data_list),\n",
    "        \"metadata_length\": len(metadata),\n",
    "        \"summary\": f\"Processed {len(data_list)} items\",\n",
    "    }\n",
    "\n",
    "\n",
    "# ðŸ”‘ Example 3: Sensitive Configuration Filtering\n",
    "def filter_sensitive_config(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Remove sensitive configuration from logs.\"\"\"\n",
    "    processed = inputs.copy()\n",
    "    # List of sensitive keys to redact\n",
    "    sensitive_keys = [\"api_key\", \"password\", \"secret\", \"token\", \"private_key\"]\n",
    "\n",
    "    for key in list(processed.keys()):\n",
    "        if any(sensitive in key.lower() for sensitive in sensitive_keys):\n",
    "            processed[key] = \"<REDACTED>\"\n",
    "        elif isinstance(processed[key], dict):\n",
    "            # Recursively filter nested dictionaries\n",
    "            processed[key] = filter_sensitive_config({\"nested\": processed[key]})[\n",
    "                \"nested\"\n",
    "            ]\n",
    "\n",
    "    return processed\n",
    "\n",
    "\n",
    "@weave.op(postprocess_inputs=filter_sensitive_config)\n",
    "def configure_api_client(api_key: str, endpoint: str, secret_token: str) -> dict:\n",
    "    \"\"\"Configure API client while hiding sensitive data in logs.\"\"\"\n",
    "    return {\"endpoint\": endpoint, \"configured\": True, \"auth_method\": \"token\"}\n",
    "\n",
    "\n",
    "# ðŸ§ª Test serialization controls\n",
    "sensitive_email = \"\"\"\n",
    "Hi Support,\n",
    "My name is John Smith and my email is john.smith@company.com.\n",
    "My phone number is 555-123-4567 and SSN is 123-45-6789.\n",
    "Please help with my ProWidget issue!\n",
    "\"\"\"\n",
    "\n",
    "result1 = analyze_sensitive_email(sensitive_email)\n",
    "print(\"âœ… PII redacted in logs (check Weave UI)\")\n",
    "\n",
    "large_data = list(range(1000))  # Large list\n",
    "long_text = \"This is a very long string. \" * 100  # Long string\n",
    "result2 = process_large_dataset(large_data, long_text)\n",
    "print(\"âœ… Large objects summarized\")\n",
    "\n",
    "result3 = configure_api_client(\n",
    "    api_key=\"secret_key_12345\",\n",
    "    endpoint=\"https://api.example.com\",\n",
    "    secret_token=\"super_secret_token\",\n",
    ")\n",
    "print(\"âœ… Sensitive config filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd6a7e4",
   "metadata": {},
   "source": [
    "### ðŸ”— Part 1.5: OpenTelemetry Integration\n",
    "\n",
    "Weave supports OpenTelemetry traces, allowing integration with existing observability infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99264af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "\n",
    "# ðŸ”§ Configure OTEL to send traces to Weave\n",
    "def setup_otel_for_weave(\n",
    "    entity: str,\n",
    "    project: str,\n",
    "    api_key,\n",
    "    endpoint: str = \"https://trace.wandb.ai/otel/v1/traces\",\n",
    "):\n",
    "    \"\"\"Set up OpenTelemetry to send traces to Weave.\"\"\"\n",
    "    if not entity:\n",
    "        raise ValueError(\"Entity is required\")\n",
    "    if not project:\n",
    "        raise ValueError(\"Project is required\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API key is required\")\n",
    "\n",
    "    auth = base64.b64encode(f\"api:{api_key}\".encode()).decode()\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Basic {auth}\",\n",
    "        \"project_id\": f\"{entity}/{project}\",\n",
    "    }\n",
    "\n",
    "    # Create tracer provider\n",
    "    tracer_provider = trace_sdk.TracerProvider()\n",
    "\n",
    "    # Configure OTLP exporter for Weave\n",
    "    exporter = OTLPSpanExporter(endpoint=endpoint, headers=headers)\n",
    "    tracer_provider.add_span_processor(SimpleSpanProcessor(exporter))\n",
    "    trace.set_tracer_provider(tracer_provider)\n",
    "\n",
    "    return trace.get_tracer(__name__)\n",
    "\n",
    "\n",
    "def otel_function(tracer, data: str) -> str:\n",
    "    \"\"\"A function traced by OpenTelemetry.\"\"\"\n",
    "    with tracer.start_as_current_span(\"otel_processing\") as span:\n",
    "        span.set_attribute(\"input.data\", data)\n",
    "        span.set_attribute(\"processing.type\", \"otel\")\n",
    "        result = f\"OTEL processed: {data}\"\n",
    "        span.set_attribute(\"output.result\", result)\n",
    "        return result\n",
    "\n",
    "\n",
    "# Example OTEL integration\n",
    "api_key = set_env(\"WANDB_API_KEY\")\n",
    "# FILL OUT ENTITY BELOW\n",
    "tracer = setup_otel_for_weave(entity=\"\", project=\"weave-workshop\", api_key=api_key)\n",
    "otel_function(tracer, \"Hello from OTEL\")\n",
    "\n",
    "print(\"ðŸ”— OpenTelemetry integration example completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91e2dce",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned how to use Weave's tracing capabilities:\n",
    "\n",
    "- âœ… **Function Tracing**: Use `@weave.op` to automatically track function calls\n",
    "- âœ… **Nested Debugging**: Debug complex pipelines with automatic call traces\n",
    "- âœ… **Exception Tracking**: Monitor failures with full context preservation\n",
    "- âœ… **Media Support**: Trace multimodal applications with automatic media logging\n",
    "- âœ… **Custom Serialization**: Control data logging with preprocessing functions\n",
    "- âœ… **OpenTelemetry**: Integrate with existing observability infrastructure\n",
    "\n",
    "**Next Steps:**\n",
    "- Continue to Part 2: Evaluations to learn systematic testing and model comparison\n",
    "- Check the Weave UI to explore your traces and debug your applications\n",
    "- Try tracing your own LLM applications with `@weave.op`\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Tracing is automatic with `@weave.op` - no manual logging required\n",
    "- Weave integrates with 20+ popular AI libraries out of the box\n",
    "- Rich debugging context helps you understand exactly what happened\n",
    "- Production-ready features like PII redaction and custom serialization"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
