{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "033e2bef",
   "metadata": {},
   "source": [
    "# Part 1: Tracing & Debugging with Weave\n",
    "\n",
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "Learn how to use Weave's automatic tracing capabilities to debug and monitor LLM applications.\n",
    "\n",
    "**In this section:**\n",
    "- ðŸ” **Function Tracing**: Automatically track function calls with `@weave.op`\n",
    "- ðŸ› **Nested Debugging**: Debug complex pipelines with call traces\n",
    "- âš ï¸ **Exception Tracking**: Monitor and debug failures\n",
    "- ðŸ–¼ï¸ **Media Support**: Trace multimodal applications with images and audio\n",
    "- ðŸ”’ **Custom Serialization**: Control what data gets logged\n",
    "- ðŸ”— **OpenTelemetry**: Integrate with existing observability tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd242d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install dependencies and configure API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd8354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install wandb weave openai pydantic nest_asyncio opentelemetry-exporter-otlp 'weave[video_support]' -qqq\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "from typing import Any\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import weave\n",
    "\n",
    "# ðŸ”‘ Setup your API keys\n",
    "print(\"ðŸ“ Setting up API keys...\")\n",
    "\n",
    "# Weights & Biases will automatically prompt if needed\n",
    "# It checks: 1) WANDB_API_KEY env var, 2) ~/.netrc, 3) prompts user\n",
    "print(\"âœ… W&B authentication will be handled automatically by Weave\")\n",
    "print(\"   (Optional: You can set WANDB_API_KEY env variable if you prefer)\")\n",
    "\n",
    "# OpenAI requires manual setup\n",
    "print(\"\\nðŸ¤– OpenAI Setup:\")\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\n",
    "        \"You can generate your OpenAI API key here: https://platform.openai.com/api-keys\"\n",
    "    )\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "else:\n",
    "    print(\"âœ… OpenAI API key found in environment\")\n",
    "\n",
    "print(\"\\n---\")\n",
    "\n",
    "# ðŸ  Initialize your W&B project\n",
    "print(\"ðŸ Initializing Weave...\")\n",
    "weave_client = weave.init(\"weave-workshop\")  # ðŸ Your W&B project name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06db38ec",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## ðŸ” Part 1: Tracing & Debugging with Weave\n",
    "\n",
    "Let's start by building a simple LLM application and see how Weave automatically tracks everything.\n",
    "\n",
    "Note: We're using `gpt-4o-mini` which supports structured outputs while being cost-effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb90efd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define our data structure\n",
    "class CustomerEmail(BaseModel):\n",
    "    customer_name: str\n",
    "    product: str\n",
    "    issue: str\n",
    "    sentiment: str = Field(description=\"positive, neutral, or negative\")\n",
    "\n",
    "\n",
    "# ðŸ Track functions with @weave.op\n",
    "@weave.op\n",
    "def analyze_customer_email(email: str) -> CustomerEmail:\n",
    "    \"\"\"Analyze a customer support email and extract key information.\"\"\"\n",
    "    client = OpenAI()\n",
    "\n",
    "    # ðŸŽ¯ Note: OpenAI calls are automatically traced by Weave!\n",
    "    # Weave automatically integrates with dozens of popular libraries including:\n",
    "    # OpenAI, Anthropic, LangChain, LlamaIndex, HuggingFace, and more\n",
    "    # See full list: https://weave-docs.wandb.ai/guides/integrations/\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",  # Using mini model for cost efficiency\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Extract customer name, product, issue, and sentiment.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": email,\n",
    "            },\n",
    "        ],\n",
    "        response_format=CustomerEmail,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.parsed\n",
    "\n",
    "\n",
    "# Let's test it!\n",
    "test_email = \"\"\"\n",
    "Hi Support,\n",
    "\n",
    "I'm really frustrated! My new ProWidget 3000 stopped working after just 2 days.\n",
    "The screen went completely black and won't turn on no matter what I try.\n",
    "\n",
    "Please help!\n",
    "Sarah Johnson\n",
    "\"\"\"\n",
    "\n",
    "# ðŸŽ¯ Run the function - Weave will automatically track this call\n",
    "result = analyze_customer_email(test_email)\n",
    "print(\"âœ… Analysis complete!\")\n",
    "print(f\"Customer: {result.customer_name}\")\n",
    "print(f\"Sentiment: {result.sentiment}\")\n",
    "print(\"\\nðŸ” Check the Weave UI to see the trace!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672b4f29",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### ðŸ› Part 1.1: Debugging with Call Traces\n",
    "\n",
    "Weave tracks nested function calls, making debugging easy. Let's build a more complex example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2c59e8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "@weave.op\n",
    "def preprocess_email(email: str) -> str:\n",
    "    \"\"\"Clean and standardize email text.\"\"\"\n",
    "    # Remove extra whitespace\n",
    "    cleaned = \" \".join(email.split())\n",
    "    # Add some metadata for debugging\n",
    "    print(f\"ðŸ“§ Original length: {len(email)}, Cleaned length: {len(cleaned)}\")\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def classify_urgency(email: str, sentiment: str) -> str:\n",
    "    \"\"\"Determine urgency level based on content and sentiment.\"\"\"\n",
    "    urgent_keywords = [\n",
    "        \"urgent\",\n",
    "        \"asap\",\n",
    "        \"immediately\",\n",
    "        \"frustrated\",\n",
    "        \"broken\",\n",
    "        \"stopped working\",\n",
    "    ]\n",
    "\n",
    "    # Check for urgent keywords\n",
    "    email_lower = email.lower()\n",
    "    has_urgent_keywords = any(keyword in email_lower for keyword in urgent_keywords)\n",
    "\n",
    "    if sentiment == \"negative\" and has_urgent_keywords:\n",
    "        return \"high\"\n",
    "    elif sentiment == \"negative\" or has_urgent_keywords:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"low\"\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def process_support_ticket(email: str) -> dict[str, Any]:\n",
    "    \"\"\"Complete support ticket processing pipeline.\"\"\"\n",
    "    # Step 1: Clean the email\n",
    "    cleaned_email = preprocess_email(email)\n",
    "\n",
    "    # Step 2: Analyze the email\n",
    "    analysis = analyze_customer_email(cleaned_email)\n",
    "\n",
    "    # Step 3: Determine urgency\n",
    "    urgency = classify_urgency(cleaned_email, analysis.sentiment)\n",
    "\n",
    "    # Return complete ticket info\n",
    "    return {\n",
    "        \"customer_name\": analysis.customer_name,\n",
    "        \"product\": analysis.product,\n",
    "        \"issue\": analysis.issue,\n",
    "        \"sentiment\": analysis.sentiment,\n",
    "        \"urgency\": urgency,\n",
    "        \"needs_immediate_attention\": urgency == \"high\",\n",
    "    }\n",
    "\n",
    "\n",
    "# ðŸŽ¯ Run the pipeline - see the nested traces in Weave!\n",
    "ticket = process_support_ticket(test_email)\n",
    "print(\"\\nðŸŽ« Ticket processed!\")\n",
    "print(f\"Urgency: {ticket['urgency']}\")\n",
    "print(f\"Needs immediate attention: {ticket['needs_immediate_attention']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd1946",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### ðŸž Part 1.2: Exception Tracking\n",
    "\n",
    "Weave automatically tracks exceptions in nested function calls, making debugging easy.\n",
    "Let's see how exceptions flow through parent and child operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea50cc9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "@weave.op\n",
    "def risky_operation(data: str) -> str:\n",
    "    \"\"\"A child operation that might fail.\"\"\"\n",
    "    if \"error\" in data.lower():\n",
    "        raise ValueError(f\"Found 'error' in data: {data}\")\n",
    "    if len(data) < 5:\n",
    "        raise ValueError(\"Data too short!\")\n",
    "    return f\"Processed: {data}\"\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def safe_processor(inputs: list[str]) -> dict[str, Any]:\n",
    "    \"\"\"A parent operation that handles child failures gracefully.\"\"\"\n",
    "    results = {\"successful\": [], \"failed\": []}\n",
    "\n",
    "    for i, data in enumerate(inputs):\n",
    "        try:\n",
    "            # Call the risky child operation\n",
    "            processed = risky_operation(data)\n",
    "            results[\"successful\"].append(\n",
    "                {\"index\": i, \"data\": data, \"result\": processed}\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Catch and log the exception\n",
    "            results[\"failed\"].append({\"index\": i, \"data\": data, \"error\": str(e)})\n",
    "            print(f\"âŒ Failed to process item {i}: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Test with mixed data - some will succeed, some will fail\n",
    "test_data = [\n",
    "    \"Valid data here\",  # âœ… Will succeed\n",
    "    \"err\",  # âŒ Too short\n",
    "    \"This contains error word\",  # âŒ Contains 'error'\n",
    "    \"Another good input\",  # âœ… Will succeed\n",
    "    \"bad\",  # âŒ Too short\n",
    "]\n",
    "\n",
    "print(\"ðŸž Testing exception tracking in nested operations...\")\n",
    "result = safe_processor(test_data)\n",
    "\n",
    "print(\"\\nðŸ“Š Results:\")\n",
    "print(f\"âœ… Successful: {len(result['successful'])}\")\n",
    "print(f\"âŒ Failed: {len(result['failed'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4686904",
   "metadata": {},
   "source": [
    "### ðŸŽ¬ Part 1.3: Media Support & Multimodal Tracing\n",
    "\n",
    "Weave can automatically trace and log various media types including images, videos, audio, and PDFs.\n",
    "This is especially useful for multimodal AI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7de0fb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Let's demonstrate media support with different types\n",
    "import base64\n",
    "import wave\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# ðŸ“¸ Image Support - Weave automatically logs PIL.Image objects\n",
    "@weave.op\n",
    "def generate_sample_image() -> Image.Image:\n",
    "    \"\"\"Generate a sample image using OpenAI DALL-E API.\"\"\"\n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=\"A cute robot learning about data science, digital art style\",\n",
    "        size=\"1024x1024\",\n",
    "        quality=\"standard\",\n",
    "        n=1,\n",
    "    )\n",
    "\n",
    "    # Download and return as PIL Image - Weave will automatically log this!\n",
    "    image_url = response.data[0].url\n",
    "    image_response = requests.get(image_url, stream=True)\n",
    "    image = Image.open(image_response.raw)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "# ðŸŽµ Audio Support - Weave automatically logs wave.Wave_read objects\n",
    "@weave.op\n",
    "def generate_sample_audio(text: str) -> wave.Wave_read:\n",
    "    \"\"\"Generate audio using OpenAI's text-to-speech API.\"\"\"\n",
    "    client = OpenAI()\n",
    "\n",
    "    with client.audio.speech.with_streaming_response.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"alloy\",\n",
    "        input=text,\n",
    "        response_format=\"wav\",\n",
    "    ) as response:\n",
    "        response.stream_to_file(\"sample_audio.wav\")\n",
    "\n",
    "    # Return wave file - Weave will automatically log this with audio player!\n",
    "    return wave.open(\"sample_audio.wav\", \"rb\")\n",
    "\n",
    "\n",
    "# ðŸ–¼ï¸ Multimodal Analysis - Combining image and text\n",
    "@weave.op\n",
    "def analyze_image_with_gpt4_vision(image: Image.Image, question: str) -> str:\n",
    "    \"\"\"Analyze an image using GPT-4 Vision.\"\"\"\n",
    "    client = OpenAI()\n",
    "\n",
    "    # Convert PIL image to base64 for API\n",
    "    import io\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format=\"PNG\")\n",
    "    image_base64 = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # Supports vision\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": question},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"},\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=300,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# Test image generation and analysis\n",
    "print(\"\\nðŸ“¸ Generating image...\")\n",
    "sample_image = generate_sample_image()\n",
    "print(f\"âœ… Generated image: {sample_image.size}\")\n",
    "\n",
    "print(\"\\nðŸ” Analyzing image with GPT-4 Vision...\")\n",
    "analysis = analyze_image_with_gpt4_vision(\n",
    "    sample_image, \"What do you see in this image? Describe it in one sentence.\"\n",
    ")\n",
    "print(f\"ðŸ¤– Analysis: {analysis}\")\n",
    "\n",
    "# Test audio generation\n",
    "print(\"\\nðŸŽµ Generating audio...\")\n",
    "sample_audio = generate_sample_audio(\n",
    "    \"Welcome to the Weave workshop! This audio will be automatically logged.\"\n",
    ")\n",
    "print(\"âœ… Generated audio file\")\n",
    "\n",
    "\n",
    "print(\"\\nðŸ’¡ Check the Weave UI to see:\")\n",
    "print(\"  - ðŸ“¸ Images displayed with thumbnails and full-size view\")\n",
    "print(\"  - ðŸŽµ Audio files with built-in audio player and waveform\")\n",
    "print(\"  - ðŸŽ¬ Video clips with video player (if moviepy available)\")\n",
    "print(\"  - ðŸ”— All media automatically linked to their function calls\")\n",
    "print(\"  - ðŸ“Š Media metadata (dimensions, duration, file size, etc.)\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Key Benefits:\")\n",
    "print(\"  - No manual upload needed - Weave handles everything automatically\")\n",
    "print(\"  - Media is preserved with full context of the function call\")\n",
    "print(\"  - Easy to debug multimodal AI applications\")\n",
    "print(\"  - Share results with team members through Weave UI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ca04a",
   "metadata": {},
   "source": [
    "### ðŸ”’ Part 1.4: Custom Serialization\n",
    "\n",
    "Control what gets logged and how with Weave's serialization features.\n",
    "Use `postprocess_inputs` and `postprocess_output` to customize what data gets stored.\n",
    "Perfect for PII redaction, large object handling, sensitive data filtering, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c599c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Any, Dict\n",
    "\n",
    "\n",
    "# ðŸ”’ Example 1: PII Redaction\n",
    "def redact_pii_inputs(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Redact PII from inputs before logging.\"\"\"\n",
    "    processed = inputs.copy()\n",
    "\n",
    "    if \"email_content\" in processed:\n",
    "        text = processed[\"email_content\"]\n",
    "        # Redact email addresses\n",
    "        text = re.sub(\n",
    "            r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\", \"<EMAIL>\", text\n",
    "        )\n",
    "        # Redact phone numbers\n",
    "        text = re.sub(r\"\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b\", \"<PHONE>\", text)\n",
    "        # Redact SSN\n",
    "        text = re.sub(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\", \"<SSN>\", text)\n",
    "        processed[\"email_content\"] = text\n",
    "\n",
    "    return processed\n",
    "\n",
    "\n",
    "def redact_pii_output(output: Any) -> Any:\n",
    "    \"\"\"Redact PII from outputs before logging.\"\"\"\n",
    "    if hasattr(output, \"customer_name\"):\n",
    "        # Create a copy and redact the name\n",
    "        output_dict = output.dict() if hasattr(output, \"dict\") else output\n",
    "        if isinstance(output_dict, dict) and \"customer_name\" in output_dict:\n",
    "            output_dict[\"customer_name\"] = \"<CUSTOMER_NAME>\"\n",
    "        return output_dict\n",
    "    return output\n",
    "\n",
    "\n",
    "@weave.op(postprocess_inputs=redact_pii_inputs, postprocess_output=redact_pii_output)\n",
    "def analyze_sensitive_email(email_content: str) -> CustomerEmail:\n",
    "    \"\"\"Analyze email while protecting PII in logs.\"\"\"\n",
    "    return analyze_customer_email(email_content)\n",
    "\n",
    "\n",
    "# ðŸ“¦ Example 2: Large Object Handling\n",
    "def summarize_large_inputs(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Summarize large objects to avoid logging huge data.\"\"\"\n",
    "    processed = inputs.copy()\n",
    "\n",
    "    for key, value in processed.items():\n",
    "        if isinstance(value, (list, tuple)) and len(value) > 10:\n",
    "            # Only log first/last few items for large lists\n",
    "            processed[key] = {\n",
    "                \"type\": f\"{type(value).__name__}\",\n",
    "                \"length\": len(value),\n",
    "                \"sample_start\": value[:3],\n",
    "                \"sample_end\": value[-3:],\n",
    "                \"note\": \"Large object truncated for logging\",\n",
    "            }\n",
    "        elif isinstance(value, str) and len(value) > 1000:\n",
    "            # Truncate very long strings\n",
    "            processed[key] = {\n",
    "                \"type\": \"string\",\n",
    "                \"length\": len(value),\n",
    "                \"preview\": value[:200] + \"...\",\n",
    "                \"note\": \"Long string truncated for logging\",\n",
    "            }\n",
    "\n",
    "    return processed\n",
    "\n",
    "\n",
    "@weave.op(postprocess_inputs=summarize_large_inputs)\n",
    "def process_large_dataset(data_list: list, metadata: str) -> dict:\n",
    "    \"\"\"Process large datasets while keeping logs manageable.\"\"\"\n",
    "    return {\n",
    "        \"processed_count\": len(data_list),\n",
    "        \"metadata_length\": len(metadata),\n",
    "        \"summary\": f\"Processed {len(data_list)} items\",\n",
    "    }\n",
    "\n",
    "\n",
    "# ðŸŽ¯ Example 3: Sensitive Configuration Filtering\n",
    "def filter_sensitive_config(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Remove sensitive configuration from logs.\"\"\"\n",
    "    processed = inputs.copy()\n",
    "\n",
    "    # List of sensitive keys to redact\n",
    "    sensitive_keys = [\"api_key\", \"password\", \"secret\", \"token\", \"private_key\"]\n",
    "\n",
    "    for key in list(processed.keys()):\n",
    "        if any(sensitive in key.lower() for sensitive in sensitive_keys):\n",
    "            processed[key] = \"<REDACTED>\"\n",
    "        elif isinstance(processed[key], dict):\n",
    "            # Recursively filter nested dictionaries\n",
    "            processed[key] = filter_sensitive_config({\"nested\": processed[key]})[\n",
    "                \"nested\"\n",
    "            ]\n",
    "\n",
    "    return processed\n",
    "\n",
    "\n",
    "@weave.op(postprocess_inputs=filter_sensitive_config)\n",
    "def configure_api_client(api_key: str, endpoint: str, secret_token: str) -> dict:\n",
    "    \"\"\"Configure API client while hiding sensitive data in logs.\"\"\"\n",
    "    return {\"endpoint\": endpoint, \"configured\": True, \"auth_method\": \"token\"}\n",
    "\n",
    "\n",
    "# ðŸ”„ Example 4: Data Transformation for Logging\n",
    "def transform_for_logging(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Transform data to a more readable format for logs.\"\"\"\n",
    "    processed = inputs.copy()\n",
    "\n",
    "    # Convert complex objects to readable summaries\n",
    "    for key, value in processed.items():\n",
    "        if hasattr(value, \"__dict__\"):\n",
    "            # Convert objects to their string representation\n",
    "            processed[key] = {\n",
    "                \"type\": type(value).__name__,\n",
    "                \"summary\": str(value)[:100],\n",
    "                \"attributes\": list(vars(value).keys())\n",
    "                if hasattr(value, \"__dict__\")\n",
    "                else [],\n",
    "            }\n",
    "\n",
    "    return processed\n",
    "\n",
    "\n",
    "def enhance_output_logging(output: Any) -> Any:\n",
    "    \"\"\"Add metadata to output for better logging.\"\"\"\n",
    "    if isinstance(output, dict):\n",
    "        enhanced = output.copy()\n",
    "        enhanced[\"_logged_at\"] = \"workshop_demo\"\n",
    "        enhanced[\"_output_type\"] = \"processed_result\"\n",
    "        return enhanced\n",
    "    return output\n",
    "\n",
    "\n",
    "@weave.op(\n",
    "    postprocess_inputs=transform_for_logging, postprocess_output=enhance_output_logging\n",
    ")\n",
    "def complex_data_processor(user_object: Any, config: dict) -> dict:\n",
    "    \"\"\"Process complex data with enhanced logging.\"\"\"\n",
    "    return {\n",
    "        \"status\": \"completed\",\n",
    "        \"config_keys\": list(config.keys()) if isinstance(config, dict) else [],\n",
    "        \"user_data_processed\": True,\n",
    "    }\n",
    "\n",
    "\n",
    "# ðŸ§ª Let's test all the serialization controls!\n",
    "print(\"ðŸ”’ Testing custom serialization and privacy controls...\")\n",
    "\n",
    "# Test 1: PII Redaction\n",
    "print(\"\\nðŸ“§ Testing PII redaction...\")\n",
    "sensitive_email = \"\"\"\n",
    "Hi Support,\n",
    "My name is John Smith and my email is john.smith@company.com.\n",
    "My phone number is 555-123-4567 and SSN is 123-45-6789.\n",
    "Please help with my ProWidget issue!\n",
    "\"\"\"\n",
    "\n",
    "result1 = analyze_sensitive_email(sensitive_email)\n",
    "print(\"âœ… PII redacted in logs (check Weave UI)\")\n",
    "\n",
    "# Test 2: Large Object Handling\n",
    "print(\"\\nðŸ“¦ Testing large object handling...\")\n",
    "large_data = list(range(1000))  # Large list\n",
    "long_text = \"This is a very long string. \" * 100  # Long string\n",
    "\n",
    "result2 = process_large_dataset(large_data, long_text)\n",
    "print(f\"âœ… Large objects summarized: {result2}\")\n",
    "\n",
    "# Test 3: Sensitive Configuration\n",
    "print(\"\\nðŸ” Testing sensitive config filtering...\")\n",
    "result3 = configure_api_client(\n",
    "    api_key=\"secret_key_12345\",\n",
    "    endpoint=\"https://api.example.com\",\n",
    "    secret_token=\"super_secret_token\",\n",
    ")\n",
    "print(f\"âœ… Sensitive config filtered: {result3}\")\n",
    "\n",
    "# Test 4: Data Transformation\n",
    "print(\"\\nðŸ”„ Testing data transformation...\")\n",
    "\n",
    "\n",
    "class SampleObject:\n",
    "    def __init__(self):\n",
    "        self.name = \"test\"\n",
    "        self.value = 42\n",
    "\n",
    "\n",
    "sample_obj = SampleObject()\n",
    "sample_config = {\"debug\": True, \"timeout\": 30}\n",
    "\n",
    "result4 = complex_data_processor(sample_obj, sample_config)\n",
    "print(f\"âœ… Data transformed for logging: {result4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8da2d91",
   "metadata": {},
   "source": [
    "### ðŸ”— Part 1.5: OpenTelemetry Integration\n",
    "\n",
    "Weave supports OpenTelemetry (OTEL) traces, allowing you to integrate with existing observability infrastructure.\n",
    "Send OTLP-formatted traces directly to Weave alongside your native Weave traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b041ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "ENTITY = ...\n",
    "\n",
    "\n",
    "# ðŸ”— Configure OTEL to send traces to Weave\n",
    "def setup_otel_for_weave(project_name: str = \"weave-workshop\"):\n",
    "    \"\"\"Set up OpenTelemetry to send traces to Weave.\"\"\"\n",
    "    # Weave OTEL endpoint\n",
    "    PROJECT_ID = f\"{ENTITY}/{project_name}\"  # Replace with your entity\n",
    "    OTEL_ENDPOINT = \"https://trace.wandb.ai/otel/v1/traces\"\n",
    "\n",
    "    # Authentication (in real usage, get from environment)\n",
    "    WANDB_API_KEY = os.environ.get(\"WANDB_API_KEY\", \"your-api-key\")\n",
    "    auth = base64.b64encode(f\"api:{WANDB_API_KEY}\".encode()).decode()\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Basic {auth}\",\n",
    "        \"project_id\": PROJECT_ID,\n",
    "    }\n",
    "\n",
    "    # Create tracer provider\n",
    "    tracer_provider = trace_sdk.TracerProvider()\n",
    "\n",
    "    # Configure OTLP exporter for Weave\n",
    "    exporter = OTLPSpanExporter(\n",
    "        endpoint=OTEL_ENDPOINT,\n",
    "        headers=headers,\n",
    "    )\n",
    "\n",
    "    tracer_provider.add_span_processor(SimpleSpanProcessor(exporter))\n",
    "    trace.set_tracer_provider(tracer_provider)\n",
    "\n",
    "    return trace.get_tracer(__name__)\n",
    "\n",
    "\n",
    "def otel_function(tracer, data: str) -> str:\n",
    "    \"\"\"A function traced by OpenTelemetry.\"\"\"\n",
    "    with tracer.start_as_current_span(\"otel_processing\") as span:\n",
    "        span.set_attribute(\"input.data\", data)\n",
    "        span.set_attribute(\"processing.type\", \"otel\")\n",
    "\n",
    "        result = f\"OTEL processed: {data}\"\n",
    "        span.set_attribute(\"output.result\", result)\n",
    "        return result\n",
    "\n",
    "\n",
    "tracer = setup_otel_for_weave()\n",
    "otel_function(tracer, \"Hello from OTEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5a67df",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned how to use Weave's tracing capabilities:\n",
    "\n",
    "- âœ… **Function Tracing**: Use `@weave.op` to automatically track function calls\n",
    "- âœ… **Nested Debugging**: Debug complex pipelines with automatic call traces\n",
    "- âœ… **Exception Tracking**: Monitor failures with full context preservation\n",
    "- âœ… **Media Support**: Trace multimodal applications with automatic media logging\n",
    "- âœ… **Custom Serialization**: Control data logging with preprocessing functions\n",
    "- âœ… **OpenTelemetry**: Integrate with existing observability infrastructure\n",
    "\n",
    "**Next Steps:**\n",
    "- **Continue to Part 2: Evaluations** to learn systematic testing and model comparison\n",
    "- Check the Weave UI to explore your traces and debug your applications\n",
    "- Try tracing your own LLM applications with `@weave.op`\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Tracing is automatic with `@weave.op` - no manual logging required\n",
    "- Weave integrates with 20+ popular AI libraries out of the box\n",
    "- Rich debugging context helps you understand exactly what happened\n",
    "- Production-ready features like PII redaction and custom serialization"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
