{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d410784c",
   "metadata": {},
   "source": [
    "# ğŸ Weave Workshop: Build, Track, and Evaluate LLM Applications\n",
    "\n",
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "Welcome to the Weave workshop! In this hands-on session, you'll learn how to use Weave to develop, debug, and evaluate AI-powered applications.\n",
    "\n",
    "**What you'll learn:**\n",
    "- ğŸ” **Trace & Debug**: Track every LLM call, see inputs/outputs, and debug issues\n",
    "- ğŸ“Š **Evaluate**: Build rigorous evaluations with multiple scoring functions\n",
    "- ğŸƒ **Compare**: Run A/B tests and compare different approaches\n",
    "- ğŸ“ˆ **Monitor**: Track costs, latency, and performance metrics\n",
    "- ğŸ¯ **Iterate**: Use data-driven insights to improve your application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6242dd3",
   "metadata": {},
   "source": [
    "## ğŸ”‘ Prerequisites\n",
    "\n",
    "Before we begin, let's set up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa5de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install wandb weave openai pydantic -qqq\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "from getpass import getpass\n",
    "from typing import Any, Optional\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import weave\n",
    "from weave import Dataset, Evaluation, Model\n",
    "\n",
    "# ğŸ”‘ Setup your API keys\n",
    "print(\"---\")\n",
    "print(\n",
    "    \"You can find your Weights and Biases API key here: https://wandb.ai/settings#api\"\n",
    ")\n",
    "if not os.environ.get(\"WANDB_API_KEY\"):\n",
    "    os.environ[\"WANDB_API_KEY\"] = getpass(\"Enter your Weights and Biases API key: \")\n",
    "print(\"---\")\n",
    "print(\"You can generate your OpenAI API key here: https://platform.openai.com/api-keys\")\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "print(\"---\")\n",
    "\n",
    "# ğŸ  Initialize your W&B project\n",
    "weave_client = weave.init(\"weave-workshop\")  # ğŸ Your W&B project name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645eb74",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## ğŸ” Part 1: Tracing & Debugging with Weave\n",
    "\n",
    "Let's start by building a simple LLM application and see how Weave automatically tracks everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a1456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our data structure\n",
    "class CustomerEmail(BaseModel):\n",
    "    customer_name: str\n",
    "    product: str\n",
    "    issue: str\n",
    "    sentiment: str = Field(description=\"positive, neutral, or negative\")\n",
    "\n",
    "\n",
    "# ğŸ Track functions with @weave.op\n",
    "@weave.op\n",
    "def analyze_customer_email(email: str) -> CustomerEmail:\n",
    "    \"\"\"Analyze a customer support email and extract key information.\"\"\"\n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a customer support analyst. Extract key information from emails.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Analyze this customer email and extract the customer name, product, issue, and sentiment:\\n\\n{email}\",\n",
    "            },\n",
    "        ],\n",
    "        response_format=CustomerEmail,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.parsed\n",
    "\n",
    "\n",
    "# Let's test it!\n",
    "test_email = \"\"\"\n",
    "Hi Support,\n",
    "\n",
    "I'm really frustrated! My new ProWidget 3000 stopped working after just 2 days.\n",
    "The screen went completely black and won't turn on no matter what I try.\n",
    "\n",
    "Please help!\n",
    "Sarah Johnson\n",
    "\"\"\"\n",
    "\n",
    "# ğŸ¯ Run the function - Weave will automatically track this call\n",
    "result = analyze_customer_email(test_email)\n",
    "print(\"âœ… Analysis complete!\")\n",
    "print(f\"Customer: {result.customer_name}\")\n",
    "print(f\"Sentiment: {result.sentiment}\")\n",
    "print(\"\\nğŸ” Check the Weave UI to see the trace!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198e61a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## ğŸ› Part 2: Debugging with Call Traces\n",
    "\n",
    "Weave tracks nested function calls, making debugging easy. Let's build a more complex example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op\n",
    "def preprocess_email(email: str) -> str:\n",
    "    \"\"\"Clean and standardize email text.\"\"\"\n",
    "    # Remove extra whitespace\n",
    "    cleaned = \" \".join(email.split())\n",
    "    # Add some metadata for debugging\n",
    "    print(f\"ğŸ“§ Original length: {len(email)}, Cleaned length: {len(cleaned)}\")\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def classify_urgency(email: str, sentiment: str) -> str:\n",
    "    \"\"\"Determine urgency level based on content and sentiment.\"\"\"\n",
    "    urgent_keywords = [\n",
    "        \"urgent\",\n",
    "        \"asap\",\n",
    "        \"immediately\",\n",
    "        \"frustrated\",\n",
    "        \"broken\",\n",
    "        \"stopped working\",\n",
    "    ]\n",
    "\n",
    "    # Check for urgent keywords\n",
    "    email_lower = email.lower()\n",
    "    has_urgent_keywords = any(keyword in email_lower for keyword in urgent_keywords)\n",
    "\n",
    "    if sentiment == \"negative\" and has_urgent_keywords:\n",
    "        return \"high\"\n",
    "    elif sentiment == \"negative\" or has_urgent_keywords:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"low\"\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def process_support_ticket(email: str) -> dict[str, Any]:\n",
    "    \"\"\"Complete support ticket processing pipeline.\"\"\"\n",
    "    # Step 1: Clean the email\n",
    "    cleaned_email = preprocess_email(email)\n",
    "\n",
    "    # Step 2: Analyze the email\n",
    "    analysis = analyze_customer_email(cleaned_email)\n",
    "\n",
    "    # Step 3: Determine urgency\n",
    "    urgency = classify_urgency(cleaned_email, analysis.sentiment)\n",
    "\n",
    "    # Return complete ticket info\n",
    "    return {\n",
    "        \"customer_name\": analysis.customer_name,\n",
    "        \"product\": analysis.product,\n",
    "        \"issue\": analysis.issue,\n",
    "        \"sentiment\": analysis.sentiment,\n",
    "        \"urgency\": urgency,\n",
    "        \"needs_immediate_attention\": urgency == \"high\",\n",
    "    }\n",
    "\n",
    "\n",
    "# ğŸ¯ Run the pipeline - see the nested traces in Weave!\n",
    "ticket = process_support_ticket(test_email)\n",
    "print(\"\\nğŸ« Ticket processed!\")\n",
    "print(f\"Urgency: {ticket['urgency']}\")\n",
    "print(f\"Needs immediate attention: {ticket['needs_immediate_attention']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd103cb3",
   "metadata": {},
   "source": [
    "## ğŸ“Š Part 3: Building Evaluations\n",
    "\n",
    "Now let's evaluate our email analyzer using Weave's evaluation framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed5a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation dataset\n",
    "eval_examples = [\n",
    "    {\n",
    "        \"email\": \"Hello, I'm John Smith. My DataProcessor Pro crashed and I lost all my work. This is unacceptable!\",\n",
    "        \"expected_name\": \"John Smith\",\n",
    "        \"expected_product\": \"DataProcessor Pro\",\n",
    "        \"expected_sentiment\": \"negative\",\n",
    "    },\n",
    "    {\n",
    "        \"email\": \"Hi there! Jane Doe here. Just wanted to say the CloudSync Plus is working perfectly. Great product!\",\n",
    "        \"expected_name\": \"Jane Doe\",\n",
    "        \"expected_product\": \"CloudSync Plus\",\n",
    "        \"expected_sentiment\": \"positive\",\n",
    "    },\n",
    "    {\n",
    "        \"email\": \"My SmartHub isn't connecting to WiFi. Can you help? Thanks, Bob Wilson\",\n",
    "        \"expected_name\": \"Bob Wilson\",\n",
    "        \"expected_product\": \"SmartHub\",\n",
    "        \"expected_sentiment\": \"neutral\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create a Weave Dataset\n",
    "support_dataset = Dataset(name=\"support_emails\", rows=eval_examples)\n",
    "\n",
    "\n",
    "# ğŸ¯ Define scoring functions\n",
    "@weave.op\n",
    "def name_accuracy(expected_name: str, output: CustomerEmail) -> dict[str, Any]:\n",
    "    \"\"\"Check if the extracted name matches.\"\"\"\n",
    "    is_correct = expected_name.lower() == output.customer_name.lower()\n",
    "    return {\"correct\": is_correct, \"score\": 1.0 if is_correct else 0.0}\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def sentiment_accuracy(\n",
    "    expected_sentiment: str, output: CustomerEmail\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Check if the sentiment analysis is correct.\"\"\"\n",
    "    is_correct = expected_sentiment.lower() == output.sentiment.lower()\n",
    "    return {\"correct\": is_correct, \"score\": 1.0 if is_correct else 0.0}\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def extraction_quality(email: str, output: CustomerEmail) -> dict[str, Any]:\n",
    "    \"\"\"Evaluate overall extraction quality.\"\"\"\n",
    "    score = 0.0\n",
    "    feedback = []\n",
    "\n",
    "    # Check if all fields are extracted\n",
    "    if output.customer_name and output.customer_name != \"Unknown\":\n",
    "        score += 0.33\n",
    "    else:\n",
    "        feedback.append(\"Missing customer name\")\n",
    "\n",
    "    if output.product and output.product != \"Unknown\":\n",
    "        score += 0.33\n",
    "    else:\n",
    "        feedback.append(\"Missing product\")\n",
    "\n",
    "    if output.issue and len(output.issue) > 10:\n",
    "        score += 0.34\n",
    "    else:\n",
    "        feedback.append(\"Issue description too short\")\n",
    "\n",
    "    return {\n",
    "        \"score\": score,\n",
    "        \"feedback\": \"; \".join(feedback)\n",
    "        if feedback\n",
    "        else \"All fields extracted successfully\",\n",
    "    }\n",
    "\n",
    "\n",
    "# ğŸš€ Run the evaluation\n",
    "evaluation = Evaluation(\n",
    "    name=\"email_analyzer_eval\",\n",
    "    dataset=support_dataset,\n",
    "    scorers=[name_accuracy, sentiment_accuracy, extraction_quality],\n",
    ")\n",
    "\n",
    "print(\"ğŸƒ Running evaluation...\")\n",
    "eval_results = asyncio.run(evaluation.evaluate(analyze_customer_email))\n",
    "print(\"âœ… Evaluation complete! Check the Weave UI for detailed results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f0bf12",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## ğŸ† Part 4: Model Comparison\n",
    "\n",
    "Let's compare different approaches using Weave's Model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d944927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different model variants\n",
    "class EmailAnalyzerModel(Model):\n",
    "    \"\"\"Base model for email analysis with configurable parameters.\"\"\"\n",
    "\n",
    "    model_name: str = \"gpt-4o-mini\"\n",
    "    temperature: float = 0.1\n",
    "    system_prompt: str = \"You are a customer support analyst.\"\n",
    "\n",
    "    @weave.op\n",
    "    def predict(self, email: str) -> CustomerEmail:\n",
    "        \"\"\"Analyze email with configurable parameters.\"\"\"\n",
    "        client = OpenAI()\n",
    "\n",
    "        response = client.beta.chat.completions.parse(\n",
    "            model=self.model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"Analyze this email:\\n{email}\"},\n",
    "            ],\n",
    "            response_format=CustomerEmail,\n",
    "            temperature=self.temperature,\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.parsed\n",
    "\n",
    "\n",
    "# Create model variants\n",
    "basic_model = EmailAnalyzerModel(\n",
    "    name=\"basic_analyzer\",\n",
    "    system_prompt=\"Extract customer name, product, issue, and sentiment from the email.\",\n",
    ")\n",
    "\n",
    "detailed_model = EmailAnalyzerModel(\n",
    "    name=\"detailed_analyzer\",\n",
    "    system_prompt=\"\"\"You are an expert customer support analyst.\n",
    "    Carefully extract:\n",
    "    - Customer name (look for signatures or greetings)\n",
    "    - Product name (exact product mentioned)\n",
    "    - Issue description (concise but complete)\n",
    "    - Sentiment (positive/neutral/negative based on tone)\n",
    "    Be precise and thorough.\"\"\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "empathetic_model = EmailAnalyzerModel(\n",
    "    name=\"empathetic_analyzer\",\n",
    "    system_prompt=\"\"\"You are an empathetic customer support specialist.\n",
    "    Read between the lines to understand the customer's emotional state.\n",
    "    Extract customer information while being sensitive to their frustration level.\"\"\",\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169f900",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## ğŸ”„ Part 5: A/B Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2eaa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op\n",
    "async def compare_models(models: list[Model], dataset: Dataset) -> dict[str, Any]:\n",
    "    \"\"\"Run A/B comparison of multiple models.\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for model in models:\n",
    "        print(f\"\\nğŸ“Š Evaluating {model.name}...\")\n",
    "        evaluation = Evaluation(\n",
    "            name=f\"comparison_{model.name}\",\n",
    "            dataset=dataset,\n",
    "            scorers=[name_accuracy, sentiment_accuracy, extraction_quality],\n",
    "        )\n",
    "\n",
    "        # Run evaluation\n",
    "        eval_result = await evaluation.evaluate(model)\n",
    "        results[model.name] = eval_result\n",
    "\n",
    "        print(f\"âœ… {model.name} evaluation complete!\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Run the comparison\n",
    "print(\"ğŸ Starting model comparison...\")\n",
    "comparison_results = asyncio.run(\n",
    "    compare_models([basic_model, detailed_model, empathetic_model], support_dataset)\n",
    ")\n",
    "print(\"\\nğŸ‰ Comparison complete! View the results in the Weave UI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d2707",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## ğŸ“ˆ Part 6: Cost & Performance Tracking\n",
    "\n",
    "Weave automatically tracks metrics like latency and token usage. Let's explore these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e550b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op\n",
    "def analyze_with_fallback(\n",
    "    email: str,\n",
    "    primary_model: str = \"gpt-4o-mini\",\n",
    "    fallback_model: str = \"gpt-3.5-turbo\",\n",
    ") -> CustomerEmail:\n",
    "    \"\"\"Analyze email with automatic fallback on error.\"\"\"\n",
    "    client = OpenAI()\n",
    "    try:\n",
    "        response = client.beta.chat.completions.parse(\n",
    "            model=primary_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Extract customer info from email.\"},\n",
    "                {\"role\": \"user\", \"content\": email},\n",
    "            ],\n",
    "            response_format=CustomerEmail,\n",
    "        )\n",
    "        print(f\"âœ… Used primary model: {primary_model}\")\n",
    "        return response.choices[0].message.parsed\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Primary model failed: {e}\")\n",
    "        print(f\"ğŸ”„ Falling back to {fallback_model}\")\n",
    "        response = client.beta.chat.completions.parse(\n",
    "            model=fallback_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Extract customer info from email.\"},\n",
    "                {\"role\": \"user\", \"content\": email},\n",
    "            ],\n",
    "            response_format=CustomerEmail,\n",
    "        )\n",
    "        return response.choices[0].message.parsed\n",
    "\n",
    "\n",
    "# Test the fallback mechanism\n",
    "test_emails = [\n",
    "    \"Hi, I'm Alice Brown. My UltraPhone is overheating constantly!\",\n",
    "    \"Bob Green here. The MegaTablet screen is cracked after dropping it.\",\n",
    "    \"Carol White needs help with CloudBackup not syncing properly.\",\n",
    "]\n",
    "\n",
    "print(\"ğŸ”„ Testing fallback mechanism...\")\n",
    "for email in test_emails:\n",
    "    result = analyze_with_fallback(email)\n",
    "    print(f\"  Processed: {result.customer_name} - {result.sentiment}\")\n",
    "\n",
    "print(\"\\nğŸ’° Check the Weave UI to see:\")\n",
    "print(\"  - Token usage for each call\")\n",
    "print(\"  - Latency comparisons\")\n",
    "print(\"  - Cost tracking (when available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c0777",
   "metadata": {},
   "source": [
    "## ğŸ¯ Part 7: Production Monitoring\n",
    "\n",
    "Use Weave to monitor your application in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96ce959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def production_email_handler(\n",
    "    email: str, request_id: Optional[str] = None\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Production-ready email handler with monitoring.\"\"\"\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # Generate request ID if not provided\n",
    "    if not request_id:\n",
    "        request_id = f\"req_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{random.randint(1000, 9999)}\"\n",
    "\n",
    "    try:\n",
    "        # Process the email\n",
    "        analysis = analyze_customer_email(email)\n",
    "        urgency = classify_urgency(email, analysis.sentiment)\n",
    "\n",
    "        # Log success metrics\n",
    "        processing_time = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "        result: dict[str, Any] = {\n",
    "            \"request_id\": request_id,\n",
    "            \"status\": \"success\",\n",
    "            \"processing_time_seconds\": processing_time,\n",
    "            \"analysis\": analysis.model_dump(),\n",
    "            \"urgency\": urgency,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "        # Log for monitoring\n",
    "        if urgency == \"high\":\n",
    "            print(f\"ğŸš¨ HIGH URGENCY TICKET: {request_id}\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log error metrics\n",
    "        return {\n",
    "            \"request_id\": request_id,\n",
    "            \"status\": \"error\",\n",
    "            \"error\": str(e),\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "\n",
    "# Simulate production traffic\n",
    "print(\"ğŸ­ Simulating production traffic...\")\n",
    "production_emails = [\n",
    "    \"URGENT: I'm CEO Jane Smith. Our Enterprise Suite is down and we're losing money!\",\n",
    "    \"Hi, just checking if CloudSync has a mobile app? Thanks, Tom\",\n",
    "    \"My DataVault backup failed. Need help ASAP! - Mary Johnson\",\n",
    "]\n",
    "\n",
    "for email in production_emails:\n",
    "    result = production_email_handler(email)\n",
    "    print(f\"  [{result['request_id']}] Status: {result['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52c0ff6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## ğŸ” Part 8: Debugging Failed Calls\n",
    "\n",
    "Weave makes it easy to debug when things go wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed6811",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op\n",
    "def problematic_analyzer(email: str) -> Optional[CustomerEmail]:\n",
    "    \"\"\"An analyzer that might fail - perfect for debugging!\"\"\"\n",
    "    if \"error\" in email.lower():\n",
    "        raise ValueError(\"Email contains error keyword!\")\n",
    "    if len(email) < 20:\n",
    "        print(\"âš ï¸ Email too short, returning None\")\n",
    "        return None\n",
    "    if \"urgent\" in email.lower():\n",
    "        import time\n",
    "\n",
    "        print(\"â³ Processing urgent email (simulating delay)...\")\n",
    "        time.sleep(2)\n",
    "    return analyze_customer_email(email)\n",
    "\n",
    "\n",
    "# Test with problematic inputs\n",
    "test_cases = [\n",
    "    (\"normal@example.com: Help with login\", \"Normal case\"),\n",
    "    (\"Short email\", \"Too short\"),\n",
    "    (\"error@example.com: System error occurred\", \"Contains error keyword\"),\n",
    "    (\"URGENT: Database is down!\", \"Slow processing\"),\n",
    "]\n",
    "\n",
    "print(\"ğŸ› Testing edge cases...\")\n",
    "for email, description in test_cases:\n",
    "    print(f\"\\nğŸ“§ Test: {description}\")\n",
    "    try:\n",
    "        result = problematic_analyzer(email)\n",
    "        if result:\n",
    "            print(f\"  âœ… Success: {result.customer_name}\")\n",
    "        else:\n",
    "            print(\"  âš ï¸ Returned None\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Error: {e}\")\n",
    "\n",
    "print(\"\\nğŸ” Check the Weave UI to:\")\n",
    "print(\"  - See failed calls highlighted in red\")\n",
    "print(\"  - Inspect error messages and stack traces\")\n",
    "print(\"  - Review inputs that caused failures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa11b53d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## ğŸš€ Part 9: Advanced Features\n",
    "\n",
    "Let's explore some advanced Weave features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0436fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metadata and tags\n",
    "@weave.op\n",
    "def analyze_with_metadata(\n",
    "    email: str, source: str = \"unknown\", priority: str = \"normal\"\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Analyze email with custom metadata tracking.\"\"\"\n",
    "    result = analyze_customer_email(email)\n",
    "    return {\n",
    "        \"analysis\": result.model_dump() if result else {},\n",
    "        \"metadata\": {\n",
    "            \"source\": source,\n",
    "            \"priority\": priority,\n",
    "            \"processed_at\": datetime.now().isoformat(),\n",
    "            \"model_used\": \"gpt-4o-mini\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# Test with metadata\n",
    "sources = [\"web_form\", \"email\", \"chat\", \"phone_transcript\"]\n",
    "priorities = [\"low\", \"normal\", \"high\", \"urgent\"]\n",
    "\n",
    "print(\"ğŸ“Š Processing emails from different sources...\")\n",
    "for i, email in enumerate(test_emails):\n",
    "    source = sources[i % len(sources)]\n",
    "    priority = priorities[i % len(priorities)]\n",
    "\n",
    "    result = analyze_with_metadata(email, source=source, priority=priority)\n",
    "    print(f\"  {source} ({priority}): {result['analysis']['sentiment']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f352b",
   "metadata": {},
   "source": [
    "## ğŸ“ Workshop Summary\n",
    "\n",
    "### What you've learned:\n",
    "\n",
    "1. **ğŸ” Tracing**: Every function call is automatically tracked with `@weave.op`\n",
    "2. **ğŸ› Debugging**: See complete call traces, inputs, outputs, and errors\n",
    "3. **ğŸ“Š Evaluation**: Build rigorous evaluations with custom scorers\n",
    "4. **ğŸ† Comparison**: Compare different models and approaches\n",
    "5. **ğŸ“ˆ Monitoring**: Track performance, costs, and errors in production\n",
    "6. **ğŸ¯ Insights**: Use data to improve your application\n",
    "\n",
    "### Next steps:\n",
    "\n",
    "- ğŸ“š Explore the [Weave documentation](https://weave-docs.wandb.ai/)\n",
    "- ğŸ§ª Try building your own evaluations\n",
    "- ğŸ”„ Integrate Weave into your existing projects\n",
    "- ğŸ“Š Use the Weave UI to analyze your application's behavior\n",
    "\n",
    "### Pro tips:\n",
    "\n",
    "- Use descriptive names for your `@weave.op` functions\n",
    "- Add type hints for better trace visualization\n",
    "- Create reusable Models for easy comparison\n",
    "- Build comprehensive evaluation datasets\n",
    "- Monitor key metrics in production\n",
    "\n",
    "Happy building with Weave! ğŸ"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
