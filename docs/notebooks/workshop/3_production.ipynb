{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83594029",
   "metadata": {},
   "source": [
    "# Part 3: Production Monitoring with Weave\n",
    "\n",
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "Learn how to monitor LLM applications in production using Weave's scorer system for real-time guardrails and quality monitoring.\n",
    "\n",
    "**In this section:**\n",
    "- 🛡️ **Guardrails**: Block or modify responses with content moderation\n",
    "- 📊 **Quality Monitoring**: Track extraction quality and completeness\n",
    "- ⚡ **Performance Tracking**: Monitor response times and SLA compliance\n",
    "- 🔄 **Real-time Scoring**: Apply scorers to live production calls\n",
    "- 👥 **Human Feedback**: Collect feedback and build datasets from production\n",
    "- 📈 **Continuous Improvement**: Use production data to improve models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6f882d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install dependencies and configure API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d485075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install wandb weave openai pydantic nest_asyncio ipywidgets -qqq\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from getpass import getpass\n",
    "from typing import Any, Optional\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import weave\n",
    "from weave import Scorer\n",
    "\n",
    "# Setup API keys\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"Get your OpenAI API key: https://platform.openai.com/api-keys\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# Initialize Weave\n",
    "weave_client = weave.init(\"weave-workshop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e8cd8c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 🎯 Part 3: Production Monitoring\n",
    "\n",
    "Use Weave's scorer system for real-time guardrails and quality monitoring.\n",
    "This demonstrates the apply_scorer pattern for production use.\n",
    "\n",
    "**Key Concepts**:\n",
    "- **Guardrails**: Block or modify responses (e.g., toxicity filter)\n",
    "- **Monitors**: Track quality metrics without blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779f7032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our data structure\n",
    "class CustomerEmail(BaseModel):\n",
    "    customer_name: str\n",
    "    product: str\n",
    "    issue: str\n",
    "    sentiment: str = Field(description=\"positive, neutral, or negative\")\n",
    "\n",
    "\n",
    "# 🎯 Track functions with @weave.op\n",
    "@weave.op\n",
    "def analyze_customer_email(email: str) -> CustomerEmail:\n",
    "    \"\"\"Analyze a customer support email and extract key information.\"\"\"\n",
    "    client = OpenAI()\n",
    "\n",
    "    # 🔥 OpenAI calls are automatically traced by Weave!\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",  # Using mini model for cost efficiency\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Extract customer name, product, issue, and sentiment.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": email,\n",
    "            },\n",
    "        ],\n",
    "        response_format=CustomerEmail,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.parsed\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def classify_urgency(email: str, sentiment: str) -> str:\n",
    "    \"\"\"Determine urgency level based on content and sentiment.\"\"\"\n",
    "    urgent_keywords = [\n",
    "        \"urgent\",\n",
    "        \"asap\",\n",
    "        \"immediately\",\n",
    "        \"frustrated\",\n",
    "        \"broken\",\n",
    "        \"stopped working\",\n",
    "    ]\n",
    "\n",
    "    # Check for urgent keywords\n",
    "    email_lower = email.lower()\n",
    "    has_urgent_keywords = any(keyword in email_lower for keyword in urgent_keywords)\n",
    "\n",
    "    # Combine sentiment and keywords to determine urgency\n",
    "    if sentiment == \"negative\" and has_urgent_keywords:\n",
    "        return \"high\"\n",
    "    elif sentiment == \"negative\" or has_urgent_keywords:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"low\"\n",
    "\n",
    "\n",
    "# 🛡️ Define production scorers\n",
    "class ContentModerationScorer(Scorer):\n",
    "    \"\"\"Production-ready content moderation scorer.\"\"\"\n",
    "\n",
    "    @weave.op\n",
    "    def score(self, output: dict) -> dict:\n",
    "        \"\"\"Check for inappropriate content using multiple signals.\"\"\"\n",
    "        # Handle both success and error cases\n",
    "        if output.get(\"status\") != \"success\":\n",
    "            return {\"flagged\": False, \"flags\": [], \"severity\": \"none\", \"action\": \"pass\"}\n",
    "\n",
    "        analysis = output.get(\"analysis\", {})\n",
    "        issue_text = analysis.get(\"issue\", \"\").lower()\n",
    "        sentiment = analysis.get(\"sentiment\", \"neutral\")\n",
    "\n",
    "        # Check for various inappropriate content patterns\n",
    "        profanity_patterns = [\n",
    "            \"stupid\",\n",
    "            \"idiotic\",\n",
    "            \"garbage\",\n",
    "            \"trash\",\n",
    "            \"sucks\",\n",
    "            \"terrible\",\n",
    "            \"awful\",\n",
    "            \"worst\",\n",
    "        ]\n",
    "        threat_patterns = [\"sue\", \"lawyer\", \"legal action\", \"court\", \"lawsuit\"]\n",
    "\n",
    "        flags = []\n",
    "        severity = \"none\"\n",
    "\n",
    "        # Check profanity\n",
    "        profanity_found = []\n",
    "        for word in profanity_patterns:\n",
    "            if word in issue_text:\n",
    "                profanity_found.append(word)\n",
    "\n",
    "        if profanity_found:\n",
    "            flags.append(f\"Profanity detected: {', '.join(profanity_found)}\")\n",
    "            severity = \"medium\"\n",
    "\n",
    "        # Check threats\n",
    "        threats_found = []\n",
    "        for pattern in threat_patterns:\n",
    "            if pattern in issue_text:\n",
    "                threats_found.append(pattern)\n",
    "\n",
    "        if threats_found:\n",
    "            flags.append(f\"Legal threat: {', '.join(threats_found)}\")\n",
    "            severity = \"high\"\n",
    "\n",
    "        # Check extreme sentiment with profanity\n",
    "        if sentiment == \"negative\" and profanity_found:\n",
    "            severity = \"high\"\n",
    "            flags.append(\"Negative sentiment with profanity\")\n",
    "\n",
    "        return {\n",
    "            \"flagged\": len(flags) > 0,\n",
    "            \"flags\": flags,\n",
    "            \"severity\": severity,\n",
    "            \"action\": \"block\"\n",
    "            if severity == \"high\"\n",
    "            else (\"review\" if severity == \"medium\" else \"pass\"),\n",
    "        }\n",
    "\n",
    "\n",
    "class ExtractionQualityScorer(Scorer):\n",
    "    \"\"\"Monitor extraction quality and completeness.\"\"\"\n",
    "\n",
    "    @weave.op\n",
    "    def score(self, output: dict, email: str) -> dict:\n",
    "        \"\"\"Comprehensive quality assessment.\"\"\"\n",
    "        if output.get(\"status\") != \"success\":\n",
    "            return {\n",
    "                \"quality_score\": 0.0,\n",
    "                \"passed\": False,\n",
    "                \"issues\": [\"Failed to process email\"],\n",
    "                \"recommendations\": [],\n",
    "                \"extraction_grade\": \"F\",\n",
    "            }\n",
    "\n",
    "        analysis = output.get(\"analysis\", {})\n",
    "        quality_metrics = {\n",
    "            \"completeness\": 0.0,\n",
    "            \"specificity\": 0.0,\n",
    "            \"accuracy\": 0.0,\n",
    "            \"consistency\": 0.0,\n",
    "        }\n",
    "        issues = []\n",
    "        recommendations = []\n",
    "\n",
    "        # 1. Completeness checks (40% weight)\n",
    "        if analysis.get(\"customer_name\") and analysis[\"customer_name\"] not in [\n",
    "            \"Unknown\",\n",
    "            \"\",\n",
    "            None,\n",
    "        ]:\n",
    "            quality_metrics[\"completeness\"] += 0.15\n",
    "        else:\n",
    "            issues.append(\"Missing customer name\")\n",
    "            recommendations.append(\"Check email signatures and greetings for names\")\n",
    "\n",
    "        if analysis.get(\"product\") and analysis[\"product\"] not in [\"Unknown\", \"\", None]:\n",
    "            quality_metrics[\"completeness\"] += 0.15\n",
    "        else:\n",
    "            issues.append(\"Missing product identification\")\n",
    "            recommendations.append(\"Look for product names mentioned in the email\")\n",
    "\n",
    "        if analysis.get(\"issue\") and len(analysis[\"issue\"]) > 10:\n",
    "            quality_metrics[\"completeness\"] += 0.10\n",
    "        else:\n",
    "            issues.append(\"Issue description too brief or missing\")\n",
    "            recommendations.append(\"Extract a more detailed problem description\")\n",
    "\n",
    "        # 2. Specificity checks (30% weight)\n",
    "        product_name = analysis.get(\"product\", \"\")\n",
    "        if product_name and any(char.isdigit() for char in str(product_name)):\n",
    "            # Product includes version/model number\n",
    "            quality_metrics[\"specificity\"] += 0.15\n",
    "        elif product_name:\n",
    "            recommendations.append(\n",
    "                \"Extract product version/model numbers when available\"\n",
    "            )\n",
    "\n",
    "        issue_desc = analysis.get(\"issue\", \"\")\n",
    "        if issue_desc and len(str(issue_desc)) > 30:\n",
    "            quality_metrics[\"specificity\"] += 0.15\n",
    "        elif issue_desc:\n",
    "            recommendations.append(\"Provide more specific issue details\")\n",
    "\n",
    "        # 3. Accuracy checks (20% weight)\n",
    "        # Check if extracted content actually appears in email\n",
    "        email_lower = email.lower()\n",
    "        customer_name = analysis.get(\"customer_name\", \"\")\n",
    "        if customer_name and customer_name != \"Unknown\":\n",
    "            name_parts = customer_name.lower().split()\n",
    "            # Check if at least part of the name appears in email\n",
    "            if any(part in email_lower for part in name_parts if len(part) > 2):\n",
    "                quality_metrics[\"accuracy\"] += 0.10\n",
    "            else:\n",
    "                issues.append(\"Extracted name not found in original email\")\n",
    "\n",
    "        product_mentioned = analysis.get(\"product\", \"\")\n",
    "        if product_mentioned and product_mentioned != \"Unknown\":\n",
    "            # Check for partial matches (product names might be extracted differently)\n",
    "            product_words = product_mentioned.lower().split()\n",
    "            if any(word in email_lower for word in product_words if len(word) > 3):\n",
    "                quality_metrics[\"accuracy\"] += 0.10\n",
    "            else:\n",
    "                issues.append(\"Extracted product not clearly mentioned in email\")\n",
    "\n",
    "        # 4. Consistency checks (10% weight)\n",
    "        sentiment = analysis.get(\"sentiment\", \"neutral\")\n",
    "        urgency = output.get(\"urgency\", \"low\")\n",
    "\n",
    "        # Check sentiment/urgency consistency\n",
    "        consistency_ok = True\n",
    "        if sentiment == \"negative\" and urgency == \"low\":\n",
    "            if not any(\n",
    "                word in issue_desc.lower() for word in [\"minor\", \"small\", \"slight\"]\n",
    "            ):\n",
    "                consistency_ok = False\n",
    "                issues.append(\n",
    "                    \"Negative sentiment but low urgency - might be inconsistent\"\n",
    "                )\n",
    "        elif sentiment == \"positive\" and urgency == \"high\":\n",
    "            consistency_ok = False\n",
    "            issues.append(\"Positive sentiment with high urgency is unusual\")\n",
    "\n",
    "        if consistency_ok:\n",
    "            quality_metrics[\"consistency\"] += 0.10\n",
    "\n",
    "        # Calculate overall score\n",
    "        total_score = sum(quality_metrics.values())\n",
    "\n",
    "        return {\n",
    "            \"quality_score\": total_score,\n",
    "            \"quality_metrics\": quality_metrics,\n",
    "            \"passed\": total_score >= 0.6,  # Lowered threshold for demo\n",
    "            \"issues\": issues,\n",
    "            \"recommendations\": recommendations,\n",
    "            \"extraction_grade\": \"A\"\n",
    "            if total_score >= 0.9\n",
    "            else (\n",
    "                \"B\"\n",
    "                if total_score >= 0.8\n",
    "                else (\n",
    "                    \"C\" if total_score >= 0.6 else (\"D\" if total_score >= 0.4 else \"F\")\n",
    "                )\n",
    "            ),\n",
    "        }\n",
    "\n",
    "\n",
    "@weave.op\n",
    "def production_email_handler(\n",
    "    email: str, request_id: Optional[str] = None\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Production-ready email handler that returns structured analysis results.\"\"\"\n",
    "    # Generate request ID if not provided\n",
    "    if not request_id:\n",
    "        request_id = f\"req_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{random.randint(1000, 9999)}\"\n",
    "\n",
    "    try:\n",
    "        # Process the email using our existing analyzer\n",
    "        analysis = analyze_customer_email(email)\n",
    "\n",
    "        # Calculate urgency based on the analysis\n",
    "        urgency = classify_urgency(email, analysis.sentiment)\n",
    "\n",
    "        # Return structured result that scorers expect\n",
    "        return {\n",
    "            \"request_id\": request_id,\n",
    "            \"status\": \"success\",\n",
    "            \"analysis\": {\n",
    "                \"customer_name\": analysis.customer_name,\n",
    "                \"product\": analysis.product,\n",
    "                \"issue\": analysis.issue,\n",
    "                \"sentiment\": analysis.sentiment,\n",
    "            },\n",
    "            \"urgency\": urgency,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log error and return error response\n",
    "        return {\n",
    "            \"request_id\": request_id,\n",
    "            \"status\": \"error\",\n",
    "            \"error\": str(e),\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "\n",
    "# Initialize scorers\n",
    "content_moderation_scorer = ContentModerationScorer()\n",
    "quality_scorer = ExtractionQualityScorer()\n",
    "\n",
    "\n",
    "async def handle_email_with_monitoring(email: str) -> dict[str, Any]:\n",
    "    \"\"\"Handle email with production monitoring and guardrails.\"\"\"\n",
    "    # Process the email and get the Call object\n",
    "    result, call = production_email_handler.call(email)\n",
    "\n",
    "    if result[\"status\"] == \"success\":\n",
    "        # Apply content moderation (guardrail)\n",
    "        moderation_check = await call.apply_scorer(content_moderation_scorer)\n",
    "\n",
    "        # Apply quality monitoring\n",
    "        quality_check = await call.apply_scorer(\n",
    "            quality_scorer, additional_scorer_kwargs={\"email\": email}\n",
    "        )\n",
    "\n",
    "        # Handle moderation results\n",
    "        if moderation_check.result[\"flagged\"]:\n",
    "            action = moderation_check.result[\"action\"]\n",
    "            if action == \"block\":\n",
    "                print(f\"🚫 Content BLOCKED: {moderation_check.result['flags']}\")\n",
    "                result[\"blocked\"] = True\n",
    "                result[\"block_reason\"] = moderation_check.result[\"flags\"]\n",
    "            elif action == \"review\":\n",
    "                print(\n",
    "                    f\"⚠️ Content flagged for review: {moderation_check.result['flags']}\"\n",
    "                )\n",
    "                result[\"needs_review\"] = True\n",
    "                result[\"review_reason\"] = moderation_check.result[\"flags\"]\n",
    "\n",
    "        # Add quality metrics\n",
    "        result[\"quality_metrics\"] = {\n",
    "            \"grade\": quality_check.result[\"extraction_grade\"],\n",
    "            \"score\": quality_check.result[\"quality_score\"],\n",
    "            \"passed\": quality_check.result[\"passed\"],\n",
    "        }\n",
    "\n",
    "        # Show quality issues and recommendations\n",
    "        if quality_check.result[\"issues\"]:\n",
    "            print(f\"📊 Quality issues: {quality_check.result['issues']}\")\n",
    "\n",
    "        if quality_check.result[\"recommendations\"]:\n",
    "            print(f\"💡 Recommendations: {quality_check.result['recommendations']}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# 🧪 Test production monitoring with realistic scenarios\n",
    "print(\"🏭 Testing production monitoring with realistic scenarios...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "production_test_emails = [\n",
    "    # Good quality extraction - should pass all checks\n",
    "    {\n",
    "        \"email\": \"Hello Support Team,\\n\\nI'm Sarah Mitchell from Acme Corp. Our CloudSync Enterprise v3.2.1 stopped syncing files yesterday at 2pm. The error message says 'Authentication failed'. This is really frustrating and affecting our entire team.\\n\\nBest regards,\\nSarah Mitchell\\nIT Manager, Acme Corp\",\n",
    "        \"expected\": \"✅ High quality extraction with version numbers\",\n",
    "    },\n",
    "    # Profanity with legal threat - should be blocked\n",
    "    {\n",
    "        \"email\": \"This stupid software is absolute garbage! I'm John Davis and your DataSync Pro is the worst trash I've ever used. My lawyer will be contacting you about this terrible product that lost our data!\",\n",
    "        \"expected\": \"🚫 Should be blocked - profanity + legal threat\",\n",
    "    },\n",
    "    # Poor quality but processable - low score but not blocked\n",
    "    {\n",
    "        \"email\": \"Hi support, product broken. Fix please. - Tom\",\n",
    "        \"expected\": \"📊 Low quality - minimal details but processable\",\n",
    "    },\n",
    "    # Good extraction with negative sentiment - quality pass\n",
    "    {\n",
    "        \"email\": \"Dear Support,\\n\\nI'm Mary Johnson, CTO at TechStart Inc. Our DataVault Pro v2.5 backup failed last night with error code 'E501: connection timeout'. This is concerning as we rely on nightly backups for compliance.\\n\\nMary Johnson\\nCTO, TechStart Inc\",\n",
    "        \"expected\": \"✅ Good quality despite negative sentiment\",\n",
    "    },\n",
    "    # Needs review - mild profanity - should flag for review\n",
    "    {\n",
    "        \"email\": \"Mike Wilson here. Your EmailPro system really sucks compared to what was promised, but I guess it's still better than the competition. Can you help me configure the spam filter? It's blocking legitimate emails.\",\n",
    "        \"expected\": \"⚠️ Should flag for review - mild profanity\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for i, test_case in enumerate(production_test_emails):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"📧 Test {i+1}/5: {test_case['expected']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Show email preview\n",
    "    email_lines = test_case[\"email\"].split(\"\\n\")\n",
    "    print(\"📝 Email Content:\")\n",
    "    for line in email_lines[:3]:  # Show first 3 lines\n",
    "        if line.strip():\n",
    "            print(f\"   {line[:70]}{'...' if len(line) > 70 else ''}\")\n",
    "    if len(email_lines) > 3:\n",
    "        print(f\"   ... ({len(email_lines)-3} more lines)\")\n",
    "\n",
    "    # Process with monitoring\n",
    "    result = asyncio.run(handle_email_with_monitoring(test_case[\"email\"]))\n",
    "\n",
    "    # Show extraction results\n",
    "    print(\"\\n🔍 Extraction Results:\")\n",
    "    if result[\"status\"] == \"success\":\n",
    "        analysis = result[\"analysis\"]\n",
    "        print(f\"   Customer: {analysis.get('customer_name', 'Unknown')}\")\n",
    "        print(f\"   Product: {analysis.get('product', 'Unknown')}\")\n",
    "        print(\n",
    "            f\"   Issue: {analysis.get('issue', 'Unknown')[:50]}{'...' if len(analysis.get('issue', '')) > 50 else ''}\"\n",
    "        )\n",
    "        print(f\"   Sentiment: {analysis.get('sentiment', 'Unknown')}\")\n",
    "        print(f\"   Urgency: {result.get('urgency', 'Unknown')}\")\n",
    "    else:\n",
    "        print(f\"   ❌ Error: {result.get('error', 'Unknown error')}\")\n",
    "\n",
    "    # Show scorer results\n",
    "    print(\"\\n📊 Scorer Results:\")\n",
    "\n",
    "    # Content Moderation\n",
    "    if result[\"status\"] == \"success\":\n",
    "        if result.get(\"blocked\"):\n",
    "            print(\"   🚫 Content Moderation: BLOCKED\")\n",
    "            print(f\"      Reason: {result['block_reason']}\")\n",
    "        elif result.get(\"needs_review\"):\n",
    "            print(\"   ⚠️ Content Moderation: REVIEW NEEDED\")\n",
    "            print(f\"      Flags: {result['review_reason']}\")\n",
    "        else:\n",
    "            print(\"   ✅ Content Moderation: PASSED\")\n",
    "\n",
    "    # Quality Assessment\n",
    "    if result[\"status\"] == \"success\":\n",
    "        quality = result.get(\"quality_metrics\", {})\n",
    "        print(\n",
    "            f\"   📏 Quality Assessment: Grade {quality.get('grade', 'F')} (Score: {quality.get('score', 0):.2f})\"\n",
    "        )\n",
    "\n",
    "        # Show what contributed to the score\n",
    "        if quality.get(\"score\", 0) < 0.6:\n",
    "            print(\n",
    "                f\"      Status: {'⚠️ Below threshold' if quality.get('passed', False) else '❌ Failed'}\"\n",
    "            )\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\n🎯 Summary of Production Monitoring Demonstration:\")\n",
    "print(\"\\n1. **Successful Cases** (Tests 1, 4):\")\n",
    "print(\"   - High-quality extractions with version numbers\")\n",
    "print(\"   - All required fields present and accurate\")\n",
    "\n",
    "print(\"\\n2. **Blocked Content** (Test 2):\")\n",
    "print(\"   - Multiple profanity words + legal threats = automatic block\")\n",
    "print(\"   - Protects support agents from abusive content\")\n",
    "\n",
    "print(\"\\n3. **Review Required** (Test 5):\")\n",
    "print(\"   - Mild profanity triggers review flag\")\n",
    "print(\"   - Human can decide if response is appropriate\")\n",
    "\n",
    "print(\"\\n4. **Quality Issues** (Test 3):\")\n",
    "print(\"   - Missing customer name or product details\")\n",
    "print(\"   - Too brief to be actionable\")\n",
    "print(\"   - Would need human intervention\")\n",
    "\n",
    "print(\"\\n💡 Key Insights:\")\n",
    "print(\"   - Different scorers serve different purposes\")\n",
    "print(\"   - Guardrails (block/review) vs Monitors (quality/performance)\")\n",
    "print(\"   - All scorer results are tracked in Weave for analysis\")\n",
    "print(\"\\n✅ Check the Weave UI to see detailed scorer results and traces!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e008896",
   "metadata": {},
   "source": [
    "## 3.1: Human Feedback & Data Collection\n",
    "\n",
    "Learn how to collect human feedback and build datasets from production data.\n",
    "This creates a feedback loop for continuous model improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3bab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "\n",
    "# Create an interactive feedback collection interface\n",
    "class EmailAnalyzerFeedbackApp:\n",
    "    def __init__(self):\n",
    "        self.current_call = None\n",
    "        self.setup_ui()\n",
    "\n",
    "    def setup_ui(self):\n",
    "        \"\"\"Create the interactive UI components.\"\"\"\n",
    "        # Input area\n",
    "        self.email_input = widgets.Textarea(\n",
    "            value=\"Hi Support,\\n\\nI'm having issues with my CloudSync Pro. It keeps crashing when I try to sync large files. This is really frustrating!\\n\\nThanks,\\nJohn Smith\",\n",
    "            placeholder=\"Enter a customer email to analyze...\",\n",
    "            description=\"Email:\",\n",
    "            layout=widgets.Layout(width=\"100%\", height=\"120px\"),\n",
    "        )\n",
    "\n",
    "        # Analyze button\n",
    "        self.analyze_button = widgets.Button(\n",
    "            description=\"Analyze Email\",\n",
    "            button_style=\"primary\",\n",
    "            layout=widgets.Layout(width=\"150px\"),\n",
    "        )\n",
    "        self.analyze_button.on_click(self.analyze_email)\n",
    "\n",
    "        # Output area\n",
    "        self.output_area = widgets.Output()\n",
    "\n",
    "        # Feedback buttons (initially hidden)\n",
    "        self.feedback_area = widgets.VBox([])\n",
    "\n",
    "        # Main layout\n",
    "        self.app = widgets.VBox(\n",
    "            [\n",
    "                widgets.HTML(\"<h3>🔄 Interactive Email Analyzer with Feedback</h3>\"),\n",
    "                widgets.HTML(\n",
    "                    \"<p>Enter an email below, analyze it, and provide feedback to improve the model:</p>\"\n",
    "                ),\n",
    "                self.email_input,\n",
    "                self.analyze_button,\n",
    "                self.output_area,\n",
    "                self.feedback_area,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def analyze_email(self, button):\n",
    "        \"\"\"Analyze the email and show results.\"\"\"\n",
    "        with self.output_area:\n",
    "            clear_output()\n",
    "            print(\"🔄 Analyzing email...\")\n",
    "\n",
    "        try:\n",
    "            # Use the .call() method to get both result and call object\n",
    "            email_text = self.email_input.value.strip()\n",
    "            if not email_text:\n",
    "                with self.output_area:\n",
    "                    clear_output()\n",
    "                    print(\"❌ Please enter an email to analyze.\")\n",
    "                return\n",
    "\n",
    "            # Add session attributes for tracking\n",
    "            with weave.attributes(\n",
    "                {\"session\": str(uuid.uuid4()), \"env\": \"workshop_demo\"}\n",
    "            ):\n",
    "                result, call = production_email_handler.call(email_text)\n",
    "\n",
    "            self.current_call = call\n",
    "\n",
    "            # Display results\n",
    "            with self.output_area:\n",
    "                clear_output()\n",
    "                if result[\"status\"] == \"success\":\n",
    "                    analysis = result[\"analysis\"]\n",
    "                    print(\"✅ Analysis Complete!\")\n",
    "                    print(f\"📧 Customer: {analysis['customer_name']}\")\n",
    "                    print(f\"🏷️ Product: {analysis['product']}\")\n",
    "                    print(f\"📝 Issue: {analysis['issue']}\")\n",
    "                    print(f\"😊 Sentiment: {analysis['sentiment']}\")\n",
    "                    print(f\"⚡ Urgency: {result['urgency']}\")\n",
    "                else:\n",
    "                    print(f\"❌ Error: {result.get('error', 'Unknown error')}\")\n",
    "\n",
    "            # Show feedback buttons\n",
    "            self.show_feedback_buttons()\n",
    "\n",
    "        except Exception as e:\n",
    "            with self.output_area:\n",
    "                clear_output()\n",
    "                print(f\"❌ Error analyzing email: {str(e)}\")\n",
    "\n",
    "    def show_feedback_buttons(self):\n",
    "        \"\"\"Display feedback buttons after analysis.\"\"\"\n",
    "        if not self.current_call:\n",
    "            return\n",
    "\n",
    "        # Feedback buttons\n",
    "        thumbs_up = widgets.Button(\n",
    "            description=\"👍 Good\",\n",
    "            button_style=\"success\",\n",
    "            layout=widgets.Layout(width=\"100px\"),\n",
    "        )\n",
    "        thumbs_down = widgets.Button(\n",
    "            description=\"👎 Bad\",\n",
    "            button_style=\"danger\",\n",
    "            layout=widgets.Layout(width=\"100px\"),\n",
    "        )\n",
    "\n",
    "        # Text feedback\n",
    "        feedback_text = widgets.Textarea(\n",
    "            placeholder=\"Optional: Explain what was good or bad about this analysis...\",\n",
    "            description=\"Comments:\",\n",
    "            layout=widgets.Layout(width=\"100%\", height=\"80px\"),\n",
    "        )\n",
    "\n",
    "        submit_feedback = widgets.Button(\n",
    "            description=\"Submit Feedback\",\n",
    "            button_style=\"info\",\n",
    "            layout=widgets.Layout(width=\"150px\"),\n",
    "        )\n",
    "\n",
    "        # Feedback status\n",
    "        feedback_status = widgets.Output()\n",
    "\n",
    "        # Event handlers\n",
    "        def on_thumbs_up(button):\n",
    "            self.add_feedback(\"👍\", feedback_text.value, feedback_status)\n",
    "\n",
    "        def on_thumbs_down(button):\n",
    "            self.add_feedback(\"👎\", feedback_text.value, feedback_status)\n",
    "\n",
    "        def on_submit_feedback(button):\n",
    "            if feedback_text.value.strip():\n",
    "                self.add_feedback(None, feedback_text.value, feedback_status)\n",
    "            else:\n",
    "                with feedback_status:\n",
    "                    clear_output()\n",
    "                    print(\"⚠️ Please enter some feedback text.\")\n",
    "\n",
    "        thumbs_up.on_click(on_thumbs_up)\n",
    "        thumbs_down.on_click(on_thumbs_down)\n",
    "        submit_feedback.on_click(on_submit_feedback)\n",
    "\n",
    "        # Layout feedback area\n",
    "        self.feedback_area.children = [\n",
    "            widgets.HTML(\"<hr><h4>📝 Provide Feedback</h4>\"),\n",
    "            widgets.HTML(\"<p>Help improve the model by rating this analysis:</p>\"),\n",
    "            widgets.HBox(\n",
    "                [thumbs_up, thumbs_down], layout=widgets.Layout(margin=\"10px 0\")\n",
    "            ),\n",
    "            feedback_text,\n",
    "            submit_feedback,\n",
    "            feedback_status,\n",
    "        ]\n",
    "\n",
    "    def add_feedback(self, reaction, note, status_output):\n",
    "        \"\"\"Add feedback to the current call.\"\"\"\n",
    "        if not self.current_call:\n",
    "            with status_output:\n",
    "                clear_output()\n",
    "                print(\"❌ No call to add feedback to.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Add reaction if provided\n",
    "            if reaction:\n",
    "                self.current_call.feedback.add_reaction(reaction)\n",
    "\n",
    "            # Add note if provided\n",
    "            if note and note.strip():\n",
    "                self.current_call.feedback.add_note(note.strip())\n",
    "\n",
    "            with status_output:\n",
    "                clear_output()\n",
    "                feedback_parts = []\n",
    "                if reaction:\n",
    "                    feedback_parts.append(f\"reaction ({reaction})\")\n",
    "                if note and note.strip():\n",
    "                    feedback_parts.append(\"comment\")\n",
    "\n",
    "                feedback_desc = \" and \".join(feedback_parts)\n",
    "                print(f\"✅ Feedback submitted: {feedback_desc}\")\n",
    "                print(\n",
    "                    \"🔍 Check the Weave UI to see your feedback attached to the call!\"\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            with status_output:\n",
    "                clear_output()\n",
    "                print(f\"❌ Error submitting feedback: {str(e)}\")\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display the app.\"\"\"\n",
    "        display(self.app)\n",
    "\n",
    "\n",
    "# Create and display the feedback app\n",
    "print(\"🚀 Starting Interactive Email Analyzer with Feedback Collection...\")\n",
    "feedback_app = EmailAnalyzerFeedbackApp()\n",
    "feedback_app.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98379f82",
   "metadata": {},
   "source": [
    "### 📊 Analyzing Feedback Data\n",
    "\n",
    "Once you've collected feedback, you can query and analyze it programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57dad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query feedback from the project\n",
    "print(\"📊 Querying feedback data from your project...\")\n",
    "\n",
    "try:\n",
    "    # Get all feedback in the project\n",
    "    all_feedback = weave_client.get_feedback()\n",
    "\n",
    "    if all_feedback:\n",
    "        print(f\"\\n📈 Found {len(all_feedback)} feedback items:\")\n",
    "\n",
    "        # Analyze feedback by type\n",
    "        reactions = {}\n",
    "        notes = []\n",
    "\n",
    "        for feedback in all_feedback:\n",
    "            if feedback.feedback_type == \"reaction\":\n",
    "                reaction = feedback.payload.get(\"emoji\", \"unknown\")\n",
    "                reactions[reaction] = reactions.get(reaction, 0) + 1\n",
    "            elif feedback.feedback_type == \"note\":\n",
    "                notes.append(feedback.payload.get(\"note\", \"\"))\n",
    "\n",
    "        # Show reaction summary\n",
    "        if reactions:\n",
    "            print(\"\\n👍👎 Reaction Summary:\")\n",
    "            for reaction, count in reactions.items():\n",
    "                print(f\"  {reaction}: {count}\")\n",
    "\n",
    "        # Show recent notes\n",
    "        if notes:\n",
    "            print(f\"\\n💬 Recent Comments ({len(notes)} total):\")\n",
    "            for i, note in enumerate(notes[-3:], 1):  # Show last 3\n",
    "                print(f\"  {i}. {note[:100]}{'...' if len(note) > 100 else ''}\")\n",
    "\n",
    "        # Show feedback details\n",
    "        print(\"\\n🔍 Feedback Details:\")\n",
    "        for i, feedback in enumerate(all_feedback[-3:], 1):  # Show last 3\n",
    "            print(f\"  {i}. Type: {feedback.feedback_type}\")\n",
    "            print(f\"     Created: {feedback.created_at}\")\n",
    "            print(f\"     Payload: {feedback.payload}\")\n",
    "            print()\n",
    "\n",
    "    else:\n",
    "        print(\"📭 No feedback found yet. Try using the interactive app above!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error querying feedback: {str(e)}\")\n",
    "    print(\"💡 Make sure you've submitted some feedback using the app above.\")\n",
    "\n",
    "print(\"\\n💡 Pro Tips for Production Feedback:\")\n",
    "print(\"  - Set up automated feedback collection in your production app\")\n",
    "print(\"  - Use feedback to identify problematic cases for your evaluation datasets\")\n",
    "print(\"  - Track feedback trends over time to monitor model performance\")\n",
    "print(\"  - Filter calls by feedback type to find specific issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b702c2b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned how to monitor LLM applications in production:\n",
    "\n",
    "- ✅ **Guardrails**: Implemented content moderation to block inappropriate responses\n",
    "- ✅ **Quality Monitoring**: Built comprehensive quality assessment scorers\n",
    "- ✅ **Real-time Scoring**: Applied scorers to production calls with `call.apply_scorer()`\n",
    "- ✅ **Production Patterns**: Handled errors, edge cases, and performance monitoring\n",
    "- ✅ **Human Feedback**: Created interactive feedback collection systems\n",
    "\n",
    "**Next Steps:**\n",
    "- Deploy these patterns in your real applications\n",
    "- Set up automated feedback collection in production\n",
    "- Build custom scorers for domain-specific quality checks\n",
    "- Monitor quality metrics over time in the Weave UI\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Production monitoring requires both guardrails (blocking) and monitors (tracking)\n",
    "- Scorers can be applied in real-time to any Weave-traced function call\n",
    "- Quality assessment should be comprehensive: completeness, accuracy, consistency\n",
    "- Human feedback creates a continuous improvement loop for model development\n",
    "- All scorer results and feedback are automatically tracked and visualized in Weave"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
