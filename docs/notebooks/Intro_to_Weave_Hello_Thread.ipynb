{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LeCBIPQIDq0"
   },
   "source": [
    "# Introduction to Threads\n",
    "\n",
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "Weave is a toolkit for developing AI-powered applications.\n",
    "\n",
    "_Threads_ in Weave group related traces into conversations, making it easy to track multi-turn interactions with LLMs.\n",
    "\n",
    "While individual traces capture single function calls, threads automatically organize these traces into coherent sequences‚Äîperfect for debugging chat sessions, multi-step workflows, or any scenario where context builds across multiple operations.\n",
    "\n",
    "Simply use the same thread ID across related `@weave.op` decorated functions, and Weave will link them together, giving you a complete view of how your application handles extended conversations or complex workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McE7cuqSxMiP"
   },
   "source": [
    "## üîë Prerequisites (using W&B Inference)\n",
    "\n",
    "This guide uses the [W&B Inference service](https://weave-docs.wandb.ai/guides/integrations/inference) to provide hosted model inference.\n",
    "\n",
    "Before you can use the guide, you must complete the [W&B Inference service prerequisites](https://weave-docs.wandb.ai/guides/integrations/inference#prerequisites). \n",
    "\n",
    "\n",
    "> **Tip** \n",
    ">\n",
    "> Familiarize yourself with [W&B Inference usage information and limits](https://weave-docs.wandb.ai/guides/integrations/inference#usage-information-and-limits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56XteuP7s7sm"
   },
   "outputs": [],
   "source": [
    "# Install dependancies and imports\n",
    "!pip install wandb weave openai -q\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import weave\n",
    "\n",
    "# üîë Setup your API keys\n",
    "# Running this cell will prompt you for your API key with `getpass` and will not echo to the terminal.\n",
    "#####\n",
    "print(\"---\")\n",
    "print(\"Find your Weights & Biases API key here: https://wandb.ai/authorize\")\n",
    "os.environ[\"WANDB_API_KEY\"] = getpass(\"Enter your Weights & Biases API key: \")\n",
    "print(\"---\")\n",
    "os.environ[\"WANDB_TEAM\"] = input(\n",
    "    \"Enter your Weights & Biases entity/team name [my_great_team]: \"\n",
    ")\n",
    "os.environ[\"WANDB_PROJECT\"] = input(\n",
    "    \"Enter your Weights & Biases project name [my_super_project]: \"\n",
    ")\n",
    "print(\"---\")\n",
    "#####\n",
    "\n",
    "# üè† Enter your W&B project name\n",
    "weave_client = weave.init(\n",
    "    f\"{os.environ['WANDB_TEAM']}/{os.environ['WANDB_PROJECT']}\"\n",
    ")  # Initialize as: `team_name/project_name`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mmzfm_cxr6Z"
   },
   "source": [
    "## üêù Create your first threads\n",
    "\n",
    "The following code sample demonstrates how to capture and visualize a capture Traces and Threads.\\\n",
    "Specifically, you create a thread context, which helps you to create, resume, and trace threads in W&B Weave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I1w-C5MHtjRg"
   },
   "outputs": [],
   "source": [
    "# Create customer service bot\n",
    "from datetime import datetime\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class CustomerProfile(BaseModel):\n",
    "    customer_id: str\n",
    "    name: str\n",
    "    account_type: str\n",
    "    order_history: list[str]\n",
    "    open_issues: list[str]\n",
    "\n",
    "\n",
    "class TicketStatus(BaseModel):\n",
    "    ticket_id: str\n",
    "    status: str  # \"open\", \"in_progress\", \"resolved\"\n",
    "    priority: str  # \"low\", \"medium\", \"high\"\n",
    "    created_at: datetime\n",
    "    resolved_at: datetime | None = None\n",
    "\n",
    "\n",
    "class CustomerServiceBot:\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI(\n",
    "            base_url=\"https://api.inference.wandb.ai/v1\",\n",
    "            api_key=os.environ[\"WANDB_API_KEY\"],\n",
    "            project=f\"{os.environ['WANDB_TEAM']}/{os.environ['WANDB_PROJECT']}\",  # Project name as: `team_name/project_name`\n",
    "        )\n",
    "        # Mock database of customer profiles\n",
    "        self.customer_db = {\n",
    "            \"CUST-12345\": {\n",
    "                \"name\": \"Alice Johnson\",\n",
    "                \"account_type\": \"Premium\",\n",
    "                \"order_history\": [\"ORD-001\", \"ORD-002\", \"ORD-003\"],\n",
    "                \"open_issues\": [\"Missing package for ORD-003\"],\n",
    "            }\n",
    "        }\n",
    "        # Store ticket information\n",
    "        self.tickets = {}\n",
    "\n",
    "    @weave.op\n",
    "    def retrieve_customer_profile(self, customer_id: str) -> CustomerProfile:\n",
    "        \"\"\"TURN-LEVEL: Retrieve customer information from database.\"\"\"\n",
    "        profile_data = self.customer_db.get(customer_id, {})\n",
    "        if not profile_data:\n",
    "            return CustomerProfile(\n",
    "                customer_id=customer_id,\n",
    "                name=\"Unknown\",\n",
    "                account_type=\"None\",\n",
    "                order_history=[],\n",
    "                open_issues=[],\n",
    "            )\n",
    "        return CustomerProfile(customer_id=customer_id, **profile_data)\n",
    "\n",
    "    @weave.op\n",
    "    def create_support_ticket(self, customer_id: str, issue: str) -> str:\n",
    "        \"\"\"TURN-LEVEL: Create a new support ticket for the customer.\"\"\"\n",
    "        ticket_id = f\"TKT-{len(self.tickets) + 1001}\"\n",
    "        self.tickets[ticket_id] = TicketStatus(\n",
    "            ticket_id=ticket_id,\n",
    "            status=\"open\",\n",
    "            priority=\"medium\",\n",
    "            created_at=datetime.now(),\n",
    "        )\n",
    "        return ticket_id\n",
    "\n",
    "    @weave.op\n",
    "    def generate_response(\n",
    "        self, customer_profile: CustomerProfile, message: str, context: list[dict]\n",
    "    ) -> str:\n",
    "        \"\"\"TURN-LEVEL: Generate AI response based on customer message and context.\"\"\"\n",
    "        system_prompt = f\"\"\"You are a helpful customer service representative.\n",
    "Customer Info:\n",
    "- Name: {customer_profile.name}\n",
    "- Account Type: {customer_profile.account_type}\n",
    "- Open Issues: {\", \".join(customer_profile.open_issues) if customer_profile.open_issues else \"None\"}\n",
    "\n",
    "Be professional, empathetic, and solution-oriented.\"\"\"\n",
    "\n",
    "        messages = (\n",
    "            [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "            + context\n",
    "            + [{\"role\": \"user\", \"content\": message}]\n",
    "        )\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    @weave.op\n",
    "    def check_order_status(self, order_id: str) -> dict:\n",
    "        \"\"\"TURN-LEVEL: Check the status of a specific order.\"\"\"\n",
    "        # Mock order status lookup\n",
    "        order_statuses = {\n",
    "            \"ORD-001\": {\"status\": \"delivered\", \"date\": \"2024-01-15\"},\n",
    "            \"ORD-002\": {\"status\": \"delivered\", \"date\": \"2024-01-20\"},\n",
    "            \"ORD-003\": {\"status\": \"in_transit\", \"expected\": \"2024-01-28\"},\n",
    "        }\n",
    "        return order_statuses.get(order_id, {\"status\": \"not_found\"})\n",
    "\n",
    "    @weave.op\n",
    "    def mark_ticket_resolved(self, ticket_id: str) -> bool:\n",
    "        \"\"\"TURN-LEVEL: Mark a support ticket as resolved.\"\"\"\n",
    "        if ticket_id in self.tickets:\n",
    "            self.tickets[ticket_id].status = \"resolved\"\n",
    "            self.tickets[ticket_id].resolved_at = datetime.now()\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s--XDIvdwvrB"
   },
   "outputs": [],
   "source": [
    "# Example: Customer service conversation with async interactions\n",
    "bot = CustomerServiceBot()\n",
    "service_id = \"30JpiK8wERBiv0NxzlqTKn4LWcj\"\n",
    "customer_id = \"CUST-12345\"\n",
    "thread_id = f\"support_thread_{service_id}\"\n",
    "\n",
    "# Store conversation state that persists between sessions\n",
    "conversation_state = {\"context\": [], \"ticket_id\": None, \"status\": \"active\"}\n",
    "\n",
    "# ---\n",
    "\n",
    "# SESSION 1: Customer initiates conversation\n",
    "print(\"=== SESSION 1: Customer initiates support request ===\")\n",
    "with weave.thread(thread_id) as thread_ctx:\n",
    "    print(f\"Thread ID: {thread_ctx.thread_id}\\n\")\n",
    "\n",
    "    # Turn 1: Customer initiates contact\n",
    "    print(\"Customer: Hi, I'm having issues with my recent order\")\n",
    "\n",
    "    # Retrieve customer profile (non-LLM operation)\n",
    "    profile = bot.retrieve_customer_profile(customer_id)\n",
    "    print(f\"[System: Retrieved profile for {profile.name}]\")\n",
    "\n",
    "    # Generate initial response\n",
    "    response = bot.generate_response(\n",
    "        profile,\n",
    "        \"Hi, I'm having issues with my recent order\",\n",
    "        conversation_state[\"context\"],\n",
    "    )\n",
    "    print(f\"Bot: {response}\\n\")\n",
    "\n",
    "    # Update conversation state\n",
    "    conversation_state[\"context\"].extend(\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"Hi, I'm having issues with my recent order\"},\n",
    "            {\"role\": \"assistant\", \"content\": response},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"[Customer leaves to check order details...]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJfqPpUowvo9"
   },
   "outputs": [],
   "source": [
    "# SESSION 2: Customer returns with more information\n",
    "print(\"\\n‚è∞ Time passes... Customer returns 2 hours later\\n\")\n",
    "print(\"=== SESSION 2: Customer provides order details ===\")\n",
    "with weave.thread(thread_id) as thread_ctx:\n",
    "    print(f\"Resuming thread: {thread_ctx.thread_id}\\n\")\n",
    "\n",
    "    # Retrieve saved conversation context\n",
    "    print(\n",
    "        f\"[System: Found {len(conversation_state['context']) // 2} previous turns in conversation]\"\n",
    "    )\n",
    "\n",
    "    # Turn 2: Customer provides more details\n",
    "    print(\n",
    "        \"Customer: My order ORD-003 should have arrived yesterday but I haven't received it\"\n",
    "    )\n",
    "\n",
    "    # Retrieve customer profile again\n",
    "    profile = bot.retrieve_customer_profile(customer_id)\n",
    "\n",
    "    # Check order status (non-LLM operation)\n",
    "    order_status = bot.check_order_status(\"ORD-003\")\n",
    "    print(f\"[System: Order status - {order_status}]\")\n",
    "\n",
    "    # Generate response with order information\n",
    "    response = bot.generate_response(\n",
    "        profile,\n",
    "        \"My order ORD-003 should have arrived yesterday but I haven't received it\",\n",
    "        conversation_state[\"context\"],\n",
    "    )\n",
    "    print(f\"Bot: {response}\\n\")\n",
    "\n",
    "    # Update conversation state\n",
    "    conversation_state[\"context\"].extend(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"My order ORD-003 should have arrived yesterday but I haven't received it\",\n",
    "            },\n",
    "            {\"role\": \"assistant\", \"content\": response},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create support ticket\n",
    "    ticket_id = bot.create_support_ticket(customer_id, \"Missing package for ORD-003\")\n",
    "    conversation_state[\"ticket_id\"] = ticket_id\n",
    "    print(f\"[System: Created support ticket {ticket_id}]\")\n",
    "\n",
    "    print(\"[Customer needs to leave for a meeting...]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZYmZl8XwveC"
   },
   "outputs": [],
   "source": [
    "# SESSION 3: Customer follows up\n",
    "print(\"\\n‚è∞ Time passes... Customer returns next day\\n\")\n",
    "print(\"=== SESSION 3: Customer checks on ticket status ===\")\n",
    "with weave.thread(thread_id) as thread_ctx:\n",
    "    print(f\"Resuming thread: {thread_ctx.thread_id}\\n\")\n",
    "\n",
    "    # Retrieve saved state\n",
    "    print(f\"[System: Found {len(conversation_state['context']) // 2} previous turns]\")\n",
    "    print(f\"[System: Active ticket: {conversation_state['ticket_id']}]\")\n",
    "\n",
    "    # Retrieve customer profile\n",
    "    profile = bot.retrieve_customer_profile(customer_id)\n",
    "\n",
    "    # Turn 3: Customer asks for update\n",
    "    print(\"Customer: Hi, I'm back. Any update on my missing package?\")\n",
    "\n",
    "    response = bot.generate_response(\n",
    "        profile,\n",
    "        \"Hi, I'm back. Any update on my missing package?\",\n",
    "        conversation_state[\"context\"],\n",
    "    )\n",
    "    print(f\"Bot: {response}\\n\")\n",
    "\n",
    "    # Update conversation state\n",
    "    conversation_state[\"context\"].extend(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Hi, I'm back. Any update on my missing package?\",\n",
    "            },\n",
    "            {\"role\": \"assistant\", \"content\": response},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Turn 4: Resolution\n",
    "    print(\"Customer: Great, thanks for resolving this!\")\n",
    "\n",
    "    # Mark ticket as resolved (non-LLM operation)\n",
    "    resolved = bot.mark_ticket_resolved(conversation_state[\"ticket_id\"])\n",
    "    print(\n",
    "        f\"[System: Ticket {conversation_state['ticket_id']} marked as resolved: {resolved}]\"\n",
    "    )\n",
    "\n",
    "    # Final response\n",
    "    response = bot.generate_response(\n",
    "        profile, \"Great, thanks for resolving this!\", conversation_state[\"context\"]\n",
    "    )\n",
    "    print(f\"Bot: {response}\")\n",
    "\n",
    "    conversation_state[\"status\"] = \"resolved\"\n",
    "    print(\n",
    "        f\"\\n[Thread {thread_ctx.thread_id} completed with {len(conversation_state['context']) // 2} total turns across 3 sessions]\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGqeyYMmw7Hl"
   },
   "source": [
    "## üöÄ Looking for more examples?\n",
    "- Check out the [Quickstart guide](https://weave-docs.wandb.ai/quickstart).\n",
    "- Learn more about [advanced tracing topics](https://weave-docs.wandb.ai/tutorial-tracing_2).\n",
    "- Learn more about [tracing in Weave](https://weave-docs.wandb.ai/guides/tracking/tracing)\n",
    "- Learn more about the [inference service](https://weave-docs.wandb.ai/guides/integrations/inference).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
