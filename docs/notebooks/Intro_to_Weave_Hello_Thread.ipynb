{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LeCBIPQIDq0"
      },
      "source": [
        "# Introduction to Threads\n",
        "\n",
        "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "\n",
        "Weave is a toolkit for developing AI-powered applications.\n",
        "\n",
        "Threads in Weave group related traces into conversations, making it easy to track multi-turn interactions with LLMs.\n",
        "\n",
        "While individual traces capture single function calls, threads automatically organize these traces into coherent sequences—perfect for debugging chat sessions, multi-step workflows, or any scenario where context builds across multiple operations.\n",
        "\n",
        "Simply use the same thread ID across related @weave.op decorated functions, and Weave will link them together, giving you a complete view of how your application handles extended conversations or complex workflows.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McE7cuqSxMiP"
      },
      "source": [
        "## 🔑 Prerequisites (using W&B Inference)\n",
        "\n",
        "You can use W&B Inference to jumpstart your projects with hosted model inference.\\\n",
        "Before you can begin tracing in Weave, complete the following prerequisites.\n",
        "\n",
        "1. Install the W&B Weave SDK and log in with your [API key](https://wandb.ai/settings#api).\n",
        "2. Initialize your W&B project.\n",
        "3. Use your OpenAI SDK as you usually would with `https://api.inference.wandb.ai/v1` as your `base_url`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56XteuP7s7sm"
      },
      "outputs": [],
      "source": [
        "# Install dependancies and imports\n",
        "!pip install wandb weave openai -q\n",
        "\n",
        "import os\n",
        "import json\n",
        "import weave\n",
        "from getpass import getpass\n",
        "\n",
        "# 🔑 Setup your API keys\n",
        "# Running this cell will prompt you for your API key with `getpass` and will not echo to the terminal.\n",
        "#####\n",
        "print(\"---\")\n",
        "print(\"Find your Weights & Biases API key here: https://wandb.ai/authorize\")\n",
        "os.environ[\"WANDB_API_KEY\"] = getpass(\"Enter your Weights & Biases API key: \")\n",
        "print(\"---\")\n",
        "os.environ[\"WANDB_TEAM\"] = input(\"Enter your Weights & Biases entity/team name [my_great_team]: \")\n",
        "os.environ[\"WANDB_PROJECT\"] = input(\"Enter your Weights & Biases project name [my_super_project]: \")\n",
        "print(\"---\")\n",
        "#####\n",
        "\n",
        "# 🏠 Enter your W&B project name\n",
        "weave_client = weave.init(f\"{os.environ['WANDB_TEAM']}/{os.environ['WANDB_PROJECT']}\") # Initialize as: `team_name/project_name`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mmzfm_cxr6Z"
      },
      "source": [
        "## 🐝 Create your first threads\n",
        "\n",
        "The following code sample shows how to capture and visualize a capture Traces and Threads in W&B Weave.\\\n",
        "This will help demonstrate how you can create a thread context which will help you create, resume, and trace to threads in W&B Weave."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1w-C5MHtjRg"
      },
      "outputs": [],
      "source": [
        "# Create customer service bot\n",
        "import json\n",
        "from pydantic import BaseModel\n",
        "from datetime import datetime\n",
        "from openai import OpenAI\n",
        "\n",
        "class CustomerProfile(BaseModel):\n",
        "    customer_id: str\n",
        "    name: str\n",
        "    account_type: str\n",
        "    order_history: list[str]\n",
        "    open_issues: list[str]\n",
        "\n",
        "class TicketStatus(BaseModel):\n",
        "    ticket_id: str\n",
        "    status: str  # \"open\", \"in_progress\", \"resolved\"\n",
        "    priority: str  # \"low\", \"medium\", \"high\"\n",
        "    created_at: datetime\n",
        "    resolved_at: datetime | None = None\n",
        "\n",
        "class CustomerServiceBot:\n",
        "    def __init__(self):\n",
        "        self.client = OpenAI(\n",
        "          base_url='https://api.inference.wandb.ai/v1',\n",
        "          api_key=os.environ[\"WANDB_API_KEY\"],\n",
        "          project=f\"{os.environ['WANDB_TEAM']}/{os.environ['WANDB_PROJECT']}\", # Project name as: `team_name/project_name`\n",
        "        )\n",
        "        # Mock database of customer profiles\n",
        "        self.customer_db = {\n",
        "            \"CUST-12345\": {\n",
        "                \"name\": \"Alice Johnson\",\n",
        "                \"account_type\": \"Premium\",\n",
        "                \"order_history\": [\"ORD-001\", \"ORD-002\", \"ORD-003\"],\n",
        "                \"open_issues\": [\"Missing package for ORD-003\"]\n",
        "            }\n",
        "        }\n",
        "        # Store ticket information\n",
        "        self.tickets = {}\n",
        "\n",
        "    @weave.op\n",
        "    def retrieve_customer_profile(self, customer_id: str) -> CustomerProfile:\n",
        "        \"\"\"TURN-LEVEL: Retrieve customer information from database.\"\"\"\n",
        "        profile_data = self.customer_db.get(customer_id, {})\n",
        "        if not profile_data:\n",
        "            return CustomerProfile(\n",
        "                customer_id=customer_id,\n",
        "                name=\"Unknown\",\n",
        "                account_type=\"None\",\n",
        "                order_history=[],\n",
        "                open_issues=[]\n",
        "            )\n",
        "        return CustomerProfile(\n",
        "            customer_id=customer_id,\n",
        "            **profile_data\n",
        "        )\n",
        "\n",
        "    @weave.op\n",
        "    def create_support_ticket(self, customer_id: str, issue: str) -> str:\n",
        "        \"\"\"TURN-LEVEL: Create a new support ticket for the customer.\"\"\"\n",
        "        ticket_id = f\"TKT-{len(self.tickets) + 1001}\"\n",
        "        self.tickets[ticket_id] = TicketStatus(\n",
        "            ticket_id=ticket_id,\n",
        "            status=\"open\",\n",
        "            priority=\"medium\",\n",
        "            created_at=datetime.now()\n",
        "        )\n",
        "        return ticket_id\n",
        "\n",
        "    @weave.op\n",
        "    def generate_response(self, customer_profile: CustomerProfile, message: str, context: list[dict]) -> str:\n",
        "        \"\"\"TURN-LEVEL: Generate AI response based on customer message and context.\"\"\"\n",
        "        system_prompt = f\"\"\"You are a helpful customer service representative.\n",
        "Customer Info:\n",
        "- Name: {customer_profile.name}\n",
        "- Account Type: {customer_profile.account_type}\n",
        "- Open Issues: {', '.join(customer_profile.open_issues) if customer_profile.open_issues else 'None'}\n",
        "\n",
        "Be professional, empathetic, and solution-oriented.\"\"\"\n",
        "\n",
        "        messages = [{\"role\": \"system\", \"content\": system_prompt}] + context + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
        "            messages=messages,\n",
        "            temperature=0.7,\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    @weave.op\n",
        "    def check_order_status(self, order_id: str) -> dict:\n",
        "        \"\"\"TURN-LEVEL: Check the status of a specific order.\"\"\"\n",
        "        # Mock order status lookup\n",
        "        order_statuses = {\n",
        "            \"ORD-001\": {\"status\": \"delivered\", \"date\": \"2024-01-15\"},\n",
        "            \"ORD-002\": {\"status\": \"delivered\", \"date\": \"2024-01-20\"},\n",
        "            \"ORD-003\": {\"status\": \"in_transit\", \"expected\": \"2024-01-28\"}\n",
        "        }\n",
        "        return order_statuses.get(order_id, {\"status\": \"not_found\"})\n",
        "\n",
        "    @weave.op\n",
        "    def mark_ticket_resolved(self, ticket_id: str) -> bool:\n",
        "        \"\"\"TURN-LEVEL: Mark a support ticket as resolved.\"\"\"\n",
        "        if ticket_id in self.tickets:\n",
        "            self.tickets[ticket_id].status = \"resolved\"\n",
        "            self.tickets[ticket_id].resolved_at = datetime.now()\n",
        "            return True\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Customer service conversation with async interactions\n",
        "bot = CustomerServiceBot()\n",
        "service_id = \"30JpiK8wERBiv0NxzlqTKn4LWcj\"\n",
        "customer_id = \"CUST-12345\"\n",
        "thread_id = f\"support_thread_{service_id}\"\n",
        "\n",
        "# Store conversation state that persists between sessions\n",
        "conversation_state = {\n",
        "    \"context\": [],\n",
        "    \"ticket_id\": None,\n",
        "    \"status\": \"active\"\n",
        "}\n",
        "\n",
        "# ---\n",
        "\n",
        "# SESSION 1: Customer initiates conversation\n",
        "print(\"=== SESSION 1: Customer initiates support request ===\")\n",
        "with weave.thread(thread_id) as thread_ctx:\n",
        "    print(f\"Thread ID: {thread_ctx.thread_id}\\n\")\n",
        "\n",
        "    # Turn 1: Customer initiates contact\n",
        "    print(\"Customer: Hi, I'm having issues with my recent order\")\n",
        "\n",
        "    # Retrieve customer profile (non-LLM operation)\n",
        "    profile = bot.retrieve_customer_profile(customer_id)\n",
        "    print(f\"[System: Retrieved profile for {profile.name}]\")\n",
        "\n",
        "    # Generate initial response\n",
        "    response = bot.generate_response(\n",
        "        profile,\n",
        "        \"Hi, I'm having issues with my recent order\",\n",
        "        conversation_state[\"context\"]\n",
        "    )\n",
        "    print(f\"Bot: {response}\\n\")\n",
        "\n",
        "    # Update conversation state\n",
        "    conversation_state[\"context\"].extend([\n",
        "        {\"role\": \"user\", \"content\": \"Hi, I'm having issues with my recent order\"},\n",
        "        {\"role\": \"assistant\", \"content\": response}\n",
        "    ])\n",
        "\n",
        "    print(\"[Customer leaves to check order details...]\")"
      ],
      "metadata": {
        "id": "s--XDIvdwvrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SESSION 2: Customer returns with more information\n",
        "print(\"\\n⏰ Time passes... Customer returns 2 hours later\\n\")\n",
        "print(\"=== SESSION 2: Customer provides order details ===\")\n",
        "with weave.thread(thread_id) as thread_ctx:\n",
        "    print(f\"Resuming thread: {thread_ctx.thread_id}\\n\")\n",
        "\n",
        "    # Retrieve saved conversation context\n",
        "    print(f\"[System: Found {len(conversation_state['context'])//2} previous turns in conversation]\")\n",
        "\n",
        "    # Turn 2: Customer provides more details\n",
        "    print(\"Customer: My order ORD-003 should have arrived yesterday but I haven't received it\")\n",
        "\n",
        "    # Retrieve customer profile again\n",
        "    profile = bot.retrieve_customer_profile(customer_id)\n",
        "\n",
        "    # Check order status (non-LLM operation)\n",
        "    order_status = bot.check_order_status(\"ORD-003\")\n",
        "    print(f\"[System: Order status - {order_status}]\")\n",
        "\n",
        "    # Generate response with order information\n",
        "    response = bot.generate_response(\n",
        "        profile,\n",
        "        \"My order ORD-003 should have arrived yesterday but I haven't received it\",\n",
        "        conversation_state[\"context\"]\n",
        "    )\n",
        "    print(f\"Bot: {response}\\n\")\n",
        "\n",
        "    # Update conversation state\n",
        "    conversation_state[\"context\"].extend([\n",
        "        {\"role\": \"user\", \"content\": \"My order ORD-003 should have arrived yesterday but I haven't received it\"},\n",
        "        {\"role\": \"assistant\", \"content\": response}\n",
        "    ])\n",
        "\n",
        "    # Create support ticket\n",
        "    ticket_id = bot.create_support_ticket(customer_id, \"Missing package for ORD-003\")\n",
        "    conversation_state[\"ticket_id\"] = ticket_id\n",
        "    print(f\"[System: Created support ticket {ticket_id}]\")\n",
        "\n",
        "    print(\"[Customer needs to leave for a meeting...]\")"
      ],
      "metadata": {
        "id": "aJfqPpUowvo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SESSION 3: Customer follows up\n",
        "print(\"\\n⏰ Time passes... Customer returns next day\\n\")\n",
        "print(\"=== SESSION 3: Customer checks on ticket status ===\")\n",
        "with weave.thread(thread_id) as thread_ctx:\n",
        "    print(f\"Resuming thread: {thread_ctx.thread_id}\\n\")\n",
        "\n",
        "    # Retrieve saved state\n",
        "    print(f\"[System: Found {len(conversation_state['context'])//2} previous turns]\")\n",
        "    print(f\"[System: Active ticket: {conversation_state['ticket_id']}]\")\n",
        "\n",
        "    # Retrieve customer profile\n",
        "    profile = bot.retrieve_customer_profile(customer_id)\n",
        "\n",
        "    # Turn 3: Customer asks for update\n",
        "    print(\"Customer: Hi, I'm back. Any update on my missing package?\")\n",
        "\n",
        "    response = bot.generate_response(\n",
        "        profile,\n",
        "        \"Hi, I'm back. Any update on my missing package?\",\n",
        "        conversation_state[\"context\"]\n",
        "    )\n",
        "    print(f\"Bot: {response}\\n\")\n",
        "\n",
        "    # Update conversation state\n",
        "    conversation_state[\"context\"].extend([\n",
        "        {\"role\": \"user\", \"content\": \"Hi, I'm back. Any update on my missing package?\"},\n",
        "        {\"role\": \"assistant\", \"content\": response}\n",
        "    ])\n",
        "\n",
        "    # Turn 4: Resolution\n",
        "    print(\"Customer: Great, thanks for resolving this!\")\n",
        "\n",
        "    # Mark ticket as resolved (non-LLM operation)\n",
        "    resolved = bot.mark_ticket_resolved(conversation_state[\"ticket_id\"])\n",
        "    print(f\"[System: Ticket {conversation_state['ticket_id']} marked as resolved: {resolved}]\")\n",
        "\n",
        "    # Final response\n",
        "    response = bot.generate_response(\n",
        "        profile,\n",
        "        \"Great, thanks for resolving this!\",\n",
        "        conversation_state[\"context\"]\n",
        "    )\n",
        "    print(f\"Bot: {response}\")\n",
        "\n",
        "    conversation_state[\"status\"] = \"resolved\"\n",
        "    print(f\"\\n[Thread {thread_ctx.thread_id} completed with {len(conversation_state['context'])//2} total turns across 3 sessions]\")"
      ],
      "metadata": {
        "id": "CZYmZl8XwveC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGqeyYMmw7Hl"
      },
      "source": [
        "## 🚀 Looking for more examples?\n",
        "- Check out the [Quickstart guide](https://weave-docs.wandb.ai/quickstart).\n",
        "- Learn more about [advanced tracing topics](https://weave-docs.wandb.ai/tutorial-tracing_2).\n",
        "- Learn more about [tracing in Weave](https://weave-docs.wandb.ai/guides/tracking/tracing)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}