{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Traces\n",
    "\n",
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "Weave is a toolkit for developing AI-powered applications.\n",
    "\n",
    "You can use Weave to:\n",
    "- Log and debug language model inputs, outputs, and traces.\n",
    "- Build rigorous, apples-to-apples evaluations for language model use cases.\n",
    "- Organize all the information generated across the LLM workflow, from experimentation to evaluations to production.\n",
    "\n",
    "Weave traces let you automatically capture the inputs, outputs, and internal structure of your Python functions—especially useful when working with LLMs. By decorating a function with `@weave.op`, Weave records a rich trace of how your function runs, including any nested operations or external API calls. This makes it easy to debug, understand, and visualize how your code is interacting with language models, all from within your notebook.\n",
    "\n",
    "To get started, complete the prerequisites. Then, define a function with the `@weave.op` decorator to track LLM calls, run it on an example input, and Weave will automatically capture and visualize the trace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McE7cuqSxMiP"
   },
   "source": [
    "## 🔑 Prerequisites\n",
    "\n",
    "Before you can begin tracing in Weave, complete the following prerequisites.\n",
    "\n",
    "1. Install the W&B Weave SDK and log in with your [API key](https://wandb.ai/settings#api).\n",
    "2. Install the OpenAI SDK and log in with your [API key](https://platform.openai.com/api-keys).\n",
    "3. Initialize your W&B project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56XteuP7s7sm"
   },
   "outputs": [],
   "source": [
    "# Install dependancies and imports\n",
    "!pip install wandb weave openai -q\n",
    "\n",
    "import json\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "import weave\n",
    "\n",
    "# 🔑 Setup your API keys\n",
    "# Running this cell will prompt you for your API key with `getpass` and will not echo to the terminal.\n",
    "#####\n",
    "print(\"---\")\n",
    "print(\n",
    "    \"You can find your Weights and Biases API key here: https://wandb.ai/settings#api\"\n",
    ")\n",
    "os.environ[\"WANDB_API_KEY\"] = getpass(\"Enter your Weights and Biases API key: \")\n",
    "print(\"---\")\n",
    "print(\"You can generate your OpenAI API key here: https://platform.openai.com/api-keys\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "print(\"---\")\n",
    "#####\n",
    "\n",
    "# 🏠 Enter your W&B project name\n",
    "weave_client = weave.init(\"MY_PROJECT_NAME\")  # 🐝 Your W&B project name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mmzfm_cxr6Z"
   },
   "source": [
    "## 🐝 Run your first trace\n",
    "\n",
    "The following code sample shows how to capture and visualize a trace in Weave using the `@weave.op` decorator. It defines a function called `extract_fruit` that sends a prompt to OpenAI's GPT-4o to extract structured data (fruit, color, and flavor) from a sentence. By decorating the function with `@weave.op`, Weave automatically tracks the function execution, including inputs, outputs, and intermediate steps. When the function is called with a sample sentence, the full trace is saved and viewable in the Weave UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I1w-C5MHtjRg"
   },
   "outputs": [],
   "source": [
    "@weave.op()  # 🐝 Decorator to track requests\n",
    "def extract_fruit(sentence: str) -> dict:\n",
    "    client = OpenAI()\n",
    "    system_prompt = (\n",
    "        \"Parse sentences into a JSON dict with keys: fruit, color and flavor.\"\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": sentence},\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    extracted = response.choices[0].message.content\n",
    "    return json.loads(extracted)\n",
    "\n",
    "\n",
    "sentence = \"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.\"\n",
    "extract_fruit(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGqeyYMmw7Hl"
   },
   "source": [
    "## 🚀 Looking for more examples?\n",
    "- Check out the [Quickstart guide](https://weave-docs.wandb.ai/quickstart).\n",
    "- Learn more about [advanced tracing topics](https://weave-docs.wandb.ai/tutorial-tracing_2).\n",
    "- Learn more about [tracing in Weave](https://weave-docs.wandb.ai/guides/tracking/tracing)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
