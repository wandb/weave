{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBqN8UqJFkTU"
   },
   "source": [
    "<!-- docusaurus_head_meta::start\n",
    "---\n",
    "title: Custom Model Cost\n",
    "---\n",
    "docusaurus_head_meta::end -->\n",
    "\n",
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "<!--- @wandbcode{prompt-optim-notebook} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EauaASOOUsB"
   },
   "source": [
    "# Setting up a custom cost model\n",
    "\n",
    "Weave calculates costs based on the number of tokens used and the model used.\n",
    "Weave grabs this usage and model from the output and associates them with the call.\n",
    "\n",
    "Let's set up a simple custom model, that calculates its own token usage, and stores that in weave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hedL2oOzFzV"
   },
   "source": [
    "## Set up the environment\n",
    "\n",
    "We install and import all needed packages.\n",
    "We set `WANDB_API_KEY` in our env so that we may easily login with `wandb.login()` (this should be given to the colab as a secret).\n",
    "\n",
    "We set the project in W&B we want to log this into in `name_of_wandb_project`.\n",
    "\n",
    "**_NOTE:_** `name_of_wandb_project` may also be in the format of `{team_name}/{project_name}` to specify a team to log the traces into.\n",
    "\n",
    "We then fetch a weave client by calling `weave.init()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJcDCJWWShcZ",
    "outputId": "c299298b-2ed4-48d4-bf18-f157c6c1613a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.1/374.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.7/310.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "%pip install wandb weave datetime --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sm4jLwmcSbRa",
    "outputId": "61433309-6180-4f57-8b41-00cb8d19b282"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import wandb\n",
    "from google.colab import userdata\n",
    "\n",
    "import weave\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = userdata.get(\"WANDB_API_KEY\")\n",
    "name_of_wandb_project = \"custom-cost-model\"\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKawLdN3SmJG",
    "outputId": "71f993e2-36bc-4dcb-bdcc-8475d90fa6e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: jwlee64.\n",
      "View Weave data at https://wandb.ai/jwlee64/custom-cost-model/weave\n"
     ]
    }
   ],
   "source": [
    "weave_client = weave.init(name_of_wandb_project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBbdEOZB0NRF"
   },
   "source": [
    "## Setting up a model with weave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KF1E9lq_3rYN"
   },
   "outputs": [],
   "source": [
    "from weave import Model\n",
    "\n",
    "\n",
    "class YourModel(Model):\n",
    "    attribute1: str\n",
    "    attribute2: int\n",
    "\n",
    "    def simple_token_count(self, text: str) -> int:\n",
    "        return len(text) // 3\n",
    "\n",
    "    # This is a custom op that we are defining\n",
    "    # It takes in a string, and outputs a dict with the usage counts, model name, and the output\n",
    "    @weave.op()\n",
    "    def custom_model_generate(self, input_data: str) -> dict:\n",
    "        # Model logic goes here\n",
    "        # Here is where you would have a custom generate function\n",
    "        prediction = self.attribute1 + \" \" + input_data\n",
    "\n",
    "        # Usage counts\n",
    "        prompt_tokens = self.simple_token_count(input_data)\n",
    "        completion_tokens = self.simple_token_count(prediction)\n",
    "\n",
    "        # We return a dictionary with the usage counts, model name, and the output\n",
    "        # Weave will automatically associate this with the trace\n",
    "        # This object {usage, model, output} matches the output of a OpenAI Call\n",
    "        return {\n",
    "            \"usage\": {\n",
    "                \"input_tokens\": prompt_tokens,\n",
    "                \"output_tokens\": completion_tokens,\n",
    "            },\n",
    "            \"model\": \"your_model_name\",\n",
    "            \"output\": prediction,\n",
    "        }\n",
    "\n",
    "    # In our predict function we call our custom generate function, and return the output.\n",
    "    @weave.op()\n",
    "    def predict(self, input_data: str) -> dict:\n",
    "        # Here is where you would do any post processing of the data\n",
    "        outputs = self.custom_model_generate(input_data)\n",
    "        return outputs[\"output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2POaCQQw0dek"
   },
   "source": [
    "## Add a custom cost\n",
    "\n",
    "Here we add a custom cost, and now that we have a custom cost, and our calls have usage, we can fetch the calls with `include_cost` and our calls with have costs under `summary.weave.costs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zvqi8tjvSyIk",
    "outputId": "6f1c2afe-bf85-400e-97c4-dce474c16c32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/jwlee64/custom-cost-model/r/call/0191ed26-6b43-7901-8fd0-6c444794c1b2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[WeaveObject(Call(op_name='weave:///jwlee64/custom-cost-model/op/YourModel.predict:NpWYTb8xXYErwikUiWHzvgJPqXdOAOCQ816AXvr0OHI', trace_id='0191ed1e-cd04-7082-a0fc-55b1821ce2bb', project_id='jwlee64/custom-cost-model', parent_id=None, inputs={'self': ObjectRef(entity='jwlee64', project='custom-cost-model', name='YourModel', digest='ZoME9yTFGmehBF84YRElT076gwaGfGVKeYYzcEBEuEY', extra=()), 'input_data': 'world'}, id='0191ed1e-cd04-7082-a0fc-55a48d5b3229', output='Hello world', exception=None, summary={'usage': {'your_model_name': {'input_tokens': 1, 'output_tokens': 3, 'requests': 1}}, 'weave': {'status': <TraceStatus.SUCCESS: 'success'>, 'trace_name': 'YourModel.predict', 'latency_ms': 2, 'costs': {'your_model_name': {'prompt_tokens': 1, 'completion_tokens': 3, 'requests': 1, 'total_tokens': 0, 'prompt_tokens_total_cost': 0.10000000149011612, 'completion_tokens_total_cost': 0.6000000089406967, 'prompt_token_cost': 0.1, 'completion_token_cost': 0.2, 'prompt_token_cost_unit': 'USD', 'completion_token_cost_unit': 'USD', 'effective_date': '2024-09-12 22:34:06.541', 'provider_id': 'default', 'pricing_level': 'project', 'pricing_level_id': 'UHJvamVjdEludGVybmFsSWQ6Mzk5Njg0MTY=', 'created_at': '2024-09-12 22:34:06.541', 'created_by': 'VXNlcjo0NTM4MTM='}}}}, display_name=None, attributes={'weave': {'client_version': '0.51.6', 'source': 'python-sdk', 'os_name': 'Linux', 'os_version': '#1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024', 'os_release': '6.1.85+', 'sys_version': '3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]'}}, started_at=datetime.datetime(2024, 9, 13, 20, 41, 44, 452000, tzinfo=TzInfo(UTC)), ended_at=datetime.datetime(2024, 9, 13, 20, 41, 44, 454000, tzinfo=TzInfo(UTC)), deleted_at=None, _children=[], _feedback=None)),\n",
       " WeaveObject(Call(op_name='weave:///jwlee64/custom-cost-model/op/YourModel.predict:NpWYTb8xXYErwikUiWHzvgJPqXdOAOCQ816AXvr0OHI', trace_id='0191ed1f-0208-7260-a273-4d36393f39d4', project_id='jwlee64/custom-cost-model', parent_id=None, inputs={'self': ObjectRef(entity='jwlee64', project='custom-cost-model', name='YourModel', digest='ZoME9yTFGmehBF84YRElT076gwaGfGVKeYYzcEBEuEY', extra=()), 'input_data': 'world'}, id='0191ed1f-0208-7260-a273-4d2817bb2b76', output='Hello world', exception=None, summary={'usage': {'your_model_name': {'input_tokens': 1, 'output_tokens': 3, 'requests': 1}}, 'weave': {'status': <TraceStatus.SUCCESS: 'success'>, 'trace_name': 'YourModel.predict', 'latency_ms': 1, 'costs': {'your_model_name': {'prompt_tokens': 1, 'completion_tokens': 3, 'requests': 1, 'total_tokens': 0, 'prompt_tokens_total_cost': 0.10000000149011612, 'completion_tokens_total_cost': 0.6000000089406967, 'prompt_token_cost': 0.1, 'completion_token_cost': 0.2, 'prompt_token_cost_unit': 'USD', 'completion_token_cost_unit': 'USD', 'effective_date': '2024-09-13 20:41:44.697', 'provider_id': 'default', 'pricing_level': 'project', 'pricing_level_id': 'UHJvamVjdEludGVybmFsSWQ6Mzk5NzQ1NTY=', 'created_at': '2024-09-13 20:41:44.697', 'created_by': 'VXNlcjo0NTM4MTM='}}}}, display_name=None, attributes={'weave': {'client_version': '0.51.6', 'source': 'python-sdk', 'os_name': 'Linux', 'os_version': '#1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024', 'os_release': '6.1.85+', 'sys_version': '3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]'}}, started_at=datetime.datetime(2024, 9, 13, 20, 41, 58, 24000, tzinfo=TzInfo(UTC)), ended_at=datetime.datetime(2024, 9, 13, 20, 41, 58, 25000, tzinfo=TzInfo(UTC)), deleted_at=None, _children=[], _feedback=None)),\n",
       " WeaveObject(Call(op_name='weave:///jwlee64/custom-cost-model/op/YourModel.predict:NpWYTb8xXYErwikUiWHzvgJPqXdOAOCQ816AXvr0OHI', trace_id='0191ed25-1ae9-74b3-b312-b2c81566be94', project_id='jwlee64/custom-cost-model', parent_id=None, inputs={'self': ObjectRef(entity='jwlee64', project='custom-cost-model', name='YourModel', digest='ZoME9yTFGmehBF84YRElT076gwaGfGVKeYYzcEBEuEY', extra=()), 'input_data': 'world'}, id='0191ed25-1ae9-74b3-b312-b2bd5928fe19', output='Hello world', exception=None, summary={'usage': {'your_model_name': {'input_tokens': 1, 'output_tokens': 3, 'requests': 1}}, 'weave': {'status': <TraceStatus.SUCCESS: 'success'>, 'trace_name': 'YourModel.predict', 'latency_ms': 2, 'costs': {'your_model_name': {'prompt_tokens': 1, 'completion_tokens': 3, 'requests': 1, 'total_tokens': 0, 'prompt_tokens_total_cost': 0.10000000149011612, 'completion_tokens_total_cost': 0.6000000089406967, 'prompt_token_cost': 0.1, 'completion_token_cost': 0.2, 'prompt_token_cost_unit': 'USD', 'completion_token_cost_unit': 'USD', 'effective_date': '2024-09-13 20:41:58.323', 'provider_id': 'default', 'pricing_level': 'project', 'pricing_level_id': 'UHJvamVjdEludGVybmFsSWQ6Mzk5NzQ1NTY=', 'created_at': '2024-09-13 20:41:58.323', 'created_by': 'VXNlcjo0NTM4MTM='}}}}, display_name=None, attributes={'weave': {'client_version': '0.51.6', 'source': 'python-sdk', 'os_name': 'Linux', 'os_version': '#1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024', 'os_release': '6.1.85+', 'sys_version': '3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]'}}, started_at=datetime.datetime(2024, 9, 13, 20, 48, 37, 610000, tzinfo=TzInfo(UTC)), ended_at=datetime.datetime(2024, 9, 13, 20, 48, 37, 612000, tzinfo=TzInfo(UTC)), deleted_at=None, _children=[], _feedback=None))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YourModel(attribute1=\"Hello\", attribute2=1)\n",
    "model.predict(\"world\")\n",
    "\n",
    "# We then add a custom cost to our project\n",
    "weave_client.add_cost(\n",
    "    llm_id=\"your_model_name\", prompt_token_cost=0.1, completion_token_cost=0.2\n",
    ")\n",
    "\n",
    "# We can then query for the calls, and with include_costs=True\n",
    "# we receive the costs back attached to the calls\n",
    "calls = weave_client.get_calls(filter={\"trace_roots_only\": True}, include_costs=True)\n",
    "\n",
    "list(calls)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
