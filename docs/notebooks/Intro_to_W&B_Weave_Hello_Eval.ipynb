{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "\n",
        "Weave is a toolkit for developing AI-powered applications.\n",
        "\n",
        "You can use Weave to:\n",
        "- Log and debug language model inputs, outputs, and traces.\n",
        "- Build rigorous, apples-to-apples evaluations for language model use cases.\n",
        "- Organize all the information generated across the LLM workflow, from experimentation to evaluations to production."
      ],
      "metadata": {
        "id": "Tjh24iCFw8TH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”‘ Prerequisites\n",
        "\n",
        "Install the W&B Weave SDK, OpenAI SDK, and login with your API keys.\\\n",
        "You can find your Weights and Biases API key here: https://wandb.ai/settings#api \\\n",
        "You can generate your OpenAI API key here: https://platform.openai.com/api-keys\n"
      ],
      "metadata": {
        "id": "McE7cuqSxMiP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56XteuP7s7sm"
      },
      "outputs": [],
      "source": [
        "# Install dependancies and imports\n",
        "!pip install wandb weave openai -q\n",
        "\n",
        "import os\n",
        "import openai\n",
        "import json\n",
        "import weave\n",
        "\n",
        "from getpass import getpass\n",
        "from openai import OpenAI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# ðŸ”‘ Setup your API keys\n",
        "# Running this cell will prompt you for your API key with `getpass` and will not echo to the terminal.\n",
        "#####\n",
        "print(\"---\")\n",
        "print(\"You can find your Weights and Biases API key here: https://wandb.ai/settings#api\")\n",
        "os.environ[\"WANDB_API_KEY\"] = getpass('Enter your Weights and Biases API key: ')\n",
        "print(\"---\")\n",
        "print(\"You can generate your OpenAI API key here: https://platform.openai.com/api-keys\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass('Enter your OpenAI API key: ')\n",
        "print(\"---\")\n",
        "#####\n",
        "\n",
        "# ðŸ  Enter your W&B project name\n",
        "weave_client = weave.init('MY_PROJECT_NAME') # ðŸ Your W&B project name"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ Run your first evaluation\n",
        "\n",
        "To iterate on an application, we need a way to evaluate if it's improving.\\\n",
        "To do so, a common practice is to test it against the same set of examples when there is a change. \\\n",
        "Run this sample code to see your first evaluation."
      ],
      "metadata": {
        "id": "0mmzfm_cxr6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Construct a Weave model\n",
        "class FruitExtract(BaseModel):\n",
        "    fruit: str\n",
        "    color: str\n",
        "    flavor: str\n",
        "\n",
        "class ExtractFruitsModel(weave.Model):\n",
        "    model_name: str\n",
        "    prompt_template: str\n",
        "\n",
        "    @weave.op()\n",
        "    def predict(self, sentence: str) -> dict:\n",
        "        client = OpenAI()\n",
        "\n",
        "        response = client.beta.chat.completions.parse(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": self.prompt_template.format(sentence=sentence)}\n",
        "            ],\n",
        "            response_format=FruitExtract\n",
        "        )\n",
        "        result = response.choices[0].message.parsed\n",
        "        return result\n",
        "\n",
        "model = ExtractFruitsModel(\n",
        "    name='gpt4o',\n",
        "    model_name='gpt-4o',\n",
        "    prompt_template='Extract fields (\"fruit\": <str>, \"color\": <str>, \"flavor\": <str>) as json, from the following text : {sentence}'\n",
        ")\n",
        "\n",
        "# 2. Collect some samples\n",
        "sentences = [\n",
        "    \"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.\",\n",
        "    \"Pounits are a bright green color and are more savory than sweet.\",\n",
        "    \"Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\"\n",
        "]\n",
        "labels = [\n",
        "    {'fruit': 'neoskizzles', 'color': 'purple', 'flavor': 'candy'},\n",
        "    {'fruit': 'pounits', 'color': 'green', 'flavor': 'savory'},\n",
        "    {'fruit': 'glowls', 'color': 'orange', 'flavor': 'sour, bitter'}\n",
        "]\n",
        "examples = [\n",
        "    {'id': '0', 'sentence': sentences[0], 'target': labels[0]},\n",
        "    {'id': '1', 'sentence': sentences[1], 'target': labels[1]},\n",
        "    {'id': '2', 'sentence': sentences[2], 'target': labels[2]}\n",
        "]\n",
        "\n",
        "# 3. Define a scoring function for your evaluation\n",
        "@weave.op()\n",
        "def fruit_name_score(target: dict, output: FruitExtract) -> dict:\n",
        "    target_flavors = [f.strip().lower() for f in target['flavor'].split(',')]\n",
        "    output_flavors = [f.strip().lower() for f in output.flavor.split(',')]\n",
        "    # Check if any target flavor is present in the output flavors\n",
        "    matches = any(tf in of for tf in target_flavors for of in output_flavors)\n",
        "    return {'correct': matches}\n",
        "\n",
        "# 4. Run your evaluation\n",
        "evaluation = weave.Evaluation(\n",
        "    name='fruit_eval',\n",
        "    dataset=examples, scorers=[fruit_name_score],\n",
        ")\n",
        "await evaluation.evaluate(model)"
      ],
      "metadata": {
        "id": "I1w-C5MHtjRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸš€ Looking for more examples?\n",
        "Check out our full getting started guide here:\\\n",
        "https://weave-docs.wandb.ai/tutorial-eval \\\n",
        "and when you're ready check out our guide on building a RAB-based application:\\\n",
        "https://weave-docs.wandb.ai/tutorial-rag"
      ],
      "metadata": {
        "id": "JGqeyYMmw7Hl"
      }
    }
  ]
}