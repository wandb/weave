{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- docusaurus_head_meta::start\n",
    "---\n",
    "title: Chain of Density Summarization\n",
    "---\n",
    "docusaurus_head_meta::end -->\n",
    "\n",
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "<!--- @wandbcode{cod-notebook} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization using Chain of Density\n",
    "\n",
    "Summarizing complex technical documents while preserving crucial details is a challenging task. The Chain of Density (CoD) summarization technique offers a solution by iteratively refining summaries to be more concise and information-dense. This guide demonstrates how to implement CoD using Weave for tracking and evaluating the application. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Chain of Density Summarization?\n",
    "\n",
    "[![arXiv](https://img.shields.io/badge/arXiv-2309.04269-b31b1b.svg)](https://arxiv.org/abs/2309.04269)\n",
    "\n",
    "Chain of Density (CoD) is an iterative summarization technique that produces increasingly concise and information-dense summaries. It works by:\n",
    "\n",
    "1. Starting with an initial summary\n",
    "2. Iteratively refining the summary, making it more concise while preserving key information\n",
    "3. Increasing the density of entities and technical details with each iteration\n",
    "\n",
    "This approach is particularly useful for summarizing scientific papers or technical documents where preserving detailed information is crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use Weave?\n",
    "\n",
    "In this tutorial, we'll use Weave to implement and evaluate a Chain of Density summarization pipeline for ArXiv papers. You'll learn how to:\n",
    "\n",
    "1. **Track your LLM pipeline**: Use Weave to automatically log inputs, outputs, and intermediate steps of your summarization process.\n",
    "2. **Evaluate LLM outputs**: Create rigorous, apples-to-apples evaluations of your summaries using Weave's built-in tools.\n",
    "3. **Build composable operations**: Combine and reuse Weave operations across different parts of your summarization pipeline.\n",
    "4. **Integrate seamlessly**: Add Weave to your existing Python code with minimal overhead.\n",
    "\n",
    "By the end of this tutorial, you'll have created a CoD summarization pipeline that leverages Weave's capabilities for model serving, evaluation, and result tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment\n",
    "\n",
    "First, let's set up our environment and import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU anthropic weave pydantic requests PyPDF2 set-env-colab-kaggle-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">To get an Anthropic API key:\n",
    "> 1. Sign up for an account at https://www.anthropic.com\n",
    "> 2. Navigate to the API section in your account settings\n",
    "> 3. Generate a new API key\n",
    "> 4. Store the API key securely in your .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import anthropic\n",
    "import requests\n",
    "from pydantic import BaseModel\n",
    "from PyPDF2 import PdfReader\n",
    "from set_env import set_env\n",
    "\n",
    "import weave\n",
    "\n",
    "set_env(\"WANDB_API_KEY\")\n",
    "set_env(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "weave.init(\"summarization-chain-of-density-cookbook\")\n",
    "anthropic_client = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using Weave to track our experiment and Anthropic's Claude model for text generation. The `weave.init(<project name>)` call sets up a new Weave project for our summarization task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the ArxivPaper model\n",
    "\n",
    "We'll create a simple `ArxivPaper` class to represent our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ArxivPaper model\n",
    "class ArxivPaper(BaseModel):\n",
    "    entry_id: str\n",
    "    updated: datetime\n",
    "    published: datetime\n",
    "    title: str\n",
    "    authors: list[str]\n",
    "    summary: str\n",
    "    pdf_url: str\n",
    "\n",
    "\n",
    "# Create sample ArxivPaper\n",
    "arxiv_paper = ArxivPaper(\n",
    "    entry_id=\"http://arxiv.org/abs/2406.04744v1\",\n",
    "    updated=datetime(2024, 6, 7, 8, 43, 7, tzinfo=timezone.utc),\n",
    "    published=datetime(2024, 6, 7, 8, 43, 7, tzinfo=timezone.utc),\n",
    "    title=\"CRAG -- Comprehensive RAG Benchmark\",\n",
    "    authors=[\"Xiao Yang\", \"Kai Sun\", \"Hao Xin\"],  # Truncated for brevity\n",
    "    summary=\"Retrieval-Augmented Generation (RAG) has recently emerged as a promising solution...\",  # Truncated\n",
    "    pdf_url=\"https://arxiv.org/pdf/2406.04744\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class encapsulates the metadata and content of an ArXiv paper, which will be the input to our summarization pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PDF content\n",
    "\n",
    "To work with the full paper content, we'll add a function to load and extract text from PDFs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op()\n",
    "def load_pdf(pdf_url: str) -> str:\n",
    "    # Download the PDF\n",
    "    response = requests.get(pdf_url)\n",
    "    pdf_file = io.BytesIO(response.content)\n",
    "\n",
    "    # Read the PDF\n",
    "    pdf_reader = PdfReader(pdf_file)\n",
    "\n",
    "    # Extract text from all pages\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Chain of Density summarization\n",
    "\n",
    "Now, let's implement the core CoD summarization logic using Weave operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain of Density Summarization\n",
    "@weave.op()\n",
    "def summarize_current_summary(\n",
    "    document: str,\n",
    "    instruction: str,\n",
    "    current_summary: str = \"\",\n",
    "    iteration: int = 1,\n",
    "    model: str = \"claude-3-sonnet-20240229\",\n",
    "):\n",
    "    prompt = f\"\"\"\n",
    "    Document: {document}\n",
    "    Current summary: {current_summary}\n",
    "    Instruction to focus on: {instruction}\n",
    "    Iteration: {iteration}\n",
    "\n",
    "    Generate an increasingly concise, entity-dense, and highly technical summary from the provided document that specifically addresses the given instruction.\n",
    "    \"\"\"\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=model, max_tokens=4096, messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.content[0].text\n",
    "\n",
    "\n",
    "@weave.op()\n",
    "def iterative_density_summarization(\n",
    "    document: str,\n",
    "    instruction: str,\n",
    "    current_summary: str,\n",
    "    density_iterations: int,\n",
    "    model: str = \"claude-3-sonnet-20240229\",\n",
    "):\n",
    "    iteration_summaries = []\n",
    "    for iteration in range(1, density_iterations + 1):\n",
    "        current_summary = summarize_current_summary(\n",
    "            document, instruction, current_summary, iteration, model\n",
    "        )\n",
    "        iteration_summaries.append(current_summary)\n",
    "    return current_summary, iteration_summaries\n",
    "\n",
    "\n",
    "@weave.op()\n",
    "def final_summary(\n",
    "    instruction: str, current_summary: str, model: str = \"claude-3-sonnet-20240229\"\n",
    "):\n",
    "    prompt = f\"\"\"\n",
    "    Given this summary: {current_summary}\n",
    "    And this instruction to focus on: {instruction}\n",
    "    Create an extremely dense, final summary that captures all key technical information in the most concise form possible, while specifically addressing the given instruction.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        anthropic_client.messages.create(\n",
    "            model=model, max_tokens=4096, messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        .content[0]\n",
    "        .text\n",
    "    )\n",
    "\n",
    "\n",
    "@weave.op()\n",
    "def chain_of_density_summarization(\n",
    "    document: str,\n",
    "    instruction: str,\n",
    "    current_summary: str = \"\",\n",
    "    model: str = \"claude-3-sonnet-20240229\",\n",
    "    density_iterations: int = 2,\n",
    "):\n",
    "    current_summary, iteration_summaries = iterative_density_summarization(\n",
    "        document, instruction, current_summary, density_iterations, model\n",
    "    )\n",
    "    final_summary_text = final_summary(instruction, current_summary, model)\n",
    "    return {\n",
    "        \"final_summary\": final_summary_text,\n",
    "        \"accumulated_summary\": current_summary,\n",
    "        \"iteration_summaries\": iteration_summaries,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what each function does:\n",
    "\n",
    "- `summarize_current_summary`: Generates a single summary iteration based on the current state.\n",
    "- `iterative_density_summarization`: Applies the CoD technique by calling `summarize_current_summary` multiple times.\n",
    "- `chain_of_density_summarization`: Orchestrates the entire summarization process and returns the results.\n",
    "\n",
    "By using `@weave.op()` decorators, we ensure that Weave tracks the inputs, outputs, and execution of these functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Weave Model\n",
    "\n",
    "Now, let's wrap our summarization pipeline in a Weave Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weave Model\n",
    "class ArxivChainOfDensityPipeline(weave.Model):\n",
    "    model: str = \"claude-3-sonnet-20240229\"\n",
    "    density_iterations: int = 3\n",
    "\n",
    "    @weave.op()\n",
    "    def predict(self, paper: ArxivPaper, instruction: str) -> dict:\n",
    "        text = load_pdf(paper[\"pdf_url\"])\n",
    "        result = chain_of_density_summarization(\n",
    "            text,\n",
    "            instruction,\n",
    "            model=self.model,\n",
    "            density_iterations=self.density_iterations,\n",
    "        )\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `ArxivChainOfDensityPipeline` class encapsulates our summarization logic as a Weave Model, providing several key benefits:\n",
    "\n",
    "1. Automatic experiment tracking: Weave captures inputs, outputs, and parameters for each run of the model.\n",
    "2. Versioning: Changes to the model's attributes or code are automatically versioned, creating a clear history of how your summarization pipeline evolves over time.\n",
    "3. Reproducibility: The versioning and tracking make it easy to reproduce any previous result or configuration of your summarization pipeline.\n",
    "4. Hyperparameter management: Model attributes (like `model` and `density_iterations`) are clearly defined and tracked across different runs, facilitating experimentation.\n",
    "5. Integration with Weave ecosystem: Using `weave.Model` allows seamless integration with other Weave tools, such as evaluations and serving capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement evaluation metrics\n",
    "\n",
    "To assess the quality of our summaries, we'll implement simple evaluation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "@weave.op()\n",
    "def evaluate_summary(\n",
    "    summary: str, instruction: str, model: str = \"claude-3-sonnet-20240229\"\n",
    ") -> dict:\n",
    "    prompt = f\"\"\"\n",
    "    Summary: {summary}\n",
    "    Instruction: {instruction}\n",
    "\n",
    "    Evaluate the summary based on the following criteria:\n",
    "    1. Relevance (1-5): How well does the summary address the given instruction?\n",
    "    2. Conciseness (1-5): How concise is the summary while retaining key information?\n",
    "    3. Technical Accuracy (1-5): How accurately does the summary convey technical details?\n",
    "\n",
    "    Your response MUST be in the following JSON format:\n",
    "    {{\n",
    "        \"relevance\": {{\n",
    "            \"score\": <int>,\n",
    "            \"explanation\": \"<string>\"\n",
    "        }},\n",
    "        \"conciseness\": {{\n",
    "            \"score\": <int>,\n",
    "            \"explanation\": \"<string>\"\n",
    "        }},\n",
    "        \"technical_accuracy\": {{\n",
    "            \"score\": <int>,\n",
    "            \"explanation\": \"<string>\"\n",
    "        }}\n",
    "    }}\n",
    "\n",
    "    Ensure that the scores are integers between 1 and 5, and that the explanations are concise.\n",
    "    \"\"\"\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=model, max_tokens=1000, messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    print(response.content[0].text)\n",
    "\n",
    "    eval_dict = json.loads(response.content[0].text)\n",
    "\n",
    "    return {\n",
    "        \"relevance\": eval_dict[\"relevance\"][\"score\"],\n",
    "        \"conciseness\": eval_dict[\"conciseness\"][\"score\"],\n",
    "        \"technical_accuracy\": eval_dict[\"technical_accuracy\"][\"score\"],\n",
    "        \"average_score\": sum(eval_dict[k][\"score\"] for k in eval_dict) / 3,\n",
    "        \"evaluation_text\": response.content[0].text,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These evaluation functions use the Claude model to assess the quality of the generated summaries based on relevance, conciseness, and technical accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Weave Dataset and run evaluation\n",
    "\n",
    "To evaluate our pipeline, we'll create a Weave Dataset and run an evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Weave Dataset\n",
    "dataset = weave.Dataset(\n",
    "    name=\"arxiv_papers\",\n",
    "    rows=[\n",
    "        {\n",
    "            \"paper\": arxiv_paper,\n",
    "            \"instruction\": \"What was the approach to experimenting with different data mixtures?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "weave.publish(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our evaluation, we'll use an LLM-as-a-judge approach. This technique involves using a language model to assess the quality of outputs generated by another model or system. It leverages the LLM's understanding and reasoning capabilities to provide nuanced evaluations, especially for tasks where traditional metrics may fall short."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![arXiv](https://img.shields.io/badge/arXiv-2306.05685-b31b1b.svg)](https://arxiv.org/abs/2306.05685)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scorer function\n",
    "@weave.op()\n",
    "def quality_scorer(instruction: str, model_output: dict) -> dict:\n",
    "    result = evaluate_summary(model_output[\"final_summary\"], instruction)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "evaluation = weave.Evaluation(dataset=dataset, scorers=[quality_scorer])\n",
    "arxiv_chain_of_density_pipeline = ArxivChainOfDensityPipeline()\n",
    "results = await evaluation.evaluate(arxiv_chain_of_density_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a dataset with our sample ArXiv paper, defines a quality scorer, and runs an evaluation of our summarization pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this example, we've demonstrated how to implement a Chain of Density summarization pipeline for ArXiv papers using Weave. We've shown how to:\n",
    "\n",
    "1. Create Weave operations for each step of the summarization process\n",
    "2. Wrap the pipeline in a Weave Model for easy tracking and evaluation\n",
    "3. Implement custom evaluation metrics using Weave operations\n",
    "4. Create a dataset and run an evaluation of the pipeline\n",
    "\n",
    "Weave's seamless integration allows us to track inputs, outputs, and intermediate steps throughout the summarization process, making it easier to debug, optimize, and evaluate our LLM application.\n",
    "You can extend this example to handle larger datasets, implement more sophisticated evaluation metrics, or integrate with other LLM workflows.\n",
    "\n",
    "<a \n",
    "  href=\"https://wandb.ai/wandb_fc/arxiv-reader/reports/Building-a-bot-to-summarize-arXiv-papers-as-PDFs-using-Anthrophic-and-W-B-Weave--Vmlldzo4Nzg0ODI4\"\n",
    "  target=\"_blank\"\n",
    "  rel=\"noopener noreferrer\"\n",
    "  className=\"button button--primary button--lg\"\n",
    ">\n",
    "  View Full Report on W&B\n",
    "</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
