{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- docusaurus_head_meta::start\n",
    "---\n",
    "title: Weights & Biases MCP Server\n",
    "---\n",
    "docusaurus_head_meta::end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLKCxvuewpXp"
   },
   "source": [
    "# The Weights & Biases MCP Server\n",
    "\n",
    "The W&B MCP Server enables AI assistants like Cursor, Windsurf, Claude Code and Claude Desktop to directly query and analyze your Weights & Biases data. This gives your AI coding assistant powerful capabilities to help you understand experiments, debug issues, and generate insights from your W&B Models and W&B Weave data.\n",
    "\n",
    ":::note\n",
    "The **[wandb MCP server documentation on GitHub](https://github.com/wandb/wandb-mcp-server/blob/main/README.md)** contains a fuller, in-depth guide on installation, available tools and troubleshooting.\n",
    ":::\n",
    "\n",
    "## Why use the W&B MCP Server?\n",
    "\n",
    "When building AI applications, you often need to:\n",
    "- Compare hyperparameters across experiment runs\n",
    "- Analyze Weave evaluation traces to debug LLM applications  \n",
    "- Create visualizations of training metrics\n",
    "- Generate reports summarizing experiment results\n",
    "\n",
    "The MCP server lets your AI assistant do all of this directly, without you having to manually copy data or write analysis code from scratch.\n",
    "\n",
    "## Available tools\n",
    "\n",
    "The server provides four main tools your AI assistant can use:\n",
    "\n",
    "### `query_wandb_tool`\n",
    "Query W&B experiment tracking data including runs, sweeps, and metrics. Your assistant can find the best performing models and compare metrics and hyperparameters across experiments.\n",
    "\n",
    "### `query_weave_traces_tool`\n",
    "Access Weave traces and evaluations for debugging LLM applications. Analyze latency, token usage, error rates, and trace through complex LLM workflows.\n",
    "\n",
    "### `execute_sandbox_code_tool`\n",
    "Run Python code in secure sandboxes to perform custom analysis, create visualizations, and process data. Supports both cloud (E2B) and local (Pyodide) execution environments.\n",
    "\n",
    "### `create_wandb_report_tool`\n",
    "Generate shareable W&B Reports with visualizations and analysis that you can share with your team.\n",
    "\n",
    "## Quick start\n",
    "\n",
    "1. Install the `uv` package manager:\n",
    "   ```bash\n",
    "   curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "   ```\n",
    "\n",
    "2. Get your W&B API key from [wandb.ai/authorize](https://wandb.ai/authorize)\n",
    "\n",
    "3. Configure your AI assistant by adding the MCP server to its configuration file:\n",
    "   ```json\n",
    "   {\n",
    "     \"mcpServers\": {\n",
    "       \"wandb\": {\n",
    "         \"command\": \"uvx\",\n",
    "         \"args\": [\"wandb-mcp-server\"],\n",
    "         \"env\": {\n",
    "           \"WANDB_API_KEY\": \"your-api-key\"\n",
    "         }\n",
    "       }\n",
    "     }\n",
    "   }\n",
    "   ```\n",
    "\n",
    "4. Restart your AI assistant to load the server\n",
    "\n",
    "### 1-line Quickstart helpers for Cursor, Windsurf, Claude and more\n",
    "\n",
    "The [full wandb MCP server documentation on GitHub](https://github.com/wandb/wandb-mcp-server/blob/main/README.md) contains 1-line quickstart helpers for Cursor, Windsurf, Claude Code and Claude Desktop.\n",
    "\n",
    "## Example queries\n",
    "\n",
    "Once configured, you can ask your AI assistant questions like:\n",
    "\n",
    "- \"What are the top 5 runs by validation accuracy in my `dog-labs/pug-classification` project?\"\n",
    "- \"Show me all Weave traces where latency exceeded 2 seconds in the last hour\"\n",
    "- \"Create a scatter plot comparing learning rate vs final loss for all runs\"\n",
    "- \"Generate a report summarizing the performance of different model architectures\"\n",
    "\n",
    "## Learn more\n",
    "\n",
    "For detailed configuration options, sandbox setup, and troubleshooting, see the [full documentation on GitHub](https://github.com/wandb/wandb-mcp-server/blob/main/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "QLKCxvuewpXp",
    "P7zY5fho4hOG",
    "JKY6F0d06gRh",
    "detJ21276p31",
    "KU36knXx6ZW5"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
