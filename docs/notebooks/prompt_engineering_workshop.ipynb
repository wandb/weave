{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"First, let's install the pre-requisites for this workshop.\"\"\"\n",
    "\n",
    "%pip install weave openai pydantic -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Baisc authentication setup for OpenAI\"\"\"\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not os.environ[\"OPENAI_API_KEY\"] or True:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Next, let's define a simple use case: Support Triage\"\"\"\n",
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import weave\n",
    "\n",
    "\n",
    "class MessageProperties(BaseModel):\n",
    "    customer_name: str\n",
    "    product_model: str\n",
    "    issue_description: str\n",
    "\n",
    "@weave.op\n",
    "def extract_properties_from_message(message: str) -> MessageProperties:\n",
    "    # Define the system prompt\n",
    "    system_prompt = \"\"\"\n",
    "    You are a helpful assistant that extracts properties from a customer support message.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the user prompt\n",
    "    user_prompt = f\"\"\"\n",
    "    Extract the following properties:\n",
    "    - customer_name\n",
    "    - product_model\n",
    "    - issue_description\n",
    "\n",
    "    from the customer support message:\n",
    "    {message}\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the OpenAI client\n",
    "    openai = OpenAI()\n",
    "\n",
    "    # Fetch the response\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Parse the response\n",
    "    parsed = json.loads(response.choices[0].message.content)\n",
    "\n",
    "    # Validate the response\n",
    "    result = MessageProperties.model_validate(parsed)\n",
    "\n",
    "    # Return the result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mNow, let's run this on a basic example:\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m result = \u001b[43mextract_properties_from_message\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHello, My XPhone 12 Pro keeps randomly shutting off mid-call. Please help.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/github/wandb/core/services/weave-python/weave-public/weave/trace/op.py:1240\u001b[39m, in \u001b[36mop.<locals>.op_deco.<locals>.create_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1238\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> R:\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m     res, _ = \u001b[43m_call_sync_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__should_raise\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1243\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(R, res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/github/wandb/core/services/weave-python/weave-public/weave/trace/op.py:394\u001b[39m, in \u001b[36m_call_sync_func\u001b[39m\u001b[34m(op, __weave, __should_raise, __require_explicit_finish, *args, **kwargs)\u001b[39m\n\u001b[32m    392\u001b[39m \u001b[38;5;66;03m# Handle all of the possible cases where we would skip tracing.\u001b[39;00m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tracing_setting_disabled() \u001b[38;5;129;01mor\u001b[39;00m should_skip_tracing_for_op(op):\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m     call.output = res\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res, call\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mextract_properties_from_message\u001b[39m\u001b[34m(message)\u001b[39m\n\u001b[32m     36\u001b[39m response = openai.chat.completions.create(\n\u001b[32m     37\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-3.5-turbo\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m     messages=[\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     ],\n\u001b[32m     42\u001b[39m )\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Parse the response\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m parsed = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Validate the response\u001b[39;00m\n\u001b[32m     48\u001b[39m result = MessageProperties.model_validate(parsed)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.9/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.9/lib/python3.12/json/decoder.py:338\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    334\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    336\u001b[39m \n\u001b[32m    337\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m     end = _w(s, end).end()\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.9/lib/python3.12/json/decoder.py:356\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now, let's run this on a basic example:\n",
    "\"\"\"\n",
    "\n",
    "result = extract_properties_from_message(\n",
    "    \"Hello, My XPhone 12 Pro keeps randomly shutting off mid-call. Please help.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: Logged in as Weights & Biases user: timssweeney.\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: View Weave data at https://wandb.ai/timssweeney/prompt_eng_workshop/weave\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: 🍩 https://wandb.ai/timssweeney/prompt_eng_workshop/r/call/0196ef63-d3fa-7bb3-8a8d-c108f313d6b5\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m weave.init(\u001b[33m\"\u001b[39m\u001b[33mprompt_eng_workshop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m result = \u001b[43mextract_properties_from_message\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHello, My XPhone 12 Pro keeps randomly shutting off mid-call. Please help.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/github/wandb/core/services/weave-python/weave-public/weave/trace/op.py:1240\u001b[39m, in \u001b[36mop.<locals>.op_deco.<locals>.create_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1238\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> R:\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m     res, _ = \u001b[43m_call_sync_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__should_raise\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1243\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(R, res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/github/wandb/core/services/weave-python/weave-public/weave/trace/op.py:497\u001b[39m, in \u001b[36m_call_sync_func\u001b[39m\u001b[34m(op, __weave, __should_raise, __require_explicit_finish, *args, **kwargs)\u001b[39m\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    499\u001b[39m     finish(exception=e)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mextract_properties_from_message\u001b[39m\u001b[34m(message)\u001b[39m\n\u001b[32m     36\u001b[39m response = openai.chat.completions.create(\n\u001b[32m     37\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-3.5-turbo\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m     messages=[\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     ],\n\u001b[32m     42\u001b[39m )\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Parse the response\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m parsed = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Validate the response\u001b[39;00m\n\u001b[32m     48\u001b[39m result = MessageProperties.model_validate(parsed)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.9/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.9/lib/python3.12/json/decoder.py:338\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    334\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    336\u001b[39m \n\u001b[32m    337\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m     end = _w(s, end).end()\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.9/lib/python3.12/json/decoder.py:356\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "weave.init(\"prompt_eng_workshop\")\n",
    "\n",
    "result = extract_properties_from_message(\n",
    "    \"Hello, My XPhone 12 Pro keeps randomly shutting off mid-call. Please help.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the synthetic dataset\n",
    "dataset = [\n",
    "    {\n",
    "        \"email\": \"Hello,\\nI'm John Doe. My XPhone 12 Pro keeps randomly shutting off mid-call. Please help!\\nThanks, John.\",\n",
    "        \"gold\": {\n",
    "            \"customer_name\": \"John Doe\",\n",
    "            \"product_model\": \"XPhone 12 Pro\",\n",
    "            \"issue_description\": \"My XPhone 12 Pro keeps randomly shutting off mid-call\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"email\": \"Hi support,\\nThis is Jane. I bought an AeroWatch V2 last week. The strap fell apart after one day.\\nRegards,\\nJane\",\n",
    "        \"gold\": {\n",
    "            \"customer_name\": \"Jane\",\n",
    "            \"product_model\": \"AeroWatch V2\",\n",
    "            \"issue_description\": \"The strap fell apart after one day\",\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "# 2. Schema and fields\n",
    "SCHEMA_FIELDS = [\"customer_name\", \"product_model\", \"issue_description\"]\n",
    "\n",
    "# 3. Few-shot exemplars (use first 3 of dataset)\n",
    "FEW_SHOT_EXAMPLES = dataset[:3]\n",
    "\n",
    "# 4. Prompt templates\n",
    "ZERO_SHOT_TEMPLATE = \"\"\"\n",
    "Extract the following fields from the customer email and output valid JSON:\n",
    "- customer_name\n",
    "- product_model\n",
    "- issue_description\n",
    "\n",
    "Email:\n",
    "\\\"\\\"\\\"{email}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 5. Placeholder for model call\n",
    "def call_model(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Replace this function with actual LLM API call.\n",
    "    For example, using OpenAI:\n",
    "        response = openai.ChatCompletion.create(...)\n",
    "        return response.choices[0].message.content\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Implement your LLM API call here\")\n",
    "\n",
    "\n",
    "# 6. Evaluation function\n",
    "def evaluate(prompt_fn, use_few_shot: bool = False) -> Tuple[Dict[str, int], int]:\n",
    "    \"\"\"\n",
    "    Runs the model against the dataset, returning per-field correct counts\n",
    "    and the number of full-pass examples.\n",
    "    \"\"\"\n",
    "    results = {f: 0 for f in SCHEMA_FIELDS}\n",
    "    full_pass = 0\n",
    "\n",
    "    few_shot_block = format_few_shot_examples(FEW_SHOT_EXAMPLES) if use_few_shot else \"\"\n",
    "\n",
    "    for example in dataset:\n",
    "        email = example[\"email\"]\n",
    "        gold = example[\"gold\"]\n",
    "\n",
    "        if use_few_shot:\n",
    "            prompt = prompt_fn(few_shot_block, email)\n",
    "        else:\n",
    "            prompt = prompt_fn(email)\n",
    "\n",
    "        try:\n",
    "            output = call_model(prompt)\n",
    "            parsed = json.loads(output)\n",
    "        except Exception:\n",
    "            # Malformed JSON or API error counts as failure on all fields\n",
    "            continue\n",
    "\n",
    "        ok = True\n",
    "        for f in SCHEMA_FIELDS:\n",
    "            if parsed.get(f, \"\").strip() == gold[f].strip():\n",
    "                results[f] += 1\n",
    "            else:\n",
    "                ok = False\n",
    "        if ok:\n",
    "            full_pass += 1\n",
    "\n",
    "    return results, full_pass\n",
    "\n",
    "\n",
    "# 7. Prompt builder functions\n",
    "def build_zero_shot_prompt(email: str) -> str:\n",
    "    return ZERO_SHOT_TEMPLATE.format(email=email)\n",
    "\n",
    "\n",
    "def build_few_shot_prompt(few_shot_block: str, email: str) -> str:\n",
    "    return FEW_SHOT_TEMPLATE.format(examples=few_shot_block, email=email)\n",
    "\n",
    "\n",
    "# 8. Main demonstration\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Zero-Shot Evaluation ===\")\n",
    "    try:\n",
    "        zs_results, zs_full = evaluate(build_zero_shot_prompt, use_few_shot=False)\n",
    "        total = len(dataset)\n",
    "        for f in SCHEMA_FIELDS:\n",
    "            print(f\"{f}: {zs_results[f]}/{total} correct\")\n",
    "        print(f\"Full-pass: {zs_full}/{total}\")\n",
    "    except NotImplementedError as e:\n",
    "        print(e)\n",
    "\n",
    "    print(\"\\n=== Few-Shot Evaluation ===\")\n",
    "    try:\n",
    "        fs_results, fs_full = evaluate(build_few_shot_prompt, use_few_shot=True)\n",
    "        total = len(dataset)\n",
    "        for f in SCHEMA_FIELDS:\n",
    "            print(f\"{f}: {fs_results[f]}/{total} correct\")\n",
    "        print(f\"Full-pass: {fs_full}/{total}\")\n",
    "    except NotImplementedError as e:\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wandb-weave-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
