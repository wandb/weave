# Weave Documentation

> Consolidated LLM-friendly documentation for Weave.



## Table of Contents



### Core Types

- [Models](https://weave-docs.wandb.ai/guides/core-types/models)

- [Media](https://weave-docs.wandb.ai/guides/core-types/media)

- [Env Vars](https://weave-docs.wandb.ai/guides/core-types/env-vars)

- [Datasets](https://weave-docs.wandb.ai/guides/core-types/datasets)

- [Prompts](https://weave-docs.wandb.ai/guides/core-types/prompts)

- [Evaluations](https://weave-docs.wandb.ai/guides/core-types/evaluations)



### Evaluation

- [Builtin Scorers](https://weave-docs.wandb.ai/guides/evaluation/builtin_scorers)

- [Guardrails And Monitors](https://weave-docs.wandb.ai/guides/evaluation/guardrails_and_monitors)

- [Scorers](https://weave-docs.wandb.ai/guides/evaluation/scorers)

- [Weave Local Scorers](https://weave-docs.wandb.ai/guides/evaluation/weave_local_scorers)

- [Evaluation Logger](https://weave-docs.wandb.ai/guides/evaluation/evaluation_logger)



### Integrations

- [Smolagents](https://weave-docs.wandb.ai/guides/integrations/smolagents)

- [Huggingface](https://weave-docs.wandb.ai/guides/integrations/huggingface)

- [Local Models](https://weave-docs.wandb.ai/guides/integrations/local_models)

- [Dspy](https://weave-docs.wandb.ai/guides/integrations/dspy)

- [Anthropic](https://weave-docs.wandb.ai/guides/integrations/anthropic)

- [Groq](https://weave-docs.wandb.ai/guides/integrations/groq)

- [Litellm](https://weave-docs.wandb.ai/guides/integrations/litellm)

- [Mcp](https://weave-docs.wandb.ai/guides/integrations/mcp)

- [Openai](https://weave-docs.wandb.ai/guides/integrations/openai)

- [Bedrock](https://weave-docs.wandb.ai/guides/integrations/bedrock)

- [Openai Agents](https://weave-docs.wandb.ai/guides/integrations/openai_agents)

- [Nvidia Nim](https://weave-docs.wandb.ai/guides/integrations/nvidia_nim)

- [Langchain](https://weave-docs.wandb.ai/guides/integrations/langchain)

- [Pydantic Ai](https://weave-docs.wandb.ai/guides/integrations/pydantic_ai)

- [Cohere](https://weave-docs.wandb.ai/guides/integrations/cohere)

- [Mistral](https://weave-docs.wandb.ai/guides/integrations/mistral)

- [Index](https://weave-docs.wandb.ai/guides/integrations/index)

- [Cerebras](https://weave-docs.wandb.ai/guides/integrations/cerebras)

- [Instructor](https://weave-docs.wandb.ai/guides/integrations/instructor)

- [Google](https://weave-docs.wandb.ai/guides/integrations/google)

- [Together Ai](https://weave-docs.wandb.ai/guides/integrations/together_ai)

- [Llamaindex](https://weave-docs.wandb.ai/guides/integrations/llamaindex)

- [Notdiamond](https://weave-docs.wandb.ai/guides/integrations/notdiamond)

- [Openrouter](https://weave-docs.wandb.ai/guides/integrations/openrouter)

- [Crewai](https://weave-docs.wandb.ai/guides/integrations/crewai)

- [Azure](https://weave-docs.wandb.ai/guides/integrations/azure)



### Introduction

- [Introduction](https://weave-docs.wandb.ai/introduction)



### Other

- [Troubleshooting](https://weave-docs.wandb.ai/guides/troubleshooting)

- [Intro Notebook](https://weave-docs.wandb.ai/reference/generated_typescript_docs/intro-notebook)



### Platform

- [Weave Self Managed](https://weave-docs.wandb.ai/guides/platform/weave-self-managed)

- [Index](https://weave-docs.wandb.ai/guides/platform/index)



### Python SDK

- [Index](https://weave-docs.wandb.ai/reference/python-sdk/weave/index)

- [Weave.Trace.Op](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace/weave.trace.op)

- [Weave.Trace.Weave Client](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace/weave.trace.weave_client)

- [Weave.Trace.Util](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace/weave.trace.util)

- [Weave.Trace.Feedback](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace/weave.trace.feedback)

- [Weave.Trace Server Bindings.Remote Http Trace Server](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace_server_bindings/weave.trace_server_bindings.remote_http_trace_server)

- [Weave.Trace Server.Trace Server Interface](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace_server/weave.trace_server.trace_server_interface)

- [Weave.Trace Server.Interface.Query](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace_server/interface/weave.trace_server.interface.query)



### Quickstart

- [Quickstart](https://weave-docs.wandb.ai/quickstart)



### Service API

- ["Refs Read Batch"](https://weave-docs.wandb.ai/reference/service-api/refs-read-batch-refs-read-batch-post.api)

- ["Objs Query"](https://weave-docs.wandb.ai/reference/service-api/objs-query-objs-query-post.api)

- ["Call Start"](https://weave-docs.wandb.ai/reference/service-api/call-start-call-start-post.api)

- ["Table Update"](https://weave-docs.wandb.ai/reference/service-api/table-update-table-update-post.api)

- ["Table Query Stats Batch"](https://weave-docs.wandb.ai/reference/service-api/table-query-stats-batch-table-query-stats-batch-post.api)

- ["Feedback Purge"](https://weave-docs.wandb.ai/reference/service-api/feedback-purge-feedback-purge-post.api)

- ["Table Query"](https://weave-docs.wandb.ai/reference/service-api/table-query-table-query-post.api)

- ["Calls Query Stream"](https://weave-docs.wandb.ai/reference/service-api/calls-query-stream-calls-stream-query-post.api)

- ["Cost Create"](https://weave-docs.wandb.ai/reference/service-api/cost-create-cost-create-post.api)

- ["Read Root"](https://weave-docs.wandb.ai/reference/service-api/read-root-health-get.api)

- ["Calls Delete"](https://weave-docs.wandb.ai/reference/service-api/calls-delete-calls-delete-post.api)

- ["Call Update"](https://weave-docs.wandb.ai/reference/service-api/call-update-call-update-post.api)

- ["Read Version"](https://weave-docs.wandb.ai/reference/service-api/read-version-version-get.api)

- ["Table Query Stats"](https://weave-docs.wandb.ai/reference/service-api/table-query-stats-table-query-stats-post.api)

- ["FastAPI"](https://weave-docs.wandb.ai/reference/service-api/fastapi.info)

- ["Obj Read"](https://weave-docs.wandb.ai/reference/service-api/obj-read-obj-read-post.api)

- ["Table Create"](https://weave-docs.wandb.ai/reference/service-api/table-create-table-create-post.api)

- ["Server Info"](https://weave-docs.wandb.ai/reference/service-api/server-info-server-info-get.api)

- ["Obj Create"](https://weave-docs.wandb.ai/reference/service-api/obj-create-obj-create-post.api)

- ["Feedback Create"](https://weave-docs.wandb.ai/reference/service-api/feedback-create-feedback-create-post.api)

- ["Call End"](https://weave-docs.wandb.ai/reference/service-api/call-end-call-end-post.api)

- ["File Content"](https://weave-docs.wandb.ai/reference/service-api/file-content-file-content-post.api)

- ["Cost Purge"](https://weave-docs.wandb.ai/reference/service-api/cost-purge-cost-purge-post.api)

- ["Export Trace"](https://weave-docs.wandb.ai/reference/service-api/export-trace-otel-v-1-traces-post.api)

- ["Feedback Query"](https://weave-docs.wandb.ai/reference/service-api/feedback-query-feedback-query-post.api)

- ["Call Read"](https://weave-docs.wandb.ai/reference/service-api/call-read-call-read-post.api)

- ["Calls Query Stats"](https://weave-docs.wandb.ai/reference/service-api/calls-query-stats-calls-query-stats-post.api)

- ["File Create"](https://weave-docs.wandb.ai/reference/service-api/file-create-file-create-post.api)

- ["Cost Query"](https://weave-docs.wandb.ai/reference/service-api/cost-query-cost-query-post.api)

- ["Call Start Batch"](https://weave-docs.wandb.ai/reference/service-api/call-start-batch-call-upsert-batch-post.api)

- ["Feedback Replace"](https://weave-docs.wandb.ai/reference/service-api/feedback-replace-feedback-replace-post.api)

- ["Obj Delete"](https://weave-docs.wandb.ai/reference/service-api/obj-delete-obj-delete-post.api)



### Tools

- [Comparison](https://weave-docs.wandb.ai/guides/tools/comparison)

- [Deploy](https://weave-docs.wandb.ai/guides/tools/deploy)

- [Playground](https://weave-docs.wandb.ai/guides/tools/playground)

- [Saved Views](https://weave-docs.wandb.ai/guides/tools/saved-views)

- [Index](https://weave-docs.wandb.ai/guides/tools/index)

- [Serve](https://weave-docs.wandb.ai/guides/tools/serve)



### Tracking

- [Costs](https://weave-docs.wandb.ai/guides/tracking/costs)

- [Ops](https://weave-docs.wandb.ai/guides/tracking/ops)

- [Faqs](https://weave-docs.wandb.ai/guides/tracking/faqs)

- [Otel](https://weave-docs.wandb.ai/guides/tracking/otel)

- [Video](https://weave-docs.wandb.ai/guides/tracking/video)

- [Objects](https://weave-docs.wandb.ai/guides/tracking/objects)

- [Trace Tree](https://weave-docs.wandb.ai/guides/tracking/trace-tree)

- [Index](https://weave-docs.wandb.ai/guides/tracking/index)

- [Tracing](https://weave-docs.wandb.ai/guides/tracking/tracing)

- [Feedback](https://weave-docs.wandb.ai/guides/tracking/feedback)

- [Redact Pii](https://weave-docs.wandb.ai/guides/tracking/redact-pii)



### Tutorials

- [Tutorial Eval](https://weave-docs.wandb.ai/tutorial-eval)

- [Tutorial Rag](https://weave-docs.wandb.ai/tutorial-rag)

- [Tutorial Weave Models](https://weave-docs.wandb.ai/tutorial-weave_models)

- [Tutorial Tracing 2](https://weave-docs.wandb.ai/tutorial-tracing_2)



### TypeScript SDK

- [Readme](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/README)

- [Weaveclient](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/classes/WeaveClient)

- [Dataset](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/classes/Dataset)

- [Weaveobject](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/classes/WeaveObject)

- [Evaluation](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/classes/Evaluation)

- [Op](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/type-aliases/Op)

- [Requirecurrentcallstackentry](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/requireCurrentCallStackEntry)

- [Weaveaudio](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/weaveAudio)

- [Weaveimage](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/weaveImage)

- [Op](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/op)

- [Login](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/login)

- [Init](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/init)

- [Wrapopenai](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/wrapOpenAI)

- [Requirecurrentchildsummary](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/requireCurrentChildSummary)

- [Callsfilter](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/interfaces/CallsFilter)

- [Callschema](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/interfaces/CallSchema)



### Example Notebooks

- [Scorers as Guardrails](https://weave-docs.wandb.ai/reference/gen_notebooks/scorers_as_guardrails)

- [Intro To Weave Hello Eval](https://weave-docs.wandb.ai/reference/gen_notebooks/Intro_to_Weave_Hello_Eval)

- [Service API](https://weave-docs.wandb.ai/reference/gen_notebooks/weave_via_service_api)

- [Custom Model Cost](https://weave-docs.wandb.ai/reference/gen_notebooks/custom_model_cost)

- [Log Feedback from Production](https://weave-docs.wandb.ai/reference/gen_notebooks/feedback_prod)

- [Intro To Weave Hello Trace](https://weave-docs.wandb.ai/reference/gen_notebooks/Intro_to_Weave_Hello_Trace)

- [NotDiamond Custom Routing](https://weave-docs.wandb.ai/reference/gen_notebooks/notdiamond_custom_routing)

- [Handling and Redacting PII](https://weave-docs.wandb.ai/reference/gen_notebooks/pii)

- [Prompt Optimization](https://weave-docs.wandb.ai/reference/gen_notebooks/dspy_prompt_optimization)

- [Code Generation](https://weave-docs.wandb.ai/reference/gen_notebooks/codegen)

- [Models And Weave Integration Demo](https://weave-docs.wandb.ai/reference/gen_notebooks/Models_and_Weave_Integration_Demo)

- [Introduction Notebook](https://weave-docs.wandb.ai/reference/gen_notebooks/01-intro_notebook)

- [Integrating with Weave - Production Dashboard](https://weave-docs.wandb.ai/reference/gen_notebooks/online_monitoring)

- [Using HuggingFace Datasets in evaluations with `preprocess_model_input`](https://weave-docs.wandb.ai/reference/gen_notebooks/hf_dataset_evals)

- [Log Calls from Existing CSV](https://weave-docs.wandb.ai/reference/gen_notebooks/import_from_csv)

- [Structured Outputs for Multi-Agent Systems](https://weave-docs.wandb.ai/reference/gen_notebooks/multi-agent-structured-output)

- [Ocr Pipeline](https://weave-docs.wandb.ai/reference/gen_notebooks/ocr-pipeline)

- [Chain of Density Summarization](https://weave-docs.wandb.ai/reference/gen_notebooks/chain_of_density)

- [Log Audio With Weave](https://weave-docs.wandb.ai/reference/gen_notebooks/audio_with_weave)

- [Leaderboard Quickstart](https://weave-docs.wandb.ai/reference/gen_notebooks/leaderboard_quickstart)



<!--- Docs: Core Types -->
<!--- Models -->

# Models

# Models

A `Model` is a combination of data (which can include configuration, trained model weights, or other information) and code that defines how the model operates. By structuring your code to be compatible with this API, you benefit from a structured way to version your application so you can more systematically keep track of your experiments.


  
    To create a model in Weave, you need the following:

    - a class that inherits from `weave.Model`
    - type definitions on all parameters
    - a typed `predict` function with `@weave.op()` decorator

    ```python
    from weave import Model
    import weave

    class YourModel(Model):
        attribute1: str
        attribute2: int

        @weave.op()
        def predict(self, input_data: str) -> dict:
            # Model logic goes here
            prediction = self.attribute1 + ' ' + input_data
            return {'pred': prediction}
    ```

    You can call the model as usual with:

    ```python
    import weave
    weave.init('intro-example')

    model = YourModel(attribute1='hello', attribute2=5)
    model.predict('world')
    ```

    This will track the model settings along with the inputs and outputs anytime you call `predict`.

    ## Automatic versioning of models

    When you change the parameters or the code that defines your model, these changes will be logged and the version will be updated.
    This ensures that you can compare the predictions across different versions of your model. Use this to iterate on prompts or to try the latest LLM and compare predictions across different settings.

    For example, here we create a new model:

    ```python
    import weave
    weave.init('intro-example')

    model = YourModel(attribute1='howdy', attribute2=10)
    model.predict('world')
    ```

    After calling this, you will see that you now have two versions of this Model in the UI, each with different tracked calls.

    ## Serve models

    To serve a model, you can easily spin up a FastAPI server by calling:

    ```bash
    weave serve 
    ```

    For additional instructions, see [serve](/guides/tools/serve).

    ## Track production calls

    To separate production calls, you can add an additional attribute to the predictions for easy filtering in the UI or API.

    ```python
    with weave.attributes({'env': 'production'}):
        model.predict('world')
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```

[Source](https://weave-docs.wandb.ai/guides/core-types/models)

<!--- Docs: Core Types -->
<!--- Media -->

# Media

# Logging media

Weave supports logging and displaying video, images, and audio.

## Video

Weave automatically logs videos using [`moviepy`](https://zulko.github.io/moviepy/). This allows you to pass video inputs and outputs to traced functions, and Weave will automatically handle uploading and storing video data.

> 💡 **Note**: Video support is currently only available in Python.

For usage information, see [Video Support](../tracking/video).

## Images

Logging type: `PIL.Image.Image`. 

> 🚨 **Important**: Base64-encoded image strings (e.g., `data:image/jpeg;base64,...`) are technically supported but discouraged. They can cause performance issues and should only be used if absolutely necessary (e.g., for integration with specific APIs).

The following example shows how to log an image generated via the OpenAI DALL-E API:


  
  
    ```python
    import weave
    from openai import OpenAI
    import requests
    from PIL import Image

    weave.init('image-example')
    client = OpenAI()

    @weave.op
    def generate_image(prompt: str) -> Image:
        response = client.images.generate(
            model="dall-e-3",
            prompt=prompt,
            size="1024x1024",
            quality="standard",
            n=1,
        )
        image_url = response.data[0].url
        image_response = requests.get(image_url, stream=True)
        image = Image.open(image_response.raw)

        # return a PIL.Image.Image object to be logged as an image
        return image

    generate_image("a cat with a pumpkin hat")
    ```

  
  

    ```typescript
        
    async function main() {
        const client = await weave.init('image-example');
        const openai = new OpenAI();

        const generateImage = weave.op(async (prompt: string) => {
            const response = await openai.images.generate({
                model: 'dall-e-3',
                prompt: prompt,
                size: '1024x1024',
                quality: 'standard',
                n: 1,
            });
            const imageUrl = response.data[0].url;
            const imgResponse = await fetch(imageUrl);
            const data = Buffer.from(await imgResponse.arrayBuffer());

            return weave.weaveImage({data});
        });

        generateImage('a cat with a pumpkin hat');
    }

    main();
    ```

  


This image is logged to Weave and automatically displayed in the UI. 



## Audio

Logging type: `wave.Wave_read`. 

The following example shows how to log an audio file using OpenAI's speech generation API.


  
  
    ```python
    import weave
    from openai import OpenAI
    import wave

    weave.init("audio-example")
    client = OpenAI()


    @weave.op
    def make_audio_file_streaming(text: str) -> wave.Wave_read:
        with client.audio.speech.with_streaming_response.create(
            model="tts-1",
            voice="alloy",
            input=text,
            response_format="wav",
        ) as res:
            res.stream_to_file("output.wav")

        # return a wave.Wave_read object to be logged as audio
        return wave.open("output.wav")

    make_audio_file_streaming("Hello, how are you?")
    ```

  
  

    ```typescript
        
    async function main() {
        await weave.init('audio-example');
        const openai = new OpenAI();

        const makeAudioFileStreaming = weave.op(async function audio(text: string) {
            const response = await openai.audio.speech.create({
                model: 'tts-1',
                voice: 'alloy',
                input: text,
                response_format: 'wav',
            });

            const chunks: Uint8Array[] = [];
            for await (const chunk of response.body) {
                chunks.push(chunk);
            }
            return weave.weaveAudio({data: Buffer.concat(chunks)});
        });

        await makeAudioFileStreaming('Hello, how are you?');
    }

    main();
    ```

  


This audio is logged to Weave and automatically displayed in the UI, along with an audio player. In the audio player, you can view and download the raw audio waveform.



> 🌟 **Tip**: Try our cookbook for [Audio Logging](/reference/gen_notebooks/audio_with_weave) or Open in Colab. The cookbook also includes an advanced example of a Real Time Audio API based assistant integrated with Weave.

[Source](https://weave-docs.wandb.ai/guides/core-types/media)

<!--- Docs: Core Types -->
<!--- Env Vars -->

# Env Vars

# Environment variables

Weave provides a set of environment variables to configure and optimize its behavior. You can set these variables in your shell or within scripts to control specific functionality.

```bash
# Example of setting environment variables in the shell
export WEAVE_PARALLELISM=10  # Controls the number of parallel workers
export WEAVE_PRINT_CALL_LINK=false  # Disables call link output
```

```python
# Example of setting environment variables in Python
import os

os.environ["WEAVE_PARALLELISM"] = "10"
os.environ["WEAVE_PRINT_CALL_LINK"] = "false"
```

## Available Environment Variables

| Variable | Type | Default | Description |
|----------|------|---------|-------------|
| `WANDB_API_KEY` | `string` | `None` | If set, automatically log into W&B Weave without being prompted for your API key. To generate an API key, log in to your W&B account and go to [https://wandb.ai/authorize](https://wandb.ai/authorize). |
| `WEAVE_DISABLED` | `bool` | `false` | When set to `true`, disables all Weave tracing. Weave ops will behave like regular functions. |
| `WEAVE_PRINT_CALL_LINK` | `bool` | `true` | Controls whether to print a link to the Weave UI when calling a Weave op. |
| `WEAVE_CAPTURE_CODE` | `bool` | `true` | Controls whether to save code for ops so they can be reloaded for later use. |
| `WEAVE_DEBUG_HTTP` | `bool` | `false` | When set to `true`, turns on HTTP request and response logging for debugging. |
| `WEAVE_PARALLELISM` | `int` | `20` | In evaluations, controls the number of examples to evaluate in parallel. Set to `1` to run examples sequentially. |
| `WEAVE_TRACE_LANGCHAIN` | `bool` | `true` | Controls global tracing for LangChain. Set to `false` to explicitly disable LangChain tracing. |
| `WEAVE_USE_SERVER_CACHE` | `bool` | `true` | Enables server response caching. When enabled, responses from the server are cached to disk to improve performance for repeated queries. |
| `WEAVE_SERVER_CACHE_SIZE_LIMIT` | `int` | `1000000000` | Sets the maximum size limit for the server cache in bytes. When the cache reaches this size, older entries are automatically removed to make space for new ones. Important: the underlying implementation uses SQLite which has a Write Ahead Log (WAL) that will grow to 4MB regardless of this setting. This WAL will be removed when the program exits. |
| `WEAVE_SERVER_CACHE_DIR` | `str` | `None` | Specifies the directory where cache files should be stored. If not set, a temporary directory is used. |
| `WEAVE_MAX_CALLS_QUEUE_SIZE` | `int` | `100000` | Sets the maximum size of the calls queue.  Defaults to 100_000.  Setting a value of 0 means the queue can grow unbounded. |
| `WEAVE_RETRY_MAX_ATTEMPTS` | `int` | `3` | Sets the maximum number of retry attempts for failed requests. |
| `WEAVE_RETRY_MAX_INTERVAL` | `float` | `300.0` | Sets the maximum interval between retry attempts in seconds. |
| `WANDB_BASE_URL` | `string` | `None` | Sets the Weave host URL. Equivalent to entering the host URL when prompted by `wandb.login()`. You can specify `WANDB_BASE_URL` and `WANDB_API_KEY` before using `weave.init()` to automatically log into and authenticate to Weave. |

> 💡 **Note**: All boolean environment variables accept the following values (case-insensitive):
- `true`, `1`, `yes`, `on` for True
- `false`, `0`, `no`, `off` for False

[Source](https://weave-docs.wandb.ai/guides/core-types/env-vars)

<!--- Docs: Core Types -->
<!--- Datasets -->

# Datasets

# Datasets

Weave `Dataset`s help you to organize, collect, track, and version examples for LLM application evaluation for easy comparison. You can create and interact with `Dataset`s programmatically and via the UI. 

This page describes:

- Basic `Dataset` operations in Python and TypeScript and how to get started  
- How to create a `Dataset` in Python and TypeScript from objects such as Weave [calls](../tracking/tracing.mdx)
- Available operations on a `Dataset` in the UI

## `Dataset` quickstart

The following code samples demonstrate how to perform fundamental `Dataset` operations using Python and TypeScript. Using the SDKs, you can:

- Create a `Dataset`
- Publish the `Dataset`
- Retrieve the `Dataset`
- Access a specific example in the `Dataset`

Select a tab to see Python and TypeScript-specific code. 


  
    ```python
    import weave
    from weave import Dataset
    # Initialize Weave
    weave.init('intro-example')

    # Create a dataset
    dataset = Dataset(
        name='grammar',
        rows=[
            {'id': '0', 'sentence': "He no likes ice cream.", 'correction': "He doesn't like ice cream."},
            {'id': '1', 'sentence': "She goed to the store.", 'correction': "She went to the store."},
            {'id': '2', 'sentence': "They plays video games all day.", 'correction': "They play video games all day."}
        ]
    )

    # Publish the dataset
    weave.publish(dataset)

    # Retrieve the dataset
    dataset_ref = weave.ref('grammar').get()

    # Access a specific example
    example_label = dataset_ref.rows[2]['sentence']
    ```

  
  
    ```typescript
    
    // Initialize Weave
    await weave.init('intro-example');

    // Create a dataset
    const dataset = new weave.Dataset({
        name: 'grammar',
        rows: [
            {id: '0', sentence: "He no likes ice cream.", correction: "He doesn't like ice cream."},
            {id: '1', sentence: "She goed to the store.", correction: "She went to the store."},
            {id: '2', sentence: "They plays video games all day.", correction: "They play video games all day."}
        ]
    });

    // Publish the dataset
    await dataset.save();

    // Access a specific example
    const exampleLabel = datasetRef.getRow(2).sentence;
    ```

  


## Create a `Dataset` from other objects


  
  In Python, `Dataset`s can also be constructed from common Weave objects like [calls](../tracking/tracing.mdx), and Python objects like `pandas.DataFrame`s. This feature is useful if you want to create an example `Dataset` from specific examples.

  ### Weave call

  To create a `Dataset` from one or more Weave calls, retrieve the call object(s), and add them to a list in the `from_calls` method.

  ```python
  @weave.op
  def model(task: str) -> str:
      return f"Now working on {task}"

  res1, call1 = model.call(task="fetch")
  res2, call2 = model.call(task="parse")

  dataset = Dataset.from_calls([call1, call2])
  # Now you can use the dataset to evaluate the model, etc.
  ```

  ### Pandas DataFrame

  To create a `Dataset` from a Pandas `DataFrame` object, use the `from_pandas` method. 

  To convert the `Dataset` back, use `to_pandas`.

  ```python
  import pandas as pd

  df = pd.DataFrame([
      {'id': '0', 'sentence': "He no likes ice cream.", 'correction': "He doesn't like ice cream."},
      {'id': '1', 'sentence': "She goed to the store.", 'correction': "She went to the store."},
      {'id': '2', 'sentence': "They plays video games all day.", 'correction': "They play video games all day."}
  ])
  dataset = Dataset.from_pandas(df)
  df2 = dataset.to_pandas()

  assert df.equals(df2)
  ```

  
  
   This feature is not currently available in TypeScript.  Stay tuned!
  


## Create, edit, and delete a `Dataset` in the UI

You can create, edit, and delete `Dataset`s in the UI.

### Create a new `Dataset`

1. Navigate to the Weave project you want to edit.

2. In the sidebar, select **Traces**.

3. Select one or more calls that you want to create a new `Dataset` for.

4. In the upper right-hand menu, click the **Add selected rows to a dataset** icon (located next to the trashcan icon).

5. From the **Choose a dataset** dropdown, select **Create new**. The **Dataset name** field appears.

6. In the **Dataset name** field, enter a name for your dataset. Options to **Configure dataset fields**  appear.

    :::important
    Dataset names must start with a letter or number and can only contain letters, numbers, hyphens, and underscores.
    :::

7. (Optional) In **Configure dataset fields**, select the fields from your calls to include in the dataset.  
    - You can customize the column names for each selected field.
    - You can select a subset of fields to include in the new `Dataset`, or deselect all fields.

8. Once you've configured the dataset fields, click **Next**. A preview of your new `Dataset` appears. 

9. (Optional) Click any of the editable fields in your **Dataset** to edit the entry.

10. Click **Create dataset**. Your new dataset is created.

11. In the confirmation popup, click **View the dataset** to view the new `Dataset`. Alternatively, go to the **Datasets** tab.

### Edit a `Dataset` 

1. Navigate to the Weave project containing the `Dataset` you want to edit.

2. From the sidebar, select **Datasets**. Your available `Dataset`s display.

   

3. In the **Object** column, click the name and version of the `Dataset` you want to edit. A pop-out modal showing `Dataset` information like name, version, author, and `Dataset` rows displays.

   

4. In the upper right-hand corner of the modal, click the **Edit dataset** button (the pencil icon). An **+ Add row** button displays at the bottom of the modal.

    

5. Click **+ Add row**. A green row displays at the top of your existing `Dataset` rows, indicating that you can add a new row to the `Dataset`. 

    

6. To add data to a new row, click the desired column within that row. The default **id** column in a `Dataset` row cannot be edited, as Weave assigns it automatically upon creation. An editing modal appears with **Text**, **Code**, and **Diff** options for formatting.

    

7. Repeat step 6 for each column that you want to add data to in the new row. 

    

8. Repeat step 5 for each row that you want to add to the `Dataset`.

9. Once you're done editing, publish your `Dataset` by clicking **Publish** in the upper right-hand corner of the modal. Alternatively, if you don't want to publish your changes, click **Cancel**. 

    

   Once published, the new version of the `Dataset` with updated rows is available in the UI. 

     
     
   
### Delete a `Dataset`

1. Navigate to the Weave project containing the `Dataset` you want to edit.

2. From the sidebar, select **Datasets**. Your available `Dataset`s display.

3. In the **Object** column, click the name and version of the `Dataset` you want to delete. A pop-out modal showing `Dataset` information like name, version, author, and `Dataset` rows displays.

4. In the upper right-hand corner of the modal, click the trashcan icon. 

   A pop-up modal prompting you to confirm `Dataset` deletion displays. 

   

5. In the pop-up modal, click the red **Delete** button to delete the `Dataset`. Alternatively, click **Cancel** if you don't want to delete the `Dataset`. 

   Now, the `Dataset` is deleted, and no longer visible in the **Datasets** tab in your Weave dashboard.

### Add a new example to a `Dataset`

1. Navigate to the Weave project you want to edit.

2. In the sidebar, select **Traces**.

3. Select one or more calls with `Datasets` for which you want to create new examples.

4. In the upper right-hand menu, click the **Add selected rows to a dataset** icon (located next to the trashcan icon). Optionally, toggle **Show latest versions** to off to display all versions of all available datasets.

5. From the **Choose a dataset** dropdown, select the `Dataset` you want to add examples to. Options to **Configure field mapping** will display.

6. (Optional) In **Configure field mapping**, you can adjust the mapping of fields from your calls to the corresponding dataset columns.

7. Once you've configured field mappings, click **Next**. A preview of your new `Dataset` appears.

8. In the empty row (green), add your new example value(s). Note that the **id** field is not editable and is created automatically by Weave.

9. Click **Add to dataset**. Alternatively, to return to the **Configure field mapping** screen, click **Back**.

10. In the confirmation popup, click **View the dataset** to see the changes. Alternatively, navigate to the **Datasets** tab to view the updates to your `Dataset`.

[Source](https://weave-docs.wandb.ai/guides/core-types/datasets)

<!--- Docs: Core Types -->
<!--- Prompts -->

# Prompts

# Prompts

> 🚨 **Important**: This feature is only accessible through the Python SDK. All code examples on this page are provided in Python.

Creating, evaluating, and refining prompts is a core activity for AI engineers.
Small changes to a prompt can have big impacts on your application's behavior.
Weave lets you create prompts, save and retrieve them, and evolve them over time.

Weave is unopinionated about how a Prompt is constructed. If your needs are simple you can use our built-in `weave.StringPrompt` or `weave.MessagesPrompt` classes. If your needs are more complex you can subclass those or our base class `weave.Prompt` and override the
`format` method.

When you publish one of these objects with `weave.publish`, it will appear in your Weave project on the "Prompts" page.

## StringPrompt

```python
import weave
weave.init('intro-example')
system_prompt = weave.StringPrompt("You are a pirate")
weave.publish(system_prompt, name="pirate_prompt")

from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-4o",
  messages=[
    {
      "role": "system",
      "content": system_prompt.format()
    },
    {
      "role": "user",
      "content": "Explain general relativity in one paragraph."
    }
  ],
)
```

Perhaps this prompt does not yield the desired effect, so we modify the prompt to be more
clearly instructive.

```python
import weave
weave.init('intro-example')
system_prompt = weave.StringPrompt("Talk like a pirate. I need to know I'm listening to a pirate.")
weave.publish(system_prompt, name="pirate_prompt")

from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-4o",
  messages=[
    {
      "role": "system",
      "content": system_prompt.format()
    },
    {
      "role": "user",
      "content": "Explain general relativity in one paragraph."
    }
  ],
)
```

When viewing this prompt object, I can see that it has two versions.



I can also select them for comparison to see exactly what changed.



## MessagesPrompt

The `MessagesPrompt` can be used to replace an array of Message objects.

```python
import weave
weave.init('intro-example')
prompt = weave.MessagesPrompt([
    {
        "role": "system",
        "content": "You are a stegosaurus, but don't be too obvious about it."
    },
    {
        "role": "user",
        "content": "What's good to eat around here?"
    }
])
weave.publish(prompt, name="dino_prompt")

from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-4o",
  messages=prompt.format(),
)
```

## Parameterizing prompts

As the `format` method's name suggests, you can pass arguments to
fill in template placeholders in the content string.

```python
import weave
weave.init('intro-example')
prompt = weave.StringPrompt("Solve the equation {equation}")
weave.publish(prompt, name="calculator_prompt")

from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-4o",
  messages=[
    {
      "role": "user",
      "content": prompt.format(equation="1 + 1 = ?")
    }
  ],
)
```

This also works with `MessagesPrompt`.

```python
import weave
weave.init('intro-example')
prompt = weave.MessagesPrompt([
{
    "role": "system",
    "content": "You will be provided with a description of a scene and your task is to provide a single word that best describes an associated emotion."
},
{
    "role": "user",
    "content": "{scene}"
}
])
weave.publish(prompt, name="emotion_prompt")

from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-4o",
  messages=prompt.format(scene="A dog is lying on a dock next to a fisherman."),
)
```

[Source](https://weave-docs.wandb.ai/guides/core-types/prompts)

<!--- Docs: Core Types -->
<!--- Evaluations -->

# Evaluations

# Evaluation Overview

Evaluation-driven development helps you reliably iterate on an application. The `Evaluation` class is designed to assess the performance of a `Model` on a given `Dataset` or set of examples using scoring functions.



```python
import weave
from weave import Evaluation
import asyncio

# Collect your examples
examples = [
    {"question": "What is the capital of France?", "expected": "Paris"},
    {"question": "Who wrote 'To Kill a Mockingbird'?", "expected": "Harper Lee"},
    {"question": "What is the square root of 64?", "expected": "8"},
]

# Define any custom scoring function
@weave.op()
def match_score1(expected: str, output: dict) -> dict:
    # Here is where you'd define the logic to score the model output
    return {'match': expected == output['generated_text']}

@weave.op()
def function_to_evaluate(question: str):
    # here's where you would add your LLM call and return the output
    return  {'generated_text': 'Paris'}

# Score your examples using scoring functions
evaluation = Evaluation(
    dataset=examples, scorers=[match_score1]
)

# Start tracking the evaluation
weave.init('intro-example')
# Run the evaluation
asyncio.run(evaluation.evaluate(function_to_evaluate))
```

:::info Looking for a less opinionated approach?

If you prefer a more flexible evaluation framework, check out Weave's [`EvaluationLogger`](../evaluation/evaluation_logger.md). The imperative approach offers more flexibility for complex workflows, while the standard evaluation framework provides more structure and guidance.
:::

## Create an Evaluation

To systematically improve your application, it's helpful to test your changes against a consistent dataset of potential inputs so that you catch regressions and can inspect your apps behaviour under different conditions. Using the `Evaluation` class, you can be sure you're comparing apples-to-apples by keeping track of all of the details that you're experimenting and evaluating with.

Weave will take each example, pass it through your application and score the output on multiple custom scoring functions. By doing this, you'll have a view of the performance of your application, and a rich UI to drill into individual outputs and scores.

### Define an evaluation dataset

First, define a [Dataset](/guides/core-types/datasets) or list of dictionaries with a collection of examples to be evaluated. These examples are often failure cases that you want to test for, these are similar to unit tests in Test-Driven Development (TDD).

### Defining scoring functions

Then, create a list of scoring functions. These are used to score each example. Each function should have a `output` and optionally, other inputs from your examples, and return a dictionary with the scores.

Scoring functions need to have a `output` keyword argument, but the other arguments are user defined and are taken from the dataset examples. It will only take the necessary keys by using a dictionary key based on the argument name.

This will take `expected` from the dictionary for scoring.

```python
import weave

# Collect your examples
examples = [
    {"question": "What is the capital of France?", "expected": "Paris"},
    {"question": "Who wrote 'To Kill a Mockingbird'?", "expected": "Harper Lee"},
    {"question": "What is the square root of 64?", "expected": "8"},
]

# Define any custom scoring function
@weave.op()
def match_score1(expected: str, output: dict) -> dict:
    # Here is where you'd define the logic to score the model output
    return {'match': expected == output['generated_text']}
```

### Optional: Define a custom `Scorer` class

In some applications we want to create custom `Scorer` classes - where for example a standardized `LLMJudge` class should be created with specific parameters (e.g. chat model, prompt), specific scoring of each row, and specific calculation of an aggregate score.

See the tutorial on defining a `Scorer` class in the next chapter on [Model-Based Evaluation of RAG applications](/tutorial-rag#optional-defining-a-scorer-class) for more information.

### Define a Model to evaluate

To evaluate a `Model`, call `evaluate` on it using an `Evaluation`. `Models` are used when you have parameters that you want to experiment with and capture in weave.

```python
from weave import Model, Evaluation
import asyncio

class MyModel(Model):
    prompt: str

    @weave.op()
    def predict(self, question: str):
        # here's where you would add your LLM call and return the output
        return {'generated_text': 'Hello, ' + self.prompt}

model = MyModel(prompt='World')

evaluation = Evaluation(
    dataset=examples, scorers=[match_score1]
)
weave.init('intro-example') # begin tracking results with weave
asyncio.run(evaluation.evaluate(model))
```

This will run `predict` on each example and score the output with each scoring functions.

#### Custom Naming

You can change the name of the Evaluation itself by passing a `name` parameter to the `Evaluation` class.

```python
evaluation = Evaluation(
    dataset=examples, scorers=[match_score1], name="My Evaluation"
)
```

You can also change the name of individual evaluations by setting the `display_name` key of the `__weave` dictionary.

> 💡 **Note**: Using the `__weave` dictionary sets the call display name which is distinct from the Evaluation object name. In the
UI, you will see the display name if set, otherwise the Evaluation object name will be used.


```python
evaluation = Evaluation(
    dataset=examples, scorers=[match_score1]
)
evaluation.evaluate(model, __weave={"display_name": "My Evaluation Run"})
```

### Define a function to evaluate

Alternatively, you can also evaluate a function that is wrapped in a `@weave.op()`.

```python
@weave.op()
def function_to_evaluate(question: str):
    # here's where you would add your LLM call and return the output
    return  {'generated_text': 'some response'}

asyncio.run(evaluation.evaluate(function_to_evaluate))
```

### Pulling it all together

```python
from weave import Evaluation, Model
import weave
import asyncio
weave.init('intro-example')
examples = [
    {"question": "What is the capital of France?", "expected": "Paris"},
    {"question": "Who wrote 'To Kill a Mockingbird'?", "expected": "Harper Lee"},
    {"question": "What is the square root of 64?", "expected": "8"},
]

@weave.op()
def match_score1(expected: str, output: dict) -> dict:
    return {'match': expected == output['generated_text']}

@weave.op()
def match_score2(expected: dict, output: dict) -> dict:
    return {'match': expected == output['generated_text']}

class MyModel(Model):
    prompt: str

    @weave.op()
    def predict(self, question: str):
        # here's where you would add your LLM call and return the output
        return {'generated_text': 'Hello, ' + question + self.prompt}

model = MyModel(prompt='World')
evaluation = Evaluation(dataset=examples, scorers=[match_score1, match_score2])

asyncio.run(evaluation.evaluate(model))

@weave.op()
def function_to_evaluate(question: str):
    # here's where you would add your LLM call and return the output
    return  {'generated_text': 'some response' + question}

asyncio.run(evaluation.evaluate(function_to_evaluate))
```

## Advanced evaluation usage

### Using `preprocess_model_input` to format dataset rows before evaluating

> 🚨 **Important**: The `preprocess_model_input` function is only applied to inputs before passing them to the model's prediction function.  
Scorer functions always receive the original dataset example, without any preprocessing applied.

The `preprocess_model_input` parameter allows you to transform your dataset examples before they are passed to your evaluation function. This is useful when you need to:

- Rename fields to match your model's expected input
- Transform data into the correct format
- Add or remove fields
- Load additional data for each example

Here's a simple example that shows how to use `preprocess_model_input` to rename fields:

```python
import weave
from weave import Evaluation
import asyncio

# Our dataset has "input_text" but our model expects "question"
examples = [
    {"input_text": "What is the capital of France?", "expected": "Paris"},
    {"input_text": "Who wrote 'To Kill a Mockingbird'?", "expected": "Harper Lee"},
    {"input_text": "What is the square root of 64?", "expected": "8"},
]

@weave.op()
def preprocess_example(example):
    # Rename input_text to question
    return {
        "question": example["input_text"]
    }

@weave.op()
def match_score(expected: str, output: dict) -> dict:
    return {'match': expected == output['generated_text']}

@weave.op()
def function_to_evaluate(question: str):
    return {'generated_text': f'Answer to: {question}'}

# Create evaluation with preprocessing
evaluation = Evaluation(
    dataset=examples,
    scorers=[match_score],
    preprocess_model_input=preprocess_example
)

# Run the evaluation
weave.init('preprocessing-example')
asyncio.run(evaluation.evaluate(function_to_evaluate))
```

In this example, our dataset contains examples with an `input_text` field, but our evaluation function expects a `question` parameter. The `preprocess_example` function transforms each example by renaming the field, allowing the evaluation to work correctly.

The preprocessing function:

1. Receives the raw example from your dataset
2. Returns a dictionary with the fields your model expects
3. Is applied to each example before it's passed to your evaluation function

This is particularly useful when working with external datasets that may have different field names or structures than what your model expects.

### Using HuggingFace Datasets with evaluations

We are continuously improving our integrations with third-party services and libraries.

While we work on building more seamless integrations, you can use `preprocess_model_input` as a temporary workaround for using HuggingFace Datasets in Weave evaluations.

See our [Using HuggingFace Datasets in evaluations cookbook](/reference/gen_notebooks/hf_dataset_evals) for the current approach.

## Saved views 

You can save your Evals table configurations, filters, and sorts as _saved views_ for quick access to your preferred setup. You can configure and access saved views via the UI and the Python SDK. For more information, see [Saved Views](/guides/tools/saved-views.md).

[Source](https://weave-docs.wandb.ai/guides/core-types/evaluations)



<!--- Docs: Evaluation -->
<!--- Builtin Scorers -->

# Builtin Scorers

# Builtin Scorers


  
    **Installation**

    To use Weave's predefined scorers you need to install some additional dependencies:

    ```bash
    pip install weave[scorers]
    ```

    **LLM-evaluators**
    Update Feb 2025: The pre-defined scorers that leverage LLMs now automatically integrate with litellm.
    You no longer need to pass an LLM client; just set the `model_id`. 
    See the supported models [here](https://docs.litellm.ai/docs/providers).

    ## `HallucinationFreeScorer`

    This scorer checks if your AI system's output includes any hallucinations based on the input data.

    ```python
    from weave.scorers import HallucinationFreeScorer

    scorer = HallucinationFreeScorer()
    ```

    **Customization:**

    - Customize the `system_prompt` and `user_prompt` fields of the scorer to define what "hallucination" means for you.

    **Notes:**

    - The `score` method expects an input column named `context`. If your dataset uses a different name, use the `column_map` attribute to map `context` to the dataset column.

    Here you have an example in the context of an evaluation:

    ```python
    import asyncio
    import weave
    from weave.scorers import HallucinationFreeScorer

    # Initialize scorer with a column mapping if needed.
    hallucination_scorer = HallucinationFreeScorer(
        model_id="openai/gpt-4o", # or any other model supported by litellm
        column_map={"context": "input", "output": "other_col"}
    )

    # Create dataset
    dataset = [
        {"input": "John likes various types of cheese."},
        {"input": "Pepe likes various types of cheese."},
    ]

    @weave.op
    def model(input: str) -> str:
        return "The person's favorite cheese is cheddar."

    # Run evaluation
    evaluation = weave.Evaluation(
        dataset=dataset,
        scorers=[hallucination_scorer],
    )
    result = asyncio.run(evaluation.evaluate(model))
    print(result)
    # Example output:
    # {'HallucinationFreeScorer': {'has_hallucination': {'true_count': 2, 'true_fraction': 1.0}}, 'model_latency': {'mean': ...}}
    ```

    ---

    ## `SummarizationScorer`

    Use an LLM to compare a summary to the original text and evaluate the quality of the summary.

    ```python
    from weave.scorers import SummarizationScorer

    scorer = SummarizationScorer(
        model_id="openai/gpt-4o"  # or any other model supported by litellm
    )
    ```

    **How It Works:**

    This scorer evaluates summaries in two ways:

    1. **Entity Density:** Checks the ratio of unique entities (like names, places, or things) mentioned in the summary to the total word count in the summary in order to estimate the "information density" of the summary. Uses an LLM to extract the entities. Similar to how entity density is used in the Chain of Density paper, https://arxiv.org/abs/2309.04269
    2. **Quality Grading:** An LLM evaluator grades the summary as `poor`, `ok`, or `excellent`. These grades are then mapped to scores (0.0 for poor, 0.5 for ok, and 1.0 for excellent) for aggregate performance evaluation.

    **Customization:**

    - Adjust `summarization_evaluation_system_prompt` and `summarization_evaluation_prompt` to tailor the evaluation process.

    **Notes:**

    - The scorer uses litellm internally.
    - The `score` method expects the original text (the one being summarized) to be present in the `input` column. Use `column_map` if your dataset uses a different name.

    Here you have an example usage in the context of an evaluation:

    ```python
    import asyncio
    import weave
    from weave.scorers import SummarizationScorer

    class SummarizationModel(weave.Model):
        @weave.op()
        async def predict(self, input: str) -> str:
            return "This is a summary of the input text."

    # Initialize scorer
    summarization_scorer = SummarizationScorer(
        model_id="openai/gpt-4o"  # or any other model supported by litellm
    )
    # Create dataset
    dataset = [
        {"input": "The quick brown fox jumps over the lazy dog."},
        {"input": "Artificial Intelligence is revolutionizing various industries."}
    ]
    # Run evaluation
    evaluation = weave.Evaluation(dataset=dataset, scorers=[summarization_scorer])
    results = asyncio.run(evaluation.evaluate(SummarizationModel()))
    print(results)
    # Example output:
    # {'SummarizationScorer': {'is_entity_dense': {'true_count': 0, 'true_fraction': 0.0}, 'summarization_eval_score': {'mean': 0.0}, 'entity_density': {'mean': 0.0}}, 'model_latency': {'mean': ...}}
    ```

    ---

    ## `OpenAIModerationScorer`

    The `OpenAIModerationScorer` uses OpenAI's Moderation API to check if the AI system's output contains disallowed content, such as hate speech or explicit material.

    ```python
    from weave.scorers import OpenAIModerationScorer

    scorer = OpenAIModerationScorer()
    ```

    **How It Works:**

    - Sends the AI's output to the OpenAI Moderation endpoint and returns a structured response indicating if the content is flagged.

    **Notes:**
    Here is an example in the context of an evaluation:

    ```python
    import asyncio
    import weave
    from weave.scorers import OpenAIModerationScorer

    class MyModel(weave.Model):
        @weave.op
        async def predict(self, input: str) -> str:
            return input

    # Initialize scorer
    moderation_scorer = OpenAIModerationScorer()

    # Create dataset
    dataset = [
        {"input": "I love puppies and kittens!"},
        {"input": "I hate everyone and want to hurt them."}
    ]

    # Run evaluation
    evaluation = weave.Evaluation(dataset=dataset, scorers=[moderation_scorer])
    results = asyncio.run(evaluation.evaluate(MyModel()))
    print(results)
    # Example output:
    # {'OpenAIModerationScorer': {'flagged': {'true_count': 1, 'true_fraction': 0.5}, 'categories': {'violence': {'true_count': 1, 'true_fraction': 1.0}}}, 'model_latency': {'mean': ...}}
    ```

    ---

    ## `EmbeddingSimilarityScorer`

    The `EmbeddingSimilarityScorer` computes the cosine similarity between the embeddings of the AI system's output and a target text from your dataset. It is useful for measuring how similar the AI's output is to a reference text.

    ```python
    from weave.scorers import EmbeddingSimilarityScorer

    similarity_scorer = EmbeddingSimilarityScorer(
        model_id="openai/text-embedding-3-small",  # or any other model supported by litellm
        threshold=0.4  # the cosine similarity threshold
    )
    ```

    Note: You can use `column_map` to map the `target` column to a different name.

    **Parameters:**

    - `threshold` (float): The minimum cosine similarity score (between -1 and 1) needed to consider the two texts similar (defaults to `0.5`).

    Here is an example usage in the context of an evaluation:

    ```python
    import asyncio
    import weave
    from weave.scorers import EmbeddingSimilarityScorer

    # Initialize scorer
    similarity_scorer = EmbeddingSimilarityScorer(
        model_id="openai/text-embedding-3-small",  # or any other model supported by litellm
        threshold=0.7
    )
    # Create dataset
    dataset = [
        {
            "input": "He's name is John",
            "target": "John likes various types of cheese.",
        },
        {
            "input": "He's name is Pepe.",
            "target": "Pepe likes various types of cheese.",
        },
    ]
    # Define model
    @weave.op
    def model(input: str) -> str:
        return "John likes various types of cheese."

    # Run evaluation
    evaluation = weave.Evaluation(
        dataset=dataset,
        scorers=[similarity_scorer],
    )
    result = asyncio.run(evaluation.evaluate(model))
    print(result)
    # Example output:
    # {'EmbeddingSimilarityScorer': {'is_similar': {'true_count': 1, 'true_fraction': 0.5}, 'similarity_score': {'mean': 0.844851403}}, 'model_latency': {'mean': ...}}
    ```

    ---

    ## `ValidJSONScorer`

    The `ValidJSONScorer` checks whether the AI system's output is valid JSON. This scorer is useful when you expect the output to be in JSON format and need to verify its validity.

    ```python
    from weave.scorers import ValidJSONScorer

    json_scorer = ValidJSONScorer()
    ```

    Here is an example in the context of an evaluation:

    ```python
    import asyncio
    import weave
    from weave.scorers import ValidJSONScorer

    class JSONModel(weave.Model):
        @weave.op()
        async def predict(self, input: str) -> str:
            # This is a placeholder.
            # In a real scenario, this would generate JSON.
            return '{"key": "value"}'

    model = JSONModel()
    json_scorer = ValidJSONScorer()

    dataset = [
        {"input": "Generate a JSON object with a key and value"},
        {"input": "Create an invalid JSON"}
    ]

    evaluation = weave.Evaluation(dataset=dataset, scorers=[json_scorer])
    results = asyncio.run(evaluation.evaluate(model))
    print(results)
    # Example output:
    # {'ValidJSONScorer': {'json_valid': {'true_count': 2, 'true_fraction': 1.0}}, 'model_latency': {'mean': ...}}
    ```

    ---

    ## `ValidXMLScorer`

    The `ValidXMLScorer` checks whether the AI system's output is valid XML. It is useful when expecting XML-formatted outputs.

    ```python
    from weave.scorers import ValidXMLScorer

    xml_scorer = ValidXMLScorer()
    ```

    Here is an example in the context of an evaluation:

    ```python
    import asyncio
    import weave
    from weave.scorers import ValidXMLScorer

    class XMLModel(weave.Model):
        @weave.op()
        async def predict(self, input: str) -> str:
            # This is a placeholder. In a real scenario, this would generate XML.
            return 'value'

    model = XMLModel()
    xml_scorer = ValidXMLScorer()

    dataset = [
        {"input": "Generate a valid XML with a root element"},
        {"input": "Create an invalid XML"}
    ]

    evaluation = weave.Evaluation(dataset=dataset, scorers=[xml_scorer])
    results = asyncio.run(evaluation.evaluate(model))
    print(results)
    # Example output:
    # {'ValidXMLScorer': {'xml_valid': {'true_count': 2, 'true_fraction': 1.0}}, 'model_latency': {'mean': ...}}
    ```

    ---

    ## `PydanticScorer`

    The `PydanticScorer` validates the AI system's output against a Pydantic model to ensure it adheres to a specified schema or data structure.

    ```python
    from weave.scorers import PydanticScorer
    from pydantic import BaseModel

    class FinancialReport(BaseModel):
        revenue: int
        year: str

    pydantic_scorer = PydanticScorer(model=FinancialReport)
    ```

    ---

    ## RAGAS - `ContextEntityRecallScorer`

    The `ContextEntityRecallScorer` estimates context recall by extracting entities from both the AI system's output and the provided context, then computing the recall score. It is based on the [RAGAS](https://github.com/explodinggradients/ragas) evaluation library.

    ```python
    from weave.scorers import ContextEntityRecallScorer

    entity_recall_scorer = ContextEntityRecallScorer(
        model_id="openai/gpt-4o"
    )
    ```

    **How It Works:**

    - Uses an LLM to extract unique entities from the output and context and calculates recall.
    - **Recall** indicates the proportion of important entities from the context that are captured in the output.
    - Returns a dictionary with the recall score.

    **Notes:**

    - Expects a `context` column in your dataset. Use the `column_map` attribute if the column name is different.

    ---

    ## RAGAS - `ContextRelevancyScorer`

    The `ContextRelevancyScorer` evaluates the relevancy of the provided context to the AI system's output. It is based on the [RAGAS](https://github.com/explodinggradients/ragas) evaluation library.

    ```python
    from weave.scorers import ContextRelevancyScorer

    relevancy_scorer = ContextRelevancyScorer(
        model_id="openai/gpt-4o",  # or any other model supported by litellm
        relevancy_prompt="""
    Given the following question and context, rate the relevancy of the context to the question on a scale from 0 to 1.

    Question: {question}
    Context: {context}
    Relevancy Score (0-1):
    """
    )
    ```

    **How It Works:**

    - Uses an LLM to rate the relevancy of the context to the output on a scale from 0 to 1.
    - Returns a dictionary with the `relevancy_score`.

    **Notes:**

    - Expects a `context` column in your dataset. Use `column_map` if a different name is used.
    - Customize the `relevancy_prompt` to define how relevancy is assessed.

    Here is an example usage in the context of an evaluation:

    ```python
    import asyncio
    from textwrap import dedent
    import weave
    from weave.scorers import ContextEntityRecallScorer, ContextRelevancyScorer

    class RAGModel(weave.Model):
        @weave.op()
        async def predict(self, question: str) -> str:
            "Retrieve relevant context"
            return "Paris is the capital of France."

    # Define prompts
    relevancy_prompt: str = dedent("""
        Given the following question and context, rate the relevancy of the context to the question on a scale from 0 to 1.

        Question: {question}
        Context: {context}
        Relevancy Score (0-1):
        """)
    # Initialize scorers
    entity_recall_scorer = ContextEntityRecallScorer()
    relevancy_scorer = ContextRelevancyScorer(relevancy_prompt=relevancy_prompt)
    # Create dataset
    dataset = [
        {
            "question": "What is the capital of France?",
            "context": "Paris is the capital city of France."
        },
        {
            "question": "Who wrote Romeo and Juliet?",
            "context": "William Shakespeare wrote many famous plays."
        }
    ]
    # Run evaluation
    evaluation = weave.Evaluation(
        dataset=dataset,
        scorers=[entity_recall_scorer, relevancy_scorer]
    )
    results = asyncio.run(evaluation.evaluate(RAGModel()))
    print(results)
    # Example output:
    # {'ContextEntityRecallScorer': {'recall': {'mean': ...}}, 
    # 'ContextRelevancyScorer': {'relevancy_score': {'mean': ...}}, 
    # 'model_latency': {'mean': ...}}
    ```
  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


**Note:** The built-in scorers were calibrated using OpenAI models (e.g. `openai/gpt-4o`, `openai/text-embedding-3-small`). If you wish to experiment with other providers, you can simply update the `model_id`. For example, to use an Anthropic model:

```python
from weave.scorers import SummarizationScorer

# Switch to Anthropic's Claude model
summarization_scorer = SummarizationScorer(
    model_id="anthropic/claude-3-5-sonnet-20240620"
)
```

[Source](https://weave-docs.wandb.ai/guides/evaluation/builtin_scorers)

<!--- Docs: Evaluation -->
<!--- Guardrails And Monitors -->

# Guardrails And Monitors

# Online Evaluation: Guardrails and Monitors



## Introduction

Building production LLM applications? Two questions likely keep you up at night:
1. How do you ensure your LLMs generate safe, appropriate content?
2. How do you measure and improve output quality over time?

Weave's unified scoring system answers both questions through a simple yet powerful framework. Whether you need active safety controls (guardrails) or passive quality monitoring, this guide will show you how to implement robust evaluation systems for your LLM applications.

The foundation of Weave's evaluation system is the [**Scorer**](./scorers.md) - a component that evaluates your function's inputs and outputs to measure quality, safety, or any other metric you care about. Scorers are versatile and can be used in two ways:

- **As Guardrails**: Block or modify unsafe content before it reaches users
- **As Monitors**: Track quality metrics over time to identify trends and improvements

:::note Terminology
Throughout this guide, we'll refer to functions decorated with `@weave.op` as "ops". These are regular Python functions that have been enhanced with Weave's tracking capabilities.
:::

#### Ready-to-Use Scorers
While this guide shows you how to create custom scorers, Weave comes with a variety of [predefined scorers](./builtin_scorers.mdx) that you can use right away, including:
- [Hallucination detection](./builtin_scorers.mdx#hallucinationfreescorer)
- [Summarization quality](./builtin_scorers.mdx#summarizationscorer)
- [Embedding similarity](./builtin_scorers.mdx#embeddingsimilarityscorer)
- [Relevancy evaluation](./builtin_scorers.mdx#ragas---contextrelevancyscorer)
- And more!

### Guardrails vs. Monitors: When to Use Each

While scorers power both guardrails and monitors, they serve different purposes:

| Aspect | Guardrails | Monitors |
|--------|------------|----------|
| **Purpose** | Active intervention to prevent issues | Passive observation for analysis |
| **Timing** | Real-time, before output reaches users | Can be asynchronous or batched |
| **Performance** | Must be fast (affects response time) | Can be slower, run in background |
| **Sampling** | Usually every request | Often sampled (e.g., 10% of calls) |
| **Control Flow** | Can block/modify outputs | No impact on application flow |
| **Resource Usage** | Must be efficient | Can use more resources if needed |

For example, a toxicity scorer could be used:
- 🛡️ **As a Guardrail**: Block toxic content immediately
- 📊 **As a Monitor**: Track toxicity levels over time

> 💡 **Note**: Every scorer result is automatically stored in Weave's database. This means your guardrails double as monitors without any extra work! You can always analyze historical scorer results, regardless of how they were originally used.

### Using the `.call()` Method

To use scorers with Weave ops, you'll need access to both the operation's result and its tracking information. The `.call()` method provides both:

```python
# Instead of calling the op directly:
result = generate_text(input)  # Primary way to call the op but doesn't give access to the Call object

# Use the .call() method to get both result and Call object:
result, call = generate_text.call(input)  # Now you can use the call object with scorers
```

:::tip Why Use `.call()`?
The Call object is essential for associating the score with the call in the database. While you can directly call the scoring function, this would not be associated with the call, and therefore not searchable, filterable, or exportable for later analysis.

For more details about Call objects, see the [Calls guide section on Call objects](../tracking/tracing.mdx#getting-a-handle-to-the-call-object-during-execution).
:::

## Getting Started with Scorers

### Basic Example

Here's a simple example showing how to use `.call()` with a scorer:

```python
import weave
from weave import Scorer

class LengthScorer(Scorer):
    @weave.op
    def score(self, output: str) -> dict:
        """A simple scorer that checks output length."""
        return {
            "length": len(output),
            "is_short": len(output) < 100
        }

@weave.op
def generate_text(prompt: str) -> str:
    return "Hello, world!"

# Get both result and Call object
result, call = generate_text.call("Say hello")

# Now you can apply scorers
await call.apply_scorer(LengthScorer())
```

## Using Scorers as Guardrails {#using-scorers-as-guardrails}

Guardrails act as safety checks that run before allowing LLM output to reach users. Here's a practical example:

```python
import weave
from weave import Scorer

@weave.op
def generate_text(prompt: str) -> str:
    """Generate text using an LLM."""
    # Your LLM generation logic here
    return "Generated response..."

class ToxicityScorer(Scorer):
    @weave.op
    def score(self, output: str) -> dict:
        """
        Evaluate content for toxic language.
        """
        # Your toxicity detection logic here
        return {
            "flagged": False,  # True if content is toxic
            "reason": None     # Optional explanation if flagged
        }

async def generate_safe_response(prompt: str) -> str:
    # Get result and Call object
    result, call = generate_text.call(prompt)
    
    # Check safety
    safety = await call.apply_scorer(ToxicityScorer())
    if safety.result["flagged"]:
        return f"I cannot generate that content: {safety.result['reason']}"
    
    return result
```

:::note Scorer Timing
When applying scorers:
- The main operation (`generate_text`) completes and is marked as finished in the UI
- Scorers run asynchronously after the main operation
- Scorer results are attached to the call once they complete
- You can view scorer results in the UI or query them via the API
:::

## Using Scorers as Monitors {#using-scorers-as-monitors}

Monitors help track quality metrics over time without blocking operations. This is useful for:
- Identifying quality trends
- Detecting model drift
- Gathering data for model improvements

```python
import weave
from weave import Scorer
from weave.scorers import ValidJSONScorer, ValidXMLScorer

import random

@weave.op
def generate_text(prompt: str) -> str:
    """Generate text using an LLM."""
    return "Generated response..."

async def generate_with_monitoring(prompt: str) -> str:
    # Get both the result and tracking information
    result, call = generate_text.call(prompt)
    
    # Sample monitoring (only monitor 10% of calls)
    if random.random() < 0.1:
        # Monitor multiple aspects asynchronously
        await call.apply_scorer(ValidJSONScorer())
        await call.apply_scorer(ValidXMLScorer())
    
    return result
```

## AWS Bedrock Guardrails

The `BedrockGuardrailScorer` uses AWS Bedrock's guardrail feature to detect and filter content based on configured policies. It calls the `apply_guardrail` API to apply the guardrail to the content.

To use the `BedrockGuardrailScorer`, you need the following:
- An AWS account with Bedrock access
- An AWS account with access to Bedrock
- A configured guardrail in the AWS Bedrock console
- The `boto3` Python package

> 🌟 **Tip**: You don't need to create your own Bedrock client—Weave creates it for you.  To specify a region, pass the `bedrock_runtime_kwargs` parameter to the scorer.

For more details on creating a guardrail, see the [Bedrock guardrails notebook](https://github.com/aws-samples/amazon-bedrock-samples/blob/main/responsible_ai/bedrock-guardrails/guardrails-api.ipynb).
```python
import weave
import boto3
from weave.scorers.bedrock_guardrails import BedrockGuardrailScorer

# Initialize Weave
weave.init("my_app")

# Create a guardrail scorer
guardrail_scorer = BedrockGuardrailScorer(
    guardrail_id="your-guardrail-id",  # Replace "your-guardrail-id" with your guardrail ID
    guardrail_version="DRAFT",          # Use guardrail_version to use a specific guardrail version
    source="INPUT",                             # Can be "INPUT" or "OUTPUT"
    bedrock_runtime_kwargs={"region_name": "us-east-1"}  # AWS region
)

@weave.op
def generate_text(prompt: str) -> str:
    # Add your text generation logic here
    return "Generated text..."

# Use the guardrail as a safety check
async def generate_safe_text(prompt: str) -> str:
    result, call = generate_text.call(prompt)
    
    # Apply the guardrail
    score = await call.apply_scorer(guardrail_scorer)
    
    # Check if the content passed the guardrail
    if not score.result.passed:
        # Use the modified output if available
        if score.result.metadata.get("modified_output"):
            return score.result.metadata["modified_output"]
        return "I cannot generate that content due to content policy restrictions."
    
    return result
```


## Implementation Details

### The Scorer Interface

A scorer is a class that inherits from `Scorer` and implements a `score` method. The method receives:
- `output`: The result from your function
- Any input parameters matching your function's parameters

Here's a comprehensive example:

```python
@weave.op
def generate_styled_text(prompt: str, style: str, temperature: float) -> str:
    """Generate text in a specific style."""
    return "Generated text in requested style..."

class StyleScorer(Scorer):
    @weave.op
    def score(self, output: str, prompt: str, style: str) -> dict:
        """
        Evaluate if the output matches the requested style.
        
        Args:
            output: The generated text (automatically provided)
            prompt: Original prompt (matched from function input)
            style: Requested style (matched from function input)
        """
        return {
            "style_match": 0.9,  # How well it matches requested style
            "prompt_relevance": 0.8  # How relevant to the prompt
        }

# Example usage
async def generate_and_score():
    # Generate text with style
    result, call = generate_styled_text.call(
        prompt="Write a story",
        style="noir",
        temperature=0.7
    )
    
    # Score the result
    score = await call.apply_scorer(StyleScorer())
    print(f"Style match score: {score.result['style_match']}")
```

### Score Parameters

#### Parameter Matching Rules
- The `output` parameter is special and always contains the function's result
- Other parameters must match the function's parameter names exactly
- Scorers can use any subset of the function's parameters
- Parameter types should match the function's type hints

#### Handling Parameter Name Mismatches

Sometimes your scorer's parameter names might not match your function's parameter names exactly. For example:

```python
@weave.op
def generate_text(user_input: str):  # Uses 'user_input'
    return process(user_input)

class QualityScorer(Scorer):
    @weave.op
    def score(self, output: str, prompt: str):  # Expects 'prompt'
        """Evaluate response quality."""
        return {"quality_score": evaluate_quality(prompt, output)}

result, call = generate_text.call(user_input="Say hello")

# Map 'prompt' parameter to 'user_input'
scorer = QualityScorer(column_map={"prompt": "user_input"})
await call.apply_scorer(scorer)
```

Common use cases for `column_map`:
- Different naming conventions between functions and scorers
- Reusing scorers across different functions
- Using third-party scorers with your function names


#### Adding Additional Parameters

Sometimes scorers need extra parameters that aren't part of your function. You can provide these using `additional_scorer_kwargs`:

```python
class ReferenceScorer(Scorer):
    @weave.op
    def score(self, output: str, reference_answer: str):
        """Compare output to a reference answer."""
        similarity = compute_similarity(output, reference_answer)
        return {"matches_reference": similarity > 0.8}

# Provide the reference answer as an additional parameter
await call.apply_scorer(
    ReferenceScorer(),
    additional_scorer_kwargs={
        "reference_answer": "The Earth orbits around the Sun."
    }
)
```

This is useful when your scorer needs context or configuration that isn't part of the original function call.


### Using Scorers: Two Approaches

1. **With Weave's Op System** (Recommended)
```python
result, call = generate_text.call(input)
score = await call.apply_scorer(MyScorer())
```

2. **Direct Usage** (Quick Experiments)
```python
scorer = MyScorer()
score = scorer.score(output="some text")
```

**When to use each:**
- 👉 Use the op system for production, tracking, and analysis
- 👉 Use direct scoring for quick experiments or one-off evaluations

**Tradeoffs of Direct Usage:**
- ✅ Simpler for quick tests
- ✅ No Op required
- ❌ No association with the LLM/Op call

### Score Analysis


For detailed information about querying calls and their scorer results, see our [Score Analysis Guide](./scorers.md#score-analysis) and our [Data Access Guide](/guides/tracking/tracing#querying--exporting-calls).


## Production Best Practices

### 1. Set Appropriate Sampling Rates
```python
@weave.op
def generate_text(prompt: str) -> str:
    return generate_response(prompt)

async def generate_with_sampling(prompt: str) -> str:
    result, call = generate_text.call(prompt)
    
    # Only monitor 10% of calls
    if random.random() < 0.1:
        await call.apply_scorer(ToxicityScorer())
        await call.apply_scorer(QualityScorer())
    
    return result
```

### 2. Monitor Multiple Aspects
```python
async def evaluate_comprehensively(call):
    await call.apply_scorer(ToxicityScorer())
    await call.apply_scorer(QualityScorer())
    await call.apply_scorer(LatencyScorer())
```
### 3. Analyze and Improve
- Review trends in the Weave Dashboard
- Look for patterns in low-scoring outputs
- Use insights to improve your LLM system
- Set up alerts for concerning patterns (coming soon)

### 4. Access Historical Data
Scorer results are stored with their associated calls and can be accessed through:
- The Call object's `feedback` field
- The Weave Dashboard
- Our query APIs

### 5. Initialize Guards Efficiently

For optimal performance, especially with locally-run models, initialize your guards outside of the main function. This pattern is particularly important when:
- Your scorers load ML models
- You're using local LLMs where latency is critical
- Your scorers maintain network connections
- You have high-traffic applications

See the Complete Example section below for a demonstration of this pattern.

:::caution Performance Tips
For Guardrails:
- Keep logic simple and fast
- Consider caching common results
- Avoid heavy external API calls
- Initialize guards outside of your main functions to avoid repeated initialization costs

For Monitors:
- Use sampling to reduce load
- Can use more complex logic
- Can make external API calls
:::

## Complete Example

Here's a comprehensive example that brings together all the concepts we've covered:

```python
import weave
from weave import Scorer
import asyncio
import random
from typing import Optional

class ToxicityScorer(Scorer):
    def __init__(self):
        # Initialize any expensive resources here
        self.model = load_toxicity_model()
    
    @weave.op
    async def score(self, output: str) -> dict:
        """Check content for toxic language."""
        try:
            result = await self.model.evaluate(output)
            return {
                "flagged": result.is_toxic,
                "reason": result.explanation if result.is_toxic else None
            }
        except Exception as e:
            # Log error and default to conservative behavior
            print(f"Toxicity check failed: {e}")
            return {"flagged": True, "reason": "Safety check unavailable"}

class QualityScorer(Scorer):
    @weave.op
    async def score(self, output: str, prompt: str) -> dict:
        """Evaluate response quality and relevance."""
        return {
            "coherence": evaluate_coherence(output),
            "relevance": evaluate_relevance(output, prompt),
            "grammar": evaluate_grammar(output)
        }

# Initialize scorers at module level (optional optimization)
toxicity_guard = ToxicityScorer()
quality_monitor = QualityScorer()
relevance_monitor = RelevanceScorer()

@weave.op
def generate_text(
    prompt: str,
    style: Optional[str] = None,
    temperature: float = 0.7
) -> str:
    """Generate an LLM response."""
    # Your LLM generation logic here
    return "Generated response..."

async def generate_safe_response(
    prompt: str,
    style: Optional[str] = None,
    temperature: float = 0.7
) -> str:
    """Generate a response with safety checks and quality monitoring."""
    try:
        # Generate initial response
        result, call = generate_text.call(
            prompt=prompt,
            style=style,
            temperature=temperature
        )

        # Apply safety check (guardrail)
        safety = await call.apply_scorer(toxicity_guard)
        if safety.result["flagged"]:
            return f"I cannot generate that content: {safety.result['reason']}"

        # Sample quality monitoring (10% of requests)
        if random.random() < 0.1:
            # Run quality checks in parallel
            await asyncio.gather(
                call.apply_scorer(quality_monitor),
                call.apply_scorer(relevance_monitor)
            )
        
        return result

    except Exception as e:
        # Log error and return user-friendly message
        print(f"Generation failed: {e}")
        return "I'm sorry, I encountered an error. Please try again."

# Example usage
async def main():
    # Basic usage
    response = await generate_safe_response("Tell me a story")
    print(f"Basic response: {response}")
    
    # Advanced usage with all parameters
    response = await generate_safe_response(
        prompt="Tell me a story",
        style="noir",
        temperature=0.8
    )
    print(f"Styled response: {response}")

```

This example demonstrates:
- Proper scorer initialization and error handling
- Combined use of guardrails and monitors
- Async operation with parallel scoring
- Production-ready error handling and logging

## Next Steps

- Explore [Available Scorers](./scorers.md)
- Learn about [Weave Ops](../../guides/tracking/ops.md)

[Source](https://weave-docs.wandb.ai/guides/evaluation/guardrails_and_monitors)

<!--- Docs: Evaluation -->
<!--- Scorers -->

# Scorers

# Scoring Overview

In Weave, Scorers are used to evaluate AI outputs and return evaluation metrics. They take the AI's output, analyze it, and return a dictionary of results. Scorers can use your input data as reference if needed and can also output extra information, such as explanations or reasonings from the evaluation.


  
    Scorers are passed to a `weave.Evaluation` object during evaluation. There are two types of Scorers in weave:

    1. **Function-based Scorers:** Simple Python functions decorated with `@weave.op`.
    2. **Class-based Scorers:** Python classes that inherit from `weave.Scorer` for more complex evaluations.

    Scorers must return a dictionary and can return multiple metrics, nested metrics and non-numeric values such as text returned from a LLM-evaluator about its reasoning.

  
  
    Scorers are special ops passed to a `weave.Evaluation` object during evaluation.
  


## Create your own Scorers

:::tip[Ready-to-Use Scorers]
While this guide shows you how to create custom scorers, Weave comes with a variety of [predefined scorers](./builtin_scorers.mdx) and [local SLM scorers](./weave_local_scorers.md) that you can use right away, including:
- [Hallucination detection](./builtin_scorers.mdx#hallucinationfreescorer)
- [Summarization quality](./builtin_scorers.mdx#summarizationscorer)
- [Embedding similarity](./builtin_scorers.mdx#embeddingsimilarityscorer)
- [Toxicity detection (local)](./weave_local_scorers.md#weavetoxicityscorerv1)
- [Context Relevance scoring (local)](./weave_local_scorers.md#weavecontextrelevancescorerv1)
- And more!
:::

### Function-based Scorers


  
    These are functions decorated with `@weave.op` that return a dictionary. They're great for simple evaluations like:

    ```python
    import weave

    @weave.op
    def evaluate_uppercase(text: str) -> dict:
        return {"text_is_uppercase": text.isupper()}

    my_eval = weave.Evaluation(
        dataset=[{"text": "HELLO WORLD"}],
        scorers=[evaluate_uppercase]
    )
    ```

    When the evaluation is run, `evaluate_uppercase` checks if the text is all uppercase.

  
  
    These are functions wrapped with `weave.op` that accept an object with `modelOutput` and optionally `datasetRow`.  They're great for simple evaluations like:
    ```typescript
    import * as weave from 'weave'

    const evaluateUppercase = weave.op(
        ({modelOutput}) => modelOutput.toUpperCase() === modelOutput,
        {name: 'textIsUppercase'}
    );


    const myEval = new weave.Evaluation({
        dataset: [{text: 'HELLO WORLD'}],
        scorers: [evaluateUppercase],
    })
    ```

  


### Class-based Scorers


  
    For more advanced evaluations, especially when you need to keep track of additional scorer metadata, try different prompts for your LLM-evaluators, or make multiple function calls, you can use the `Scorer` class.

    **Requirements:**

    1. Inherit from `weave.Scorer`.
    2. Define a `score` method decorated with `@weave.op`.
    3. The `score` method must return a dictionary.

    Example:

    ```python
    import weave
    from openai import OpenAI
    from weave import Scorer

    llm_client = OpenAI()

    #highlight-next-line
    class SummarizationScorer(Scorer):
        model_id: str = "gpt-4o"
        system_prompt: str = "Evaluate whether the summary is good."

        @weave.op
        def some_complicated_preprocessing(self, text: str) -> str:
            processed_text = "Original text: \n" + text + "\n"
            return processed_text

        @weave.op
        def call_llm(self, summary: str, processed_text: str) -> dict:
            res = llm_client.chat.completions.create(
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": (
                        f"Analyse how good the summary is compared to the original text."
                        f"Summary: {summary}\n{processed_text}"
                    )}])
            return {"summary_quality": res}

        @weave.op
        def score(self, output: str, text: str) -> dict:
            """Score the summary quality.

            Args:
                output: The summary generated by an AI system
                text: The original text being summarized
            """
            processed_text = self.some_complicated_preprocessing(text)
            eval_result = self.call_llm(summary=output, processed_text=processed_text)
            return {"summary_quality": eval_result}

    evaluation = weave.Evaluation(
        dataset=[{"text": "The quick brown fox jumps over the lazy dog."}],
        scorers=[summarization_scorer])
    ```

    This class evaluates how good a summary is by comparing it to the original text.

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


## How Scorers Work

### Scorer Keyword Arguments


  
    Scorers can access both the output from your AI system and the input data from the dataset row.

    - **Input:** If you would like your scorer to use data from your dataset row, such as a "label" or "target" column then you can easily make this available to the scorer by adding a `label` or `target` keyword argument to your scorer definition.

    For example if you wanted to use a column called "label" from your dataset then your scorer function (or `score` class method) would have a parameter list like this:

    ```python
    @weave.op
    def my_custom_scorer(output: str, label: int) -> dict:
        ...
    ```

    When a weave `Evaluation` is run, the output of the AI system is passed to the `output` parameter. The `Evaluation` also automatically tries to match any additional scorer argument names to your dataset columns. If customizing your scorer arguments or dataset columns is not feasible, you can use column mapping - see below for more.

    - **Output:** Include an `output` parameter in your scorer function's signature to access the AI system's output.

    ### Mapping Column Names with `column_map`

    Sometimes, the `score` methods' argument names don't match the column names in your dataset. You can fix this using a `column_map`.

    If you're using a class-based scorer, pass a dictionary to the `column_map` attribute of `Scorer` when you initialise your scorer class. This dictionary maps your `score` method's argument names to the dataset's column names, in the order: `{scorer_keyword_argument: dataset_column_name}`.

    Example:

    ```python
    import weave
    from weave import Scorer

    # A dataset with news articles to be summarised
    dataset = [
        {"news_article": "The news today was great...", "date": "2030-04-20", "source": "Bright Sky Network"},
        ...
    ]

    # Scorer class
    class SummarizationScorer(Scorer):

        @weave.op
        def score(self, output, text) -> dict:
            """
                output: output summary from a LLM summarization system
                text: the text being summarised
            """
            ...  # evaluate the quality of the summary

    # create a scorer with a column mapping the `text` argument to the `news_article` data column
    scorer = SummarizationScorer(column_map={"text" : "news_article"})
    ```

    Now, the `text` argument in the `score` method will receive data from the `news_article` dataset column.

    **Notes:**

    - Another equivalent option to map your columns is to subclass the `Scorer` and overload the `score` method mapping the columns explicitly.

    ```python
    import weave
    from weave import Scorer

    class MySummarizationScorer(SummarizationScorer):

        @weave.op
        def score(self, output: str, news_article: str) -> dict:  # Added type hints
            # overload the score method and map columns manually
            return super().score(output=output, text=news_article)
    ```

  
  
    Scorers can access both the output from your AI system and the contents of the dataset row.

    You can easily access relevant columns from the dataset row by adding a `datasetRow` keyword argument to your scorer definition.

    ```typescript
    const myScorer = weave.op(
        ({modelOutput, datasetRow}) => {
            return modelOutput * 2 === datasetRow.expectedOutputTimesTwo;
        },
        {name: 'myScorer'}
    );
    ```

    ### Mapping Column Names with `columnMapping`
    > 🚨 **Important**:     In TypeScript, this feature is currently on the `Evaluation` object, not individual scorers.

    :::

    Sometimes your `datasetRow` keys will not exactly match the scorer's naming scheme, but they are semantically similar. You can map the columns using the `Evaluation`'s `columnMapping` option.

    The mapping is always from the scorer's perspective, i.e. `{scorer_key: dataset_column_name}`.

    Example:

    ```typescript
    const myScorer = weave.op(
        ({modelOutput, datasetRow}) => {
            return modelOutput * 2 === datasetRow.expectedOutputTimesTwo;
        },
        {name: 'myScorer'}
    );

    const myEval = new weave.Evaluation({
        dataset: [{expected: 2}],
        scorers: [myScorer],
        columnMapping: {expectedOutputTimesTwo: 'expected'}
    });
    ```

  


### Final summarization of the scorer


  
    During evaluation, the scorer will be computed for each row of your dataset. To provide a final score for the evaluation we provide an `auto_summarize` depending on the returning type of the output.
    - Averages are computed for numerical columns
    - Count and fraction for boolean columns
    - Other column types are ignored

    You can override the `summarize` method on the `Scorer` class and provide your own way of computing the final scores. The `summarize` function expects:

    - A single parameter `score_rows`: This is a list of dictionaries, where each dictionary contains the scores returned by the `score` method for a single row of your dataset.
    - It should return a dictionary containing the summarized scores.

    **Why this is useful?**

    When you need to score all rows before deciding on the final value of the score for the dataset.

    ```python
    class MyBinaryScorer(Scorer):
        """
        Returns True if the full output matches the target, False if not
        """

        @weave.op
        def score(self, output, target):
            return {"match": output == target}

        def summarize(self, score_rows: list) -> dict:
            full_match = all(row["match"] for row in score_rows)
            return {"full_match": full_match}
    ```

    > In this example, the default `auto_summarize` would have returned the count and proportion of True.

    If you want to learn more, check the implementation of [CorrectnessLLMJudge](/tutorial-rag#optional-defining-a-scorer-class).

  
  
    During evaluation, the scorer will be computed for each row of your dataset.  To provide a final score, we use an internal `summarizeResults` function that aggregates depending on the output type.
    - Averages are computed for numerical columns
    - Count and fraction for boolean columns
    - Other column types are ignored

    We don't currently support custom summarization.

  


### Applying Scorers to a Call

To apply scorers to your Weave ops, you'll need to use the `.call()` method which provides access to both the operation's result and its tracking information. This allows you to associate scorer results with specific calls in Weave's database.

For more information on how to use the `.call()` method, see the [Calling Ops](../tracking/tracing#calling-ops#getting-a-handle-to-the-call-object-during-execution) guide.


  
    Here's a basic example:

    ```python
    # Get both result and Call object
    result, call = generate_text.call("Say hello")

    # Apply a scorer
    score = await call.apply_scorer(MyScorer())
    ```

    You can also apply multiple scorers to the same call:

    ```python
    # Apply multiple scorers in parallel
    await asyncio.gather(
        call.apply_scorer(quality_scorer),
        call.apply_scorer(toxicity_scorer)
    )
    ```

    **Notes:**
    - Scorer results are automatically stored in Weave's database
    - Scorers run asynchronously after the main operation completes
    - You can view scorer results in the UI or query them via the API

    For more detailed information about using scorers as guardrails or monitors, including production best practices and complete examples, see our [Guardrails and Monitors guide](./guardrails_and_monitors.md).

  
  
    ```plaintext
    This feature is not available in TypeScript yet. Stay tuned!
    ```
  


### Use `preprocess_model_input` 

You can use the `preprocess_model_input` parameter to modify dataset examples before they reach your model during evaluation. 
important
The `preprocess_model_input` function only transforms inputs before they are passed to the model’s prediction function.

Scorer functions always receive the original dataset examples, without any preprocessing applied.
:::

For usage information and an example, see [Using `preprocess_model_input` to format dataset rows before evaluating](../core-types/evaluations.md#using-preprocess_model_input-to-format-dataset-rows-before-evaluating).

## Score Analysis

In this section, we'll show you how to analyze the scores for a single call, multiple calls, and all calls scored by a specific scorer.

### Analyze a single Call's Scores

#### Single Call API

To retrieve the calls for a single call, you can use the `get_call` method.

```python
client = weave.init("my-project")

# Get a single call
call = client.get_call("call-uuid-here")

# Get the feedback for the call which contains the scores
feedback = list(call.feedback)
```


#### Single Call UI



Scores for an individual call are displayed in the call details page under the "Scores" tab.


### Analyze multiple Calls' Scores

#### Multiple Calls API

To retrieve the calls for multiple calls, you can use the `get_calls` method.

```python
client = weave.init("my-project")

# Get multiple calls - use whatever filters you want and include feedback
calls = client.get_calls(..., include_feedback=True)

# Iterate over the calls and access the feedback which contains the scores
for call in calls:
    feedback = list(call.feedback)
```

#### Multiple Calls UI



Scores for multiple calls are displayed in the traces table under the "Scores" column.

### Analyze all Calls scored by a specific Scorer

#### All Calls by Scorer API

To retrieve all calls scored by a specific scorer, you can use the `get_calls` method.

```python
client = weave.init("my-project")

# To get all the calls scored by any version of a scorer, use the scorer name (typically the class name)
calls = client.get_calls(scored_by=["MyScorer"], include_feedback=True)

# To get all the calls scored by a specific version of a scorer, use the entire ref
# Refs can be obtained from the scorer object or via the UI.
calls = client.get_calls(scored_by=[myScorer.ref.uri()], include_feedback=True)

# Iterate over the calls and access the feedback which contains the scores
for call in calls:
    feedback = list(call.feedback)
```


#### All Calls by Scorer UI

Finally, if you would like to see all the calls scored by a Scorer, navigate to the Scorers Tab in the UI and select "Programmatic Scorer" tab. Click your Scorer to open the Scorer details page.



Next, click the `View Traces` button under `Scores` to view all the calls scored by your Scorer.



This will default to the selected version of the Scorer. You can remove the version filter to see all the calls scored by any version of the Scorer.

[Source](https://weave-docs.wandb.ai/guides/evaluation/scorers)

<!--- Docs: Evaluation -->
<!--- Weave Local Scorers -->

# Weave Local Scorers

# Weave Local Scorers





Weave's local scorers are a suite of small language models that run locally on your machine with minimal latency. These models evaluate the safety and quality of your AI system’s inputs, context, and outputs.

Some of these models are fine-tuned by Weights & Biases, while others are state-of-the-art open-source models trained by the community. Weights & Biases (W&B) Reports were used for training and evaluation. You can find the full details in this [list of W&B Reports](https://wandb.ai/c-metrics/weave-scorers/reports/Weave-Scorers-v1--VmlldzoxMDQ0MDE1OA).

The model weights are publicly available in W&B Artifacts, and are automatically downloaded when you instantiate the scorer class. The artifact paths can be found here if you'd like to download them yourself: `weave.scorers.default_models`

The object returned by these scorers contains a `passed` boolean attribute indicating whether the input text is safe or high quality, as well as a `metadata` attribute that contains more detail such as the raw score from the model.

> 🌟 **Tip**: While local scorers can be run on CPUs and GPUs, use GPUs for best performance.  


  

    ## Prerequisites

    Before you can use Weave local scorers, install additional dependencies:

    ```bash
    pip install weave[scorers]
    ```

    ## Select a scorer

    The following local scorers are available. Select a scorer based on your use case.

    | Scorer                           | Scenario                                                                                                                                                                      |
    |----------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
    | [WeaveToxicityScorerV1](#weavetoxicityscorerv1)                  | Identify toxic or harmful content in your AI system's inputs and outputs, including hate speech or threats.                                                       |
    | [WeaveBiasScorerV1](#weavebiasscorerv1)                          | Detect biased or stereotypical content in your AI system's inputs and outputs. Ideal for reducing harmful biases in generated text.                               |
    | [WeaveHallucinationScorerV1](#weavehallucinationscorerv1)       | Identify whether your RAG system generates hallucinations in its output based on the input and context provided.                                                  |
    | [WeaveContextRelevanceScorerV1](#weavecontextrelevancescorerv1) | Measure whether the AI system's output is relevant to the input and context provided.                                                                             |
    | [WeaveCoherenceScorerV1](#weavecoherencescorerv1)                | Evaluate the coherence and logical structure of the AI system's output.                                                                                           |
    | [WeaveFluencyScorerV1](#weavefluencyscorerv1)                    | Measure whether the AI system's output is fluent.                                                                                                                  |
    | [WeaveTrustScorerV1](#weavetrustscorerv1)                        | An aggregate scorer that leverages the toxicity, hallucination, context relevance, fluency, and coherence scorers.                                                |
    | [PresidioScorer](#presidioscorer)                                | Detect Personally Identifiable Information (PII) in your AI system's inputs and outputs using the Presidio library from Microsoft.                                |

    ## `WeaveBiasScorerV1`

    This scorer assesses gender and race/origin bias along two dimensions:
        
        - Race and Origin: Racism and bias against a country or region of origin, immigration status, ethnicity, etc.
        - Gender and Sexuality: Sexism, misogyny, homophobia, transphobia, sexual harassment, etc.

    `WeaveBiasScorerV1` uses a fine-tuned [deberta-small-long-nli](https://huggingface.co/tasksource/deberta-small-long-nli) model. For more details on the model, dataset, and calibration process, see the [WeaveBiasScorerV1 W&B Report](https://wandb.ai/c-metrics/bias-benchmark/reports/Bias-Scorer--VmlldzoxMDM2MTgzNw).

    ### Usage notes 

    - The `score` method expects a string to be passed to the `output` parameter. 
    - A higher score means that there is a stronger prediction of bias in the text.
    - The `threshold` parameter is set but can also be overridden on initialization.
    
    ### Usage example

    ```python
    import weave
    from weave.scorers import WeaveBiasScorerV1

    bias_scorer = WeaveBiasScorerV1()
    result = bias_scorer.score(output="Martian men are terrible at cleaning")

    print(f"The text is biased: {not result.passed}")
    print(result)
    ```

    ---

    ## `WeaveToxicityScorerV1`

    This scorer assesses the input text for toxicity along five dimensions:
    
        - Race and Origin: Racism and bias against a country or region of origin, immigration status, ethnicity, etc.
        - Gender and Sexuality: Sexism, misogyny, homophobia, transphobia, sexual harassment, etc.
        - Religious: Bias or stereotypes against someone's religion.
        - Ability: Bias related to someone's physical, mental, or intellectual ability or disability.
        - Violence and Abuse: Overly graphic descriptions of violence, threats of violence, or incitement of violence.
    
    The `WeaveToxicityScorerV1` uses the open source [Celadon](https://huggingface.co/PleIAs/celadon) model from PleIAs. For more information, see the [WeaveToxicityScorerV1 W&B Report](https://wandb.ai/c-metrics/toxicity-benchmark/reports/Toxicity-Scorer--VmlldzoxMDMyNjc0NQ).

    ### Usage notes

    - The `score` method expects a string to be passed to the `output` parameter. 
    - The model returns scores from `0` to `3` across five different categories: 
      - If the sum of these scores is above `total_threshold` (default value `5`), the input is flagged as toxic. 
      - If any single category has a score higher than `category_threshold` (default `2`), the input is flagged as toxic.
    - To make filtering more aggressive, override `category_threshold` or `total_threshold` during initialization.

    ### Usage example

    ```python
    import weave
    from weave.scorers import WeaveToxicityScorerV1

    toxicity_scorer = WeaveToxicityScorerV1()
    result = toxicity_scorer.score(output="people from the south pole of Mars are the worst")

    print(f"Input is toxic: {not result.passed}")
    print(result)
    ```

    ---

    ## `WeaveHallucinationScorerV1`

    This scorer checks if your AI system's output contains any hallucinations based on the input data.

    The `WeaveHallucinationScorerV1` uses the open source [HHEM 2.1 model](https://huggingface.co/vectara/hallucination_evaluation_model) from Vectara. For more information, see the [WeaveHallucinationScorerV1 W&B Report](https://wandb.ai/c-metrics/hallucination/reports/Hallucination-Scorer--VmlldzoxMDM3NDA3MA).

    ### Usage notes

    - The `score` method expects values to be passed to the `query` and `output` parameters.  
    - The context should be passed to the `output` parameter (as a string or list of strings).  
    - A higher output score means a stronger prediction of hallucination in the output.
    - The `threshold` parameter is set but can be overridden on initialization.

    ### Usage example 

    ```python
    import weave
    from weave.scorers import WeaveHallucinationScorerV1

    hallucination_scorer = WeaveHallucinationScorerV1()

    result = hallucination_scorer.score(
        query="What is the capital of Antarctica?",
        context="People in Antarctica love the penguins.",
        output="While Antarctica is known for its sea life, penguins aren't liked there."
    )

    print(f"Output is hallucinated: {not result.passed}")
    print(result)
    ```

    ---

    ## `WeaveContextRelevanceScorerV1`

    This scorer is designed to be used when evaluating RAG systems. It scores the relevance of the context to the query.

    The `WeaveContextRelevanceScorerV1` uses a fine-tuned [deberta-small-long-nli](https://huggingface.co/tasksource/deberta-small-long-nli) model from tasksource. For more details, see the [WeaveContextRelevanceScorerV1 W&B Report](https://wandb.ai/c-metrics/context-relevance-scorer/reports/Context-Relevance-Scorer--VmlldzoxMDYxNjEyNA).

    ### Usage notes

    - The `score` method expects values for `query` and `output`.  
    - The context should be passed to the `output` parameter (string or list of strings).
    - A higher score means a stronger prediction that the context is relevant to the query.
    - You can pass `verbose=True` to the `score` method to get per-chunk scores.

    ### Usage example

    ```python
    import weave
    from weave.scorers import WeaveContextRelevanceScorerV1

    context_relevance_scorer = WeaveContextRelevanceScorerV1()

    result = context_relevance_scorer.score(
        query="What is the capital of Antarctica?",
        output="The Antarctic has the happiest penguins."  # context is passed to the output parameter
    )

    print(f"Output is relevant: {result.passed}")
    print(result)
    ```

    ## `WeaveCoherenceScorerV1`

    This scorer checks whether the input text is coherent.

    The `WeaveCoherenceScorerV1` uses a fine-tuned [deberta-small-long-nli](https://huggingface.co/tasksource/deberta-small-long-nli) model from tasksource. For more information, see the [WeaveCoherenceScorerV1 W&B Report](https://wandb.ai/c-metrics/coherence_scorer/reports/Coherence-Scorer--VmlldzoxMDI5MjA1MA).

    ### Usage notes

    - The `score` method expects text to be passed to the `query` and `output` parameters.
    - A higher output score means a stronger prediction of coherence.

    ### Usage example 

    ```python
    import weave
    from weave.scorers import WeaveCoherenceScorerV1

    coherence_scorer = WeaveCoherenceScorerV1()

    result = coherence_scorer.score(
        query="What is the capital of Antarctica?",
        output="but why not monkey up day"
    )

    print(f"Output is coherent: {result.passed}")
    print(result)
    ```

    ---

    ## `WeaveFluencyScorerV1`

    This scorer checks whether the input text is fluent—that is, easy to read and understand, similar to natural human language. It evaluates grammar, syntax, and overall readability.

    The `WeaveFluencyScorerV1` uses a fine-tuned [ModernBERT-base](https://huggingface.co/answerdotai/ModernBERT-base) model from AnswerDotAI. For more information, see the [WeaveFluencyScorerV1 W&B Report](https://wandb.ai/c-metrics/fluency-eval/reports/Fluency-Scorer--VmlldzoxMTA3NzE2Ng).

    ### Usage notes

    - The `score` method expects text to be passed to the `output` parameter.
    - A higher output score indicates higher fluency.

    ### Usage example 

    ```python
    import weave
    from weave.scorers import WeaveFluencyScorerV1

    fluency_scorer = WeaveFluencyScorerV1()

    result = fluency_scorer.score(
        output="The cat did stretching lazily into warmth of sunlight."
    )

    print(f"Output is fluent: {result.passed}")
    print(result)
    ```

    ---

    ## `WeaveTrustScorerV1`

    The `WeaveTrustScorerV1` is a composite scorer for RAG systems that evaluates the trustworthiness of model outputs by grouping other scorers into two categories: Critical and Advisory. Based on the composite score, it returns a trust level:

    - `high`: No issues detected  
    - `medium`: Only Advisory issues detected  
    - `low`: Critical issues detected or input is empty  

    Any input that fails a Critical scorer results in a `low` trust level. Failing an Advisory scorer results in `medium`.

    - **Critical:**
        - `WeaveToxicityScorerV1`
        - `WeaveHallucinationScorerV1`
        - `WeaveContextRelevanceScorerV1`

    - **Advisory:**
        - `WeaveFluencyScorerV1`
        - `WeaveCoherenceScorerV1`

    ### Usage notes

    - This scorer is designed for evaluating RAG pipelines.  
    - It requires `query`, `context`, and `output` keys for correct scoring.

    ### Usage example

    ```python
    import weave
    from weave.scorers import WeaveTrustScorerV1

    trust_scorer = WeaveTrustScorerV1()

    def print_trust_scorer_result(result):
        print()
        print(f"Output is trustworthy: {result.passed}")
        print(f"Trust level: {result.metadata['trust_level']}")
        if not result.passed:
            print("Triggered scorers:")
            for scorer_name, scorer_data in result.metadata['raw_outputs'].items():
                if not scorer_data.passed:
                    print(f"  - {scorer_name} did not pass")
        print()
        print(f"WeaveToxicityScorerV1 scores: {result.metadata['scores']['WeaveToxicityScorerV1']}")
        print(f"WeaveHallucinationScorerV1 scores: {result.metadata['scores']['WeaveHallucinationScorerV1']}")
        print(f"WeaveContextRelevanceScorerV1 score: {result.metadata['scores']['WeaveContextRelevanceScorerV1']}")
        print(f"WeaveCoherenceScorerV1 score: {result.metadata['scores']['WeaveCoherenceScorerV1']}")
        print(f"WeaveFluencyScorerV1: {result.metadata['scores']['WeaveFluencyScorerV1']}")
        print()

    result = trust_scorer.score(
        query="What is the capital of Antarctica?",
        context="People in Antarctica love the penguins.",
        output="The cat stretched lazily in the warm sunlight."
    )

    print_trust_scorer_result(result)
    print(result)
    ```

    ---

    ## `PresidioScorer`

    This scorer uses the [Presidio library](https://github.com/microsoft/presidio) to detect Personally Identifiable Information (PII) in your AI system's inputs and outputs.

    ### Usage notes

    - To specify specific entity types, such as emails or phone numbers, pass a list of Presidio entities to the `selected_entities` parameter. Otherwise, Presidio will detect all entity types in its default entities list.
    - To detect specific entity types, such as emails or phone numbers, pass a list to the `selected_entities` parameter.
    - You can pass custom recognizers via the `custom_recognizers` parameter as a list of `presidio.EntityRecognizer` instances.
    - To handle non-English input, use the `language` parameter to specify the language.

    ### Usage example

    ```python
    import weave
    from weave.scorers import PresidioScorer

    presidio_scorer = PresidioScorer()

    result = presidio_scorer.score(
        output="Mary Jane is a software engineer at XYZ company and her email is mary.jane@xyz.com."
    )

    print(f"Output contains PII: {not result.passed}")
    print(result)
    ```

  
  
    Weave local scorers are not available in TypeScript yet. Stay tuned!

    To use Weave scorers in TypeScript, see [function-based scorers](scorers#function-based-scorers).

[Source](https://weave-docs.wandb.ai/guides/evaluation/weave_local_scorers)

<!--- Docs: Evaluation -->
<!--- Evaluation Logger -->

# Evaluation Logger

# `EvaluationLogger`

The `EvaluationLogger` provides a flexible, incremental way to log evaluation data directly from your Python code. You don't need deep knowledge of Weave's internal data types; simply instantiate a logger and use its methods (`log_prediction`, `log_score`, `log_summary`) to record evaluation steps.

This approach is particularly helpful in complex workflows where the entire dataset or all scorers might not be defined upfront.

In contrast to the standard `Evaluation` object, which requires a predefined `Dataset` and list of `Scorer` objects, the `EvaluationLogger` allows you to log individual predictions and their associated scores incrementally as they become available.

:::info Prefer a more structured evaluation?

If you prefer a more opinionated evaluation framework with predefined datasets and scorers, see [Weave's standard Evaluation framework](../core-types/evaluations.md). 

The `EvaluationLogger` offers flexibility while the standard framework offers structure and guidance.
:::

## Basic workflow

1. _Initialize the logger:_ Create an instance of `EvaluationLogger`, optionally providing metadata about the `model` and `dataset`. Defaults will be used if omitted.
2. _Log predictions:_ Call `log_prediction` for each input/output pair from your system.
3. _Log scores:_ Use the returned `ScoreLogger` to `log_score` for the prediction. Multiple scores per prediction are supported.
4. _Finish prediction:_ Always call `finish()` after logging scores for a prediction to finalize it.
5. _Log summary:_ After all predictions are processed, call `log_summary` to aggregate scores and add optional custom metrics.

> 🚨 **Important**: After calling `finish()` on a prediction, no more scores can be logged for it.

For a Python code demonstrating the described workflow, see the [Basic example](#basic-example).

## Basic example
The following example shows how to use `EvaluationLogger` to log predictions and scores inline with your existing Python code.

The `user_model` model function is defined and applied to a list of inputs. For each example:

- The input and output are logged using `log_prediction`.
- A simple correctness score (`correctness_score`) is logged via `log_score`.
- `finish()` finalizes logging for that prediction.
Finally, `log_summary` records any aggregate metrics and triggers automatic score summarization in Weave.

```python
import weave
from openai import OpenAI
from weave.flow.eval_imperative import EvaluationLogger

# Initialize the logger (model/dataset names are optional metadata)
eval_logger = EvaluationLogger(
    model="my_model",
    dataset="my_dataset"
)

# Example input data (this can be any data structure you want)
eval_samples = [
    {'inputs': {'a': 1, 'b': 2}, 'expected': 3},
    {'inputs': {'a': 2, 'b': 3}, 'expected': 5},
    {'inputs': {'a': 3, 'b': 4}, 'expected': 7},
]

# Example model logic.  This does not have to be decorated with @weave.op,
# but if you do, it will be traced and logged.
@weave.op
def user_model(a: int, b: int) -> int:
    oai = OpenAI()
    _ = oai.chat.completions.create(messages=[{"role": "user", "content": f"What is {a}+{b}?"}], model="gpt-4o-mini")
    return a + b

# Iterate through examples, predict, and log
for sample in eval_samples:
    inputs = sample["inputs"]
    model_output = user_model(**inputs) # Pass inputs as kwargs

    # Log the prediction input and output
    pred_logger = eval_logger.log_prediction(
        inputs=inputs,
        output=model_output
    )

    # Calculate and log a score for this prediction
    expected = sample["expected"]
    correctness_score = model_output == expected
    pred_logger.log_score(
        scorer="correctness", # Simple string name for the scorer
        score=correctness_score
    )

    # Finish logging for this specific prediction
    pred_logger.finish()

# Log a final summary for the entire evaluation.
# Weave auto-aggregates the 'correctness' scores logged above.
summary_stats = {"subjective_overall_score": 0.8}
eval_logger.log_summary(summary_stats)

print("Evaluation logging complete. View results in the Weave UI.")
```

## Advanced usage

### Get outputs before logging

You can first compute your model outputs, then separately log predictions and scores. This allows for better separation of evaluation and logging logic.

```python
ev = EvaluationLogger(model="example_model", dataset="example_dataset")

outputs = [your_output_generator(**inputs) for inputs in your_dataset]
preds = [ev.log_prediction(inputs, output) for inputs, output in zip(your_dataset, outputs)]
for pred in preds:
    pred.log_score(scorer="greater_than_5_scorer", score=output > 5)
    pred.log_score(scorer="greater_than_7_scorer", score=output > 7)

ev.log_summary()
```

### Log rich media

Inputs, outputs, and scores can include rich media such as images, videos, audio, or structured tables. Simply pass a dict or media object into the `log_prediction` or `log_score` methods:

```python
import io
import wave
import struct
from PIL import Image
import random
from typing import Any
import weave

def generate_random_audio_wave_read(duration=2, sample_rate=44100):
    n_samples = duration * sample_rate
    amplitude = 32767  # 16-bit max amplitude

    buffer = io.BytesIO()

    # Write wave data to the buffer
    with wave.open(buffer, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)  # 16-bit
        wf.setframerate(sample_rate)

        for _ in range(n_samples):
            sample = random.randint(-amplitude, amplitude)
            wf.writeframes(struct.pack('<h', sample))

    # Rewind the buffer to the beginning so we can read from it
    buffer.seek(0)

    # Return a Wave_read object
    return wave.open(buffer, 'rb')

rich_media_dataset = [
    {
        'image': Image.new(
            "RGB",
            (100, 100),
            color=(
                random.randint(0, 255),
                random.randint(0, 255),
                random.randint(0, 255),
            ),
        ),
        "audio": generate_random_audio_wave_read(),
    }
    for _ in range(5)
]

@weave.op
def your_output_generator(image: Image.Image, audio) -> dict[str, Any]:
    return {
        "result": random.randint(0, 10),
        "image": image,
        "audio": audio,
    }

ev = EvaluationLogger(model="example_model", dataset="example_dataset")

for inputs in rich_media_dataset:
    output = your_output_generator(**inputs)
    pred = ev.log_prediction(inputs, output)
    pred.log_score(scorer="greater_than_5_scorer", score=output["result"] > 5)
    pred.log_score(scorer="greater_than_7_scorer", score=output["result"] > 7)

ev.log_summary()
```

### Log and compare multiple evaluations

With `EvaluationLogger`, you can log and compare multiple evaluations.

1. Run the code sample shown below.
2. In the Weave UI, navigate to the `Evals` tab.
3. Select the evals that you want to compare.
4. Click the **Compare** button. In the Compare view, you can:
   - Choose which Evals to add or remove
   - Choose which metrics to show or hide
   - Page through specific examples to see how different models performed for the same input on a given dataset
   
   For more information on comparisons, see [Comparisons](../tools/comparison.md)

```python
import weave

models = [
    "model1",
    "model2",
     {"name": "model3", "metadata": {"coolness": 9001}}
]

for model in models:
    ev = EvaluationLogger(model=model, dataset="example_dataset")
    for inputs in your_dataset:
        output = your_output_generator(**inputs)
        pred = ev.log_prediction(inputs=inputs, output=output)
        pred.log_score(scorer="greater_than_3_scorer", score=output > 3)
        pred.log_score(scorer="greater_than_5_scorer", score=output > 5)
        pred.log_score(scorer="greater_than_7_scorer", score=output > 7)
        pred.finish()

    ev.log_summary()
```





## Usage tips

- Call `finish()` promptly after each prediction.
- Use `log_summary` to capture metrics not tied to single predictions (e.g., overall latency).
- Rich media logging is great for qualitative analysis.

[Source](https://weave-docs.wandb.ai/guides/evaluation/evaluation_logger)



<!--- Docs: Integrations -->
<!--- Smolagents -->

# Smolagents

# Smolagents

> 🚨 **Important**: All code samples shown on this page are in Python.

This page explains how to integrate [Smolagents](https://huggingface.co/docs/smolagents/en/index) with W&B Weave to track and analyze your agentic applications. You'll learn how to log model inferences, monitor function calls, and organize experiments using Weave's tracing and versioning capabilities. By following the examples provided, you can capture valuable insights, debug your applications efficiently, and compare different model configurations—all within the Weave web interface.

## Overview

Smolagents is a simple framework that offers minimal abstractions for building powerful agentic applications. It supports multiple LLM providers, such as OpenAI, Hugging Face Transformers, and Anthropic.

Weave automatically captures traces for [Smolagents](https://huggingface.co/docs/smolagents/en/index). To start tracking, call `weave.init()` and use the library as usual.

## Prerequisites

1. Before you can use Smolagents with Weave, install the required libraries or upgrade to the latest versions. The following command installs or upgrades `smolagents`, `openai`, and `weave`, and suppresses output:

    ```python
    pip install -U smolagents openai weave -qqq
    ```

2. Smolagents supports multiple LLM providers, such as OpenAI, Hugging Face Transformers, and Anthropic. Set the API key for your chosen provider by setting the corresponding environment variable:

    ```python
    import os
    import getpass

    os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API key: ")
    ```

## Basic tracing

Storing traces of language model applications in a central location is essential during development and production. These traces help with debugging and serve as valuable datasets for improving your application.

Weave automatically captures traces for [Smolagents](https://huggingface.co/docs/smolagents/en/index). To start tracking, initialize Weave by calling `weave.init()`, then use the library as usual.

The following example demonstrates how to log inference calls to a tool-using LLM agent with Weave. In this scenario:

- You define a language model (OpenAI's `gpt-4o`) using Smolagents' `OpenAIServerModel`.
- You configure a search tool (`DuckDuckGoSearchTool`) that the agent can invoke when needed.
- You construct a `ToolCallingAgent`, passing in the tool and model.
- You run a query through the agent that triggers the search tool.
- Weave logs each function and model invocation, making them available for inspection via its web interface.

```python
import weave
from smolagents import DuckDuckGoSearchTool, OpenAIServerModel, ToolCallingAgent

# Initialize Weave
weave.init(project_name="smolagents")

# Define your LLM provider supported by Smolagents
model = OpenAIServerModel(model_id="gpt-4o")

# Define a DuckDuckGo web search tool based on your query
search_tool = DuckDuckGoSearchTool()

# Define a tool-calling agent
agent = ToolCallingAgent(tools=[search_tool], model=model)
answer = agent.run(
    "Get me just the title of the page at url 'https://wandb.ai/geekyrakshit/story-illustration/reports/Building-a-GenAI-assisted-automatic-story-illustrator--Vmlldzo5MTYxNTkw'?"
)
```

Once you run the code sample, navigate to your Weave project dashboard to view the traces.



## Tracing custom tools

You can declare custom tools for your agentic workflows by decorating a function with `@tool` from `smolagents` or by inheriting from the `smolagents.Tool` class.

Weave automatically tracks custom tool calls for your Smolagents workflows. The following example shows how to log a custom Smolagents tool call with Weave:

- A custom `get_weather` function is defined and decorated with `@tool` from Smolagents, enabling the agent to invoke it as part of its reasoning process.
- The function accepts a location and an optional flag for Celsius output.
- A language model is instantiated using `OpenAIServerModel`.
- A `ToolCallingAgent` is created with the custom tool and model.
- When the agent runs the query, it selects and invokes the `get_weather` tool.
- Weave logs both the model inference and the custom tool invocation, including arguments and return values.

```python
from typing import Optional

import weave
from smolagents import OpenAIServerModel, ToolCallingAgent, tool

weave.init(project_name="smolagents")

@tool
def get_weather(location: str, celsius: Optional[bool] = False) -> str:
    """
    Get the weather in the next few days for a given location.
    Args:
        location: The location.
        celsius: Whether to use Celsius for temperature.
    """
    return f"The weather in {location} is sunny with temperatures around 7°C."

model = OpenAIServerModel(model_id="gpt-4o")
agent = ToolCallingAgent(tools=[get_weather], model=model)
answer = agent.run("What is the weather in Tokyo?")
```

Once you run the code sample, navigate to your Weave project dashboard to view the traces.

[Source](https://weave-docs.wandb.ai/guides/integrations/smolagents)

<!--- Docs: Integrations -->
<!--- Huggingface -->

# Huggingface

# Hugging Face Hub

> 🚨 **Important**: All code samples shown on this page are in Python.

This page explains how to integrate [Hugging Face Hub](https://hf.co/) with W&B Weave to track and analyze your machine learning applications. You'll learn how to log model inferences, monitor function calls, and organize experiments using Weave's tracing and versioning capabilities. By following the examples provided, you can capture valuable insights, debug your applications efficiently, and compare different model configurations—all within the Weave web interface.

:::tip[Try Hugging Face Hub with Weave in Google Colab]
Do you want to experiment with Hugging Face Hub and Weave without any of the set up? You can try the code samples shown here as a Jupyter Notebook on Google Colab.


  

:::

## Overview

[Hugging Face Hub](https://hf.co/) is a machine learning platform for creators and collaborators, offering a vast collection of pre-trained models and datasets for various projects.

The `huggingface_hub` Python library provides a unified interface to run inference across multiple services for models hosted on the Hub. You can invoke these models using the [`InferenceClient`](https://huggingface.co/docs/huggingface_hub/en/package_reference/inference_client).

Weave will automatically capture traces for [`InferenceClient`](https://huggingface.co/docs/huggingface_hub/en/package_reference/inference_client). To start tracking, calling `weave.init()` and use the library as normal.

## Prerequisites

1. Before you can use `huggingface_hub` with Weave, you must install the necessary libraries, or upgrade to the latest versions. The following command installs or upgrades `huggingface_hub` and `weave` to the latest version if it's already installed, and reduces installation output.

    ```python
    pip install -U huggingface_hub weave -qqq
    ```

2. To use inference with a model on the Hugging Face Hub, set your [User Access Token](https://huggingface.co/docs/hub/security-tokens). You can either set the token from your [Hugging Face Hub Settings page](https://huggingface.co/settings/tokens) or programmatically. The following code sample prompts the user to enter their `HUGGINGFACE_TOKEN` and sets the token as an environment variable.

    ```python
    import os
    import getpass

    os.environ["HUGGINGFACE_TOKEN"] = getpass.getpass("Enter your Hugging Face Hub Token: ")
    ```

## Basic tracing

Storing traces of language model applications in a central location is essential during development and production. These traces help with debugging and serve as valuable datasets for improving your application.

Weave automatically captures traces for the [`InferenceClient`](https://huggingface.co/docs/huggingface_hub/en/package_reference/inference_client). To start tracking, initialize Weave by calling `weave.init()`, then use the library as usual.

The following example demonstrates how to log inference calls to the Hugging Face Hub using Weave:

```python
import weave
from huggingface_hub import InferenceClient

# Initialize Weave
weave.init(project_name="quickstart-huggingface")

# Initialize Hugging Face Inference Client
huggingface_client = InferenceClient(
    api_key=os.environ.get("HUGGINGFACE_TOKEN")
)

# Make a chat completion inference call to the Hugging Face Hub with the Llama-3.2-11B-Vision-Instruct model
image_url = "https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg"
response = huggingface_client.chat_completion(
    model="meta-llama/Llama-3.2-11B-Vision-Instruct",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "image_url", "image_url": {"url": image_url}},
                {"type": "text", "text": "Describe this image in one sentence."},
            ],
        }
    ],
    max_tokens=500,
    seed=42,
)
```

After the code shown above runs, Weave tracks and logs all LLM calls made with the Hugging Face Inference Client. You can view these traces in the Weave web interface.



Weave logs each inference call, providing details about inputs, outputs, and metadata.



Weave also renders the call as a chat view in the UI, displaying the entire chat history with the model.

## Trace a function

To gain deeper insights into how data flows through your application, you can use `@weave.op` to track function calls. This captures inputs, outputs, and execution logic, helping with debugging and performance analysis.

By nesting multiple ops, you can build a structured tree of tracked functions. Weave also automatically versions your code, preserving intermediate states as you experiment, even before committing changes to Git.

To start tracking, decorate the functions that you want to track with `@weave.op`.

In the following example, Weave tracks three functions: `generate_image`, `check_image_correctness`, and `generate_image_and_check_correctness`. These functions generate an image and validate whether it matches a given prompt.

```python
import base64
from PIL import Image


def encode_image(pil_image):
    import io
    buffer = io.BytesIO()
    pil_image.save(buffer, format="JPEG")
    buffer.seek(0)
    encoded_image = base64.b64encode(buffer.read()).decode("utf-8")
    return f"data:image/jpeg;base64,{encoded_image}"


@weave.op
def generate_image(prompt: str):
    return huggingface_client.text_to_image(
        prompt=prompt,
        model="black-forest-labs/FLUX.1-schnell",
        num_inference_steps=4,
    )


@weave.op
def check_image_correctness(image: Image.Image, image_generation_prompt: str):
    return huggingface_client.chat_completion(
        model="meta-llama/Llama-3.2-11B-Vision-Instruct",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "image_url", "image_url": {"url": encode_image(image)}},
                    {
                        "type": "text",
                        "text": f"Is this image correct for the prompt: {image_generation_prompt}? Answer with only one word: yes or no",
                    },
                ],
            }
        ],
        max_tokens=500,
        seed=42,
    ).choices[0].message.content


@weave.op
def generate_image_and_check_correctness(prompt: str):
    image = generate_image(prompt)
    return {
        "image": image,
        "is_correct": check_image_correctness(image, prompt),
    }


response = generate_image_and_check_correctness("A cute puppy")
```

Weave now logs all function calls wrapped with `@weave.op`, allowing you to analyze execution details in the Weave UI.

 

Weave also captures and visualizes function execution, helping you to understand data flow and logic within your application.

## Use `Model`s for experimentation

Managing LLM experiments can be challenging when multiple components are involved. The Weave [`Model`](../core-types/models.md) class helps capture and organize experimental details, such as system prompts and model configurations, allowing you to easily compare different iterations.

In addition to versioning code and capturing inputs/outputs, a `Model` stores structured parameters that control application behavior. This makes it easier to track which configurations produced the best results. You can also integrate a Weave `Model` with Weave [Serve](../tools/serve.md) and [Evaluations](../evaluation/scorers.md) for further insights.

The example below demonstrates defines a `CityVisitRecommender` model for travel recommendations. Each modification to its parameters generates a new version, making experimentation easy.

```python
import rich


class CityVisitRecommender(weave.Model):
    model: str
    temperature: float = 0.7
    max_tokens: int = 500
    seed: int = 42

    @weave.op()
    def predict(self, city: str) -> str:
        return huggingface_client.chat_completion(
            model=self.model,
            messages=[
                {
                    "role": "system",
                    "content": "You are a helpful assistant meant to suggest places to visit in a city",
                },
                {"role": "user", "content": city},
            ],
            max_tokens=self.max_tokens,
            temperature=self.temperature,
            seed=self.seed,
        ).choices[0].message.content


city_visit_recommender = CityVisitRecommender(
    model="meta-llama/Llama-3.2-11B-Vision-Instruct",
    temperature=0.7,
    max_tokens=500,
    seed=42,
)
rich.print(city_visit_recommender.predict("New York City"))
rich.print(city_visit_recommender.predict("Paris"))
```

Weave automatically logs models and tracks different versions, making it easy to analyze performance and experiment history.

[Source](https://weave-docs.wandb.ai/guides/integrations/huggingface)

<!--- Docs: Integrations -->
<!--- Local Models -->

# Local Models

# Local Models

Many developers download and run open source models like LLama-3, Mixtral, Gemma, Phi and more locally. There are quite a few ways of running these models locally and Weave supports a few of them out of the box, as long as they support OpenAI SDK compatibility.

## Wrap local model functions with `@weave.op()`

You can easily integrate Weave with any LLM yourself simply by initializing Weave with `weave.init('')` and then wrapping the calls to your LLMs with `weave.op()`. See our guide on [tracing](/guides/tracking/tracing) for more details.

## Updating your OpenAI SDK code to use local models

All of the frameworks of services that support OpenAI SDK compatibility require a few minor changes.

First and most important, is the `base_url` change during the `openai.OpenAI()` initialization.

```python
client = openai.OpenAI(
    base_url="http://localhost:1234",
)
```

In the case of local models, the `api_key` can be any string but it should be overridden, as otherwise OpenAI will try to use it from environment variables and show you an error.

## OpenAI SDK supported Local Model runners

Here's a list of apps that allows you to download and run models from Hugging Face on your computer, that support OpenAI SDK compatibility.

1. Nomic [GPT4All](https://www.nomic.ai/gpt4all) - support via Local Server in settings ([FAQ](https://docs.gpt4all.io/gpt4all_help/faq.html))
1. [LMStudio](https://lmstudio.ai/) - Local Server OpenAI SDK support [docs](https://lmstudio.ai/docs/local-server)
1. [Ollama](https://ollama.com/) - [Experimental Support](https://github.com/ollama/ollama/blob/main/docs/openai.md) for OpenAI SDK
1. llama.cpp via [llama-cpp-python](https://llama-cpp-python.readthedocs.io/en/latest/server/) python package
1. [llamafile](https://github.com/Mozilla-Ocho/llamafile#other-example-llamafiles) - `http://localhost:8080/v1` automatically supports OpenAI SDK on Llamafile run

[Source](https://weave-docs.wandb.ai/guides/integrations/local_models)

<!--- Docs: Integrations -->
<!--- Dspy -->

# Dspy

# DSPy


  


[DSPy](https://dspy-docs.vercel.app/) is a framework for algorithmically optimizing LM prompts and weights, especially when LMs are used one or more times within a pipeline. Weave automatically tracks and logs calls made using DSPy modules and functions.

## Tracing

It’s important to store traces of language model applications in a central location, both during development and in production. These traces can be useful for debugging, and as a dataset that will help you improve your application.

Weave will automatically capture traces for [DSPy](https://dspy-docs.vercel.app/). To start tracking, calling `weave.init(project_name="")` and use the library as normal.

```python
import os
import dspy
import weave

os.environ["OPENAI_API_KEY"] = ""

weave.init(project_name="")

lm = dspy.LM('openai/gpt-4o-mini')
dspy.configure(lm=lm)
classify = dspy.Predict("sentence -> sentiment")
classify(sentence="it's a charming and often affecting journey.")
```

[](https://wandb.ai/geekyrakshit/dspy-project/weave/calls)

Weave logs all LM calls in your DSPy program, providing details about inputs, outputs, and metadata.

## Track your own DSPy Modules and Signatures

A `Module` is the building block with learnable parameters for DSPy programs that abstracts a prompting technique. A `Signature` is a declarative specification of input/output behavior of a DSPy Module. Weave automatically tracks all in-built and cutom Signatures and Modules in your DSPy programs.

```python
import os
import dspy
import weave

os.environ["OPENAI_API_KEY"] = ""

weave.init(project_name="")

class Outline(dspy.Signature):
    """Outline a thorough overview of a topic."""

    topic: str = dspy.InputField()
    title: str = dspy.OutputField()
    sections: list[str] = dspy.OutputField()
    section_subheadings: dict[str, list[str]] = dspy.OutputField(
        desc="mapping from section headings to subheadings"
    )


class DraftSection(dspy.Signature):
    """Draft a top-level section of an article."""

    topic: str = dspy.InputField()
    section_heading: str = dspy.InputField()
    section_subheadings: list[str] = dspy.InputField()
    content: str = dspy.OutputField(desc="markdown-formatted section")


class DraftArticle(dspy.Module):
    def __init__(self):
        self.build_outline = dspy.ChainOfThought(Outline)
        self.draft_section = dspy.ChainOfThought(DraftSection)

    def forward(self, topic):
        outline = self.build_outline(topic=topic)
        sections = []
        for heading, subheadings in outline.section_subheadings.items():
            section, subheadings = (
                f"## {heading}",
                [f"### {subheading}" for subheading in subheadings],
            )
            section = self.draft_section(
                topic=outline.title,
                section_heading=section,
                section_subheadings=subheadings,
            )
            sections.append(section.content)
        return dspy.Prediction(title=outline.title, sections=sections)


draft_article = DraftArticle()
article = draft_article(topic="World Cup 2002")
```

[](https://wandb.ai/geekyrakshit/dspy-project/weave/calls)


## Optimization and Evaluation of your DSPy Program

Weave also automatically captures traces for DSPy optimizers and Evaluation calls which you can use to improve and evaulate your DSPy program's performance on a development set.


```python
import os
import dspy
import weave

os.environ["OPENAI_API_KEY"] = ""
weave.init(project_name="")

def accuracy_metric(answer, output, trace=None):
    predicted_answer = output["answer"].lower()
    return answer["answer"].lower() == predicted_answer

module = dspy.ChainOfThought("question -> answer: str, explanation: str")
optimizer = dspy.BootstrapFewShot(metric=accuracy_metric)
optimized_module = optimizer.compile(
    module, trainset=SAMPLE_EVAL_DATASET, valset=SAMPLE_EVAL_DATASET
)
```

[](https://wandb.ai/geekyrakshit/dspy-project/weave/calls)

[Source](https://weave-docs.wandb.ai/guides/integrations/dspy)

<!--- Docs: Integrations -->
<!--- Anthropic -->

# Anthropic

# Anthropic


  


Weave automatically tracks and logs LLM calls made via the [Anthropic Python library](https://github.com/anthropics/anthropic-sdk-python), after `weave.init()` is called.

> 💡 **Note**: Do you want to experiment with Anthropic models on Weave without any set up? Try the [LLM Playground](../tools/playground.md).

## Traces

It’s important to store traces of LLM applications in a central database, both during development and in production. You’ll use these traces for debugging, and as a dataset that will help you improve your application.

Weave will automatically capture traces for [anthropic-sdk-python](https://github.com/anthropics/anthropic-sdk-python). You can use the library as usual, start by calling `weave.init()`:

```python
import weave    
# use the anthropic library as usual
import os
from anthropic import Anthropic
weave.init("anthropic_project")

client = Anthropic(
    api_key=os.environ.get("ANTHROPIC_API_KEY"),
)

message = client.messages.create(
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": "Tell me a joke about a dog",
        }
    ],
    model="claude-3-opus-20240229",
)
print(message.content)
```


Weave will now track and log all LLM calls made through the Anthropic library. You can view the traces in the Weave web interface.

[](https://wandb.ai/capecape/anthropic_project/weave/calls)

> 💡 **Note**: We patch the anthropic `Messages.create` method for you to keep track of your LLM calls.


Weave will now track and log all LLM calls made through Anthropic. You can view the logs and insights in the Weave web interface.

## Wrapping with your own ops

Weave ops make results *reproducible* by automatically versioning code as you experiment, and they capture their inputs and outputs. Simply create a function decorated with [`@weave.op()`](https://wandb.github.io/weave/guides/tracking/ops) that calls into [`Anthropic.messages.create`](https://docs.anthropic.com/en/api/messages-examples) and Weave will track the inputs and outputs for you. Let's see how we can do this in nested example:

```python
import weave
import os
from anthropic import Anthropic
weave.init("anthropic_project")
client = Anthropic(
    api_key=os.environ.get("ANTHROPIC_API_KEY"),
)
@weave.op()
def call_anthropic(user_input:str, model:str) -> str:
    message = client.messages.create(
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": user_input,
        }
        ],
        model=model,
    )
    return message.content[0].text
@weave.op()
def generate_joke(topic: str) -> str:
    return call_anthropic(f"Tell me a joke about {topic}", model="claude-3-haiku-20240307")

print(generate_joke("chickens"))
print(generate_joke("cars"))
```

[](https://wandb.github.io/weave/guides/tracking/ops)

## Create a `Model` for easier experimentation

Organizing experimentation is difficult when there are many moving pieces. By using the [`Model`](/guides/core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app. 

In addition to versioning code and capturing inputs/outputs, [`Model`](/guides/core-types/models)s capture structured parameters that control your application’s behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and [`Evaluation`](/guides/core-types/evaluations)s.

In the example below, you can experiment with `model` and `temperature`. Every time you change one of these, you'll get a new _version_ of `JokerModel`. 

```python
import weave    
# use the anthropic library as usual
import os
from anthropic import Anthropic
weave.init('joker-anthropic')

class JokerModel(weave.Model): # Change to `weave.Model`
  model: str
  temperature: float
  
  @weave.op()
  def predict(self, topic): # Change to `predict`
    client = Anthropic()
    message = client.messages.create(
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": f"Tell me a joke about {topic}",
        }
        ],
        model=self.model,
        temperature=self.temperature
    )
    return message.content[0].text


joker = JokerModel(
    model="claude-3-haiku-20240307",
    temperature = 0.1)
result = joker.predict("Chickens and Robots")
print(result)
```

[](https://wandb.ai/capecape/anthropic_project/weave/calls)

## Tools (function calling)

Anthropic provides [tools](https://docs.anthropic.com/en/docs/tool-use) interface for calling functions. Weave will automatically track those functions calls.

```python
message = client.messages.create(
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": "What's the weather like in San Francisco?",
        }
    ],
    tools=[
        {
            "name": "get_weather",
            "description": "Get the current weather in a given location",
            "input_schema": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA",
                    }
                },
                "required": ["location"],
            },
        },
    ],
    model=model,
)

print(message)
```

We automatically capture the tools you used on the prompt and keep them versioned.

[](https://wandb.ai/capecape/anthropic_project/weave/calls)

[Source](https://weave-docs.wandb.ai/guides/integrations/anthropic)

<!--- Docs: Integrations -->
<!--- Groq -->

# Groq

# Groq


  


> 💡 **Note**: Do you want to experiment with Groq models on Weave without any set up? Try the [LLM Playground](../tools/playground.md).

[Groq](https://groq.com/) is the AI infrastructure company that delivers fast AI inference. The LPU™ Inference Engine by Groq is a hardware and software platform that delivers exceptional compute speed, quality, and energy efficiency. Weave automatically tracks and logs calls made using Groq chat completion calls.

## Tracing

It’s important to store traces of language model applications in a central location, both during development and in production. These traces can be useful for debugging, and as a dataset that will help you improve your application.

Weave will automatically capture traces for [Groq](https://groq.com/). To start tracking, calling `weave.init(project_name="")` and use the library as normal.

```python
import os
import weave
from groq import Groq

weave.init(project_name="groq-project")

client = Groq(
    api_key=os.environ.get("GROQ_API_KEY"),
)
chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "Explain the importance of fast language models",
        }
    ],
    model="llama3-8b-8192",
)
```

|  |
|---|
| Weave will now track and log all LLM calls made through the Groq library. You can view the traces in the Weave web interface. |

## Track your own ops

Wrapping a function with `@weave.op` starts capturing inputs, outputs and app logic so you can debug how data flows through your app. You can deeply nest ops and build a tree of functions that you want to track. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git.

Simply create a function decorated with [`@weave.op`](/guides/tracking/ops).

In the example below, we have the function `recommend_places_to_visit` which is a function wrapped with `@weave.op` that recommends places to visit in a city.

```python
import os
import weave
from groq import Groq


weave.init(project_name="groq-test")

client = Groq(
    api_key=os.environ.get("GROQ_API_KEY"),
)

@weave.op()
def recommend_places_to_visit(city: str, model: str="llama3-8b-8192"):
    chat_completion = client.chat.completions.create(
        messages=[
            {
                "role": "system",
                "content": "You are a helpful assistant meant to suggest places to visit in a city",
            },
            {
                "role": "user",
                "content": city,
            }
        ],
        model="llama3-8b-8192",
    )
    return chat_completion.choices[0].message.content


recommend_places_to_visit("New York")
recommend_places_to_visit("Paris")
recommend_places_to_visit("Kolkata")
```

|  |
|---|
| Decorating the `recommend_places_to_visit` function with `@weave.op` traces its inputs, outputs, and all internal LM calls made inside the function.  |

## Create a `Model` for easier experimentation

Organizing experimentation is difficult when there are many moving pieces. By using the [`Model`](../core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app. 

In addition to versioning code and capturing inputs/outputs, [`Model`](../core-types/models)s capture structured parameters that control your application’s behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and [`Evaluation`](../core-types/evaluations.md)s.

In the example below, you can experiment with `GroqCityVisitRecommender`. Every time you change one of these, you'll get a new _version_ of `GroqCityVisitRecommender`.

```python
import os
from groq import Groq
import weave


class GroqCityVisitRecommender(weave.Model):
    model: str
    groq_client: Groq

    @weave.op()
    def predict(self, city: str) -> str:
        system_message = {
            "role": "system",
            "content": """
You are a helpful assistant meant to suggest places to visit in a city
""",
        }
        user_message = {"role": "user", "content": city}
        chat_completion = self.groq_client.chat.completions.create(
            messages=[system_message, user_message],
            model=self.model,
        )
        return chat_completion.choices[0].message.content


weave.init(project_name="groq-test")
city_recommender = GroqCityVisitRecommender(
    model="llama3-8b-8192", groq_client=Groq(api_key=os.environ.get("GROQ_API_KEY"))
)
print(city_recommender.predict("New York"))
print(city_recommender.predict("San Francisco"))
print(city_recommender.predict("Los Angeles"))
```

|  |
|---|
| Tracing and versioning your calls using a [`Model`](../core-types/models) |

### Serving a Weave Model

Given a weave reference to any `weave.Model` object, you can spin up a fastapi server and [serve](https://wandb.github.io/weave/guides/tools/serve) it.

| [](https://wandb.ai/geekyrakshit/groq-test/weave/objects/GroqCityVisitRecommender/versions/6O1xPTJ9yFx8uuCjJAlI7KgcVYxXKn7JxfmVD9AQT5Q) |
|---|
| You can find the weave reference of any WeaveModel by navigating to the model and copying it from the UI. |

You can serve your model by using the following command in the terminal:

```shell
weave serve weave:///your_entity/project-name/YourModel:
```

[Source](https://weave-docs.wandb.ai/guides/integrations/groq)

<!--- Docs: Integrations -->
<!--- Litellm -->

# Litellm

# LiteLLM


  


Weave automatically tracks and logs LLM calls made via LiteLLM, after `weave.init()` is called.

## Traces

It's important to store traces of LLM applications in a central database, both during development and in production. You'll use these traces for debugging, and as a dataset that will help you improve your application.

> **Note:** When using LiteLLM, make sure to import the library using `import litellm` and call the completion function with `litellm.completion` instead of `from litellm import completion`. This ensures that all functions and parameters are correctly referenced.

Weave will automatically capture traces for LiteLLM. You can use the library as usual, start by calling `weave.init()`:

```python
import litellm
import weave
weave.init("weave_litellm_integration")

openai_response = litellm.completion(
    model="gpt-3.5-turbo", 
    messages=[{"role": "user", "content": "Translate 'Hello, how are you?' to French"}],
    max_tokens=1024
)
print(openai_response.choices[0].message.content)

claude_response = litellm.completion(
    model="claude-3-5-sonnet-20240620", 
    messages=[{"role": "user", "content": "Translate 'Hello, how are you?' to French"}],
    max_tokens=1024
)
print(claude_response.choices[0].message.content)
```

Weave will now track and log all LLM calls made through LiteLLM. You can view the traces in the Weave web interface.

## Wrapping with your own ops

Weave ops make results reproducible by automatically versioning code as you experiment, and they capture their inputs and outputs. Simply create a function decorated with `@weave.op()` that calls into LiteLLM's completion function and Weave will track the inputs and outputs for you. Here's an example:

```python
import litellm
import weave
weave.init("weave_litellm_integration")
@weave.op()
def translate(text: str, target_language: str, model: str) -> str:
    response = litellm.completion(
        model=model,
        messages=[{"role": "user", "content": f"Translate '{text}' to {target_language}"}],
        max_tokens=1024
    )
    return response.choices[0].message.content

print(translate("Hello, how are you?", "French", "gpt-3.5-turbo"))
print(translate("Hello, how are you?", "Spanish", "claude-3-5-sonnet-20240620"))
```

## Create a `Model` for easier experimentation

Organizing experimentation is difficult when there are many moving pieces. By using the `Model` class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app.

In addition to versioning code and capturing inputs/outputs, Models capture structured parameters that control your application's behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and Evaluations.

In the example below, you can experiment with different models and temperatures:

```python
import litellm
import weave
weave.init('weave_litellm_integration')
class TranslatorModel(weave.Model):
    model: str
    temperature: float
    @weave.op()
    def predict(self, text: str, target_language: str):
        response = litellm.completion(
            model=self.model,
            messages=[
                {"role": "system", "content": f"You are a translator. Translate the given text to {target_language}."},
                {"role": "user", "content": text}
            ],
            max_tokens=1024,
            temperature=self.temperature
        )
        return response.choices[0].message.content

# Create instances with different models
gpt_translator = TranslatorModel(model="gpt-3.5-turbo", temperature=0.3)
claude_translator = TranslatorModel(model="claude-3-5-sonnet-20240620", temperature=0.1)

# Use different models for translation
english_text = "Hello, how are you today?"

print("GPT-3.5 Translation to French:")
print(gpt_translator.predict(english_text, "French"))

print("\nClaude-3.5 Sonnet Translation to Spanish:")
print(claude_translator.predict(english_text, "Spanish"))
```

## Function Calling

LiteLLM supports function calling for compatible models. Weave will automatically track these function calls.

```python
import litellm
import weave
weave.init("weave_litellm_integration")

response = litellm.completion(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "Translate 'Hello, how are you?' to French"}],
    functions=[
        {
            "name": "translate",
            "description": "Translate text to a specified language",
            "parameters": {
                "type": "object",
                "properties": {
                    "text": {
                        "type": "string",
                        "description": "The text to translate",
                    },
                    "target_language": {
                        "type": "string",
                        "description": "The language to translate to",
                    }
                },
                "required": ["text", "target_language"],
            },
        },
    ],
)

print(response)
```

We automatically capture the functions you used in the prompt and keep them versioned.

[](https://wandb.ai/a-sh0ts/weave_litellm_integration/weave/calls)

[Source](https://weave-docs.wandb.ai/guides/integrations/litellm)

<!--- Docs: Integrations -->
<!--- Mcp -->

# Mcp

# Model Context Protocol (MCP) and Weave


  


The Model Context Protocol (MCP) is a standardized communication protocol that enables AI applications to exchange information with large language models (LLMs). Similar to universal connectors that transformed hardware compatibility, MCP provides an interface for LLMs to access various data sources and interact with external tools, all without requiring custom integrations for each new service.

The Weave integration lets you trace activity between your MCP client and MCP server. It gives you detailed visibility into tool calls, resource access, and prompt generation across MCP-based systems.

## How it works

> 🚨 **Important**: Currently, the integration captures client-side and server-side operations separately, but does not provide end-to-end visibility into their interaction. There's an ongoing proposal to add OpenTelemetry trace support to MCP to enable end-to-end observability. For more information, see [GitHub discussion #269](https://github.com/modelcontextprotocol/modelcontextprotocol/discussions/269).

The Weave integration automatically traces key components of the Model Context Protocol (MCP) by patching core methods with the [`weave.op()`](../tracking/ops.md) decorator. Specifically, it patches methods in the [`mcp.server.fastmcp.FastMCP`](https://github.com/modelcontextprotocol/python-sdk/blob/b4c7db6a50a5c88bae1db5c1f7fba44d16eebc6e/src/mcp/server/fastmcp/server.py#L109) and [`mcp.ClientSession`](https://github.com/modelcontextprotocol/python-sdk/blob/b4c7db6a50a5c88bae1db5c1f7fba44d16eebc6e/src/mcp/client/session.py#L84) classes.

Through this integration, Weave traces the following MCP components:

- [Tools](https://modelcontextprotocol.io/docs/concepts/tools)
- [Resources](https://modelcontextprotocol.io/docs/concepts/resources)
- [Prompts](https://modelcontextprotocol.io/docs/concepts/prompts)

[](https://wandb.ai/ayut/mcp_example/weave/traces?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fayut%2Fmcp_example%2Fop%2Frun_client%3A*%22%5D%7D&peekPath=%2Fayut%2Fmcp_example%2Fcalls%2F01966bbe-cc5e-7012-b45f-bf10617d8c1e%3FhideTraceTree%3D0)


## Use the integration

The Weave integration works with both the MCP server and client. Once installed, you can enable tracing with just two additional lines of code—one to import `weave`, and another to initialize it.

### Prerequisites

Before you begin, install the required packages:

```bash
pip install -qq "mcp[cli]" weave
```

### Configuration

The MCP integration can be configured through environment variables:

- `MCP_TRACE_LIST_OPERATIONS`: Set to `true` to trace list operations (`list_tools`, `list_resources`, and `list_prompts`) on both server and client sides.

### Server-side integration

To trace an MCP server, add two lines to your existing `FastMCP` setup: one to import Weave and one to initialize the client. Once added, tool, resource, and prompt operations will be automatically traced.

```python
# Import Weave (required for tracing)
import weave
from mcp.server.fastmcp import FastMCP

# Initialize Weave with your project name
weave_client = weave.init("my-project")

# Set up the MCP server
mcp = FastMCP("Demo")

# Define a tool (this call will be traced)
@mcp.tool()
def add(a: int, b: int) -> int:
    """Add two numbers."""
    return a + b

# Define a resource (this call will be traced)
@mcp.resource("greeting://{name}")
def get_greeting(name: str) -> str:
    """Return a personalized greeting."""
    return f"Hello, {name}!"

# Define a prompt (this call will be traced)
@mcp.prompt()
def review_code(code: str) -> str:
    """Return a prompt for reviewing code."""
    return f"Please review this code:\n\n{code}"

# Start the server
mcp.run(transport="stdio")
```

### Client-side integration

On the client side, tracing also requires just two changes: import Weave and initialize it. All tool calls, resource accesses, and prompt requests will be traced automatically.

```python
# Import Weave (required for tracing)
import weave
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

# Initialize Weave with your project name
weave_client = weave.init("my-project")

# Set up and run the MCP client
async with stdio_client(server_params) as (read, write):
    async with ClientSession(read, write) as session:
        # Initialize the session
        await session.initialize()
        
        # Call a tool (this will be traced)
        result = await session.call_tool("add", arguments={"a": 1, "b": 2})
        
        # Read a resource (this will be traced)
        resource = await session.read_resource("greeting://user")
        
        # Get a prompt (this will be traced)
        prompt = await session.get_prompt("review_code", arguments={"code": "print('Hello')"})
```

## Tutorial: `mcp_demo` example

The [`mcp_example`](https://github.com/wandb/weave/tree/master/examples/mcp_demo) demonstrates an integration between the Model Context Protocol (MCP) and Weave for tracing. It showcases how to instrument both the client and server components to capture detailed traces of their interactions. 

### Run the example

1. Clone the `weave` repository and navigate to the `mcp_demo` example:

   ```bash
   git clone https://github.com/wandb/weave
   cd weave/examples/mcp_demo
   ```

   The example includes two main files:

    - `example_server.py`: A demo MCP server built with `FastMCP`. It defines tools, resources, and prompts.
    - `example_client.py`: A client that connects to the server and interacts with its components.

2. Install the required dependencies manually:

   ```bash
   pip install mcp[cli] weave
   ```

3. Run the demo:

   ```bash
   python example_client.py example_server.py
   ```

   This command launches both the client and server. The client starts an interactive CLI where you can test various features.

### Client CLI commands

The client interface supports the following commands:

| Command               | Description                             |
|-----------------------|-----------------------------------------|
| `tools`              | List available tools                     |
| `resources`          | List available resources                 |
| `prompts`            | List available prompts                   |
| `add  `        | Add two numbers                          |
| `bmi  ` | Calculate Body Mass Index             |
| `weather `     | Get weather data for a city              |
| `greeting `    | Get a personalized greeting              |
| `user `          | Retrieve a user profile                  |
| `config`             | Fetch app configuration                 |
| `code-review ` | Generate a code review prompt            |
| `debug `      | Generate a debugging prompt              |
| `demo`               | Run a full demo of all available features. This will run each feature in sequence and produce a full trace timeline of interactions in the Weave UI. |
| `q`                  | Quit the session                         |

### Understanding the example

The `example_server.py` server defines the following:

- _Tools_: Functions such as `add()`, `calculate_bmi()`, `fetch_weather()`
- _Resources_: Endpoints like `greeting://{name}`, `config://app`, `users://{id}/profile`
- _Prompts_: Templates like `review_code()` and `debug_error()`

All server-side operations are automatically traced by Weave when you initialize the client with `weave.init()`.

The `example_client.py` client demonstrates how to:

- Connect to an MCP server
- Discover available tools, resources, and prompts
- Call tools with parameters
- Read from resource URIs
- Generate prompts with arguments
- Show usage of [`weave.op()`](../tracking/ops.md) with custom methods/functions.

Weave traces all client-side calls to provide a complete view of interactions between the client and server.

## FAQ

### Why is MCP tracing needed?

As an LLM application developer, you fall into one of three categories:

- _MCP server-side developer_: You want to expose multiple tools, resources, and prompts to the MCP client. You expose your existing application's tools, resources, etc., or you have built agents or have multiple agents orchestrated by an orchestrator agent. 

- _MCP client-side developer_: You want to plug your client-side application into multiple MCP servers. A core part of your client-side logic is making LLM calls to decide which tool to call or which resource to fetch.

- _MCP server and client developer_: You are developing both the server and the client.

If you fall into either of the first two categories, you want to know when each tool is called, what the execution flow looks like, the token count, and latency of different components in your server or client-side logic. 

If you are developing both the server and client, the ability to see a unified trace timeline can help you quickly iterate through both server and client-side logic.

In any case, an observability layer allows you to:

- Quickly iterate through your application
- Audit the workflow or execution logic
- Identify bottlenecks

[Source](https://weave-docs.wandb.ai/guides/integrations/mcp)

<!--- Docs: Integrations -->
<!--- Openai -->

# Openai

# OpenAI


  


> 💡 **Note**: Do you want to experiment with OpenAI models on Weave without any set up? Try the [LLM Playground](../tools/playground.md).

## Tracing

It’s important to store traces of LLM applications in a central database, both during development and in production. You’ll use these traces for debugging and to help build a dataset of tricky examples to evaluate against while improving your application.


  
    Weave can automatically capture traces for the [openai python library](https://platform.openai.com/docs/libraries/python-library).

    Start capturing by calling `weave.init()` with a project name your choice.

    ```python
    from openai import OpenAI
    import weave
    client = OpenAI()
    weave.init('emoji-bot')

    response = client.chat.completions.create(
      model="gpt-4",
      messages=[
        {
          "role": "system",
          "content": "You are AGI. You will be provided with a message, and your task is to respond using emojis only."
        },
        {
          "role": "user",
          "content": "How are you?"
        }
      ],
      temperature=0.8,
      max_tokens=64,
      top_p=1
    )
    ```

  
  
    Weave can automatically capture traces for the [openai typescript library](https://platform.openai.com/docs/libraries/node-js-library).

    Start capturing by calling `await weave.init()` with a project name your choice, and then wrapping your OpenAI client with `weave.wrapOpenAI`.

    ```typescript
        
    // highlight-next-line
    const client = await weave.init('emoji-bot');
    // highlight-next-line
    const openai = weave.wrapOpenAI(new OpenAI());

    const response = await openai.chat.completions.create({
      model: 'gpt-4',
      messages: [
        {
          role: 'system',
          content:
            'You are AGI. You will be provided with a message, and your task is to respond using emojis only.',
        },
        {
          role: 'user',
          content: 'How are you?',
        },
      ],
      temperature: 0.8,
      max_tokens: 64,
      top_p: 1,
    });
    ```

  


[](https://wandb.ai/_scott/emoji-bot/weave/calls)

## Track your own ops


  
Wrapping a function with `@weave.op` starts capturing inputs, outputs and app logic so you can debug how data flows through your app. You can deeply nest ops and build a tree of functions that you want to track. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git.

Simply create a function decorated with [`@weave.op`](/guides/tracking/ops) that calls into [openai python library](https://platform.openai.com/docs/reference/python-sdk?lang=python).

In the example below, we have 2 functions wrapped with op. This helps us see how intermediate steps, like the retrieval step in a RAG app, are affecting how our app behaves.

    ```python
    import weave
    from openai import OpenAI
    import requests, random
    PROMPT="""Emulate the Pokedex from early Pokémon episodes. State the name of the Pokemon and then describe it.
            Your tone is informative yet sassy, blending factual details with a touch of dry humor. Be concise, no more than 3 sentences. """
    POKEMON = ['pikachu', 'charmander', 'squirtle', 'bulbasaur', 'jigglypuff', 'meowth', 'eevee']
    client = OpenAI()
    @weave.op
    def get_pokemon_data(pokemon_name):
        # This is a step within your application, like the retrieval step within a RAG app
        url = f"https://pokeapi.co/api/v2/pokemon/{pokemon_name}"
        response = requests.get(url)
        if response.status_code == 200:
            data = response.json()
            name = data["name"]
            types = [t["type"]["name"] for t in data["types"]]
            species_url = data["species"]["url"]
            species_response = requests.get(species_url)
            evolved_from = "Unknown"
            if species_response.status_code == 200:
                species_data = species_response.json()
                if species_data["evolves_from_species"]:
                    evolved_from = species_data["evolves_from_species"]["name"]
            return {"name": name, "types": types, "evolved_from": evolved_from}
        else:
            return None
    @weave.op
    def pokedex(name: str, prompt: str) -> str:
        # This is your root op that calls out to other ops
        data = get_pokemon_data(name)
        if not data: return "Error: Unable to fetch data"
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system","content": prompt},
                {"role": "user", "content": str(data)}
            ],
            temperature=0.7,
            max_tokens=100,
            top_p=1
        )
        return response.choices[0].message.content
    weave.init('pokedex-openai')
    # Get data for a specific Pokémon
    pokemon_data = pokedex(random.choice(POKEMON), PROMPT)
    ```

Navigate to Weave and you can click `get_pokemon_data` in the UI to see the inputs & outputs of that step.


Wrapping a function with `weave.op` starts capturing inputs, outputs and app logic so you can debug how data flows through your app. You can deeply nest ops and build a tree of functions that you want to track. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git.

    Simply create a function wrapped with [`weave.op`](/guides/tracking/ops) that calls into [openai typescript library](https://platform.openai.com/docs/libraries/node-js-library).

    In the example below, we have 2 functions wrapped with op. This helps us see how intermediate steps, like the retrieval step within a RAG app, are affecting how our app behaves.

    ```typescript
        // highlight-next-line
    
    const PROMPT = `Emulate the Pokedex from early Pokémon episodes. State the name of the Pokemon and then describe it.
            Your tone is informative yet sassy, blending factual details with a touch of dry humor. Be concise, no more than 3 sentences.`;
    const POKEMON = [
      'pikachu',
      'charmander',
      'squirtle',
      'bulbasaur',
      'jigglypuff',
      'meowth',
      'eevee',
    ];

    const openai = weave.wrapOpenAI(new OpenAI());

    interface PokemonData {
      name: string;
      types: string[];
      evolved_from: string;
    }

    // highlight-next-line
    const getPokemonData = weave.op(async function getPokemonData(
      pokemonName: string
    ): Promise {
      try {
        const url = `https://pokeapi.co/api/v2/pokemon/${pokemonName}`;
        const response = await fetch(url);

        if (response.ok) {
          const data = await response.json();
          const name = data.name;
          const types = data.types.map((t: any) => t.type.name);

          const speciesResponse = await fetch(data.species.url);
          let evolved_from = 'Unknown';

          if (speciesResponse.ok) {
            const speciesData = await speciesResponse.json();
            if (speciesData.evolves_from_species) {
              evolved_from = speciesData.evolves_from_species.name;
            }
          }

          return {name, types, evolved_from};
        }
        return null;
      } catch (error) {
        return null;
      }
    });

    // highlight-next-line
    const pokedex = weave.op(async function pokedex(
      name: string,
      prompt: string
    ): Promise {
      const data = await getPokemonData(name);
      if (!data) return 'Error: Unable to fetch data';

      const response = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          {role: 'system', content: prompt},
          {role: 'user', content: JSON.stringify(data)},
        ],
        temperature: 0.7,
        max_tokens: 100,
        top_p: 1,
      });

      return response.choices[0].message.content || '';
    });

    async function main() {
      await weave.init('pokedex-openai');
      const randomPokemon = POKEMON[Math.floor(Math.random() * POKEMON.length)];
      const pokemonData = await pokedex(randomPokemon, PROMPT);
      console.log(pokemonData);
    }

    main();
    ```

  


[](https://wandb.ai/_scott/pokedex-openai/weave)

## Create a `Model` for easier experimentation


  
    Organizing experimentation is difficult when there are many moving pieces. By using the [`Model`](/guides/core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app.

    In addition to versioning code and capturing inputs/outputs, [`Model`](/guides/core-types/models)s capture structured parameters that control your application’s behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and [`Evaluation`](/guides/core-types/evaluations)s.

    In the example below, you can experiment with `model` and `system_message`. Every time you change one of these, you'll get a new _version_ of `GrammarCorrectorModel`.

    ```python
    import weave
    from openai import OpenAI

    weave.init('grammar-openai')

    class GrammarCorrectorModel(weave.Model): # Change to `weave.Model`
      model: str
      system_message: str

      @weave.op()
      def predict(self, user_input): # Change to `predict`
        client = OpenAI()
        response = client.chat.completions.create(
          model=self.model,
          messages=[
              {
                  "role": "system",
                  "content": self.system_message
              },
              {
                  "role": "user",
                  "content": user_input
              }
              ],
              temperature=0,
        )
        return response.choices[0].message.content


    corrector = GrammarCorrectorModel(
        model="gpt-3.5-turbo-1106",
        system_message = "You are a grammar checker, correct the following user input.")
    result = corrector.predict("That was so easy, it was a piece of pie!")
    print(result)
    ```

    [](https://wandb.ai/_scott/grammar-openai/weave/calls)

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


## Usage Info

The OpenAI calls return usage info as a default when `stream=False`. Weave will track this usage info and log it to weave to render token counts and cost of the call.

In case you set `stream=True`, we will automatically patch the call execution with `stream_options={"include_usage": True}` argument. This will return the usage info in the last chunk to be rendered in the UI. As a user, the stream iterator will not contain this info.

If you explicitly set `stream=True` and `stream_options={"include_usage": True}`, the returned stream object will contain the usage info. If you don't want to track the usage info you need to explicitly set `stream_options={"include_usage": False}`.

## Support for deprecated function calling

OpenAI deprecated the `functions` argument in favor of `tool_calls`. Since frameworks like Langchain, LlamaIndex, etc., still support this argument our OpenAI weave integration will trace if you pass list of function schemas to `functions` argument.

[Source](https://weave-docs.wandb.ai/guides/integrations/openai)

<!--- Docs: Integrations -->
<!--- Bedrock -->

# Bedrock

# Amazon Bedrock

Weave automatically tracks and logs LLM calls made via Amazon Bedrock, AWS's fully managed service that offers foundation models from leading AI companies through a unified API.

There are multiple ways to log LLM calls to Weave from Amazon Bedrock. You can use `weave.op` to create reusable operations for tracking any calls to a Bedrock model. Optionally, if you're using Anthropic models, you can use Weave’s built-in integration with Anthropic. 

> 🌟 **Tip**: For the latest tutorials, visit [Weights & Biases on Amazon Web Services](https://wandb.ai/site/partners/aws/).

## Traces

Weave will automatically capture traces for Bedrock API calls. You can use the Bedrock client as usual after initializing Weave and patching the client:

```python
import weave
import boto3
import json
from weave.integrations.bedrock.bedrock_sdk import patch_client

weave.init("my_bedrock_app")

# Create and patch the Bedrock client
client = boto3.client("bedrock-runtime")
patch_client(client)

# Use the client as usual
response = client.invoke_model(
    modelId="anthropic.claude-3-5-sonnet-20240620-v1:0",
    body=json.dumps({
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 100,
        "messages": [
            {"role": "user", "content": "What is the capital of France?"}
        ]
    }),
    contentType='application/json',
    accept='application/json'
)
response_dict = json.loads(response.get('body').read())
print(response_dict["content"][0]["text"])
```

of using the `converse` API:

```python
messages = [{"role": "user", "content": [{"text": "What is the capital of France?"}]}]

response = client.converse(
    modelId="anthropic.claude-3-5-sonnet-20240620-v1:0",
    system=[{"text": "You are a helpful AI assistant."}],
    messages=messages,
    inferenceConfig={"maxTokens": 100},
)
print(response["output"]["message"]["content"][0]["text"])

```

## Wrapping with your own ops

You can create reusable operations using the `@weave.op()` decorator. Here's an example showing both the `invoke_model` and `converse` APIs:

```python
@weave.op
def call_model_invoke(
    model_id: str,
    prompt: str,
    max_tokens: int = 100,
    temperature: float = 0.7
) -> dict:
    body = json.dumps({
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": max_tokens,
        "temperature": temperature,
        "messages": [
            {"role": "user", "content": prompt}
        ]
    })

    response = client.invoke_model(
        modelId=model_id,
        body=body,
        contentType='application/json',
        accept='application/json'
    )
    return json.loads(response.get('body').read())

@weave.op
def call_model_converse(
    model_id: str,
    messages: str,
    system_message: str,
    max_tokens: int = 100,
) -> dict:
    response = client.converse(
        modelId=model_id,
        system=[{"text": system_message}],
        messages=messages,
        inferenceConfig={"maxTokens": max_tokens},
    )
    return response
```



## Create a `Model` for easier experimentation

You can create a Weave Model to better organize your experiments and capture parameters. Here's an example using the `converse` API:

```python
class BedrockLLM(weave.Model):
    model_id: str
    max_tokens: int = 100
    system_message: str = "You are a helpful AI assistant."

    @weave.op
    def predict(self, prompt: str) -> str:
        "Generate a response using Bedrock's converse API"
        
        messages = [{
            "role": "user",
            "content": [{"text": prompt}]
        }]

        response = client.converse(
            modelId=self.model_id,
            system=[{"text": self.system_message}],
            messages=messages,
            inferenceConfig={"maxTokens": self.max_tokens},
        )
        return response["output"]["message"]["content"][0]["text"]

# Create and use the model
model = BedrockLLM(
    model_id="anthropic.claude-3-5-sonnet-20240620-v1:0",
    max_tokens=100,
    system_message="You are an expert software engineer that knows a lot of programming. You prefer short answers."
)
result = model.predict("What is the best way to handle errors in Python?")
print(result)
```

This approach allows you to version your experiments and easily track different configurations of your Bedrock-based application.

## Learn more

Learn more about using Amazon Bedrock with Weave

### Try Bedrock in the Weave Playground

Do you want to experiment with Amazon Bedrock models in the Weave UI without any set up? Try the [LLM Playground](../tools/playground.md).

### Report: Compare LLMs on Bedrock for text summarization with Weave

The [Compare LLMs on Bedrock for text summarization with Weave](https://wandb.ai/byyoung3/ML_NEWS3/reports/Compare-LLMs-on-Amazon-Bedrock-for-text-summarization-with-W-B-Weave--VmlldzoxMDI1MTIzNw) report explains how to use Bedrock in combination with Weave to evaluate and compare LLMs for summarization tasks, code samples included.

[Source](https://weave-docs.wandb.ai/guides/integrations/bedrock)

<!--- Docs: Integrations -->
<!--- Openai Agents -->

# Openai Agents

# OpenAI Agents SDK

The [OpenAI Agents Python SDK](https://github.com/openai/openai-agents-python) is a lightweight and powerful framework for building multi-agent workflows. You can use W&B Weave with the OpenAI Agents SDK to track and monitor your agentic applications.

## Installation

Install the required dependencies using `pip`: 

```bash
pip install weave openai-agents
```

## Get started

To use the OpenAI Agents SDK with Weave, you'll need to:

- Initialize Weave with your project name
- Add the Weave tracing processor to your agents
- Create and run your agents as usual

In the following codes sample, an OpenAI Agent is created and integrated with Weave for traceability. First, a Weave project is initialized and the `WeaveTracingProcessor` is set up to capture execution traces. A `Weather` data model is created to represent weather information. The `get_weather` function is decorated as a tool the agent can use and returns a sample weather report. An agent named `Hello world` is configured with basic instructions and access to the weather tool. The main function asynchronously runs the agent with a sample input (`What's the weather in Tokyo?`) and outputs the final response.

```python
from pydantic import BaseModel
from agents import Agent, Runner, function_tool, set_trace_processors
import agents
import weave
from weave.integrations.openai_agents.openai_agents import WeaveTracingProcessor
import asyncio

weave.init("openai-agents")
set_trace_processors([WeaveTracingProcessor()])

class Weather(BaseModel):
    city: str
    temperature_range: str
    conditions: str

@function_tool
def get_weather(city: str) -> Weather:
    return Weather(city=city, temperature_range="14-20C", conditions="Sunny with wind.")

agent = Agent(
    name="Hello world",
    instructions="You are a helpful agent.",
    tools=[get_weather]
)

async def main():
    result = await Runner.run(agent, input="What's the weather in Tokyo?")    
    print(result.final_output)

if __name__ == "__main__":
    asyncio.run(main())
```

## View traces

When the above code sample is run, a link to the Weave dashboard is generated. To see what happened during your agent execution, follow the link to see your agent traces.

[Source](https://weave-docs.wandb.ai/guides/integrations/openai_agents)

<!--- Docs: Integrations -->
<!--- Nvidia Nim -->

# Nvidia Nim

# NVIDIA NIM

Weave automatically tracks and logs LLM calls made via the [ChatNVIDIA](https://python.langchain.com/docs/integrations/chat/nvidia_ai_endpoints/) library, after `weave.init()` is called.

> 🌟 **Tip**: For the latest tutorials, visit [Weights & Biases on NVIDIA](https://wandb.ai/site/partners/nvidia).

## Tracing

It’s important to store traces of LLM applications in a central database, both during development and in production. You’ll use these traces for debugging and to help build a dataset of tricky examples to evaluate against while improving your application.


  
    Weave can automatically capture traces for the [ChatNVIDIA python library](https://python.langchain.com/docs/integrations/chat/nvidia_ai_endpoints/).

    Start capturing by calling `weave.init()` with a project name your choice.

    ```python
    from langchain_nvidia_ai_endpoints import ChatNVIDIA
    import weave
    client = ChatNVIDIA(model="mistralai/mixtral-8x7b-instruct-v0.1", temperature=0.8, max_tokens=64, top_p=1)
    weave.init('emoji-bot')

    messages=[
        {
          "role": "system",
          "content": "You are AGI. You will be provided with a message, and your task is to respond using emojis only."
        }]

    response = client.invoke(messages)
    ```

  
  
      ```plaintext
      This feature is not available in TypeScript yet since this library is only in Python.
      ```
  




## Track your own ops


  
Wrapping a function with `@weave.op` starts capturing inputs, outputs and app logic so you can debug how data flows through your app. You can deeply nest ops and build a tree of functions that you want to track. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git.

Simply create a function decorated with [`@weave.op`](/guides/tracking/ops) that calls into [ChatNVIDIA python library](https://python.langchain.com/docs/integrations/chat/nvidia_ai_endpoints/).

In the example below, we have 2 functions wrapped with op. This helps us see how intermediate steps, like the retrieval step in a RAG app, are affecting how our app behaves.

    ```python
    import weave
    from langchain_nvidia_ai_endpoints import ChatNVIDIA
    import requests, random
    PROMPT="""Emulate the Pokedex from early Pokémon episodes. State the name of the Pokemon and then describe it.
            Your tone is informative yet sassy, blending factual details with a touch of dry humor. Be concise, no more than 3 sentences. """
    POKEMON = ['pikachu', 'charmander', 'squirtle', 'bulbasaur', 'jigglypuff', 'meowth', 'eevee']
    client = ChatNVIDIA(model="mistralai/mixtral-8x7b-instruct-v0.1", temperature=0.7, max_tokens=100, top_p=1)
    @weave.op
    def get_pokemon_data(pokemon_name):
        # This is a step within your application, like the retrieval step within a RAG app
        url = f"https://pokeapi.co/api/v2/pokemon/{pokemon_name}"
        response = requests.get(url)
        if response.status_code == 200:
            data = response.json()
            name = data["name"]
            types = [t["type"]["name"] for t in data["types"]]
            species_url = data["species"]["url"]
            species_response = requests.get(species_url)
            evolved_from = "Unknown"
            if species_response.status_code == 200:
                species_data = species_response.json()
                if species_data["evolves_from_species"]:
                    evolved_from = species_data["evolves_from_species"]["name"]
            return {"name": name, "types": types, "evolved_from": evolved_from}
        else:
            return None
    @weave.op
    def pokedex(name: str, prompt: str) -> str:
        # This is your root op that calls out to other ops
        data = get_pokemon_data(name)
        if not data: return "Error: Unable to fetch data"

        messages=[
                {"role": "system","content": prompt},
                {"role": "user", "content": str(data)}
            ]

        response = client.invoke(messages)
        return response.content
    weave.init('pokedex-nvidia')
    # Get data for a specific Pokémon
    pokemon_data = pokedex(random.choice(POKEMON), PROMPT)
    ```

Navigate to Weave and you can click `get_pokemon_data` in the UI to see the inputs & outputs of that step.


    ```plaintext
    This feature is not available in TypeScript yet since this library is only in Python.
    ```





## Create a `Model` for easier experimentation


  
    Organizing experimentation is difficult when there are many moving pieces. By using the [`Model`](/guides/core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app.

    In addition to versioning code and capturing inputs/outputs, [`Model`](/guides/core-types/models)s capture structured parameters that control your application’s behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and [`Evaluation`](/guides/core-types/evaluations)s.

    In the example below, you can experiment with `model` and `system_message`. Every time you change one of these, you'll get a new _version_ of `GrammarCorrectorModel`.

    ```python
    import weave
    from langchain_nvidia_ai_endpoints import ChatNVIDIA

    weave.init('grammar-nvidia')

    class GrammarCorrectorModel(weave.Model): # Change to `weave.Model`
      system_message: str

      @weave.op()
      def predict(self, user_input): # Change to `predict`
        client = ChatNVIDIA(model="mistralai/mixtral-8x7b-instruct-v0.1", temperature=0, max_tokens=100, top_p=1)

        messages=[
              {
                  "role": "system",
                  "content": self.system_message
              },
              {
                  "role": "user",
                  "content": user_input
              }
              ]

        response = client.invoke(messages)
        return response.content


    corrector = GrammarCorrectorModel(
        system_message = "You are a grammar checker, correct the following user input.")
    result = corrector.predict("That was so easy, it was a piece of pie!")
    print(result)
    ```
  
  
    ```plaintext
    This feature is not available in TypeScript yet since this library is only in Python.
    ```
  




## Usage Info

The ChatNVIDIA integration supports `invoke`, `stream` and their async variants. It also supports tool use. 
As ChatNVIDIA is meant to be used with many types of models, it does not have function calling support.

[Source](https://weave-docs.wandb.ai/guides/integrations/nvidia_nim)

<!--- Docs: Integrations -->
<!--- Langchain -->

# Langchain

# LangChain


  


Weave is designed to make tracking and logging all calls made through the [LangChain Python library](https://github.com/langchain-ai/langchain) effortless.

When working with LLMs, debugging is inevitable. Whether a model call fails, an output is misformatted, or nested model calls create confusion, pinpointing issues can be challenging. LangChain applications often consist of multiple steps and LLM call invocations, making it crucial to understand the inner workings of your chains and agents.

Weave simplifies this process by automatically capturing traces for your [LangChain](https://python.langchain.com/v0.2/docs/introduction/) applications. This enables you to monitor and analyze your application's performance, making it easier to debug and optimize your LLM workflows.


## Getting Started

To get started, simply call `weave.init()` at the beginning of your script. The argument in weave.init() is a project name that will help you organize your traces.

```python
import weave
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# Initialize Weave with your project name
weave.init("langchain_demo")

llm = ChatOpenAI()
prompt = PromptTemplate.from_template("1 + {number} = ")

llm_chain = prompt | llm

output = llm_chain.invoke({"number": 2})

print(output)
```

## Tracking Call Metadata

To track metadata from your LangChain calls, you can use the [`weave.attributes`](https://weave-docs.wandb.ai/reference/python-sdk/weave/#function-attributes) context manager. This context manager allows you to set custom metadata for a specific block of code, such as a chain or a single request.

```python
import weave
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# Initialize Weave with your project name
weave.init("langchain_demo")

llm = ChatOpenAI()
prompt = PromptTemplate.from_template("1 + {number} = ")

llm_chain = prompt | llm
with weave.attributes({"my_awesome_attribute": "value"}):
    output = llm_chain.invoke()

print(output)
```
Weave automatically tracks the metadat against the trace of the LangChain call. You can view the metadata in the Weave web interface as shown below:

[](https://wandb.ai/parambharat/langchain_demo/weave/traces?cols=%7B%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D)

## Traces

Storing traces of LLM applications in a central database is crucial during both development and production. These traces are essential for debugging and improving your application by providing a valuable dataset.

Weave automatically captures traces for your LangChain applications. It will track and log all calls made through the LangChain library, including prompt templates, chains, LLM calls, tools, and agent steps. You can view the traces in the Weave web interface.

[](https://wandb.ai/parambharat/langchain_demo/weave/calls)

## Manually Tracing Calls

In addition to automatic tracing, you can manually trace calls using the `WeaveTracer` callback or the `weave_tracing_enabled` context manager. These methods are akin to using request callbacks in individual parts of a LangChain application.

**Note:** Weave traces Langchain Runnables by default and this is enabled when you call `weave.init()`. You can disable this behaviour by setting the environment variable `WEAVE_TRACE_LANGCHAIN` to `"false"` before calling `weave.init()`. This allows you to control the tracing behaviour of specific chains or even individual requests in your application.

### Using `WeaveTracer`

You can pass the `WeaveTracer` callback to individual LangChain components to trace specific requests.

```python
import os

os.environ["WEAVE_TRACE_LANGCHAIN"] = "false" # <- explicitly disable global tracing.

from weave.integrations.langchain import WeaveTracer
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
import weave

# Initialize Weave with your project name
weave.init("langchain_demo")  # <-- we don't enable tracing here because the env var is explicitly set to `false`
weave_tracer = WeaveTracer()
config = {"callbacks": [weave_tracer]}

llm = ChatOpenAI()
prompt = PromptTemplate.from_template("1 + {number} = ")

llm_chain = prompt | llm
output = llm_chain.invoke({"number": 2}, config=config) # <-- this enables tracing only for this chain invoke.

llm_chain.invoke({"number": 4})  # <-- this will not have tracing enabled for langchain calls but openai calls will still be traced
```

### Using `weave_tracing_enabled` Context Manager

Alternatively, you can use the `weave_tracing_enabled` context manager to enable tracing for specific blocks of code.

```python
import os

os.environ["WEAVE_TRACE_LANGCHAIN"] = "false" # <- explicitly disable global tracing.

from weave.integrations.langchain import weave_tracing_enabled
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
import weave

# Initialize Weave with your project name
weave.init("langchain_demo")  # <-- we don't enable tracing here because the env var is explicitly set to `false`

llm = ChatOpenAI()
prompt = PromptTemplate.from_template("1 + {number} = ")

llm_chain = prompt | llm
with weave_tracing_enabled():  # <-- this enables tracing only for this chain invoke.
    output = llm_chain.invoke({"number": 2})


llm_chain.invoke({"number": 4})  # <-- this will not have tracing enabled for langchain calls but openai calls will still be traced
```

## Configuration

Upon calling `weave.init`, tracing is enabled by setting the environment variable `WEAVE_TRACE_LANGCHAIN` to `"true"`. This allows Weave to automatically capture traces for your LangChain applications. If you wish to disable this behavior, set the environment variable to `"false"`.

## Relation to LangChain Callbacks

### Auto Logging

The automatic logging provided by `weave.init()` is similar to passing a constructor callback to every component in a LangChain application. This means that all interactions, including prompt templates, chains, LLM calls, tools, and agent steps, are tracked globally across your entire application.

### Manual Logging

The manual logging methods (`WeaveTracer` and `weave_tracing_enabled`) are similar to using request callbacks in individual parts of a LangChain application. These methods provide finer control over which parts of your application are traced:

- **Constructor Callbacks:** Applied to the entire chain or component, logging all interactions consistently.
- **Request Callbacks:** Applied to specific requests, allowing detailed tracing of particular invocations.

By integrating Weave with LangChain, you can ensure comprehensive logging and monitoring of your LLM applications, facilitating easier debugging and performance optimization.

For more detailed information, refer to the [LangChain documentation](https://python.langchain.com/v0.2/docs/how_to/debugging/#tracing).

## Models and Evaluations

Organizing and evaluating LLMs in applications for various use cases is challenging with multiple components, such as prompts, model configurations, and inference parameters. Using the [`weave.Model`](/guides/core-types/models), you can capture and organize experimental details like system prompts or the models you use, making it easier to compare different iterations.

The following example demonstrates wrapping a Langchain chain in a `WeaveModel`:

```python
import json
import asyncio

import weave

from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# Initialize Weave with your project name
weave.init("langchain_demo")
class ExtractFruitsModel(weave.Model):
    model_name: str
    prompt_template: str
    @weave.op()
    async def predict(self, sentence: str) -> dict:
        llm = ChatOpenAI(model=self.model_name, temperature=0.0)
        prompt = PromptTemplate.from_template(self.prompt_template)

        llm_chain = prompt | llm
        response = llm_chain.invoke({"sentence": sentence})
        result = response.content

        if result is None:
            raise ValueError("No response from model")
        parsed = json.loads(result)
        return parsed

model = ExtractFruitsModel(
    model_name="gpt-3.5-turbo-1106",
    prompt_template='Extract fields ("fruit": , "color": , "flavor": ) from the following text, as json: {sentence}',
)
sentence = "There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy."

prediction = asyncio.run(model.predict(sentence))

# if you're in a Jupyter Notebook, run:
# prediction = await model.predict(sentence)

print(prediction)
```
This code creates a model that can be visualized in the Weave UI:

[](https://wandb.ai/parambharat/langchain_demo/weave/object-versions?filter=%7B%22baseObjectClass%22%3A%22Model%22%7D&peekPath=%2Fparambharat%2Flangchain_demo%2Fobjects%2FExtractFruitsModel%2Fversions%2FBeoL6WuCH8wgjy6HfmuBMyKzArETg1oAFpYaXZSq1hw%3F%26)


You can also use Weave Models with `serve`, and [`Evaluations`](/guides/core-types/evaluations).

### Evaluations
Evaluations help you measure the performance of your models. By using the [`weave.Evaluation`](/guides/core-types/evaluations) class, you can capture how well your model performs on specific tasks or datasets, making it easier to compare different models and iterations of your application. The following example demonstrates how to evaluate the model we created:


```python

from weave.scorers import MultiTaskBinaryClassificationF1

sentences = [
    "There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.",
    "Pounits are a bright green color and are more savory than sweet.",
    "Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.",
]
labels = [
    {"fruit": "neoskizzles", "color": "purple", "flavor": "candy"},
    {"fruit": "pounits", "color": "bright green", "flavor": "savory"},
    {"fruit": "glowls", "color": "pale orange", "flavor": "sour and bitter"},
]
examples = [
    {"id": "0", "sentence": sentences[0], "target": labels[0]},
    {"id": "1", "sentence": sentences[1], "target": labels[1]},
    {"id": "2", "sentence": sentences[2], "target": labels[2]},
]

@weave.op()
def fruit_name_score(target: dict, output: dict) -> dict:
    return {"correct": target["fruit"] == output["fruit"]}


evaluation = weave.Evaluation(
    dataset=examples,
    scorers=[
        MultiTaskBinaryClassificationF1(class_names=["fruit", "color", "flavor"]),
        fruit_name_score,
    ],
)
scores = asyncio.run(evaluation.evaluate(model)))
# if you're in a Jupyter Notebook, run:
# scores = await evaluation.evaluate(model)

print(scores)
```

This code generates an evaluation trace that can be visualized in the Weave UI:

[](https://wandb.ai/parambharat/langchain_demo/weave/calls?filter=%7B%22traceRootsOnly%22%3Atrue%7D&peekPath=%2Fparambharat%2Flangchain_demo%2Fcalls%2F44c3f26c-d9d3-423e-b434-651ea5174be3)

By integrating Weave with Langchain, you can ensure comprehensive logging and monitoring of your LLM applications, facilitating easier debugging and performance optimization.


## Known Issues

- **Tracing Async Calls** - A bug in the implementation of the `AsyncCallbackManager` in Langchain results in async calls not being traced in the correct order. We have filed a [PR](https://github.com/langchain-ai/langchain/pull/23909) to fix this. Therefore, the order of calls in the trace may not be accurate when using `ainvoke`, `astream` and `abatch` methods in Langchain Runnables.

[Source](https://weave-docs.wandb.ai/guides/integrations/langchain)

<!--- Docs: Integrations -->
<!--- Pydantic Ai -->

# Pydantic Ai

# PydanticAI

You can trace [PydanticAI](https://ai.pydantic.dev/) agent and tool calls in Weave using [OpenTelemetry (OTEL)](https://opentelemetry.io/). PydanticAI is a Python agent framework built by the Pydantic team to make it easy and type-safe to build production-grade applications with Generative AI. It uses OTEL for tracing all agent and tool calls.

> 🌟 **Tip**: For more information on OTEL tracing in Weave, see [Send OTEL Traces to Weave](../tracking/otel.md).

This guide shows you how to trace PydanticAI agent and tool calls using OTEL and visualize those traces in Weave. You’ll learn how to install the required dependencies, configure an OTEL tracer to send data to Weave, and instrument your PydanticAI agents and tools. You’ll also see how to enable tracing by default across all agents in your application.

## Prerequisites

Before you begin, install the required OTEL dependencies:

```bash
pip install opentelemetry-sdk OTELemetry-exporter-otlp-proto-http
```
Then, [configure OTEL tracing in Weave](#configure-otel-tracing-in-weave).

### Configure OTEL tracing in Weave

To send traces from PydanticAI to Weave, configure OTEL with a `TracerProvider` and an `OTLPSpanExporter`. Set the exporter to the [correct endpoint and HTTP headers for authentication and project identification](#required-configuration).

> 🚨 **Important**: It is recommended that you store sensitive environment variables like your API key and project info in an environment file (e.g., `.env`), and load them using `os.environ`. This keeps your credentials secure and out of your codebase.

### Required configuration

- **Endpoint:** `https://trace.wandb.ai/otel/v1/traces`
- **Headers:**
  - `Authorization`: Basic auth using your W&B API key
  - `project_id`: Your W&B entity/project name (e.g., `myteam/myproject`)

### Example set up

The following code snippet demonstrates how to configure an OTLP span exporter and tracer provider to send OTEL traces from a PydanticAI application to Weave. 

```python
import base64
import os
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk import trace as trace_sdk
from opentelemetry.sdk.trace.export import SimpleSpanProcessor

# Load sensitive values from environment variables
WANDB_BASE_URL = "https://trace.wandb.ai"
PROJECT_ID = os.environ.get("WANDB_PROJECT_ID")  # Your W&B entity/project name e.g. "myteam/myproject"
WANDB_API_KEY = os.environ.get("WANDB_API_KEY")  # Your W&B API key

OTEL_EXPORTER_OTLP_ENDPOINT = f"{WANDB_BASE_URL}/otel/v1/traces"
AUTH = base64.b64encode(f"api:{WANDB_API_KEY}".encode()).decode()

OTEL_EXPORTER_OTLP_HEADERS = {
    "Authorization": f"Basic {AUTH}",
    "project_id": PROJECT_ID,
}

# Create the OTLP span exporter with endpoint and headers
exporter = OTLPSpanExporter(
    endpoint=OTEL_EXPORTER_OTLP_ENDPOINT,
    headers=OTEL_EXPORTER_OTLP_HEADERS,
)

# Create a tracer provider and add the exporter
tracer_provider = trace_sdk.TracerProvider()
tracer_provider.add_span_processor(SimpleSpanProcessor(exporter))
```

## Trace PydanticAI Agents with OTEL

To trace your PydanticAI agents and send trace data to Weave, pass an `InstrumentationSettings` object configured with your tracer provider to the `Agent constructor`. This ensures that all agent and tool calls are traced according to your OTEL configuration.

The following example shows how to create a simple agent with tracing enabled. The key step is setting the instrument argument when initializing the agent:

```python
from pydantic_ai import Agent
from pydantic_ai.models.instrumented import InstrumentationSettings

# Create a PydanticAI agent with OTEL tracing
agent = Agent(
    "openai:gpt-4o",
    instrument=InstrumentationSettings(tracer_provider=tracer_provider),
)

result = agent.run_sync("What is the capital of France?")
print(result.output)
```

All calls to the agent are traced and sent to Weave.

 

## Trace PydanticAI Tools with OTEL

Weave can trace any PydanticAI operations that are instrumented with OTEL, including both agent and tool calls. This means that when your agent invokes a tool (e.g. a function decorated with `@agent.tool_plain`), the entire interaction is captured and visualized in Weave, including tool inputs, outputs, and the model's reasoning.

The following example shows how to create an agent with a system prompt and a tool. Tracing is enabled automatically for both the agent and the tool:

```python
from pydantic_ai import Agent
from pydantic_ai.models.instrumented import InstrumentationSettings

# Create a PydanticAI agent with a system prompt and OTEL tracing
agent = Agent(
    "openai:gpt-4o",
    system_prompt=(
        "You are a helpful assistant that can multiply numbers. "
        "When asked to multiply numbers, use the multiply tool."
    ),
    instrument=InstrumentationSettings(tracer_provider=tracer_provider),
)

# Define a tool
@agent.tool_plain
def multiply(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b

# Ask the agent to use the tool
result = agent.run_sync("What is 7 multiplied by 8?")
print(result.output)
```

 

Both the agent call and the tool call are traced in Weave, allowing you to inspect the full reasoning and execution path of your application.

## Instrument all agents by default

To apply OTEL tracing to all PydanticAI agents in your application, use the `Agent.instrument_all()` method. This sets a default `InstrumentationSettings` instance for any agent that doesn’t explicitly specify the `instrument` parameter.

```python
from pydantic_ai import Agent
from pydantic_ai.models.instrumented import InstrumentationSettings

# Set up default instrumentation for all agents
Agent.instrument_all(InstrumentationSettings(tracer_provider=tracer_provider))

# Now, any new agent will use this instrumentation by default
agent1 = Agent("openai:gpt-4o")
agent2 = Agent("openai:gpt-4o", system_prompt="Be helpful.")

result = agent1.run_sync("What is the capital of France?")
print(result.output)
```

This is useful for larger applications where you want consistent tracing across all agents without repeating configuration. For more details, see the [PydanticAI OTEL docs](https://ai.pydantic.dev/logfire/#using-logfire).

## Learn more

- [Weave documentation: Send OTEL traces to Weave](../tracking/otel.md)
- [Official OTEL documentation](https://opentelemetry.io/)
- [Official PydanticAI documentation](https://ai.pydantic.dev/)
- [PydanticAI GitHub repository](https://github.com/pydantic/pydantic-ai)

[Source](https://weave-docs.wandb.ai/guides/integrations/pydantic_ai)

<!--- Docs: Integrations -->
<!--- Cohere -->

# Cohere

# Cohere


  


Weave automatically tracks and logs LLM calls made via the [Cohere Python library](https://github.com/cohere-ai/cohere-python) after `weave.init()` is called.

## Traces

It's important to store traces of LLM applications in a central database, both during development and in production. You'll use these traces for debugging, and as a dataset that will help you improve your application.

Weave will automatically capture traces for [cohere-python](https://github.com/cohere-ai/cohere-python). You can use the library as usual, start by calling `weave.init()`:

```python
import cohere
import os
import weave

# Use the Cohere library as usual
co = cohere.Client(api_key=os.environ["COHERE_API_KEY"])
weave.init("cohere_project")

response = co.chat(
    message="How is the weather in Boston?",
    # perform web search before answering the question. You can also use your own custom connector.
    connectors=[{"id": "web-search"}],
)
print(response.text)
```
A powerful feature of cohere models is using [connectors](https://docs.cohere.com/docs/overview-rag-connectors#using-connectors-to-create-grounded-generations) enabling you to make requests to other API on the endpoint side. The response will then contain the generated text with citation elements that link to the documents returned from the connector. 

[](https://wandb.ai/capecape/cohere_dev/weave/calls)

> 💡 **Note**: We patch the Cohere `Client.chat`, `AsyncClient.chat`, `Client.chat_stream`, and `AsyncClient.chat_stream` methods for you to keep track of your LLM calls.

## Wrapping with your own ops

Weave ops make results *reproducible* by automatically versioning code as you experiment, and they capture their inputs and outputs. Simply create a function decorated with [`@weave.op()`](/guides/tracking/ops) that calls into Cohere's chat methods, and Weave will track the inputs and outputs for you. Here's an example:

```python
import cohere
import os
import weave

co = cohere.Client(api_key=os.environ["COHERE_API_KEY"])

weave.init("cohere_project")
@weave.op()
def weather(location: str, model: str) -> str:
    response = co.chat(
        model=model,
        message=f"How is the weather in {location}?",
        # perform web search before answering the question. You can also use your own custom connector.
        connectors=[{"id": "web-search"}],
    )
    return response.text

print(weather("Boston", "command"))
```

[](https://wandb.ai/capecape/cohere_dev/weave/calls)

## Create a `Model` for easier experimentation

Organizing experimentation is difficult when there are many moving pieces. By using the [`Model`](/guides/core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app.

In addition to versioning code and capturing inputs/outputs, [`Model`](/guides/core-types/models)s capture structured parameters that control your application's behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and [`Evaluation`](/guides/core-types/evaluations)s.

In the example below, you can experiment with `model` and `temperature`. Every time you change one of these, you'll get a new _version_ of `WeatherModel`.

```python
import weave
import cohere
import os

weave.init('weather-cohere')

class WeatherModel(weave.Model):
    model: str
    temperature: float
  
    @weave.op()
    def predict(self, location: str) -> str:
        co = cohere.Client(api_key=os.environ["COHERE_API_KEY"])
        response = co.chat(
            message=f"How is the weather in {location}?",
            model=self.model,
            temperature=self.temperature,
            connectors=[{"id": "web-search"}]
        )
        return response.text

weather_model = WeatherModel(
    model="command",
    temperature=0.7
)
result = weather_model.predict("Boston")
print(result)
```

[](https://wandb.ai/capecape/cohere_dev/weave/models)

[Source](https://weave-docs.wandb.ai/guides/integrations/cohere)

<!--- Docs: Integrations -->
<!--- Mistral -->

# Mistral

# MistralAI


  


Weave automatically tracks and logs LLM calls made via the [MistralAI Python library](https://github.com/mistralai/client-python). 

> We support the new Mistral v1.0 SDK, check the migration guide [here](https://github.com/mistralai/client-python/blob/main/MIGRATION.md)

## Traces

It’s important to store traces of LLM applications in a central database, both during development and in production. You’ll use these traces for debugging, and as a dataset that will help you improve your application.

Weave will automatically capture traces for [mistralai](https://github.com/mistralai/client-python). You can use the library as usual, start by calling `weave.init()`:

```python
import weave
weave.init("cheese_recommender")

# then use mistralai library as usual
import os
from mistralai import Mistral

api_key = os.environ["MISTRAL_API_KEY"]
model = "mistral-large-latest"

client = Mistral(api_key=api_key)

messages = [
    {
        "role": "user",
        "content": "What is the best French cheese?",
    },
]

chat_response = client.chat.complete(
    model=model,
    messages=messages,
)
```

Weave will now track and log all LLM calls made through the MistralAI library. You can view the traces in the Weave web interface.

[](https://wandb.ai/capecape/mistralai_project/weave/calls)

## Wrapping with your own ops

Weave ops make results *reproducible* by automatically versioning code as you experiment, and they capture their inputs and outputs. Simply create a function decorated with [`@weave.op()`](/guides/tracking/ops) that calls into [`mistralai.client.MistralClient.chat()`](https://docs.mistral.ai/capabilities/completion/) and Weave will track the inputs and outputs for you. Let's see how we can do this for our cheese recommender:

```python
@weave.op()
def cheese_recommender(region:str, model:str) -> str:
    "Recommend the best cheese in a given region"
    
    messages = [
        {
            "role": "user",
            "content": f"What is the best cheese in {region}?",
        },
    ]

    chat_response = client.chat.complete(
        model=model,
        messages=messages,
    )
    return chat_response.choices[0].message.content

cheese_recommender(region="France", model="mistral-large-latest")
cheese_recommender(region="Spain", model="mistral-large-latest")
cheese_recommender(region="Netherlands", model="mistral-large-latest")
```

[](https://wandb.ai/capecape/mistralai_project/weave/calls)

## Create a `Model` for easier experimentation

Organizing experimentation is difficult when there are many moving pieces. By using the [`Model`](/guides/core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app. 

In addition to versioning code and capturing inputs/outputs, [`Model`](/guides/core-types/models)s capture structured parameters that control your application’s behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and [`Evaluation`](/guides/core-types/evaluations)s.

In the example below, you can experiment with `model` and `country`. Every time you change one of these, you'll get a new _version_ of `CheeseRecommender`. 

```python
import weave
from mistralai import Mistral

weave.init("mistralai_project")

class CheeseRecommender(weave.Model): # Change to `weave.Model`
    model: str
    temperature: float

    @weave.op()
    def predict(self, region:str) -> str: # Change to `predict`
        "Recommend the best cheese in a given region"
        
        client = Mistral(api_key=api_key)

        messages = [
            {
                "role": "user",
                "content": f"What is the best cheese in {region}?",
            },
        ]

        chat_response = client.chat.complete(
            model=model,
            messages=messages,
            temperature=self.temperature
        )
        return chat_response.choices[0].message.content

cheese_model = CheeseRecommender(
    model="mistral-medium-latest",
    temperature=0.0
    )
result = cheese_model.predict(region="France")
print(result)
```

[](https://wandb.ai/capecape/mistralai_project/weave/models)

[Source](https://weave-docs.wandb.ai/guides/integrations/mistral)

<!--- Docs: Integrations -->
<!--- Index -->

# Index

# Integrations

:::success[Automatic Tracking]
In most cases, all you need to do is call `weave.init()` at the top of your script or program in order for Weave to automatically patch and track any of these libraries!
:::

Weave provides automatic logging integrations for popular LLM providers and orchestration frameworks. These integrations allow you to seamlessly trace calls made through various libraries, enhancing your ability to monitor and analyze your AI applications.

## LLM Providers

LLM providers are the vendors that offer access to large language models for generating predictions. Weave integrates with these providers to log and trace the interactions with their APIs:

- **[Amazon Bedrock](/guides/integrations/bedrock)**
- **[Anthropic](/guides/integrations/anthropic)**
- **[Cerebras](/guides/integrations/cerebras)**
- **[Cohere](/guides/integrations/cohere)**
- **[Google](/guides/integrations/google)**
- **[Groq](/guides/integrations/groq)**
- **[Hugging Face Hub](/guides/integrations/huggingface)**
- **[LiteLLM](/guides/integrations/litellm)**
- **[Microsoft Azure](/guides/integrations/azure)**
- **[MistralAI](/guides/integrations/mistral)**
- **[NVIDIA NIM](/guides/integrations/nvidia_nim)**
- **[OpenAI](/guides/integrations/openai)**
- **[Open Router](/guides/integrations/openrouter)**
- **[Together AI](/guides/integrations/together_ai)**

**[Local Models](/guides/integrations/local_models)**: For when you're running models on your own infrastructure.

## Frameworks

Frameworks help orchestrate the actual execution pipelines in AI applications. They provide tools and abstractions for building complex workflows. Weave integrates with these frameworks to trace the entire pipeline:

- **[OpenAI Agents SDK](/guides/integrations/openai_agents)**
- **[LangChain](/guides/integrations/langchain)**
- **[LlamaIndex](/guides/integrations/llamaindex)**
- **[DSPy](/guides/integrations/dspy)**
- **[Instructor](/guides/integrations/instructor)**
- **[CrewAI](/guides/integrations/crewai)**
- **[Smolagents](/guides/integrations/smolagents)**
- **[PydanticAI](/guides/integrations/pydantic_ai)**

## Protocols

Weave integrates with standardized protocols that enable communication between AI applications and their supporting services:

- **[Model Context Protocol (MCP)](/guides/integrations/mcp)**

Choose an integration from the lists above to learn more about how to use Weave with your preferred LLM provider, framework, or protocol. Whether you're directly accessing LLM APIs, building complex pipelines, or using standardized protocols, Weave provides the tools to trace and analyze your AI applications effectively.

[Source](https://weave-docs.wandb.ai/guides/integrations/index)

<!--- Docs: Integrations -->
<!--- Cerebras -->

# Cerebras

# Cerebras

Weave automatically tracks and logs LLM calls made via the [Cerebras Cloud SDK](https://inference-docs.cerebras.ai/introduction).

## Traces

Tracking LLM calls is crucial for debugging and performance monitoring. Weave helps you do this by automatically capturing traces for the Cerebras Cloud SDK.

Here's an example of how to use Weave with Cerebras:

```python
import os
import weave
from cerebras.cloud.sdk import Cerebras

# Initialise the weave project
weave.init("cerebras_speedster")

# Use the Cerebras SDK as usual
api_key = os.environ["CEREBRAS_API_KEY"]
model = "llama3.1-8b"  # Cerebras model

client = Cerebras(api_key=api_key)

response = client.chat.completions.create(
    model=model,
    messages=[{"role": "user", "content": "What's the fastest land animal?"}],
)

print(response.choices[0].message.content)
```

Weave will now track and log all LLM calls made through the Cerebras SDK. You can view the traces in the Weave web interface, including details like token usage and response time.

[](https://wandb.ai/capecape/cerebras_speedster/weave/traces)

## Wrapping with your own ops

Weave ops offer a powerful way to enhance reproducibility and traceability in your experiments. By automatically versioning your code and capturing inputs and outputs. Here's an example of how you can leverage Weave ops with the Cerebras SDK:

```python
import os
import weave
from cerebras.cloud.sdk import Cerebras

# Initialise the weave project
weave.init("cerebras_speedster")

client = Cerebras(api_key=os.environ["CEREBRAS_API_KEY"])

# Weave will track the inputs, outputs and code of this function
@weave.op
def animal_speedster(animal: str, model: str) -> str:
    "Find out how fast an animal can run"
    
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": f"How fast can a {animal} run?"}],
    )
    return response.choices[0].message.content

animal_speedster("cheetah", "llama3.1-8b")
animal_speedster("ostrich", "llama3.1-8b")
animal_speedster("human", "llama3.1-8b")
```

## Create a `Model` for easier experimentation

The [Model](/guides/core-types/models) class in Weave helps you organize and compare different iterations of your app. This is particularly useful when experimenting with Cerebras models. Here's an example:


```python
import os
import weave
from cerebras.cloud.sdk import Cerebras

# Initialise the weave project
weave.init("cerebras_speedster")

client = Cerebras(api_key=os.environ["CEREBRAS_API_KEY"])

class AnimalSpeedModel(weave.Model):
    model: str
    temperature: float

    @weave.op
    def predict(self, animal: str) -> str:
        "Predict the top speed of an animal"        

        response = client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": f"What's the top speed of a {animal}?"}],
            temperature=self.temperature
        )
        return response.choices[0].message.content

speed_model = AnimalSpeedModel(
    model="llama3.1-8b",
    temperature=0.7
)
result = speed_model.predict(animal="cheetah")
print(result)
```

With this setup, you can easily experiment with different models and parameters, all while keeping track of your Cerebras-powered inferences!

[](https://wandb.ai/capecape/cerebras_speedster/weave/traces)

[Source](https://weave-docs.wandb.ai/guides/integrations/cerebras)

<!--- Docs: Integrations -->
<!--- Instructor -->

# Instructor

# Instructor


  


[Instructor](https://python.useinstructor.com/) is a lightweight library that makes it easy to get structured data like JSON from LLMs.

## Tracing

It’s important to store traces of language model applications in a central location, both during development and in production. These traces can be useful for debugging, and as a dataset that will help you improve your application.

Weave will automatically capture traces for [Instructor](https://python.useinstructor.com/). To start tracking, calling `weave.init(project_name="")` and use the library as normal.

```python
import instructor
import weave
from pydantic import BaseModel
from openai import OpenAI


# Define your desired output structure
class UserInfo(BaseModel):
    user_name: str
    age: int

# Initialize Weave
weave.init(project_name="instructor-test")

# Patch the OpenAI client
client = instructor.from_openai(OpenAI())

# Extract structured data from natural language
user_info = client.chat.completions.create(
    model="gpt-3.5-turbo",
    response_model=UserInfo,
    messages=[{"role": "user", "content": "John Doe is 30 years old."}],
)
```

|                                                                         |
|-----------------------------------------------------------------------------------------------------------------------|
| Weave will now track and log all LLM calls made using Instructor. You can view the traces in the Weave web interface. |

## Track your own ops

Wrapping a function with `@weave.op` starts capturing inputs, outputs and app logic so you can debug how data flows through your app. You can deeply nest ops and build a tree of functions that you want to track. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git.

Simply create a function decorated with [`@weave.op`](/guides/tracking/ops).

In the example below, we have the function `extract_person` which is the metric function wrapped with `@weave.op`. This helps us see how intermediate steps, such as OpenAI chat completion call.

```python
import instructor
import weave
from openai import OpenAI
from pydantic import BaseModel


# Define your desired output structure
class Person(BaseModel):
    person_name: str
    age: int


# Initialize Weave
weave.init(project_name="instructor-test")

# Patch the OpenAI client
lm_client = instructor.from_openai(OpenAI())


# Extract structured data from natural language
@weave.op()
def extract_person(text: str) -> Person:
    return lm_client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": text},
        ],
        response_model=Person,
    )


person = extract_person("My name is John and I am 20 years old")
```

|  |
|---|
| Decorating the `extract_person` function with `@weave.op` traces its inputs, outputs, and all internal LM calls made inside the function. Weave also automatically tracks and versions the structured objects generated by Instructor. |

## Create a `Model` for easier experimentation

Organizing experimentation is difficult when there are many moving pieces. By using the [`Model`](../core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app. 

In addition to versioning code and capturing inputs/outputs, [`Model`](../core-types/models)s capture structured parameters that control your application’s behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve` (see below), and [`Evaluation`](../core-types/evaluations.md)s.

In the example below, you can experiment with `PersonExtractor`. Every time you change one of these, you'll get a new _version_ of `PersonExtractor`.

```python
import asyncio
from typing import List, Iterable

import instructor
import weave
from openai import AsyncOpenAI
from pydantic import BaseModel


# Define your desired output structure
class Person(BaseModel):
    person_name: str
    age: int


# Initialize Weave
weave.init(project_name="instructor-test")

# Patch the OpenAI client
lm_client = instructor.from_openai(AsyncOpenAI())


class PersonExtractor(weave.Model):
    openai_model: str
    max_retries: int

    @weave.op()
    async def predict(self, text: str) -> List[Person]:
        model = await lm_client.chat.completions.create(
            model=self.openai_model,
            response_model=Iterable[Person],
            max_retries=self.max_retries,
            stream=True,
            messages=[
                {
                    "role": "system",
                    "content": "You are a perfect entity extraction system",
                },
                {
                    "role": "user",
                    "content": f"Extract `{text}`",
                },
            ],
        )
        return [m async for m in model]


model = PersonExtractor(openai_model="gpt-4", max_retries=2)
asyncio.run(model.predict("John is 30 years old"))
```

|  |
|---------------------------------------------------------------------------|
| Tracing and versioning your calls using a [`Model`](../core-types/models) |

## Serving a Weave Model

Given a weave reference a `weave.Model` object, you can spin up a fastapi server and [`serve`](https://wandb.github.io/weave/guides/tools/serve) it.

| [](https://wandb.ai/geekyrakshit/instructor-test/weave/objects/PersonExtractor/versions/xXpMsJvaiTOjKafz1TnHC8wMgH5ZAAwYOaBMvHuLArI) |
|----------------------------------------------------------------------------------------------------------------------------------------------------------------|
| You can find the weave reference of any `weave.Model` by navigating to the model and copying it from the UI.                                                      |

You can serve your model by using the following command in the terminal:

```shell
weave serve weave:///your_entity/project-name/YourModel:
```

[Source](https://weave-docs.wandb.ai/guides/integrations/instructor)

<!--- Docs: Integrations -->
<!--- Google -->

# Google

# Google


  


> 🌟 **Tip**: For the latest tutorials, visit [Weights & Biases on Google Cloud](https://wandb.ai/site/partners/googlecloud/).

> 💡 **Note**: Do you want to experiment with Google AI models on Weave without any set up? Try the [LLM Playground](../tools/playground.md).

This page describes how to use W&B Weave with the Google Vertex AI API and the Google Gemini API.

You can use Weave to evaluate, monitor, and iterate on your Google GenAI applications. Weave automatically captures traces for the:

1. [Google GenAI SDK](https://github.com/googleapis/python-genai), which is accessible via Python SDK, Node.js SDK, Go SDK, and REST.
2. [Google Vertex AI API](https://cloud.google.com/vertex-ai/docs), which provides access to Google’s Gemini models and [various partner models](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/use-partner-models).

> 💡 **Note**: We also have support for the deprecated [Google AI Python SDK for the Gemini API](https://github.com/google-gemini/deprecated-generative-ai-python). Note that this support is deprecated as well and will be removed in a future version.

## Get started

Weave will automatically capture traces for [Google GenAI SDK](https://github.com/googleapis/python-genai). To start tracking, calling `weave.init(project_name="")` and use the library as normal.

```python
import os
from google import genai
import weave

weave.init(project_name="google-genai")

google_client = genai.Client(api_key=os.getenv("GOOGLE_GENAI_KEY"))
response = google_client.models.generate_content(
    model="gemini-2.0-flash",
    contents="What's the capital of France?",
)
```

[](https://wandb.ai/geekyrakshit/google-genai/weave/traces)

Weave will also automatically capture traces for [Vertex APIs](https://github.com/googleapis/python-aiplatform/tree/main/vertexai/generative_models). To start tracking, calling `weave.init(project_name="")` and use the library as normal.

```python
import vertexai
import weave
from vertexai.generative_models import GenerativeModel

weave.init(project_name="vertex-ai-test")
vertexai.init(project="", location="")
model = GenerativeModel("gemini-1.5-flash-002")
response = model.generate_content(
    "What's a good name for a flower shop specialising in selling dried flower bouquets?"
)
```

## Track your own ops

Wrapping a function with `@weave.op` starts capturing inputs, outputs and app logic so you can debug how data flows through your app. You can deeply nest ops and build a tree of functions that you want to track. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git.

Simply create a function decorated with [`@weave.op`](/guides/tracking/ops).

In the example below, we have the function `recommend_places_to_visit` which is a function wrapped with `@weave.op` that recommends places to visit in a city.

```python
import os
from google import genai
import weave

weave.init(project_name="google-genai")
google_client = genai.Client(api_key=os.getenv("GOOGLE_GENAI_KEY"))


@weave.op()
def recommend_places_to_visit(city: str, model: str = "gemini-1.5-flash"):
    response = google_client.models.generate_content(
        model=model,
        contents="You are a helpful assistant meant to suggest all budget-friendly places to visit in a city",
    )
    return response.text


recommend_places_to_visit("New York")
recommend_places_to_visit("Paris")
recommend_places_to_visit("Kolkata")
```

[](https://wandb.ai/geekyrakshit/google-genai/weave/traces)

## Create a `Model` for easier experimentation

Organizing experimentation is difficult when there are many moving pieces. By using the [`Model`](../core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app. 

In addition to versioning code and capturing inputs/outputs, [`Model`](../core-types/models)s capture structured parameters that control your application’s behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and [`Evaluation`](../core-types/evaluations.md)s.

In the example below, you can experiment with `CityVisitRecommender`. Every time you change one of these, you'll get a new _version_ of `CityVisitRecommender`.

```python
import os
from google import genai
import weave

weave.init(project_name="google-genai")
google_client = genai.Client(api_key=os.getenv("GOOGLE_GENAI_KEY"))


class CityVisitRecommender(weave.Model):
    model: str

    @weave.op()
    def predict(self, city: str) -> str:
        response = google_client.models.generate_content(
            model=self.model,
            contents="You are a helpful assistant meant to suggest all budget-friendly places to visit in a city",
        )
        return response.text


city_recommender = CityVisitRecommender(model="gemini-1.5-flash")
print(city_recommender.predict("New York"))
print(city_recommender.predict("San Francisco"))
print(city_recommender.predict("Los Angeles"))
```

[Source](https://weave-docs.wandb.ai/guides/integrations/google)

<!--- Docs: Integrations -->
<!--- Together Ai -->

# Together Ai

# Together AI

Together AI is a platform for building and finetuning generative AI models, focusing on Open Source LLMs, and allowing customers to fine-tune and host their own models.

:::info

Full Weave `together` python package support is currently in development

:::

While full Weave support for the `together` python package is currently in development, Together supports the OpenAI SDK compatibility ([docs](https://docs.together.ai/docs/openai-api-compatibility)) which Weave automatically detects and integrates with.

To switch to using the Together API, simply switch out the API key to your [Together API](https://docs.together.ai/docs/get-started#access-your-api-key) key, `base_url` to `https://api.together.xyz/v1`, and model to one of their [chat models](https://docs.together.ai/docs/inference-models#chat-models).

```python
import os
import openai
import weave
weave.init('together-weave')

system_content = "You are a travel agent. Be descriptive and helpful."
user_content = "Tell me about San Francisco"
client = openai.OpenAI(
    api_key=os.environ.get("TOGETHER_API_KEY"),
    base_url="https://api.together.xyz/v1",
)
chat_completion = client.chat.completions.create(
    model="mistralai/Mixtral-8x7B-Instruct-v0.1",
    messages=[
        {"role": "system", "content": system_content},
        {"role": "user", "content": user_content},
    ],
    temperature=0.7,
    max_tokens=1024,
)
response = chat_completion.choices[0].message.content
print("Together response:\n", response)
```

While this is a simple example to get started, see our [OpenAI](/guides/integrations/openai#track-your-own-ops) guide for more details on how to integrate Weave with your own functions for more complex use cases.

[Source](https://weave-docs.wandb.ai/guides/integrations/together_ai)

<!--- Docs: Integrations -->
<!--- Llamaindex -->

# Llamaindex

# LlamaIndex

Weave is designed to simplify the tracking and logging of all calls made through the [LlamaIndex Python library](https://github.com/run-llama/llama_index).

When working with LLMs, debugging is inevitable. Whether a model call fails, an output is misformatted, or nested model calls create confusion, pinpointing issues can be challenging. [LlamaIndex](https://docs.llamaindex.ai/en/stable/) applications often consist of multiple steps and LLM call invocations, making it crucial to understand the inner workings of your chains and agents.

Weave simplifies this process by automatically capturing traces for your LlamaIndex applications. This enables you to monitor and analyze your application's performance, making it easier to debug and optimize your LLM workflows. Weave also helps with your evaluation workflows.

## Getting Started

To get started, simply call `weave.init()` at the beginning of your script. The argument in `weave.init()` is a project name that will help you organize your traces.

```python
import weave
from llama_index.core.chat_engine import SimpleChatEngine

# Initialize Weave with your project name
weave.init("llamaindex_demo")

chat_engine = SimpleChatEngine.from_defaults()
response = chat_engine.chat(
    "Say something profound and romantic about fourth of July"
)
print(response)
```

In the example above, we are creating a simple LlamaIndex chat engine which under the hood is making an OpenAI call. Check out the trace below:

[](https://wandb.ai/wandbot/test-llamaindex-weave/weave/calls/b6b5d898-2df8-4e14-b553-66ce84661e74)

## Tracing

LlamaIndex is known for its ease of connecting data with LLM. A simple RAG application requires an embedding step, retrieval step and a response synthesis step. With the increasing complexity, it becomes important to store traces of individual steps in a central database during both development and production.

These traces are essential for debugging and improving your application. Weave automatically tracks all calls made through the LlamaIndex library, including prompt templates, LLM calls, tools, and agent steps. You can view the traces in the Weave web interface.

Below is an example of a simple RAG pipeline from LlamaIndex's [Starter Tutorial (OpenAI)](https://docs.llamaindex.ai/en/stable/getting_started/starter_example/):

```python
import weave
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader

# Initialize Weave with your project name
weave.init("llamaindex_demo")

# Assuming you have a `.txt` file in the `data` directory
documents = SimpleDirectoryReader("data").load_data()
index = VectorStoreIndex.from_documents(documents)

query_engine = index.as_query_engine()
response = query_engine.query("What did the author do growing up?")
print(response)
```

The trace timeline not only captures the "events" but it also capture the execution time, cost and token counts where applicable. Drill down the trace to see the inputs and outputs of each step.

[](https://wandb.ai/wandbot/test-llamaindex-weave/weave/calls?filter=%7B%22traceRootsOnly%22%3Atrue%7D&peekPath=%2Fwandbot%2Ftest-llamaindex-weave%2Fcalls%2F6ac53407-1bb7-4c38-b5a3-c302bd877a11%3Ftracetree%3D1)

## One-click observability 🔭

LlamaIndex provides [one-click observability 🔭](https://docs.llamaindex.ai/en/stable/module_guides/observability/) to allow you to build principled LLM applications in a production setting.

Our integration leverages this capability of LlamaIndex and automatically sets [`WeaveCallbackHandler()`](https://github.com/wandb/weave/blob/master/weave/integrations/llamaindex/llamaindex.py) to `llama_index.core.global_handler`. Thus as a user of LlamaIndex and Weave all you need to do is initialize a Weave run - `weave.init()`

## Create a `Model` for easier experimentation

Organizing and evaluating LLMs in applications for various use cases is challenging with multiple components, such as prompts, model configurations, and inference parameters. Using the [`weave.Model`](/guides/core-types/models), you can capture and organize experimental details like system prompts or the models you use, making it easier to compare different iterations.

The following example demonstrates building a LlamaIndex query engine in a `WeaveModel`, using data that can be found in the [weave/data](https://github.com/wandb/weave/tree/master/data) folder:

```python
import weave

from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
from llama_index.core.node_parser import SentenceSplitter
from llama_index.llms.openai import OpenAI
from llama_index.core import PromptTemplate


PROMPT_TEMPLATE = """
You are given with relevant information about Paul Graham. Answer the user query only based on the information provided. Don't make up stuff.

User Query: {query_str}
Context: {context_str}
Answer:
"""
class SimpleRAGPipeline(weave.Model):
    chat_llm: str = "gpt-4"
    temperature: float = 0.1
    similarity_top_k: int = 2
    chunk_size: int = 256
    chunk_overlap: int = 20
    prompt_template: str = PROMPT_TEMPLATE

    def get_llm(self):
        return OpenAI(temperature=self.temperature, model=self.chat_llm)

    def get_template(self):
        return PromptTemplate(self.prompt_template)

    def load_documents_and_chunk(self, data):
        documents = SimpleDirectoryReader(data).load_data()
        splitter = SentenceSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
        )
        nodes = splitter.get_nodes_from_documents(documents)
        return nodes

    def get_query_engine(self, data):
        nodes = self.load_documents_and_chunk(data)
        index = VectorStoreIndex(nodes)

        llm = self.get_llm()
        prompt_template = self.get_template()

        return index.as_query_engine(
            similarity_top_k=self.similarity_top_k,
            llm=llm,
            text_qa_template=prompt_template,
        )
    @weave.op()
    def predict(self, query: str):
        query_engine = self.get_query_engine(
            # This data can be found in the weave repo under data/paul_graham
            "data/paul_graham",
        )
        response = query_engine.query(query)
        return {"response": response.response}
weave.init("test-llamaindex-weave")

rag_pipeline = SimpleRAGPipeline()
response = rag_pipeline.predict("What did the author do growing up?")
print(response)
```

This `SimpleRAGPipeline` class subclassed from `weave.Model` organizes the important parameters for this RAG pipeline. Decorating the `query` method with `weave.op()` allows for tracing.

[](https://wandb.ai/wandbot/test-llamaindex-weave/weave/calls?filter=%7B%22traceRootsOnly%22%3Atrue%7D&peekPath=%2Fwandbot%2Ftest-llamaindex-weave%2Fcalls%2Fa82afbf4-29a5-43cd-8c51-603350abeafd%3Ftracetree%3D1)

## Doing Evaluation with `weave.Evaluation`

Evaluations help you measure the performance of your applications. By using the [`weave.Evaluation`](/guides/core-types/evaluations) class, you can capture how well your model performs on specific tasks or datasets, making it easier to compare different models and iterations of your application. The following example demonstrates how to evaluate the model we created:

```python
import asyncio
from llama_index.core.evaluation import CorrectnessEvaluator

eval_examples = [
    {
        "id": "0",
        "query": "What programming language did Paul Graham learn to teach himself AI when he was in college?",
        "ground_truth": "Paul Graham learned Lisp to teach himself AI when he was in college.",
    },
    {
        "id": "1",
        "query": "What was the name of the startup Paul Graham co-founded that was eventually acquired by Yahoo?",
        "ground_truth": "The startup Paul Graham co-founded that was eventually acquired by Yahoo was called Viaweb.",
    },
    {
        "id": "2",
        "query": "What is the capital city of France?",
        "ground_truth": "I cannot answer this question because no information was provided in the text.",
    },
]

llm_judge = OpenAI(model="gpt-4", temperature=0.0)
evaluator = CorrectnessEvaluator(llm=llm_judge)
@weave.op()
def correctness_evaluator(query: str, ground_truth: str, output: dict):
    result = evaluator.evaluate(
        query=query, reference=ground_truth, response=output["response"]
    )
    return {"correctness": float(result.score)}
evaluation = weave.Evaluation(dataset=eval_examples, scorers=[correctness_evaluator])

rag_pipeline = SimpleRAGPipeline()
asyncio.run(evaluation.evaluate(rag_pipeline))
```

This evaluation builds on the example in the earlier section. Evaluating using `weave.Evaluation` requires an evaluation dataset, a scorer function and a `weave.Model`. Here are a few nuances about the three key components:

- Make sure that the keys of the evaluation sample dicts matches the arguments of the scorer function and of the `weave.Model`'s `predict` method.
- The `weave.Model` should have a method with the name `predict` or `infer` or `forward`. Decorate this method with `weave.op()` for tracing.
- The scorer function should be decorated with `weave.op()` and should have `output` as named argument.

[](https://wandb.ai/wandbot/llamaindex-weave/weave/calls?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fwandbot%2Fllamaindex-weave%2Fop%2FEvaluation.predict_and_score%3ANmwfShfFmgAhDGLXrF6Xn02T9MIAsCXBUcifCjyKpOM%22%5D%2C%22parentId%22%3A%2233491e66-b580-47fa-9d43-0cd6f1dc572a%22%7D&peekPath=%2Fwandbot%2Fllamaindex-weave%2Fcalls%2F33491e66-b580-47fa-9d43-0cd6f1dc572a%3Ftracetree%3D1)

By integrating Weave with LlamaIndex, you can ensure comprehensive logging and monitoring of your LLM applications, facilitating easier debugging and performance optimization using evaluation.

[Source](https://weave-docs.wandb.ai/guides/integrations/llamaindex)

<!--- Docs: Integrations -->
<!--- Notdiamond -->

# Notdiamond

# Not Diamond ¬◇

When building complex LLM workflows users may need to prompt different models according to accuracy,
cost, or call latency. Users can use [Not Diamond][nd] to route prompts in these workflows to the
right model for their needs, helping maximize accuracy while saving on model costs.

## Getting started

Make sure you have [created an account][account] and [generated an API key][keys], then add your API
key to your env as `NOTDIAMOND_API_KEY`.

]

From here, you can

- try the [quickstart guide],
- [build a custom router][custom router] with W&B Weave and Not Diamond, or
- [chat with Not Diamond][chat] to see routing in action

## Tracing

Weave integrates with [Not Diamond's Python library][python] to [automatically log API calls][ops].
You only need to run `weave.init()` at the start of your workflow, then continue using the routed
provider as usual:

```python
from notdiamond import NotDiamond

import weave
weave.init('notdiamond-quickstart')

client = NotDiamond()
session_id, provider = client.chat.completions.model_select(
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Concisely explain merge sort."}
    ],
    model=['openai/gpt-4o', 'anthropic/claude-3-5-sonnet-20240620']
)

print("LLM called: ", provider.provider)  # openai, anthropic, etc
print("Provider model: ", provider.model) # gpt-4o, claude-3-5-sonnet-20240620, etc
```

## Custom routing

You can also train your own [custom router] on [Evaluations][evals], allowing Not Diamond to route prompts
according to eval performance for specialized use cases.

Start by training a custom router:

```python
from weave.flow.eval import EvaluationResults
from weave.integrations.notdiamond.custom_router import train_router

# Build an Evaluation on gpt-4o and Claude 3.5 Sonnet
evaluation = weave.Evaluation(...)
gpt_4o = weave.Model(...)
sonnet = weave.Model(...)

model_evals = {
    'openai/gpt-4o': evaluation.get_eval_results(gpt_4o),
    'anthropic/claude-3-5-sonnet-20240620': evaluation.get_eval_results(sonnet),
}
preference_id = train_router(
    model_evals=model_evals,
    prompt_column="prompt",
    response_column="actual",
    language="en",
    maximize=True,
)
```

By reusing this preference ID in any `model_select` request, you can route your prompts
to maximize performance and minimize cost on your evaluation data:

```python
from notdiamond import NotDiamond
client = NotDiamond()

import weave
weave.init('notdiamond-quickstart')

session_id, provider = client.chat.completions.model_select(
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Concisely explain merge sort."}
    ],
    model=['openai/gpt-4o', 'anthropic/claude-3-5-sonnet-20240620'],

    # passing this preference ID reuses your custom router
    preference_id=preference_id
)

print("LLM called: ", provider.provider)  # openai, anthropic, etc
print("Provider model: ", provider.model) # gpt-4o, claude-3-5-sonnet-20240620, etc
```

## Additional support

Visit the [docs] or [send us a message][support] for further support.

[account]: https://app.notdiamond.ai
[chat]: https://chat.notdiamond.ai
[custom router]: https://docs.notdiamond.ai/docs/router-training-quickstart
[docs]: https://docs.notdiamond.ai
[evals]: ../../guides/core-types/evaluations.md
[keys]: https://app.notdiamond.ai/keys
[nd]: https://www.notdiamond.ai/
[ops]: ../../guides/tracking/ops.md
[python]: https://github.com/Not-Diamond/notdiamond-python
[quickstart guide]: https://docs.notdiamond.ai/docs/quickstart
[support]: mailto:support@notdiamond.ai

[Source](https://weave-docs.wandb.ai/guides/integrations/notdiamond)

<!--- Docs: Integrations -->
<!--- Openrouter -->

# Openrouter

# Open Router

Openrouter.ai is a unified interface for many LLMs, supporting both foundational models like OpenAI GPT-4, Anthropic Claude, Google Gemini but also open source models like LLama-3, Mixtral and [many more](https://openrouter.ai/models), some models are even offered for free. 

Open Router offers a Rest API and an OpenAI SDK compatibility ([docs](https://docs.together.ai/docs/openai-api-compatibility)) which Weave automatically detects and integrates with (see Open Router [quick start](https://openrouter.ai/docs/quick-start) for more details).

To get switch your OpenAI SDK code to Open Router, simply switch out the API key to your [Open Router API](https://openrouter.ai/docs/api-keys) key, `base_url` to `https://openrouter.ai/api/v1`, and model to one of their many [chat models](https://openrouter.ai/docs/models).

```python
import os
import openai
import weave
weave.init('together-weave')

system_content = "You are a travel agent. Be descriptive and helpful."
user_content = "Tell me about San Francisco"
client = openai.OpenAI(
    api_key=os.environ.get("OPENROUTER_API_KEY"),
    base_url="https://openrouter.ai/api/v1",
)
chat_completion = client.chat.completions.create(
    extra_headers={
    "HTTP-Referer": $YOUR_SITE_URL, # Optional, for including your app on openrouter.ai rankings.
    "X-Title": $YOUR_APP_NAME, # Optional. Shows in rankings on openrouter.ai.
    },
    model="meta-llama/llama-3.1-8b-instruct:free",
    messages=[
        {"role": "system", "content": system_content},
        {"role": "user", "content": user_content},
    ],
    temperature=0.7,
    max_tokens=1024,
)
response = chat_completion.choices[0].message.content
print("Model response:\n", response)
```

While this is a simple example to get started, see our [OpenAI](/guides/integrations/openai#track-your-own-ops) guide for more details on how to integrate Weave with your own functions for more complex use cases.

[Source](https://weave-docs.wandb.ai/guides/integrations/openrouter)

<!--- Docs: Integrations -->
<!--- Crewai -->

# Crewai

# CrewAI


  


CrewAI is a lean, lightning-fast Python framework built entirely from scratch—completely independent of LangChain or other agent frameworks. CrewAI empowers developers with both high-level simplicity ([Crews](https://docs.crewai.com/guides/crews/first-crew)) and precise low-level control ([Flows](https://docs.crewai.com/guides/flows/first-flow)), ideal for creating autonomous AI agents tailored to any scenario. Learn more about [CrewAI here](https://docs.crewai.com/introduction).


When working with AI agents, debugging and monitoring their interactions is crucial. CrewAI applications often consist of multiple agents working together, making it essential to understand how they collaborate and communicate. Weave simplifies this process by automatically capturing traces for your CrewAI applications, enabling you to monitor and analyze your agents' performance and interactions.

The integration supports both Crews and Flows.

## Getting Started with Crew

You need to install CrewAI ([more details](https://docs.crewai.com/installation)) and weave to run this example:

```
pip install crewai weave
```

Now we will create a CrewAI Crew and trace the execution using Weave. To get started, simply call `weave.init()` at the beginning of your script. The argument in weave.init() is a project name where the traces will be logged.

```python
import weave
from crewai import Agent, Task, Crew, LLM, Process

# Initialize Weave with your project name
weave.init(project_name="crewai_demo")

# Create an LLM with a temperature of 0 to ensure deterministic outputs
llm = LLM(model="gpt-4o-mini", temperature=0)

# Create agents
researcher = Agent(
    role='Research Analyst',
    goal='Find and analyze the best investment opportunities',
    backstory='Expert in financial analysis and market research',
    llm=llm,
    verbose=True,
    allow_delegation=False,
)

writer = Agent(
    role='Report Writer',
    goal='Write clear and concise investment reports',
    backstory='Experienced in creating detailed financial reports',
    llm=llm,
    verbose=True,
    allow_delegation=False,
)

# Create tasks
research_task = Task(
    description='Deep research on the {topic}',
    expected_output='Comprehensive market data including key players, market size, and growth trends.',
    agent=researcher
)

writing_task = Task(
    description='Write a detailed report based on the research',
    expected_output='The report should be easy to read and understand. Use bullet points where applicable.',
    agent=writer
)

# Create a crew
crew = Crew(
    agents=[researcher, writer],
    tasks=[research_task, writing_task],
    verbose=True,
    process=Process.sequential,
)

# Run the crew
result = crew.kickoff(inputs={"topic": "AI in material science"})
print(result)
```

Weave will track and log all calls made through the CrewAI library, including agent interactions, task executions, and LLM calls. You can view the traces in the Weave web interface.

[](https://wandb.ai/ayut/crewai_demo/weave/traces?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fayut%2Fcrewai_demo%2Fop%2Fcrewai.Crew.kickoff%3A*%22%5D%7D&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c7ac-bd52-7390-95a7-309370e9e058%3FhideTraceTree%3D0&cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D)

> 💡 **Note**: CrewAI provides several methods for better control over the kickoff process: `kickoff()`, `kickoff_for_each()`, `kickoff_async()`, and `kickoff_for_each_async()`. The integration supports logging traces from all these methods.

## Track Tools

CrewAI tools empower agents with capabilities ranging from web searching and data analysis to collaboration and delegating tasks among coworkers. The integration can trace them as well. 

We will improve the quality of the generated report in the above example by giving it access to a tool that can search the internet and return the most relevant results.

Let us first install the extra dependency.

```
pip install 'crewai[tools]'
```

In this example, we are using the `SerperDevTool` to enable our 'Research Analyst' agent to search relevant information on the internet. Learn more about this tool and API requirements [here](https://docs.crewai.com/tools/serperdevtool).

```python
# .... existing imports ....
from crewai_tools import SerperDevTool

# We provide the agent with the tool.
researcher = Agent(
    role='Research Analyst',
    goal='Find and analyze the best investment opportunities',
    backstory='Expert in financial analysis and market research',
    llm=llm,
    verbose=True,
    allow_delegation=False,
    tools=[SerperDevTool()],
)

# .... existing code ....
```

Running this Crew with an agent with access to internet produces better and more relevant result. We automatically trace the tool usage as shown in the image below.

[](https://wandb.ai/ayut/crewai_demo/weave/traces?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fayut%2Fcrewai_demo%2Fop%2Fcrewai.Crew.kickoff%3A*%22%5D%7D&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c7c7-0213-7f42-b130-caa93a79316c%3FdescendentCallId%3D0195c7c7-0a16-7f11-8cfd-9dedf1d03b3b&cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D)

> 💡 **Note**: The integration automatically patches all the tools available in the [`crewAI-tools`](https://github.com/crewAIInc/crewAI-tools) repository. 

## Getting Started with Flow

```python
import weave
# Initialize Weave with your project name
weave.init("crewai_demo")

from crewai.flow.flow import Flow, listen, router, start
from litellm import completion


class CustomerFeedbackFlow(Flow):
    model = "gpt-4o-mini"

    @start()
    def fetch_feedback(self):
        print("Fetching customer feedback")
        # In a real-world scenario, this could be replaced by an API call.
        # For this example, we simulate customer feedback.
        feedback = (
            "I had a terrible experience with the product. "
            "It broke after one use and customer service was unhelpful."
        )
        self.state["feedback"] = feedback
        return feedback

    @router(fetch_feedback)
    def analyze_feedback(self, feedback):
        # Use the language model to analyze sentiment
        prompt = (
            f"Analyze the sentiment of this customer feedback and "
            "return only 'positive' or 'negative':\n\n"
            f"Feedback: {feedback}"
        )
        response = completion(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
        )
        sentiment = response["choices"][0]["message"]["content"].strip().lower()
        # If the response is ambiguous, default to negative
        if sentiment not in ["positive", "negative"]:
            sentiment = "negative"
        return sentiment

    @listen("positive")
    def handle_positive_feedback(self):
        # Generate a thank you message for positive feedback
        prompt = "Generate a thank you message for a customer who provided positive feedback."
        response = completion(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
        )
        thank_you_message = response["choices"][0]["message"]["content"].strip()
        self.state["response"] = thank_you_message
        return thank_you_message

    @listen("negative")
    def handle_negative_feedback(self):
        # Generate an apology message with a promise to improve service for negative feedback
        prompt = (
            "Generate an apology message to a customer who provided negative feedback and offer assistance or a solution."
        )
        response = completion(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
        )
        apology_message = response["choices"][0]["message"]["content"].strip()
        self.state["response"] = apology_message
        return apology_message

# Instantiate and kickoff the flow
flow = CustomerFeedbackFlow()
result = flow.kickoff()
print(result)
```

[](https://wandb.ai/ayut/crewai_demo/weave/traces?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fayut%2Fcrewai_demo%2Fop%2Fcrewai.Flow.kickoff%3A*%22%5D%7D&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c7e3-7a63-7283-bef4-9e0eb2f0eab1&cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D)

> 💡 **Note**: The integration automatically patches the `Flow.kickoff` entry point and all the available decorators -- `@start`, `@listen`, `@router`, `@or_` and `@and_`.


## Crew Guardrail - Track your own ops

Task guardrails provide a way to validate and transform task outputs before they are passed to the next task. We can use a simple python function to validate the agent's execution on-the-fly.

Wrapping this function with `@weave.op` starts capturing inputs, outputs and app logic so you can debug how data is validated through your agents. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git.

Let's take the example of research analyst and writer. We add a guardrail to validate the length of the generated report.

```python
# .... existing imports and weave initialization ....

# Decorate your guardrail function with `@weave.op()`
@weave.op(name="guardrail-validate_blog_content")
def validate_blog_content(result: TaskOutput) -> Tuple[bool, Any]:
    # Get raw string result
    result = result.raw

    """Validate blog content meets requirements."""
    try:
        # Check word count
        word_count = len(result.split())

        if word_count > 200:
            return (False, {
                "error": "Blog content exceeds 200 words",
                "code": "WORD_COUNT_ERROR",
                "context": {"word_count": word_count}
            })

        # Additional validation logic here
        return (True, result.strip())
    except Exception as e:
        return (False, {
            "error": "Unexpected error during validation",
            "code": "SYSTEM_ERROR"
        })


# .... existing agents and research analyst task ....

writing_task = Task(
    description='Write a detailed report based on the research under 200 words',
    expected_output='The report should be easy to read and understand. Use bullet points where applicable.',
    agent=writer,
    guardrail=validate_blog_content,
)

# .... existing code to run crew ....
```

By simply decorating the guardrail function with `@weave.op` we are able to keep track of the input and output to this function along with execution time, token information if an LLM is used under the hood, code version and more.

[](https://wandb.ai/ayut/crewai_demo/weave/traces?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fayut%2Fcrewai_demo%2Fop%2Fcrewai.Crew.kickoff%3A*%22%5D%7D&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c838-38cb-71a2-8a15-651ecddf9d89%3FdescendentCallId%3D0195c838-8632-7173-846d-f230e7272c20&cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D)

## Conclusion

Do let us know what we should improve about this integration. Please open an issue if you encounter one [here](https://github.com/wandb/weave/issues/new/choose).

Learn more about how to build powerful multiagent systems using CrewAI through their [many examples](https://github.com/crewAIInc/crewAI-examples) and [documentation](https://docs.crewai.com/introduction).

[Source](https://weave-docs.wandb.ai/guides/integrations/crewai)

<!--- Docs: Integrations -->
<!--- Azure -->

# Azure

# Microsoft Azure

Weights & Biases (W&B) Weave integrates with Microsoft Azure OpenAI services, helping teams to optimize their Azure AI applications. Using W&B, you can 

> 🌟 **Tip**: For the latest tutorials, visit [Weights & Biases on Microsoft Azure](https://wandb.ai/site/partners/azure).

## Getting started

To get started using Azure with Weave, simply decorate the function(s) you want to track with `weave.op`.

```python
@weave.op()
def call_azure_chat(model_id: str, messages: list, max_tokens: int = 1000, temperature: float = 0.5):
    response = client.chat.completions.create(
        model=model_id,
        messages=messages,
        max_tokens=max_tokens,
        temperature=temperature
    )
    return {"status": "success", "response": response.choices[0].message.content}

```

## Learn more

Learn more about advanced Azure with Weave topics using the resources below.

### Use the Azure AI Model Inference API with Weave

Learn how to use the [Azure AI Model Inference API] with Weave to gain insights into Azure models in [this guide](https://wandb.ai/byyoung3/ML-NEWS2/reports/A-guide-to-using-the-Azure-AI-model-inference-API--Vmlldzo4OTY1MjEy#tutorial:-implementing-azure-ai-model-inference-api-with-w&b-weave-).

### Trace Azure OpenAI models with Weave

Learn how to trace Azure OpenAI models using Weave in [this guide](https://wandb.ai/a-sh0ts/azure-weave-cookbook/reports/How-to-use-Azure-OpenAI-and-Azure-AI-Studio-with-W-B-Weave--Vmlldzo4MTI0NDgy).

[Source](https://weave-docs.wandb.ai/guides/integrations/azure)



<!--- Docs: Introduction -->
<!--- Introduction -->

# Introduction

# W&B Weave

Weights & Biases (W&B) Weave is a framework for tracking, experimenting with, evaluating, deploying, and improving LLM-based applications. Designed for flexibility and scalability, Weave supports every stage of your LLM application development workflow:

- **Tracing & Monitoring**: [Track LLM calls and application logic](./guides/tracking/) to debug and analyze production systems.
- **Systematic Iteration**: Refine and iterate on [prompts](./guides/core-types/prompts.md), [datasets](./guides/core-types/datasets.md), and [models](./guides/core-types/models.md).
- **Experimentation**: Experiment with different models and prompts in the [LLM Playground](./guides/tools/playground.md). 
- **Evaluation**: Use custom or [pre-built scorers](./guides/evaluation/scorers#predefined-scorers) alongside our [comparison tools](./guides/tools/comparison.md) to systematically assess and enhance application performance.
- **Guardrails**: Protect your application with [pre- and post-safeguards](./guides/evaluation/guardrails_and_monitors.md) for content moderation, prompt safety, and more.

Integrate Weave with your existing development stack via the:
- [Python SDK](./reference/python-sdk/weave/index.md)
- [TypeScript SDK](./reference/typescript-sdk/weave/README.md)
- [Service API](./reference/service-api/call-start-call-start-post)

Weave supports [numerous LLM providers, local models, frameworks, protocols, and third-party services](./guides/integrations/index.md).

## Get started

Are you new to Weave? Set up and start using Weave with the [Python quickstart](/quickstart) or [TypeScript quickstart](./reference/generated_typescript_docs/intro-notebook.md).

## Advanced guides

Learn more about advanced topics:

- [Integrations](./guides/integrations/index.md): Use Weave with popular LLM providers, local models, frameworks, and third-party services.
- [Cookbooks](./reference/gen_notebooks/01-intro_notebook.md): Build with Weave using Python and TypeScript. Tutorials are available as interactive notebooks.
- [W&B AI Academy](https://www.wandb.courses/pages/w-b-courses): Build advanced RAG systems, improve LLM prompting, fine-tune LLMs, and more.

[Source](https://weave-docs.wandb.ai/introduction)



<!--- Docs: Other -->
<!--- Troubleshooting -->

# Troubleshooting

# Troubleshooting

This page provides solutions and guidance for common issues you may encounter. As we continue to expand this guide, more troubleshooting topics will be added to address a broader range of scenarios.

> 🌟 **Tip**: Do you have Weave troubleshooting advice to share with the community? Click **Edit this page** at the bottom of this guide to contribute directly by submitting a pull request.

## Trace pages load slowly

If trace pages are loading slowly, reduce the number of rows displayed to improve load time. The default value is `50`. You can either reduce the number of rows via the UI, or using query parameters.

### Adjust via the UI (recommended)

Use the **Per page** control at the bottom-right of the Traces page to adjust the number of rows displayed. In addition to the default of `50`, you can also set to `10`, `25`, or `100`.

### Use query parameters

If you prefer a manual approach, you can modify the `pageSize` query parameter in your query URL to a value less than the maximum of `100`.

## Server response caching

Weave provides server response caching to improve performance when making repeated queries or working with limited network bandwidth. While currently disabled by default, this feature is expected to become the default behavior in a future release.

### When to use caching

Server response caching is particularly beneficial when:

- You frequently run the same queries
- You have limited network bandwidth
- You're working in an environment with high latency
- You're developing offline and want to cache responses for later use

This feature is especially useful when running repeated evaluations on a dataset, as it allows caching the dataset between runs.

### How to enable caching

To enable caching, you can set the following environment variables:

```bash
# Enable server response caching
export WEAVE_USE_SERVER_CACHE=true

# Set cache size limit (default is 1GB)
export WEAVE_SERVER_CACHE_SIZE_LIMIT=1000000000

# Set cache directory (optional, defaults to temporary directory)
export WEAVE_SERVER_CACHE_DIR=/path/to/cache
```

### Caching behavior

Technically, this feature will cache idempotent requests against the server. Specifically, we cache:

- `obj_read`
- `table_query`
- `table_query_stats`
- `refs_read_batch`
- `file_content_read`

### Cache size and storage details

The cache size is controlled by `WEAVE_SERVER_CACHE_SIZE_LIMIT` (in bytes). The actual disk space used consists of three components:

1. A constant 32KB checksum file
2. A Write-Ahead Log (WAL) file up to ~4MB per running client (automatically removed when the program exits)
3. The main database file, which is at least 32KB and at most `WEAVE_SERVER_CACHE_SIZE_LIMIT`

Total disk space used:

- While running >= 32KB + ~4MB + cache size
- After exit >= 32KB + cache size

For example, with the a 5MB cache limit:

- While running: ~9MB maximum
- After exit: ~5MB maximum

## Trace data is truncated

Sometimes, large trace data is partially cut off in the Weave UI. This problem occurs because default trace output is a raw, custom Python object that Weave doesn’t know how to serialize.

To ensure that large trace data isn't cut off, define a dictionary of strings to return all trace data. 

```python
import weave

class MyObj:
    def __init__(self, x: int):
        self.x = x

    def __repr__(self):
        return f"MyObj(x={self.x})"

    def to_dict(self):
        return {"x": self.x}

@weave.op()
def make_my_obj():
    x = "s" * 10_000
    return MyObj(x)
```

## Long eval clean up times

The following two methods should be used together in order to improve performance when running evaluations with large datasets.

### Flushing

When running evaluations with large datasets, you may experience a long period of time before program execution, while the dataset is being uploaded in background threads. This generally occurs when main thread execution finished before background cleanup is complete. Calling `client.flush()` will force all background tasks to be processed in the main thread, ensuring parallel processing during main thread execution. This can improve performance when user code completes before data has been uploaded to the server.

Example:

```python
client = weave.init("fast-upload")

# ... evaluation setup
result = evaluation.Evaluate(dataset_id="my_dataset_id")

client.flush()
```

### Increasing client parallelism

Client parallelism is automatically determined based on the environment, but can be set manually using the following environment variable:

- `WEAVE_CLIENT_PARALLELISM`: The number of threads available for parallel processing. Increasing this number will increase the number of threads available for parallel processing, potentially improving the performance of background tasks like dataset uploads.

This can also be set programmatically using the `settings` argument to `weave.init()`:

```python
client = weave.init("fast-upload", settings={"client_parallelism": 100})
```

## OS errors

### `[Errno 24]: Too many open files`

This error occurs when the number of open files exceeds the limit set by your operating system. In Weave, this may happen because you're working with large image datasets. Weave uses `PIL` for image processing, which keeps file descriptors open for the duration of the program.

To resolve this issue, increase the system limit for open files to `65,536` using `ulimit`:

```bash
ulimit -n 65536
```

[Source](https://weave-docs.wandb.ai/guides/troubleshooting)

<!--- Docs: Other -->
<!--- Intro Notebook -->

# Intro Notebook

# Weave with TypeScript Quickstart Guide

You can use W&B Weave with Typescript to:

- Log and debug language model inputs, outputs, and traces
- Build rigorous, apples-to-apples evaluations for language model use cases
- Organize all the information generated across the LLM workflow, from experimentation to evaluations to production

For more information, see the [Weave documentation](/). 

## Function tracking

To use Weave in your Typescript code, initialize a new Weave project and add the `weave.op` wrapper to the functions you want to track.

After adding `weave.op` and calling the function, visit the W&B dashboard to see it tracked within your project.

We automatically track your code - check the code tab in the UI!

```typescript
async function initializeWeaveProject() {
    const PROJECT = 'weave-examples';
    await weave.init(PROJECT);
}
```

```typescript
const stripUserInput = weave.op(function stripUserInput(userInput: string): string {
    return userInput.trim();
});
```

The following example shows how basic function tracking works.

```typescript
async function demonstrateBasicTracking() {
    const result = await stripUserInput("    hello    ");
    console.log('Basic tracking result:', result);
}
```

## OpenAI integration

Weave automatically tracks all OpenAI calls, including:

- Token usage
- API costs
- Request/response pairs
- Model configurations

> 💡 **Note**: In addition to OpenAI, Weave supports automatic logging of other LLM providers, such as Anthropic and Mistral. For the full list, see [LLM Providers in the Integrations documentation](../../guides/integrations/index.md#llm-providers).

```typescript
function initializeOpenAIClient() {
    return weave.wrapOpenAI(new OpenAI({
        apiKey: process.env.OPENAI_API_KEY
    }));
}
```

```typescript
async function demonstrateOpenAITracking() {
    const client = initializeOpenAIClient();
    const result = await client.chat.completions.create({
        model: "gpt-4-turbo",
        messages: [{ role: "user", content: "Hello, how are you?" }],
    });
    console.log('OpenAI tracking result:', result);
}
```

## Nested function tracking

Weave allows you to track complex workflows by combining multiple tracked functions
and LLM calls while preserving the entire execution trace. The benefits of this include:

- Full visibility into your application's logic flow
- Easy debugging of complex chains of operations
- Performance optimization opportunities

```typescript
async function demonstrateNestedTracking() {
    const client = initializeOpenAIClient();
    
    const correctGrammar = weave.op(async function correctGrammar(userInput: string): Promise {
        const stripped = await stripUserInput(userInput);
        const response = await client.chat.completions.create({
            model: "gpt-4-turbo",
            messages: [
                {
                    role: "system",
                    content: "You are a grammar checker, correct the following user input."
                },
                { role: "user", content: stripped }
            ],
            temperature: 0,
        });
        return response.choices[0].message.content ?? '';
    });

    const grammarResult = await correctGrammar("That was so easy, it was a piece of pie!");
    console.log('Nested tracking result:', grammarResult);
}
```

## Dataset management

You can create and manage datasets with Weave using the [`weave.Dataset`](../../guides/core-types/datasets.md) class. Similar to [Weave `Models`](../../guides/core-types/models.md), `weave.Dataset` helps:

- Track and version your data
- Organize test cases
- Share datasets between team members
- Power systematic evaluations

```typescript
interface GrammarExample {
    userInput: string;
    expected: string;
}
```

```typescript
function createGrammarDataset(): weave.Dataset {
    return new weave.Dataset({
        id: 'grammar-correction',
        rows: [
            {
                userInput: "That was so easy, it was a piece of pie!",
                expected: "That was so easy, it was a piece of cake!"
            },
            {
                userInput: "I write good",
                expected: "I write well"
            },
            {
                userInput: "LLM's are best",
                expected: "LLM's are the best"
            }
        ]
    });
}
```

## Evaluation framework

Weave supports evaluation-driven development with the [`Evaluation` class](../../guides/core-types/evaluations.md). Evaluations help you reliably iterate on your GenAI application. The `Evaluation` class does the following:

- Assesses `Model` performance on a `Dataset`
- Applies custom scoring functions
- Generates detailed performance reports
- Enables comparison between model versions

You can find a complete evaluation tutorial at [http://wandb.me/weave_eval_tut](http://wandb.me/weave_eval_tut)

```typescript
class OpenAIGrammarCorrector {
    private oaiClient: ReturnType;
    
    constructor() {
        this.oaiClient = weave.wrapOpenAI(new OpenAI({
            apiKey: process.env.OPENAI_API_KEY
        }));
        this.predict = weave.op(this, this.predict);
    }

    async predict(userInput: string): Promise {
        const response = await this.oaiClient.chat.completions.create({
            model: 'gpt-4-turbo',
            messages: [
                { 
                    role: "system", 
                    content: "You are a grammar checker, correct the following user input." 
                },
                { role: "user", content: userInput }
            ],
            temperature: 0
        });
        return response.choices[0].message.content ?? '';
    }
}
```

```typescript
async function runEvaluation() {
    const corrector = new OpenAIGrammarCorrector();
    const dataset = createGrammarDataset();
    
    const exactMatch = weave.op(
        function exactMatch({ modelOutput, datasetRow }: { 
            modelOutput: string; 
            datasetRow: GrammarExample 
        }): { match: boolean } {
            return { match: datasetRow.expected === modelOutput };
        },
        { name: 'exactMatch' }
    );

    const evaluation = new weave.Evaluation({
        dataset,
        scorers: [exactMatch],
    });

    const summary = await evaluation.evaluate({
        model: weave.op((args: { datasetRow: GrammarExample }) => 
            corrector.predict(args.datasetRow.userInput)
        )
    });
    console.log('Evaluation summary:', summary);
}
```

The following `main` function runs all demonstrations:

```typescript
async function main() {
    try {
        await initializeWeaveProject();
        await demonstrateBasicTracking();
        await demonstrateOpenAITracking();
        await demonstrateNestedTracking();
        await runEvaluation();
    } catch (error) {
        console.error('Error running demonstrations:', error);
    }
}
```

[Source](https://weave-docs.wandb.ai/reference/generated_typescript_docs/intro-notebook)



<!--- Docs: Platform -->
<!--- Weave Self Managed -->

# Weave Self Managed

# W&B Weave Self-Managed

> 🚨 **Important**: Weave on self-managed infrastructure is currently in Private Preview.  

For production environments, W&B strongly recommends using [W&B Dedicated Cloud](https://docs.wandb.ai/guides/hosting/hosting-options/dedicated_cloud), where Weave is Generally Available.  

To deploy a production-grade, self-managed instance, contact `support@wandb.com`.  

This guide explains how to deploy all the components required to run W&B Weave in a self-managed environment.

A key component of a self-managed Weave deployment is [ClickHouseDB](https://clickhouse.com/), which the Weave application backend relies on.

Although the deployment process sets up a fully functional ClickHouseDB instance, you may need to take additional steps to ensure reliability and high availability for a production-ready environment.

## Requirements

- W&B Platform installed. For more information, see the [Self-Managed Deployment Guide](https://docs.wandb.ai/guides/hosting/hosting-options/self-managed/).
- [Bitnami's ClickHouse Helm Chart](https://github.com/bitnami/charts/tree/main/bitnami/clickhouse).
- An S3 bucket pre-configured for ClickHouse storage. For configuration details, see [Provide S3 Credentials](#provide-s3-credentials).
- Kubernetes Cluster Nodes with the following specifications:
  - CPU: 8 cores  
  - RAM: 64 GB  
  - Disk: 200GB+
- A Weave-enabled license from W&B. To request a license, please contact `support@wandb.com`.

> 🌟 **Tip**: For a detailed reference architecture, see [https://docs.wandb.ai/guides/hosting/self-managed/ref-arch/](https://docs.wandb.ai/guides/hosting/self-managed/ref-arch/#models-and-weave).

## 1. Configure ClickHouse

The ClickHouse deployment in this document uses the [Bitnami ClickHouse](https://bitnami.com/stack/clickhouse) package.

The Bitnami Helm chart provides good support for basic ClickHouse functionalities, particularly the use of [ClickHouse Keeper](https://clickhouse.com/docs/en/guides/sre/keeper/clickhouse-keeper).

To configure Clickhouse, complete the following steps:

1. [Configure the Helm repository](#configure-helm-repository)
2. [Create Helm Configuration](#create-helm-configuration)
3. [Provide S3 credentials](#provide-s3-credentials)

### Configure Helm repository

1. Add the Bitnami Helm repository:

   `helm repo add bitnami https://charts.bitnami.com/bitnami` 

2. Update the repository:

   `helm repo update`

### Create Helm Configuration

The most critical part of the Helm configuration is the ClickHouse configuration, which is provided in XML format. Below is an example `values.yaml` file with customizable parameters to suit your needs.
To make the configuration process easier, we have added comments in the relevant sections using the format ``.

Modify the following parameters:

- `clusterName`
- `auth.username`
- `auth.password`
- S3 bucket-related configurations

W&B recommends keeping the `clusterName` value in `values.yaml` set to `weave_cluster`.  This is the expected cluster name when W&B Weave runs the database migration. If you need to use a different name, see the [Setting `clusterName`](#setting-clustername) section for more information.

```yaml
## @param clusterName ClickHouse cluster name
clusterName: weave_cluster

## @param shards Number of ClickHouse shards to deploy
shards: 1

## @param replicaCount Number of ClickHouse replicas per shard to deploy
## if keeper enable, same as keeper count, keeper cluster by shards.
replicaCount: 3

persistence:
  enabled: true
  size: 30G # this size must be larger than cache size.

## ClickHouse resource requests and limits
resources:
  requests:
    cpu: 0.5
    memory: 500Mi
  limits:
    cpu: 3.0
    memory: 6Gi

## Authentication
auth:
  username: weave_admin
  password: "weave_123"
  existingSecret: ""
  existingSecretKey: ""

## @param logLevel Logging level
logLevel: information

## @section ClickHouse keeper configuration parameters
keeper:
  enabled: true

## @param extraEnvVars Array with extra environment variables to add to ClickHouse nodes
##
extraEnvVars:
  - name: S3_ENDPOINT
    value: "https://s3.us-east-1.amazonaws.com/bucketname/$(CLICKHOUSE_REPLICA_ID)"


## @param defaultConfigurationOverrides [string] Default configuration overrides (evaluated as a template)
defaultConfigurationOverrides: |
  
    
    
      
      
    
    
    
      {{ .Values.logLevel }}
    
    {{- if or (ne (int .Values.shards) 1) (ne (int .Values.replicaCount) 1)}}
    
      
        {{- $shards := $.Values.shards | int }}
        {{- range $shard, $e := until $shards }}
        
          true
          {{- $replicas := $.Values.replicaCount | int }}
          {{- range $i, $_e := until $replicas }}
          
            {{ printf "%s-shard%d-%d.%s.%s.svc.%s" (include "common.names.fullname" $ ) $shard $i (include "clickhouse.headlessServiceName" $) (include "common.names.namespace" $) $.Values.clusterDomain }}
            {{ $.Values.service.ports.tcp }}
          
          {{- end }}
        
        {{- end }}
      
    
    {{- end }}
    {{- if .Values.keeper.enabled }}
    
      {{ $.Values.containerPorts.keeper }}
      {{- if .Values.tls.enabled }}
      {{ $.Values.containerPorts.keeperSecure }}
      {{- end }}
      
      /bitnami/clickhouse/keeper/coordination/log
      /bitnami/clickhouse/keeper/coordination/snapshots
      
        10000
        30000
        trace
      
      
        {{- $nodes := .Values.replicaCount | int }}
        {{- range $node, $e := until $nodes }}
        
          {{ $node | int }}
          
          {{ $.Values.service.ports.keeperInter }}
        
        {{- end }}
      
    
    {{- end }}
    {{- if or .Values.keeper.enabled .Values.zookeeper.enabled .Values.externalZookeeper.servers }}
    
      {{- if or .Values.keeper.enabled }}
      {{- $nodes := .Values.replicaCount | int }}
      {{- range $node, $e := until $nodes }}
      
        
        {{ $.Values.service.ports.keeper }}
      
      {{- end }}
      {{- else if .Values.zookeeper.enabled }}
      {{- $nodes := .Values.zookeeper.replicaCount | int }}
      {{- range $node, $e := until $nodes }}
      
        
        {{ $.Values.zookeeper.service.ports.client }}
      
      {{- end }}
      {{- else if .Values.externalZookeeper.servers }}
      {{- range $node :=.Values.externalZookeeper.servers }}
      
        {{ $node }}
        {{ $.Values.externalZookeeper.port }}
      
      {{- end }}
      {{- end }}
    
    {{- end }}
    {{- if .Values.metrics.enabled }}
    
      /metrics
      
      true
      true
      true
    
    {{- end }}
    0.0.0.0
    ::
    1
    
      
        
          s3
          

          
          xxx
          xxx
          

         /var/lib/clickhouse/disks/s3_disk/
        
        
  	      cache
          s3_disk
          /var/lib/clickhouse/s3_disk_cache/cache/
          
          20Gi
          1
          1 
        
      
      
        
          
            
              s3_disk_cache
            
          
        
      
    
    
      s3_main
    
  

## @section Zookeeper subchart parameters
zookeeper:
  enabled: false
```

### S3 endpoint configuration

The bucket endpoint must be set as an environment variable to ensure each ClickHouse replica read and writes data in it's folder in the bucket.

```
extraEnvVars:
  - name: S3_ENDPOINT
    value: "https://s3.us-east-1.amazonaws.com/bucketname/$(CLICKHOUSE_REPLICA_ID)"
```

> 🚨 **Important**: Do not remove the `$(CLICKHOUSE_REPLICA_ID)` from the bucket endpoint configuration. It will ensure each ClickHouse replica is writing and reading data from it's folder in the bucket.

### Provide S3 credentials

You can specify credentials for accessing an S3 bucket by either hardcoding the configuration, or having ClickHouse fetch the data from environment variables or an EC2 instance.

#### Hardcode the configuration   
   
Directly include the credentials in the storage configuration:

```plaintext
s3

xxx
xxx
```

#### Use environment variables or EC2 Metadata

Instead of hardcoding credentials, you can enable ClickHouse to fetch them dynamically from environment variables or Amazon EC2 instance metadata.

```plaintext
true
```  

You can find more details on this at [ClickHouse: Separation of Storage and Compute](https://clickhouse.com/docs/en/guides/separation-storage-compute).

## 2. Install and deploy ClickHouse

With the repositories set up and the `values.yaml` file prepared, the next step is to install ClickHouse.

```bash
helm install clickhouse bitnami/clickhouse -f values.yaml --version 8.0.10
```

> 🚨 **Important**: Ensure you're using the version `8.0.10`. The latest chart version (`9.0.0`) doesn't work with the configuration proposed in this document.

## 3. Confirm ClickHouse deployment

Confirm that ClickHouse is deployed using the following command:

```bash
kubectl get pods
```

You should see the following pods:

```bash
NAME                                 READY   STATUS    RESTARTS   AGE
clickhouse-shard0-0                  1/1     Running   0          9m59s
clickhouse-shard0-1                  1/1     Running   0          10m
clickhouse-shard0-2                  1/1     Running   0          10m
```

## 4. Deploy Weave

Weave is already available for automatic deployment via [W&B Operator](https://docs.wandb.ai/guides/hosting/operator/#wb-kubernetes-operator). With the W&B Platform installed, complete the following steps:

1. Edit the [CR instance](https://docs.wandb.ai/guides/hosting/operator/#complete-example) used to deploy the platform.
2. Add the Weave configuration.

## 5. Gather information

1. Use Kubernetes service details to configure Weave tracing:

  - **Endpoint**: `-headless..svc.cluster.local`
    - Replace `` with your Helm release name
    - Replace `` with your `NAMESPACE`
    - Get the service details: `kubectl get svc -n `
  - **Username**: Set in the `values.yaml`
  - **Password**: Set in the `values.yaml`

2. With this information, update the W&B Platform Custom Resource(CR) by adding the following configuration:

    ```yaml
    apiVersion: apps.wandb.com/v1
    kind: WeightsAndBiases
    metadata:
      labels:
        app.kubernetes.io/name: weightsandbiases
        app.kubernetes.io/instance: wandb
      name: wandb
      namespace: default
    spec:
      values:
        global:
        [...]
          clickhouse:
            host: -headless..svc.cluster.local
            port: 8123
            password: 
            user: 
            database: wandb_weave
            # `replicated` must be set to `true` if replicating data across multiple nodes
            # This is in preview, use the env var `WF_CLICKHOUSE_REPLICATED`
            replicated: true

          weave-trace:
            enabled: true
        [...]
        weave-trace:
          install: true
          extraEnv:
            WF_CLICKHOUSE_REPLICATED: "true"
        [...]
    ```

> 🚨 **Important**: When using more than one replica (W&B recommend a least 3 replicas), ensure to have the following environment variable set for Weave Traces.
```
extraEnv:
  WF_CLICKHOUSE_REPLICATED: "true"
```
This has the same effect of `replicated: true` which in preview.


3. Set the `clusterName` in `values.yaml` to `weave_cluster`. If it is not, the database migration will fail.  

    Alternatively, ff you use a different cluster name, set the `WF_CLICKHOUSE_REPLICATED_CLUSTER` environment variable in `weave-trace.extraEnv` to match the chosen name, as shown in the example below.

    ```yaml
    [...]
      clickhouse:
        host: -headless..svc.cluster.local
        port: 8123
        password: 
        user: 
        database: wandb_weave
        # `replicated` must be set to `true` if replicating data across multiple nodes
        # This is in preview, use the env var `WF_CLICKHOUSE_REPLICATED`
        replicated: true

      weave-trace:
        enabled: true
    [...]
    weave-trace:
      install: true
      extraEnv:
        WF_CLICKHOUSE_REPLICATED: "true"
        WF_CLICKHOUSE_REPLICATED_CLUSTER: "different_cluster_name"
    [...]
    ```

    The final configuration will look like the following example:

    ```yaml
    apiVersion: apps.wandb.com/v1
    kind: WeightsAndBiases
    metadata:
      labels:
        app.kubernetes.io/name: weightsandbiases
        app.kubernetes.io/instance: wandb
      name: wandb
      namespace: default
    spec:
      values:
        global:
          license: eyJhbGnUzaHgyQjQyQWhEU3...ZieKQ2x5GGfw
          host: https://wandb.example.com

          bucket:
            name: abc-wandb-moving-pipefish
            provider: gcs

          mysql:
            database: wandb_local
            host: 10.218.0.2
            name: wandb_local
            password: 8wtX6cJHizAZvYScjDzZcUarK4zZGjpV
            port: 3306
            user: wandb

          clickhouse:
            host: -headless..svc.cluster.local
            port: 8123
            password: 
            user: 
            database: wandb_weave
            # This option must be true if replicating data across multiple nodes
            replicated: true

          weave-trace:
            enabled: true
    
        ingress:
          annotations:
            ingress.gcp.kubernetes.io/pre-shared-cert: abc-wandb-cert-creative-puma
            kubernetes.io/ingress.class: gce
            kubernetes.io/ingress.global-static-ip-name: abc-wandb-operator-address

        weave-trace:
          install: true
          extraEnv:
            WF_CLICKHOUSE_REPLICATED: "true"
    ```

4. With the Custom Resource (CR) prepared, apply the new configuration:

    ```bash
    kubectl apply -f wandb.yaml
    ```

## 6. Access Weave

Once the deployment is running, accessing the W&B endpoint configured in the `host` option should display the Weave licensing status as enabled.

[Source](https://weave-docs.wandb.ai/guides/platform/weave-self-managed)

<!--- Docs: Platform -->
<!--- Index -->

# Index

# Platform & Security

Weave is available on the following deployment options:

- **[W&B SaaS Cloud](https://docs.wandb.ai/guides/hosting/hosting-options/saas_cloud):** A multi-tenant, fully-managed platform deployed in W&B's Google Cloud Platform (GCP) account in a North America region.
- **[W&B Dedicated Cloud](https://docs.wandb.ai/guides/hosting/hosting-options/dedicated_cloud):** Generally available on AWS and in preview on GCP and Azure. 
- **[Self-managed instances](./weave-self-managed.md):** For teams that prefer to host Weave independently, guidance is available from your W&B team to evaluate deployment options.

## Identity and Access Management

Use the identity and access management capabilities for secure authentication and effective authorization in your [W&B Organization](https://docs.wandb.ai/guides/hosting/iam/org_team_struct#organization). The following capabilities are available for Weave users depending on your deployment option and [pricing plan](https://wandb.ai/site/pricing/):

- **Authenticate using Single-Sign On (SSO):** Options include public identity providers like Google and Github, as well as enterprise providers such as Okta, Azure Active Directory, and others, [using OIDC](https://docs.wandb.ai/guides/technical-faq/general#does-wb-support-sso-for-saas).
- **[Team-based logical separation](https://docs.wandb.ai/guides/models/app/settings-page/teams/):** Each team may correspond to a business unit, department, or project team within your organization.
- **Use W&B projects to organize initiatives:** Organize initiatives within teams and configure the required [visibility scope](https://docs.wandb.ai/guides/hosting/restricted-projects), including the `restricted` scope for sensitive collaborations.
- **Role-based access control:** Configure access at the [team](https://docs.wandb.ai/guides/hosting/iam/manage-organization#assign-or-update-a-team-members-role) or [project](https://docs.wandb.ai/guides/hosting/iam/restricted-projects#project-level-roles) level to ensure users access data on a need-to-know basis.
- **Scoped service accounts:** Automate Gen AI workflows using service accounts scoped to your organization or team.
- **[SCIM API and Python SDK](https://docs.wandb.ai/guides/hosting/iam/automate_iam):** Manage users and teams efficiently with SCIM API and Python SDK.

## Data Security

- **SaaS Cloud:** Data for all Weave users is stored in a shared Clickhouse Cloud cluster, encrypted using cloud-native encryption. Shared compute services process the data, ensuring isolation through a security context comprising your W&B organization, team, and project.

- **Dedicated Cloud:** Data is stored in a unique Clickhouse Cloud cluster in the cloud and region of your choice. A unique compute environment processes the data, with the following additional protections:
  - **[IP allowlisting](https://docs.wandb.ai/guides/hosting/data-security/ip-allowlisting):** Authorize access to your instance from specific IP addresses. This is an optional capability.
  - **[Private connectivity](https://docs.wandb.ai/guides/hosting/data-security/private-connectivity):** Route data securely through the cloud provider's private network. This is an optional capability.
  - **[Data encryption](https://docs.wandb.ai/guides/hosting/data-security/data-encryption):** W&B encrypts data at rest using a unique W&B-managed encryption key.
  - **Clickhouse cluster security:** W&B connects to the unique Clickhouse Cloud cluster for your Dedicated Cloud instance over the cloud provider's private network. W&B also encrypts the cluster using a unique W&B-managed encryption key, while leveraging Clickhouse's file level encryption.

> 🚨 **Important**: [The W&B Platform secure storage connector or BYOB](https://docs.wandb.ai/guides/hosting/data-security/secure-storage-connector) is not available for Weave.

## Maintenance 

If you're using Weave on SaaS Cloud or Dedicated Cloud, you avoid the overhead and costs of provisioning, operating, and maintaining the W&B platform, as it is fully managed for you.

## Compliance

> 🌟 **Tip**: To request SOC 2 reports and other security and compliance documents, refer to the [W&B Security Portal](https://security.wandb.ai/) or contact your W&B team for more information.

Security controls for both SaaS Cloud and Dedicated Cloud are periodically audited internally and externally. Both platforms are SOC 2 Type II compliant. Additionally, Dedicated Cloud is HIPAA-compliant for organizations managing PHI data while building Generative AI applications.

[Source](https://weave-docs.wandb.ai/guides/platform/index)



<!--- Docs: Python SDK -->
<!--- Index -->

# Index

# weave

The top-level functions and classes for working with Weave.

---


# API Overview



## Classes

- [`obj.Object`](#class-object)
- [`dataset.Dataset`](#class-dataset): Dataset object with easy saving and automatic versioning
- [`model.Model`](#class-model): Intended to capture a combination of code and data the operates on an input.
- [`prompt.Prompt`](#class-prompt)
- [`prompt.StringPrompt`](#class-stringprompt)
- [`prompt.MessagesPrompt`](#class-messagesprompt)
- [`eval.Evaluation`](#class-evaluation): Sets up an evaluation which includes a set of scorers and a dataset.
- [`eval_imperative.EvaluationLogger`](#class-evaluationlogger): This class provides an imperative interface for logging evaluations.
- [`scorer.Scorer`](#class-scorer)
- [`annotation_spec.AnnotationSpec`](#class-annotationspec)
- [`markdown.Markdown`](#class-markdown): A Markdown renderable.
- [`monitor.Monitor`](#class-monitor): Sets up a monitor to score incoming calls automatically.
- [`saved_view.SavedView`](#class-savedview): A fluent-style class for working with SavedView objects.

## Functions

- [`api.init`](#function-init): Initialize weave tracking, logging to a wandb project.
- [`api.publish`](#function-publish): Save and version a python object.
- [`api.ref`](#function-ref): Construct a Ref to a Weave object.
- [`call_context.require_current_call`](#function-require_current_call): Get the Call object for the currently executing Op, within that Op.
- [`call_context.get_current_call`](#function-get_current_call): Get the Call object for the currently executing Op, within that Op.
- [`api.finish`](#function-finish): Stops logging to weave.
- [`op.op`](#function-op): A decorator to weave op-ify a function or method. Works for both sync and async.
- [`api.attributes`](#function-attributes): Context manager for setting attributes on a call.


---




### function `init`

```python
init(
    project_name: 'str',
    settings: 'UserSettings | dict[str, Any] | None' = None,
    autopatch_settings: 'AutopatchSettings | None' = None,
    global_postprocess_inputs: 'PostprocessInputsFunc | None' = None,
    global_postprocess_output: 'PostprocessOutputFunc | None' = None,
    global_attributes: 'dict[str, Any] | None' = None
) → WeaveClient
```

Initialize weave tracking, logging to a wandb project. 

Logging is initialized globally, so you do not need to keep a reference to the return value of init. 

Following init, calls of weave.op() decorated functions will be logged to the specified project. 



**Args:**
 
 - `project_name`:  The name of the Weights & Biases project to log to. 
 - `settings`:  Configuration for the Weave client generally. 
 - `autopatch_settings`:  Configuration for autopatch integrations, e.g. openai 
 - `global_postprocess_inputs`:  A function that will be applied to all inputs of all ops. 
 - `global_postprocess_output`:  A function that will be applied to all outputs of all ops. 
 - `global_attributes`:  A dictionary of attributes that will be applied to all traces. 

NOTE: Global postprocessing settings are applied to all ops after each op's own postprocessing.  The order is always: 1. Op-specific postprocessing 2. Global postprocessing 



**Returns:**
 A Weave client. 

---



### function `publish`

```python
publish(obj: 'Any', name: 'str | None' = None) → ObjectRef
```

Save and version a python object. 

If an object with name already exists, and the content hash of obj does not match the latest version of that object, a new version will be created. 

TODO: Need to document how name works with this change. 



**Args:**
 
 - `obj`:  The object to save and version. 
 - `name`:  The name to save the object under. 



**Returns:**
 A weave Ref to the saved object. 

---



### function `ref`

```python
ref(location: 'str') → ObjectRef
```

Construct a Ref to a Weave object. 

TODO: what happens if obj does not exist 



**Args:**
 
 - `location`:  A fully-qualified weave ref URI, or if weave.init() has been called, "name:version" or just "name" ("latest" will be used for version in this case). 





**Returns:**
 A weave Ref to the object. 

---



### function `require_current_call`

```python
require_current_call() → Call
```

Get the Call object for the currently executing Op, within that Op. 

This allows you to access attributes of the Call such as its id or feedback while it is running. 

```python
@weave.op
def hello(name: str) -> None:
     print(f"Hello {name}!")
     current_call = weave.require_current_call()
     print(current_call.id)
``` 

It is also possible to access a Call after the Op has returned. 

If you have the Call's id, perhaps from the UI, you can use the `get_call` method on the `WeaveClient` returned from `weave.init` to retrieve the Call object. 

```python
client = weave.init("")
mycall = client.get_call("")
``` 

Alternately, after defining your Op you can use its `call` method. For example: 

```python
@weave.op
def add(a: int, b: int) -> int:
     return a + b

result, call = add.call(1, 2)
print(call.id)
``` 



**Returns:**
  The Call object for the currently executing Op 



**Raises:**
 
 - `NoCurrentCallError`:  If tracking has not been initialized or this method is  invoked outside an Op. 

---



### function `get_current_call`

```python
get_current_call() → Call | None
```

Get the Call object for the currently executing Op, within that Op. 



**Returns:**
  The Call object for the currently executing Op, or  None if tracking has not been initialized or this method is  invoked outside an Op. 

---



### function `finish`

```python
finish() → None
```

Stops logging to weave. 

Following finish, calls of weave.op() decorated functions will no longer be logged. You will need to run weave.init() again to resume logging. 

---



### function `op`

```python
op(
    func: 'Callable[P, R] | None' = None,
    name: 'str | None' = None,
    call_display_name: 'str | CallDisplayNameFunc | None' = None,
    postprocess_inputs: 'PostprocessInputsFunc | None' = None,
    postprocess_output: 'PostprocessOutputFunc | None' = None,
    tracing_sample_rate: 'float' = 1.0,
    enable_code_capture: 'bool' = True
) → Callable[[Callable[P, R]], Op[P, R]] | Op[P, R]
```

A decorator to weave op-ify a function or method. Works for both sync and async. Automatically detects iterator functions and applies appropriate behavior. 

---



### function `attributes`

```python
attributes(attributes: 'dict[str, Any]') → Iterator
```

Context manager for setting attributes on a call. 



**Example:**
 

```python
with weave.attributes({'env': 'production'}):
     print(my_function.call("World"))
``` 

---



## class `Object`





**Pydantic Fields:**

- `name`: `typing.Optional[str]`
- `description`: `typing.Optional[str]`
- `ref`: `typing.Optional[trace.refs.ObjectRef]`
---



### classmethod `from_uri`

```python
from_uri(uri: str, objectify: bool = True) → Self
```





---



### classmethod `handle_relocatable_object`

```python
handle_relocatable_object(
    v: Any,
    handler: ValidatorFunctionWrapHandler,
    info: ValidationInfo
) → Any
```






---



## class `Dataset`
Dataset object with easy saving and automatic versioning 



**Examples:**
 

```python
# Create a dataset
dataset = Dataset(name='grammar', rows=[
     {'id': '0', 'sentence': "He no likes ice cream.", 'correction': "He doesn't like ice cream."},
     {'id': '1', 'sentence': "She goed to the store.", 'correction': "She went to the store."},
     {'id': '2', 'sentence': "They plays video games all day.", 'correction': "They play video games all day."}
])

# Publish the dataset
weave.publish(dataset)

# Retrieve the dataset
dataset_ref = weave.ref('grammar').get()

# Access a specific example
example_label = dataset_ref.rows[2]['sentence']
``` 


**Pydantic Fields:**

- `name`: `typing.Optional[str]`
- `description`: `typing.Optional[str]`
- `ref`: `typing.Optional[trace.refs.ObjectRef]`
- `rows`: `typing.Union[trace.table.Table, trace.vals.WeaveTable]`
---



### method `add_rows`

```python
add_rows(rows: Iterable[dict]) → Dataset
```

Create a new dataset version by appending rows to the existing dataset. 

This is useful for adding examples to large datasets without having to load the entire dataset into memory. 



**Args:**
 
 - `rows`:  The rows to add to the dataset. 



**Returns:**
 The updated dataset. 

---



### classmethod `convert_to_table`

```python
convert_to_table(rows: Any) → Union[Table, WeaveTable]
```





---



### classmethod `from_calls`

```python
from_calls(calls: Iterable[Call]) → Self
```





---



### classmethod `from_obj`

```python
from_obj(obj: WeaveObject) → Self
```





---



### classmethod `from_pandas`

```python
from_pandas(df: 'DataFrame') → Self
```





---



### method `to_pandas`

```python
to_pandas() → DataFrame
```






---



## class `Model`
Intended to capture a combination of code and data the operates on an input. For example it might call an LLM with a prompt to make a prediction or generate text. 

When you change the attributes or the code that defines your model, these changes will be logged and the version will be updated. This ensures that you can compare the predictions across different versions of your model. Use this to iterate on prompts or to try the latest LLM and compare predictions across different settings 



**Examples:**
 

```python
class YourModel(Model):
     attribute1: str
     attribute2: int

     @weave.op()
     def predict(self, input_data: str) -> dict:
         # Model logic goes here
         prediction = self.attribute1 + ' ' + input_data
         return {'pred': prediction}
``` 


**Pydantic Fields:**

- `name`: `typing.Optional[str]`
- `description`: `typing.Optional[str]`
- `ref`: `typing.Optional[trace.refs.ObjectRef]`
---



### method `get_infer_method`

```python
get_infer_method() → Callable
```






---



## class `Prompt`





**Pydantic Fields:**

- `name`: `typing.Optional[str]`
- `description`: `typing.Optional[str]`
- `ref`: `typing.Optional[trace.refs.ObjectRef]`
---



### method `format`

```python
format(**kwargs: Any) → Any
```






---



## class `StringPrompt`






### method `__init__`

```python
__init__(content: str)
```






**Pydantic Fields:**

- `name`: `typing.Optional[str]`
- `description`: `typing.Optional[str]`
- `ref`: `typing.Optional[trace.refs.ObjectRef]`
- `content`: ``
---



### method `format`

```python
format(**kwargs: Any) → str
```





---



### classmethod `from_obj`

```python
from_obj(obj: WeaveObject) → Self
```






---



## class `MessagesPrompt`






### method `__init__`

```python
__init__(messages: list[dict])
```






**Pydantic Fields:**

- `name`: `typing.Optional[str]`
- `description`: `typing.Optional[str]`
- `ref`: `typing.Optional[trace.refs.ObjectRef]`
- `messages`: `list[dict]`
---



### method `format`

```python
format(**kwargs: Any) → list
```





---



### method `format_message`

```python
format_message(message: dict, **kwargs: Any) → dict
```





---



### classmethod `from_obj`

```python
from_obj(obj: WeaveObject) → Self
```






---



## class `Evaluation`
Sets up an evaluation which includes a set of scorers and a dataset. 

Calling evaluation.evaluate(model) will pass in rows from a dataset into a model matching  the names of the columns of the dataset to the argument names in model.predict. 

Then it will call all of the scorers and save the results in weave. 

If you want to preprocess the rows from the dataset you can pass in a function to preprocess_model_input. 



**Examples:**
 

```python
# Collect your examples
examples = [
     {"question": "What is the capital of France?", "expected": "Paris"},
     {"question": "Who wrote 'To Kill a Mockingbird'?", "expected": "Harper Lee"},
     {"question": "What is the square root of 64?", "expected": "8"},
]

# Define any custom scoring function
@weave.op()
def match_score1(expected: str, model_output: dict) -> dict:
     # Here is where you'd define the logic to score the model output
     return {'match': expected == model_output['generated_text']}

@weave.op()
def function_to_evaluate(question: str):
     # here's where you would add your LLM call and return the output
     return  {'generated_text': 'Paris'}

# Score your examples using scoring functions
evaluation = Evaluation(
     dataset=examples, scorers=[match_score1]
)

# Start tracking the evaluation
weave.init('intro-example')
# Run the evaluation
asyncio.run(evaluation.evaluate(function_to_evaluate))
``` 


**Pydantic Fields:**

- `name`: `typing.Optional[str]`
- `description`: `typing.Optional[str]`
- `ref`: `typing.Optional[trace.refs.ObjectRef]`
- `dataset`: ``
- `scorers`: `typing.Optional[list[typing.Annotated[typing.Union[trace.op.Op, flow.scorer.Scorer], BeforeValidator(func=, json_schema_input_type=PydanticUndefined)]]]`
- `preprocess_model_input`: `typing.Optional[typing.Callable[[dict], dict]]`
- `trials`: ``
- `evaluation_name`: `typing.Union[str, typing.Callable[[trace.weave_client.Call], str], NoneType]`
---



### method `evaluate`

```python
evaluate(model: Union[Op, Model]) → dict
```





---



### classmethod `from_obj`

```python
from_obj(obj: WeaveObject) → Self
```





---



### method `get_eval_results`

```python
get_eval_results(model: Union[Op, Model]) → EvaluationResults
```





---



### method `predict_and_score`

```python
predict_and_score(model: Union[Op, Model], example: dict) → dict
```





---



### method `summarize`

```python
summarize(eval_table: EvaluationResults) → dict
```






---



## class `EvaluationLogger`
This class provides an imperative interface for logging evaluations. 

An evaluation is started automatically when the first prediction is logged using the `log_prediction` method, and finished when the `log_summary` method is called. 

Each time you log a prediction, you will get back a `ScoreLogger` object. You can use this object to log scores and metadata for that specific prediction. For more information, see the `ScoreLogger` class. 



**Example:**
 ```python
     ev = EvaluationLogger()
     pred = ev.log_prediction(inputs, output)
     pred.log_score(scorer_name, score)
     ev.log_summary(summary)
    ``` 


**Pydantic Fields:**

- `name`: `str | None`
- `model`: `flow.model.Model | dict | str`
- `dataset`: `flow.dataset.Dataset | list[dict] | str`
---

#### property ui_url







---



### method `finish`

```python
finish() → None
```

Clean up the evaluation resources explicitly without logging a summary. 

Ensures all prediction calls and the main evaluation call are finalized. This is automatically called if the logger is used as a context manager. 

---



### method `log_prediction`

```python
log_prediction(inputs: 'dict', output: 'Any') → ScoreLogger
```

Log a prediction to the Evaluation, and return a reference. 

The reference can be used to log scores which are attached to the specific prediction instance. 

---



### method `log_summary`

```python
log_summary(summary: 'dict | None' = None) → None
```

Log a summary dict to the Evaluation. 

This will calculate the summary, call the summarize op, and then finalize the evaluation, meaning no more predictions or scores can be logged. 


---



## class `Scorer`





**Pydantic Fields:**

- `name`: `typing.Optional[str]`
- `description`: `typing.Optional[str]`
- `ref`: `typing.Optional[trace.refs.ObjectRef]`
- `column_map`: `typing.Optional[dict[str, str]]`
---



### method `model_post_init`

```python
model_post_init(_Scorer__context: Any) → None
```





---



### method `score`

```python
score(output: Any, **kwargs: Any) → Any
```





---



### method `summarize`

```python
summarize(score_rows: list) → Optional[dict]
```






---



## class `AnnotationSpec`





**Pydantic Fields:**

- `name`: `typing.Optional[str]`
- `description`: `typing.Optional[str]`
- `field_schema`: `dict[str, typing.Any]`
- `unique_among_creators`: ``
- `op_scope`: `typing.Optional[list[str]]`
---



### classmethod `preprocess_field_schema`

```python
preprocess_field_schema(data: dict[str, Any]) → dict[str, Any]
```





---



### classmethod `validate_field_schema`

```python
validate_field_schema(schema: dict[str, Any]) → dict[str, Any]
```





---



### method `value_is_valid`

```python
value_is_valid(payload: Any) → bool
```

Validates a payload against this annotation spec's schema. 



**Args:**
 
 - `payload`:  The data to validate against the schema 



**Returns:**
 
 - `bool`:  True if validation succeeds, False otherwise 


---



## class `Markdown`
A Markdown renderable. 



**Args:**
 
 - `markup` (str):  A string containing markdown. 
 - `code_theme` (str, optional):  Pygments theme for code blocks. Defaults to "monokai". See https://pygments.org/styles/ for code themes. 
 - `justify` (JustifyMethod, optional):  Justify value for paragraphs. Defaults to None. 
 - `style` (Union[str, Style], optional):  Optional style to apply to markdown. 
 - `hyperlinks` (bool, optional):  Enable hyperlinks. Defaults to ``True``. 
 - `inline_code_lexer`:  (str, optional): Lexer to use if inline code highlighting is  enabled. Defaults to None. 
 - `inline_code_theme`:  (Optional[str], optional): Pygments theme for inline code  highlighting, or None for no highlighting. Defaults to None. 



### method `__init__`

```python
__init__(
    markup: 'str',
    code_theme: 'str' = 'monokai',
    justify: 'JustifyMethod | None' = None,
    style: 'str | Style' = 'none',
    hyperlinks: 'bool' = True,
    inline_code_lexer: 'str | None' = None,
    inline_code_theme: 'str | None' = None
) → None
```









---



## class `Monitor`
Sets up a monitor to score incoming calls automatically. 



**Examples:**
 

```python
import weave
from weave.scorers import ValidJSONScorer

json_scorer = ValidJSONScorer()

my_monitor = weave.Monitor(
     name="my-monitor",
     description="This is a test monitor",
     sampling_rate=0.5,
     op_names=["my_op"],
     query={
         "$expr": {
             "$gt": [
                 {
                         "$getField": "started_at"
                     },
                     {
                         "$literal": 1742540400
                     }
                 ]
             }
         }
     },
     scorers=[json_scorer],
)

my_monitor.activate()
``` 


**Pydantic Fields:**

- `name`: `typing.Optional[str]`
- `description`: `typing.Optional[str]`
- `ref`: `typing.Optional[trace.refs.ObjectRef]`
- `sampling_rate`: ``
- `scorers`: `list[flow.scorer.Scorer]`
- `op_names`: `list[str]`
- `query`: `typing.Optional[trace_server.interface.query.Query]`
- `active`: ``
---



### method `activate`

```python
activate() → ObjectRef
```

Activates the monitor. 



**Returns:**
  The ref to the monitor. 

---



### method `deactivate`

```python
deactivate() → ObjectRef
```

Deactivates the monitor. 



**Returns:**
  The ref to the monitor. 

---



### classmethod `from_obj`

```python
from_obj(obj: WeaveObject) → Self
```






---



## class `SavedView`
A fluent-style class for working with SavedView objects. 



### method `__init__`

```python
__init__(view_type: 'str' = 'traces', label: 'str' = 'SavedView') → None
```






---

#### property entity





---

#### property label





---

#### property project





---

#### property view_type







---



### method `add_column`

```python
add_column(path: 'str | ObjectPath', label: 'str | None' = None) → SavedView
```





---



### method `add_columns`

```python
add_columns(*columns: 'str') → SavedView
```

Convenience method for adding multiple columns to the grid. 

---



### method `add_filter`

```python
add_filter(
    field: 'str',
    operator: 'str',
    value: 'Any | None' = None
) → SavedView
```





---



### method `add_sort`

```python
add_sort(field: 'str', direction: 'SortDirection') → SavedView
```





---



### method `column_index`

```python
column_index(path: 'int | str | ObjectPath') → int
```





---



### method `filter_op`

```python
filter_op(op_name: 'str | None') → SavedView
```





---



### method `get_calls`

```python
get_calls(
    limit: 'int | None' = None,
    offset: 'int | None' = None,
    include_costs: 'bool' = False,
    include_feedback: 'bool' = False,
    all_columns: 'bool' = False
) → CallsIter
```

Get calls matching this saved view's filters and settings. 

---



### method `get_known_columns`

```python
get_known_columns(num_calls_to_query: 'int | None' = None) → list[str]
```

Get the set of columns that are known to exist. 

---



### method `get_table_columns`

```python
get_table_columns() → list[TableColumn]
```





---



### method `hide_column`

```python
hide_column(col_name: 'str') → SavedView
```





---



### method `insert_column`

```python
insert_column(
    idx: 'int',
    path: 'str | ObjectPath',
    label: 'str | None' = None
) → SavedView
```





---



### classmethod `load`

```python
load(ref: 'str') → SavedView
```





---



### method `page_size`

```python
page_size(page_size: 'int') → SavedView
```





---



### method `pin_column_left`

```python
pin_column_left(col_name: 'str') → SavedView
```





---



### method `pin_column_right`

```python
pin_column_right(col_name: 'str') → SavedView
```





---



### method `remove_column`

```python
remove_column(path: 'int | str | ObjectPath') → SavedView
```





---



### method `remove_columns`

```python
remove_columns(*columns: 'str') → SavedView
```

Remove columns from the saved view. 

---



### method `remove_filter`

```python
remove_filter(index_or_field: 'int | str') → SavedView
```





---



### method `remove_filters`

```python
remove_filters() → SavedView
```

Remove all filters from the saved view. 

---



### method `rename`

```python
rename(label: 'str') → SavedView
```





---



### method `rename_column`

```python
rename_column(path: 'int | str | ObjectPath', label: 'str') → SavedView
```





---



### method `save`

```python
save() → SavedView
```

Publish the saved view to the server. 

---



### method `set_columns`

```python
set_columns(*columns: 'str') → SavedView
```

Set the columns to be displayed in the grid. 

---



### method `show_column`

```python
show_column(col_name: 'str') → SavedView
```





---



### method `sort_by`

```python
sort_by(field: 'str', direction: 'SortDirection') → SavedView
```





---



### method `to_grid`

```python
to_grid(limit: 'int | None' = None) → Grid
```





---



### method `to_rich_table_str`

```python
to_rich_table_str() → str
```





---



### method `ui_url`

```python
ui_url() → str | None
```

URL to show this saved view in the UI. 

Note this is the "result" page with traces etc, not the URL for the view object. 

---



### method `unpin_column`

```python
unpin_column(col_name: 'str') → SavedView
```

[Source](https://weave-docs.wandb.ai/reference/python-sdk/weave/index)

<!--- Docs: Python SDK -->
<!--- Weave.Trace.Op -->

# Weave.Trace.Op

# weave.trace.op

Defines the Op protocol and related functions.

---


# API Overview





## Functions

- [`op.call`](#function-call): Executes the op and returns both the result and a Call representing the execution.
- [`op.calls`](#function-calls): Get an iterator over all calls to this op.


---




### function `call`

```python
call(
    op: 'Op',
    *args: 'Any',
    __weave: 'WeaveKwargs | None' = None,
    __should_raise: 'bool' = False,
    __require_explicit_finish: 'bool' = False,
    **kwargs: 'Any'
) → tuple[Any, Call] | Coroutine[Any, Any, tuple[Any, Call]]
```

Executes the op and returns both the result and a Call representing the execution. 

This function will never raise.  Any errors are captured in the Call object. 

This method is automatically bound to any function decorated with `@weave.op`, allowing for usage like: 

```python
@weave.op
def add(a: int, b: int) -> int:
     return a + b

result, call = add.call(1, 2)
``` 

---



### function `calls`

```python
calls(op: 'Op') → CallsIter
```

Get an iterator over all calls to this op. 

This method is automatically bound to any function decorated with `@weave.op`, allowing for usage like: 

```python
@weave.op
def add(a: int, b: int) -> int:
     return a + b

calls = add.calls()
for call in calls:
     print(call)
```

[Source](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace/weave.trace.op)

<!--- Docs: Python SDK -->
<!--- Weave.Trace.Weave Client -->

# Weave.Trace.Weave Client

# weave.trace.weave_client



---


# API Overview



## Classes

- [`weave_client.WeaveClient`](#class-weaveclient)
- [`weave_client.Call`](#class-call): A Call represents a single operation that was executed as part of a trace.

## Functions

- [`weave_client.PaginatedIterator`](#function-paginatediterator)


---




## class `WeaveClient`






### method `__init__`

```python
__init__(
    entity: 'str',
    project: 'str',
    server: 'TraceServerInterface',
    ensure_project_exists: 'bool' = True
)
```






---

#### property num_outstanding_jobs

Returns the total number of pending jobs across all executors and the server. 

This property can be used to check the progress of background tasks without blocking the main thread. 



**Returns:**
 
 - `int`:  The total number of pending jobs 



---



### method `add_cost`

```python
add_cost(
    llm_id: 'str',
    prompt_token_cost: 'float',
    completion_token_cost: 'float',
    effective_date: 'datetime | None' = datetime.datetime(2025, 4, 30, 23, 50, 40, 886784, tzinfo=datetime.timezone.utc),
    prompt_token_cost_unit: 'str | None' = 'USD',
    completion_token_cost_unit: 'str | None' = 'USD',
    provider_id: 'str | None' = 'default'
) → CostCreateRes
```

Add a cost to the current project. 



**Examples:**
 

```python
     client.add_cost(llm_id="my_expensive_custom_model", prompt_token_cost=1, completion_token_cost=2)
     client.add_cost(llm_id="my_expensive_custom_model", prompt_token_cost=500, completion_token_cost=1000, effective_date=datetime(1998, 10, 3))
    ``` 



**Args:**
 
 - `llm_id`:  The ID of the LLM. eg "gpt-4o-mini-2024-07-18" 
 - `prompt_token_cost`:  The cost per prompt token. eg .0005 
 - `completion_token_cost`:  The cost per completion token. eg .0015 
 - `effective_date`:  Defaults to the current date. A datetime.datetime object. 
 - `provider_id`:  The provider of the LLM. Defaults to "default". eg "openai" 
 - `prompt_token_cost_unit`:  The unit of the cost for the prompt tokens. Defaults to "USD". (Currently unused, will be used in the future to specify the currency type for the cost eg "tokens" or "time") 
 - `completion_token_cost_unit`:  The unit of the cost for the completion tokens. Defaults to "USD". (Currently unused, will be used in the future to specify the currency type for the cost eg "tokens" or "time") 



**Returns:**
 A CostCreateRes object. Which has one field called a list of tuples called ids. Each tuple contains the llm_id and the id of the created cost object. 

---



### method `call`

```python
call(call_id: 'str', include_costs: 'bool' = False) → WeaveObject
```





---



### method `calls`

```python
calls(
    filter: 'CallsFilter | None' = None,
    include_costs: 'bool' = False
) → CallsIter
```





---



### method `create_call`

```python
create_call(
    op: 'str | Op',
    inputs: 'dict',
    parent: 'Call | None' = None,
    attributes: 'dict | None' = None,
    display_name: 'str | Callable[[Call], str] | None' = None,
    use_stack: 'bool' = True
) → Call
```

Create, log, and push a call onto the runtime stack. 



**Args:**
 
 - `op`:  The operation producing the call, or the name of an anonymous operation. 
 - `inputs`:  The inputs to the operation. 
 - `parent`:  The parent call. If parent is not provided, the current run is used as the parent. 
 - `display_name`:  The display name for the call. Defaults to None. 
 - `attributes`:  The attributes for the call. Defaults to None. 
 - `use_stack`:  Whether to push the call onto the runtime stack. Defaults to True. 



**Returns:**
 The created Call object. 

---



### method `delete_call`

```python
delete_call(call: 'Call') → None
```





---



### method `delete_calls`

```python
delete_calls(call_ids: 'list[str]') → None
```

Delete calls by their IDs. 

Deleting a call will also delete all of its children. 



**Args:**
 
 - `call_ids`:  A list of call IDs to delete. Ex: ["2F0193e107-8fcf-7630-b576-977cc3062e2e"] 

---



### method `delete_object_version`

```python
delete_object_version(object: 'ObjectRef') → None
```





---



### method `delete_op_version`

```python
delete_op_version(op: 'OpRef') → None
```





---



### method `fail_call`

```python
fail_call(call: 'Call', exception: 'BaseException') → None
```

Fail a call with an exception. This is a convenience method for finish_call. 

---



### method `feedback`

```python
feedback(
    query: 'Query | str | None' = None,
    reaction: 'str | None' = None,
    offset: 'int' = 0,
    limit: 'int' = 100
) → FeedbackQuery
```





---



### method `finish`

```python
finish(
    use_progress_bar: 'bool' = True,
    callback: 'Callable[[FlushStatus], None] | None' = None
) → None
```

Flushes all background tasks to ensure they are processed. 

This method blocks until all currently enqueued jobs are processed, displaying a progress bar to show the status of the pending tasks. It ensures parallel processing during main thread execution and can improve performance when user code completes before data has been uploaded to the server. 



**Args:**
 
 - `use_progress_bar`:  Whether to display a progress bar during flush.  Set to False for environments where a progress bar  would not render well (e.g., CI environments). 
 - `callback`:  Optional callback function that receives status updates.  Overrides use_progress_bar. 

---



### method `finish_call`

```python
finish_call(
    call: 'Call',
    output: 'Any' = None,
    exception: 'BaseException | None' = None,
    op: 'Op | None' = None
) → None
```





---



### method `flush`

```python
flush() → None
```

Flushes background asynchronous tasks, safe to call multiple times. 

---



### method `get`

```python
get(ref: 'ObjectRef', objectify: 'bool' = True) → Any
```





---



### method `get_call`

```python
get_call(
    call_id: 'str',
    include_costs: 'bool' = False,
    include_feedback: 'bool' = False,
    columns: 'list[str] | None' = None
) → WeaveObject
```

Get a single call by its ID. 



**Args:**
 
 - `call_id`:  The ID of the call to get. 
 - `include_costs`:  If true, cost info is included at summary.weave 
 - `include_feedback`:  If true, feedback info is included at summary.weave.feedback 
 - `columns`:  A list of columns to include in the response. If None,  all columns are included. Specifying fewer columns may be more performant. 
 - `Some columns are always included`:  id, project_id, trace_id, op_name, started_at 



**Returns:**
 A call object. 

---



### method `get_calls`

```python
get_calls(
    filter: 'CallsFilter | None' = None,
    limit: 'int | None' = None,
    offset: 'int | None' = None,
    sort_by: 'list[SortBy] | None' = None,
    query: 'Query | None' = None,
    include_costs: 'bool' = False,
    include_feedback: 'bool' = False,
    columns: 'list[str] | None' = None,
    scored_by: 'str | list[str] | None' = None,
    page_size: 'int' = 1000
) → CallsIter
```

Get a list of calls. 



**Args:**
 
 - `filter`:  A filter to apply to the calls. 
 - `limit`:  The maximum number of calls to return. 
 - `offset`:  The number of calls to skip. 
 - `sort_by`:  A list of fields to sort the calls by. 
 - `query`:  A mongo-like query to filter the calls. 
 - `include_costs`:  If true, cost info is included at summary.weave 
 - `include_feedback`:  If true, feedback info is included at summary.weave.feedback 
 - `columns`:  A list of columns to include in the response. If None,  all columns are included. Specifying fewer columns may be more performant. 
 - `Some columns are always included`:  id, project_id, trace_id, op_name, started_at 
 - `scored_by`:  Accepts a list or single item. Each item is a name or ref uri of a scorer  to filter by. Multiple scorers are ANDed together. If passing in just the name,  then scores for all versions of the scorer are returned. If passing in the full ref  URI, then scores for a specific version of the scorer are returned. 
 - `page_size`:  Tune performance by changing the number of calls fetched at a time. 



**Returns:**
 An iterator of calls. 

---



### method `get_feedback`

```python
get_feedback(
    query: 'Query | str | None' = None,
    reaction: 'str | None' = None,
    offset: 'int' = 0,
    limit: 'int' = 100
) → FeedbackQuery
```

Query project for feedback. 



**Examples:**
 ```python
     # Fetch a specific feedback object.
     # Note that this still returns a collection, which is expected
     # to contain zero or one item(s).
     client.get_feedback("1B4082A3-4EDA-4BEB-BFEB-2D16ED59AA07")

     # Find all feedback objects with a specific reaction.
     client.get_feedback(reaction="👍", limit=10)
    ``` 



**Args:**
 
 - `query`:  A mongo-style query expression. For convenience, also accepts a feedback UUID string. 
 - `reaction`:  For convenience, filter by a particular reaction emoji. 
 - `offset`:  The offset to start fetching feedback objects from. 
 - `limit`:  The maximum number of feedback objects to fetch. 



**Returns:**
 A FeedbackQuery object. 

---



### method `purge_costs`

```python
purge_costs(ids: 'list[str] | str') → None
```

Purge costs from the current project. 



**Examples:**
 

```python
     client.purge_costs([ids])
     client.purge_costs(ids)
    ``` 



**Args:**
 
 - `ids`:  The cost IDs to purge. Can be a single ID or a list of IDs. 

---



### method `query_costs`

```python
query_costs(
    query: 'Query | str | None' = None,
    llm_ids: 'list[str] | None' = None,
    offset: 'int' = 0,
    limit: 'int' = 100
) → list[CostQueryOutput]
```

Query project for costs. 



**Examples:**
 

```python
     # Fetch a specific cost object.
     # Note that this still returns a collection, which is expected
     # to contain zero or one item(s).
     client.query_costs("1B4082A3-4EDA-4BEB-BFEB-2D16ED59AA07")

     # Find all cost objects with a specific reaction.
     client.query_costs(llm_ids=["gpt-4o-mini-2024-07-18"], limit=10)
    ``` 



**Args:**
 
 - `query`:  A mongo-style query expression. For convenience, also accepts a cost UUID string. 
 - `llm_ids`:  For convenience, filter for a set of llm_ids. 
 - `offset`:  The offset to start fetching cost objects from. 
 - `limit`:  The maximum number of cost objects to fetch. 



**Returns:**
 A CostQuery object. 

---



### method `save`

```python
save(val: 'Any', name: 'str', branch: 'str' = 'latest') → Any
```

Do not call directly, use weave.publish() instead. 



**Args:**
 
 - `val`:  The object to save. 
 - `name`:  The name to save the object under. 
 - `branch`:  The branch to save the object under. Defaults to "latest". 



**Returns:**
 A deserialized version of the saved object. 


---



## class `Call`
A Call represents a single operation that was executed as part of a trace. 

">

### method `__init__`

```python
__init__(
    _op_name: 'str | Future[str]',
    trace_id: 'str',
    project_id: 'str',
    parent_id: 'str | None',
    inputs: 'dict',
    id: 'str | None' = None,
    output: 'Any' = None,
    exception: 'str | None' = None,
    summary: 'dict | None' = None,
    _display_name: 'str | Callable[[Call], str] | None' = None,
    attributes: 'dict | None' = None,
    started_at: 'datetime | None' = None,
    ended_at: 'datetime | None' = None,
    deleted_at: 'datetime | None' = None,
    _children: 'list[Call]' = &lt;factory&gt;,
    _feedback: 'RefFeedbackQuery | None' = None
) → None
```






---

#### property display_name





---

#### property feedback





---

#### property func_name

The decorated function's name that produced this call. 

This is different from `op_name` which is usually the ref of the op. 

---

#### property op_name





---

#### property ref





---

#### property ui_url







---



### method `apply_scorer`

```python
apply_scorer(
    scorer: 'Op | Scorer',
    additional_scorer_kwargs: 'dict | None' = None
) → ApplyScorerResult
```

`apply_scorer` is a method that applies a Scorer to a Call. This is useful for guarding application logic with a scorer and/or monitoring the quality of critical ops. Scorers are automatically logged to Weave as Feedback and can be used in queries & analysis. 



**Args:**
 
 - `scorer`:  The Scorer to apply. 
 - `additional_scorer_kwargs`:  Additional kwargs to pass to the scorer. This is  useful for passing in additional context that is not part of the call  inputs.useful for passing in additional context that is not part of the call  inputs. 



**Returns:**
 The result of the scorer application in the form of an `ApplyScorerResult`. 

```python
class ApplyScorerSuccess:

 - `    result`:  Any

 - `    score_call`:  Call
``` 

Example usage: 

```python
my_scorer = ... # construct a scorer
prediction, prediction_call = my_op.call(input_data)
result, score_call = prediction.apply_scorer(my_scorer)
``` 

---



### method `children`

```python
children(page_size: 'int' = 1000) → CallsIter
```

Get the children of the call. 



**Args:**
 
 - `page_size`:  Tune performance by changing the number of calls fetched at a time. 



**Returns:**
 An iterator of calls. 

---



### method `delete`

```python
delete() → bool
```

Delete the call. 

---



### method `remove_display_name`

```python
remove_display_name() → None
```





---



### method `set_display_name`

```python
set_display_name(name: 'str | None') → None
```

Set the display name for the call. 



**Args:**
 
 - `name`:  The display name to set for the call. 



**Example:**
 

```python
result, call = my_function.call("World")
call.set_display_name("My Custom Display Name")
``` 

---



### method `to_dict`

```python
to_dict() → CallDict
```






---

### function `PaginatedIterator`

```python
PaginatedIterator(*args, **kwargs)
```

[Source](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace/weave.trace.weave_client)

<!--- Docs: Python SDK -->
<!--- Weave.Trace.Util -->

# Weave.Trace.Util

# weave.trace.util



---


# API Overview



## Classes

- [`util.ContextAwareThreadPoolExecutor`](#class-contextawarethreadpoolexecutor): A ThreadPoolExecutor that runs functions with the context of the caller.
- [`util.ContextAwareThread`](#class-contextawarethread): A Thread that runs functions with the context of the caller.




---




## class `ContextAwareThreadPoolExecutor`
A ThreadPoolExecutor that runs functions with the context of the caller. 

This is a drop-in replacement for concurrent.futures.ThreadPoolExecutor that ensures weave calls behave as expected inside the executor.  Weave requires certain contextvars to be set (see call_context.py), but new threads do not automatically copy context from the parent, which can cause the call context to be lost -- not good!  This class automates contextvar copying so using this executor "just works" as the user probably expects. 

You can achieve the same effect without this class by instead writing: 

```python
with concurrent.futures.ThreadPoolExecutor() as executor:
     contexts = [copy_context() for _ in range(len(vals))]

     def _wrapped_fn(*args):
         return contexts.pop().run(fn, *args)

     executor.map(_wrapped_fn, vals)
``` 



### method `__init__`

```python
__init__(*args: 'Any', **kwargs: 'Any') → None
```








---



### method `map`

```python
map(
    fn: 'Callable',
    *iterables: 'Iterable[Any]',
    timeout: 'float | None' = None,
    chunksize: 'int' = 1
) → Iterator
```





---



### method `submit`

```python
submit(fn: 'Callable', *args: 'Any', **kwargs: 'Any') → Any
```






---



## class `ContextAwareThread`
A Thread that runs functions with the context of the caller. 

This is a drop-in replacement for threading.Thread that ensures calls behave as expected inside the thread.  Weave requires certain contextvars to be set (see call_context.py), but new threads do not automatically copy context from the parent, which can cause the call context to be lost -- not good!  This class automates contextvar copying so using this thread "just works" as the user probably expects. 

You can achieve the same effect without this class by instead writing: 

```python
def run_with_context(func, *args, **kwargs):
     context = copy_context()
     def wrapper():
         context.run(func, *args, **kwargs)
     return wrapper

thread = threading.Thread(target=run_with_context(your_func, *args, **kwargs))
thread.start()
``` 



### method `__init__`

```python
__init__(*args: 'Any', **kwargs: 'Any') → None
```






---

#### property daemon

A boolean value indicating whether this thread is a daemon thread. 

This must be set before start() is called, otherwise RuntimeError is raised. Its initial value is inherited from the creating thread; the main thread is not a daemon thread and therefore all threads created in the main thread default to daemon = False. 

The entire Python program exits when only daemon threads are left. 

---

#### property ident

Thread identifier of this thread or None if it has not been started. 

This is a nonzero integer. See the get_ident() function. Thread identifiers may be recycled when a thread exits and another thread is created. The identifier is available even after the thread has exited. 

---

#### property name

A string used for identification purposes only. 

It has no semantics. Multiple threads may be given the same name. The initial name is set by the constructor. 

---

#### property native_id

Native integral thread ID of this thread, or None if it has not been started. 

This is a non-negative integer. See the get_native_id() function. This represents the Thread ID as reported by the kernel. 



---



### method `run`

```python
run() → None
```

[Source](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace/weave.trace.util)

<!--- Docs: Python SDK -->
<!--- Weave.Trace.Feedback -->

# Weave.Trace.Feedback

# weave.trace.feedback

Classes for working with feedback on a project or ref level.

---


# API Overview



## Classes

- [`feedback.Feedbacks`](#class-feedbacks): A collection of Feedback objects with utilities.
- [`feedback.FeedbackQuery`](#class-feedbackquery): Lazy-loading object for fetching feedback from the server.
- [`feedback.RefFeedbackQuery`](#class-reffeedbackquery): Object for interacting with feedback associated with a particular ref.




---




## class `Feedbacks`
A collection of Feedback objects with utilities. 



### method `__init__`

```python
__init__(
    show_refs: 'bool',
    feedbacks: 'Iterable[Feedback] | None' = None
) → None
```








---



### method `refs`

```python
refs() → Refs
```

Return the unique refs associated with these feedbacks. 


---



## class `FeedbackQuery`
Lazy-loading object for fetching feedback from the server. 



### method `__init__`

```python
__init__(
    entity: 'str',
    project: 'str',
    query: 'Query',
    offset: 'int | None' = None,
    limit: 'int | None' = None,
    show_refs: 'bool' = False
)
```








---



### method `execute`

```python
execute() → Feedbacks
```





---



### method `refresh`

```python
refresh() → Feedbacks
```





---



### method `refs`

```python
refs() → Refs
```






---



## class `RefFeedbackQuery`
Object for interacting with feedback associated with a particular ref. 



### method `__init__`

```python
__init__(ref: 'str') → None
```








---



### method `add`

```python
add(
    feedback_type: 'str',
    payload: 'dict[str, Any] | None' = None,
    creator: 'str | None' = None,
    annotation_ref: 'str | None' = None,
    **kwargs: 'dict[str, Any]'
) → str
```

Add feedback to the ref. 

feedback_type: A string identifying the type of feedback. The "wandb." prefix is reserved. creator: The name to display for the originator of the feedback. 

---



### method `add_note`

```python
add_note(note: 'str', creator: 'str | None' = None) → str
```





---



### method `add_reaction`

```python
add_reaction(emoji: 'str', creator: 'str | None' = None) → str
```





---



### method `execute`

```python
execute() → Feedbacks
```





---



### method `purge`

```python
purge(feedback_id: 'str') → None
```





---



### method `refresh`

```python
refresh() → Feedbacks
```





---



### method `refs`

```python
refs() → Refs
```

[Source](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace/weave.trace.feedback)

<!--- Docs: Python SDK -->
<!--- Weave.Trace Server Bindings.Remote Http Trace Server -->

# Weave.Trace Server Bindings.Remote Http Trace Server

# weave.trace_server_bindings.remote_http_trace_server



---


# API Overview



## Classes

- [`remote_http_trace_server.RemoteHTTPTraceServer`](#class-remotehttptraceserver)
- [`remote_http_trace_server.ServerInfoRes`](#class-serverinfores)
- [`remote_http_trace_server.StartBatchItem`](#class-startbatchitem)
- [`remote_http_trace_server.EndBatchItem`](#class-endbatchitem)
- [`remote_http_trace_server.Batch`](#class-batch)




---




## class `RemoteHTTPTraceServer`






### method `__init__`

```python
__init__(
    trace_server_url: str,
    should_batch: bool = False,
    remote_request_bytes_limit: int = 32505856
)
```








---



### method `actions_execute_batch`

```python
actions_execute_batch(
    req: Union[ActionsExecuteBatchReq, dict[str, Any]]
) → ActionsExecuteBatchRes
```





---



### method `call_end`

```python
call_end(req: Union[CallEndReq, dict[str, Any]]) → CallEndRes
```





---



### method `call_read`

```python
call_read(req: Union[CallReadReq, dict[str, Any]]) → CallReadRes
```





---



### method `call_start`

```python
call_start(req: Union[CallStartReq, dict[str, Any]]) → CallStartRes
```





---



### method `call_start_batch`

```python
call_start_batch(req: CallCreateBatchReq) → CallCreateBatchRes
```





---



### method `call_update`

```python
call_update(req: Union[CallUpdateReq, dict[str, Any]]) → CallUpdateRes
```





---



### method `calls_delete`

```python
calls_delete(req: Union[CallsDeleteReq, dict[str, Any]]) → CallsDeleteRes
```





---



### method `calls_query`

```python
calls_query(req: Union[CallsQueryReq, dict[str, Any]]) → CallsQueryRes
```





---



### method `calls_query_stats`

```python
calls_query_stats(
    req: Union[CallsQueryStatsReq, dict[str, Any]]
) → CallsQueryStatsRes
```





---



### method `calls_query_stream`

```python
calls_query_stream(
    req: Union[CallsQueryReq, dict[str, Any]]
) → Iterator[CallSchema]
```





---



### method `completions_create`

```python
completions_create(req: CompletionsCreateReq) → CompletionsCreateRes
```





---



### method `cost_create`

```python
cost_create(req: Union[CostCreateReq, dict[str, Any]]) → CostCreateRes
```





---



### method `cost_purge`

```python
cost_purge(req: Union[CostPurgeReq, dict[str, Any]]) → CostPurgeRes
```





---



### method `cost_query`

```python
cost_query(req: Union[CostQueryReq, dict[str, Any]]) → CostQueryRes
```





---



### method `ensure_project_exists`

```python
ensure_project_exists(entity: str, project: str) → EnsureProjectExistsRes
```





---



### method `feedback_create`

```python
feedback_create(
    req: Union[FeedbackCreateReq, dict[str, Any]]
) → FeedbackCreateRes
```





---



### method `feedback_purge`

```python
feedback_purge(req: Union[FeedbackPurgeReq, dict[str, Any]]) → FeedbackPurgeRes
```





---



### method `feedback_query`

```python
feedback_query(req: Union[FeedbackQueryReq, dict[str, Any]]) → FeedbackQueryRes
```





---



### method `feedback_replace`

```python
feedback_replace(
    req: Union[FeedbackReplaceReq, dict[str, Any]]
) → FeedbackReplaceRes
```





---



### method `file_content_read`

```python
file_content_read(req: FileContentReadReq) → FileContentReadRes
```





---



### method `file_create`

```python
file_create(req: FileCreateReq) → FileCreateRes
```





---



### method `files_stats`

```python
files_stats(req: FilesStatsReq) → FilesStatsRes
```





---



### classmethod `from_env`

```python
from_env(should_batch: bool = False) → RemoteHTTPTraceServer
```





---



### method `obj_create`

```python
obj_create(req: Union[ObjCreateReq, dict[str, Any]]) → ObjCreateRes
```





---



### method `obj_delete`

```python
obj_delete(req: ObjDeleteReq) → ObjDeleteRes
```





---



### method `obj_read`

```python
obj_read(req: Union[ObjReadReq, dict[str, Any]]) → ObjReadRes
```





---



### method `objs_query`

```python
objs_query(req: Union[ObjQueryReq, dict[str, Any]]) → ObjQueryRes
```





---



### method `op_create`

```python
op_create(req: Union[OpCreateReq, dict[str, Any]]) → OpCreateRes
```





---



### method `op_read`

```python
op_read(req: Union[OpReadReq, dict[str, Any]]) → OpReadRes
```





---



### method `ops_query`

```python
ops_query(req: Union[OpQueryReq, dict[str, Any]]) → OpQueryRes
```





---



### method `otel_export`

```python
otel_export(req: OtelExportReq) → OtelExportRes
```





---



### method `refs_read_batch`

```python
refs_read_batch(req: Union[RefsReadBatchReq, dict[str, Any]]) → RefsReadBatchRes
```





---



### method `server_info`

```python
server_info() → ServerInfoRes
```





---



### method `set_auth`

```python
set_auth(auth: tuple[str, str]) → None
```





---



### method `table_create`

```python
table_create(req: Union[TableCreateReq, dict[str, Any]]) → TableCreateRes
```

Similar to `calls/batch_upsert`, we can dynamically adjust the payload size due to the property that table creation can be decomposed into a series of updates. This is useful when the table creation size is too big to be sent in a single request. We can create an empty table first, then update the table with the rows. 

---



### method `table_query`

```python
table_query(req: Union[TableQueryReq, dict[str, Any]]) → TableQueryRes
```





---



### method `table_query_stats`

```python
table_query_stats(
    req: Union[TableQueryStatsReq, dict[str, Any]]
) → TableQueryStatsRes
```





---



### method `table_query_stats_batch`

```python
table_query_stats_batch(
    req: Union[TableQueryStatsReq, dict[str, Any]]
) → TableQueryStatsRes
```





---



### method `table_query_stream`

```python
table_query_stream(req: TableQueryReq) → Iterator[TableRowSchema]
```





---



### method `table_update`

```python
table_update(req: TableUpdateReq) → TableUpdateRes
```

Similar to `calls/batch_upsert`, we can dynamically adjust the payload size due to the property that table updates can be decomposed into a series of updates. 


---



## class `ServerInfoRes`





**Pydantic Fields:**

- `min_required_weave_python_version`: ``

---



## class `StartBatchItem`





**Pydantic Fields:**

- `mode`: ``
- `req`: ``

---



## class `EndBatchItem`





**Pydantic Fields:**

- `mode`: ``
- `req`: ``

---



## class `Batch`





**Pydantic Fields:**

- `batch`: `list[typing.Union[StartBatchItem, EndBatchItem]]`

[Source](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace_server_bindings/weave.trace_server_bindings.remote_http_trace_server)

<!--- Docs: Python SDK -->
<!--- Weave.Trace Server.Trace Server Interface -->

# Weave.Trace Server.Trace Server Interface

# weave.trace_server.trace_server_interface



---


# API Overview



## Classes

- [`trace_server_interface.ActionsExecuteBatchReq`](#class-actionsexecutebatchreq)
- [`trace_server_interface.ActionsExecuteBatchRes`](#class-actionsexecutebatchres)
- [`trace_server_interface.CallBatchEndMode`](#class-callbatchendmode)
- [`trace_server_interface.CallBatchStartMode`](#class-callbatchstartmode)
- [`trace_server_interface.CallCreateBatchReq`](#class-callcreatebatchreq)
- [`trace_server_interface.CallCreateBatchRes`](#class-callcreatebatchres)
- [`trace_server_interface.CallEndReq`](#class-callendreq)
- [`trace_server_interface.CallEndRes`](#class-callendres)
- [`trace_server_interface.CallReadReq`](#class-callreadreq)
- [`trace_server_interface.CallReadRes`](#class-callreadres)
- [`trace_server_interface.CallSchema`](#class-callschema)
- [`trace_server_interface.CallStartReq`](#class-callstartreq)
- [`trace_server_interface.CallStartRes`](#class-callstartres)
- [`trace_server_interface.CallUpdateReq`](#class-callupdatereq)
- [`trace_server_interface.CallUpdateRes`](#class-callupdateres)
- [`trace_server_interface.CallsDeleteReq`](#class-callsdeletereq)
- [`trace_server_interface.CallsDeleteRes`](#class-callsdeleteres)
- [`trace_server_interface.CallsFilter`](#class-callsfilter)
- [`trace_server_interface.CallsQueryReq`](#class-callsqueryreq)
- [`trace_server_interface.CallsQueryRes`](#class-callsqueryres)
- [`trace_server_interface.CallsQueryStatsReq`](#class-callsquerystatsreq)
- [`trace_server_interface.CallsQueryStatsRes`](#class-callsquerystatsres)
- [`trace_server_interface.CompletionsCreateReq`](#class-completionscreatereq)
- [`trace_server_interface.CompletionsCreateRequestInputs`](#class-completionscreaterequestinputs)
- [`trace_server_interface.CompletionsCreateRes`](#class-completionscreateres)
- [`trace_server_interface.CostCreateInput`](#class-costcreateinput)
- [`trace_server_interface.CostCreateReq`](#class-costcreatereq)
- [`trace_server_interface.CostCreateRes`](#class-costcreateres)
- [`trace_server_interface.CostPurgeReq`](#class-costpurgereq)
- [`trace_server_interface.CostPurgeRes`](#class-costpurgeres)
- [`trace_server_interface.CostQueryOutput`](#class-costqueryoutput)
- [`trace_server_interface.CostQueryReq`](#class-costqueryreq)
- [`trace_server_interface.CostQueryRes`](#class-costqueryres)
- [`trace_server_interface.EndedCallSchemaForInsert`](#class-endedcallschemaforinsert)
- [`trace_server_interface.EnsureProjectExistsRes`](#class-ensureprojectexistsres)
- [`trace_server_interface.ExportTracePartialSuccess`](#class-exporttracepartialsuccess)
- [`trace_server_interface.ExtraKeysTypedDict`](#class-extrakeystypeddict)
- [`trace_server_interface.Feedback`](#class-feedback)
- [`trace_server_interface.FeedbackCreateReq`](#class-feedbackcreatereq)
- [`trace_server_interface.FeedbackCreateRes`](#class-feedbackcreateres)
- [`trace_server_interface.FeedbackDict`](#class-feedbackdict)
- [`trace_server_interface.FeedbackPurgeReq`](#class-feedbackpurgereq)
- [`trace_server_interface.FeedbackPurgeRes`](#class-feedbackpurgeres)
- [`trace_server_interface.FeedbackQueryReq`](#class-feedbackqueryreq)
- [`trace_server_interface.FeedbackQueryRes`](#class-feedbackqueryres)
- [`trace_server_interface.FeedbackReplaceReq`](#class-feedbackreplacereq)
- [`trace_server_interface.FeedbackReplaceRes`](#class-feedbackreplaceres)
- [`trace_server_interface.FileContentReadReq`](#class-filecontentreadreq)
- [`trace_server_interface.FileContentReadRes`](#class-filecontentreadres)
- [`trace_server_interface.FileCreateReq`](#class-filecreatereq)
- [`trace_server_interface.FileCreateRes`](#class-filecreateres)
- [`trace_server_interface.FilesStatsReq`](#class-filesstatsreq)
- [`trace_server_interface.FilesStatsRes`](#class-filesstatsres)
- [`trace_server_interface.LLMCostSchema`](#class-llmcostschema)
- [`trace_server_interface.LLMUsageSchema`](#class-llmusageschema)
- [`trace_server_interface.ObjCreateReq`](#class-objcreatereq)
- [`trace_server_interface.ObjCreateRes`](#class-objcreateres)
- [`trace_server_interface.ObjDeleteReq`](#class-objdeletereq)
- [`trace_server_interface.ObjDeleteRes`](#class-objdeleteres)
- [`trace_server_interface.ObjQueryReq`](#class-objqueryreq)
- [`trace_server_interface.ObjQueryRes`](#class-objqueryres)
- [`trace_server_interface.ObjReadReq`](#class-objreadreq)
- [`trace_server_interface.ObjReadRes`](#class-objreadres)
- [`trace_server_interface.ObjSchema`](#class-objschema)
- [`trace_server_interface.ObjSchemaForInsert`](#class-objschemaforinsert)
- [`trace_server_interface.ObjectVersionFilter`](#class-objectversionfilter)
- [`trace_server_interface.OpCreateReq`](#class-opcreatereq)
- [`trace_server_interface.OpCreateRes`](#class-opcreateres)
- [`trace_server_interface.OpQueryReq`](#class-opqueryreq)
- [`trace_server_interface.OpQueryRes`](#class-opqueryres)
- [`trace_server_interface.OpReadReq`](#class-opreadreq)
- [`trace_server_interface.OpReadRes`](#class-opreadres)
- [`trace_server_interface.OpVersionFilter`](#class-opversionfilter)
- [`trace_server_interface.OtelExportReq`](#class-otelexportreq)
- [`trace_server_interface.OtelExportRes`](#class-otelexportres)
- [`trace_server_interface.RefsReadBatchReq`](#class-refsreadbatchreq)
- [`trace_server_interface.RefsReadBatchRes`](#class-refsreadbatchres)
- [`trace_server_interface.SortBy`](#class-sortby)
- [`trace_server_interface.StartedCallSchemaForInsert`](#class-startedcallschemaforinsert)
- [`trace_server_interface.SummaryInsertMap`](#class-summaryinsertmap)
- [`trace_server_interface.SummaryMap`](#class-summarymap)
- [`trace_server_interface.TableAppendSpec`](#class-tableappendspec)
- [`trace_server_interface.TableAppendSpecPayload`](#class-tableappendspecpayload)
- [`trace_server_interface.TableCreateReq`](#class-tablecreatereq)
- [`trace_server_interface.TableCreateRes`](#class-tablecreateres)
- [`trace_server_interface.TableInsertSpec`](#class-tableinsertspec)
- [`trace_server_interface.TableInsertSpecPayload`](#class-tableinsertspecpayload)
- [`trace_server_interface.TablePopSpec`](#class-tablepopspec)
- [`trace_server_interface.TablePopSpecPayload`](#class-tablepopspecpayload)
- [`trace_server_interface.TableQueryReq`](#class-tablequeryreq)
- [`trace_server_interface.TableQueryRes`](#class-tablequeryres)
- [`trace_server_interface.TableQueryStatsBatchReq`](#class-tablequerystatsbatchreq)
- [`trace_server_interface.TableQueryStatsBatchRes`](#class-tablequerystatsbatchres)
- [`trace_server_interface.TableQueryStatsReq`](#class-tablequerystatsreq)
- [`trace_server_interface.TableQueryStatsRes`](#class-tablequerystatsres)
- [`trace_server_interface.TableRowFilter`](#class-tablerowfilter)
- [`trace_server_interface.TableRowSchema`](#class-tablerowschema)
- [`trace_server_interface.TableSchemaForInsert`](#class-tableschemaforinsert)
- [`trace_server_interface.TableStatsRow`](#class-tablestatsrow)
- [`trace_server_interface.TableUpdateReq`](#class-tableupdatereq)
- [`trace_server_interface.TableUpdateRes`](#class-tableupdateres)
- [`trace_server_interface.TraceServerInterface`](#class-traceserverinterface)
- [`trace_server_interface.TraceStatus`](#class-tracestatus): An enumeration.
- [`trace_server_interface.WeaveSummarySchema`](#class-weavesummaryschema)




---




## class `ActionsExecuteBatchReq`





**Pydantic Fields:**

- `project_id`: ``
- `action_ref`: ``
- `call_ids`: `list[str]`
- `wb_user_id`: `typing.Optional[str]`

---



## class `ActionsExecuteBatchRes`






---



## class `CallBatchEndMode`





**Pydantic Fields:**

- `mode`: ``
- `req`: ``

---



## class `CallBatchStartMode`





**Pydantic Fields:**

- `mode`: ``
- `req`: ``

---



## class `CallCreateBatchReq`





**Pydantic Fields:**

- `batch`: `list[typing.Union[CallBatchStartMode, CallBatchEndMode]]`

---



## class `CallCreateBatchRes`





**Pydantic Fields:**

- `res`: `list[typing.Union[CallStartRes, CallEndRes]]`

---



## class `CallEndReq`





**Pydantic Fields:**

- `end`: ``

---



## class `CallEndRes`






---



## class `CallReadReq`





**Pydantic Fields:**

- `project_id`: ``
- `id`: ``
- `include_costs`: `typing.Optional[bool]`
- `include_storage_size`: `typing.Optional[bool]`
- `include_total_storage_size`: `typing.Optional[bool]`

---



## class `CallReadRes`





**Pydantic Fields:**

- `call`: `typing.Optional[CallSchema]`

---



## class `CallSchema`





**Pydantic Fields:**

- `id`: ``
- `project_id`: ``
- `op_name`: ``
- `display_name`: `typing.Optional[str]`
- `trace_id`: ``
- `parent_id`: `typing.Optional[str]`
- `started_at`: ``
- `attributes`: `dict[str, typing.Any]`
- `inputs`: `dict[str, typing.Any]`
- `ended_at`: `typing.Optional[datetime.datetime]`
- `exception`: `typing.Optional[str]`
- `output`: `typing.Optional[typing.Any]`
- `summary`: `typing.Optional[SummaryMap]`
- `wb_user_id`: `typing.Optional[str]`
- `wb_run_id`: `typing.Optional[str]`
- `deleted_at`: `typing.Optional[datetime.datetime]`
- `storage_size_bytes`: `typing.Optional[int]`
- `total_storage_size_bytes`: `typing.Optional[int]`
---



### method `serialize_typed_dicts`

```python
serialize_typed_dicts(v: dict[str, Any]) → dict[str, Any]
```






---



## class `CallStartReq`





**Pydantic Fields:**

- `start`: ``

---



## class `CallStartRes`





**Pydantic Fields:**

- `id`: ``
- `trace_id`: ``

---



## class `CallUpdateReq`





**Pydantic Fields:**

- `project_id`: ``
- `call_id`: ``
- `display_name`: `typing.Optional[str]`
- `wb_user_id`: `typing.Optional[str]`

---



## class `CallUpdateRes`






---



## class `CallsDeleteReq`





**Pydantic Fields:**

- `project_id`: ``
- `call_ids`: `list[str]`
- `wb_user_id`: `typing.Optional[str]`

---



## class `CallsDeleteRes`






---



## class `CallsFilter`





**Pydantic Fields:**

- `op_names`: `typing.Optional[list[str]]`
- `input_refs`: `typing.Optional[list[str]]`
- `output_refs`: `typing.Optional[list[str]]`
- `parent_ids`: `typing.Optional[list[str]]`
- `trace_ids`: `typing.Optional[list[str]]`
- `call_ids`: `typing.Optional[list[str]]`
- `trace_roots_only`: `typing.Optional[bool]`
- `wb_user_ids`: `typing.Optional[list[str]]`
- `wb_run_ids`: `typing.Optional[list[str]]`

---



## class `CallsQueryReq`





**Pydantic Fields:**

- `project_id`: ``
- `filter`: `typing.Optional[CallsFilter]`
- `limit`: `typing.Optional[int]`
- `offset`: `typing.Optional[int]`
- `sort_by`: `typing.Optional[list[SortBy]]`
- `query`: `typing.Optional[weave.trace_server.interface.query.Query]`
- `include_costs`: `typing.Optional[bool]`
- `include_feedback`: `typing.Optional[bool]`
- `include_storage_size`: `typing.Optional[bool]`
- `include_total_storage_size`: `typing.Optional[bool]`
- `columns`: `typing.Optional[list[str]]`
- `expand_columns`: `typing.Optional[list[str]]`

---



## class `CallsQueryRes`





**Pydantic Fields:**

- `calls`: `list[CallSchema]`

---



## class `CallsQueryStatsReq`





**Pydantic Fields:**

- `project_id`: ``
- `filter`: `typing.Optional[CallsFilter]`
- `query`: `typing.Optional[weave.trace_server.interface.query.Query]`
- `limit`: `typing.Optional[int]`
- `include_total_storage_size`: `typing.Optional[bool]`

---



## class `CallsQueryStatsRes`





**Pydantic Fields:**

- `count`: ``
- `total_storage_size_bytes`: `typing.Optional[int]`

---



## class `CompletionsCreateReq`





**Pydantic Fields:**

- `project_id`: ``
- `inputs`: ``
- `wb_user_id`: `typing.Optional[str]`
- `track_llm_call`: `typing.Optional[bool]`

---



## class `CompletionsCreateRequestInputs`





**Pydantic Fields:**

- `model`: ``
- `messages`: ``
- `timeout`: `typing.Union[float, str, NoneType]`
- `temperature`: `typing.Optional[float]`
- `top_p`: `typing.Optional[float]`
- `n`: `typing.Optional[int]`
- `stop`: `typing.Union[str, list, NoneType]`
- `max_completion_tokens`: `typing.Optional[int]`
- `max_tokens`: `typing.Optional[int]`
- `modalities`: `typing.Optional[list]`
- `presence_penalty`: `typing.Optional[float]`
- `frequency_penalty`: `typing.Optional[float]`
- `logit_bias`: `typing.Optional[dict]`
- `user`: `typing.Optional[str]`
- `response_format`: `typing.Union[dict, type[pydantic.main.BaseModel], NoneType]`
- `seed`: `typing.Optional[int]`
- `tools`: `typing.Optional[list]`
- `tool_choice`: `typing.Union[str, dict, NoneType]`
- `logprobs`: `typing.Optional[bool]`
- `top_logprobs`: `typing.Optional[int]`
- `parallel_tool_calls`: `typing.Optional[bool]`
- `extra_headers`: `typing.Optional[dict]`
- `functions`: `typing.Optional[list]`
- `function_call`: `typing.Optional[str]`
- `api_version`: `typing.Optional[str]`

---



## class `CompletionsCreateRes`





**Pydantic Fields:**

- `response`: `dict[str, typing.Any]`
- `weave_call_id`: `typing.Optional[str]`

---



## class `CostCreateInput`





**Pydantic Fields:**

- `prompt_token_cost`: ``
- `completion_token_cost`: ``
- `prompt_token_cost_unit`: `typing.Optional[str]`
- `completion_token_cost_unit`: `typing.Optional[str]`
- `effective_date`: `typing.Optional[datetime.datetime]`
- `provider_id`: `typing.Optional[str]`

---



## class `CostCreateReq`





**Pydantic Fields:**

- `project_id`: ``
- `costs`: `dict[str, CostCreateInput]`
- `wb_user_id`: `typing.Optional[str]`

---



## class `CostCreateRes`





**Pydantic Fields:**

- `ids`: `list[tuple[str, str]]`

---



## class `CostPurgeReq`





**Pydantic Fields:**

- `project_id`: ``
- `query`: ``

---



## class `CostPurgeRes`






---



## class `CostQueryOutput`





**Pydantic Fields:**

- `id`: `typing.Optional[str]`
- `llm_id`: `typing.Optional[str]`
- `prompt_token_cost`: `typing.Optional[float]`
- `completion_token_cost`: `typing.Optional[float]`
- `prompt_token_cost_unit`: `typing.Optional[str]`
- `completion_token_cost_unit`: `typing.Optional[str]`
- `effective_date`: `typing.Optional[datetime.datetime]`
- `provider_id`: `typing.Optional[str]`

---



## class `CostQueryReq`





**Pydantic Fields:**

- `project_id`: ``
- `fields`: `typing.Optional[list[str]]`
- `query`: `typing.Optional[weave.trace_server.interface.query.Query]`
- `sort_by`: `typing.Optional[list[SortBy]]`
- `limit`: `typing.Optional[int]`
- `offset`: `typing.Optional[int]`

---



## class `CostQueryRes`





**Pydantic Fields:**

- `results`: `list[CostQueryOutput]`

---



## class `EndedCallSchemaForInsert`





**Pydantic Fields:**

- `project_id`: ``
- `id`: ``
- `ended_at`: ``
- `exception`: `typing.Optional[str]`
- `output`: `typing.Optional[typing.Any]`
- `summary`: ``
---



### method `serialize_typed_dicts`

```python
serialize_typed_dicts(v: dict[str, Any]) → dict[str, Any]
```






---



## class `EnsureProjectExistsRes`





**Pydantic Fields:**

- `project_name`: ``

---



## class `ExportTracePartialSuccess`





**Pydantic Fields:**

- `rejected_spans`: ``
- `error_message`: ``

---



## class `ExtraKeysTypedDict`








---



## class `Feedback`





**Pydantic Fields:**

- `project_id`: ``
- `weave_ref`: ``
- `creator`: `typing.Optional[str]`
- `feedback_type`: ``
- `payload`: `dict[str, typing.Any]`
- `annotation_ref`: `typing.Optional[str]`
- `runnable_ref`: `typing.Optional[str]`
- `call_ref`: `typing.Optional[str]`
- `trigger_ref`: `typing.Optional[str]`
- `wb_user_id`: `typing.Optional[str]`
- `id`: ``
- `created_at`: ``

---



## class `FeedbackCreateReq`





**Pydantic Fields:**

- `project_id`: ``
- `weave_ref`: ``
- `creator`: `typing.Optional[str]`
- `feedback_type`: ``
- `payload`: `dict[str, typing.Any]`
- `annotation_ref`: `typing.Optional[str]`
- `runnable_ref`: `typing.Optional[str]`
- `call_ref`: `typing.Optional[str]`
- `trigger_ref`: `typing.Optional[str]`
- `wb_user_id`: `typing.Optional[str]`

---



## class `FeedbackCreateRes`





**Pydantic Fields:**

- `id`: ``
- `created_at`: ``
- `wb_user_id`: ``
- `payload`: `dict[str, typing.Any]`

---



## class `FeedbackDict`








---



## class `FeedbackPurgeReq`





**Pydantic Fields:**

- `project_id`: ``
- `query`: ``

---



## class `FeedbackPurgeRes`






---



## class `FeedbackQueryReq`





**Pydantic Fields:**

- `project_id`: ``
- `fields`: `typing.Optional[list[str]]`
- `query`: `typing.Optional[weave.trace_server.interface.query.Query]`
- `sort_by`: `typing.Optional[list[SortBy]]`
- `limit`: `typing.Optional[int]`
- `offset`: `typing.Optional[int]`

---



## class `FeedbackQueryRes`





**Pydantic Fields:**

- `result`: `list[dict[str, typing.Any]]`

---



## class `FeedbackReplaceReq`





**Pydantic Fields:**

- `project_id`: ``
- `weave_ref`: ``
- `creator`: `typing.Optional[str]`
- `feedback_type`: ``
- `payload`: `dict[str, typing.Any]`
- `annotation_ref`: `typing.Optional[str]`
- `runnable_ref`: `typing.Optional[str]`
- `call_ref`: `typing.Optional[str]`
- `trigger_ref`: `typing.Optional[str]`
- `wb_user_id`: `typing.Optional[str]`
- `feedback_id`: ``

---



## class `FeedbackReplaceRes`





**Pydantic Fields:**

- `id`: ``
- `created_at`: ``
- `wb_user_id`: ``
- `payload`: `dict[str, typing.Any]`

---



## class `FileContentReadReq`





**Pydantic Fields:**

- `project_id`: ``
- `digest`: ``

---



## class `FileContentReadRes`





**Pydantic Fields:**

- `content`: ``

---



## class `FileCreateReq`





**Pydantic Fields:**

- `project_id`: ``
- `name`: ``
- `content`: ``

---



## class `FileCreateRes`





**Pydantic Fields:**

- `digest`: ``

---



## class `FilesStatsReq`





**Pydantic Fields:**

- `project_id`: ``

---



## class `FilesStatsRes`





**Pydantic Fields:**

- `total_size_bytes`: ``

---



## class `LLMCostSchema`








---



## class `LLMUsageSchema`








---



## class `ObjCreateReq`





**Pydantic Fields:**

- `obj`: ``

---



## class `ObjCreateRes`





**Pydantic Fields:**

- `digest`: ``

---



## class `ObjDeleteReq`





**Pydantic Fields:**

- `project_id`: ``
- `object_id`: ``
- `digests`: `typing.Optional[list[str]]`

---



## class `ObjDeleteRes`





**Pydantic Fields:**

- `num_deleted`: ``

---



## class `ObjQueryReq`





**Pydantic Fields:**

- `project_id`: ``
- `filter`: `typing.Optional[ObjectVersionFilter]`
- `limit`: `typing.Optional[int]`
- `offset`: `typing.Optional[int]`
- `sort_by`: `typing.Optional[list[SortBy]]`
- `metadata_only`: `typing.Optional[bool]`
- `include_storage_size`: `typing.Optional[bool]`

---



## class `ObjQueryRes`





**Pydantic Fields:**

- `objs`: `list[ObjSchema]`

---



## class `ObjReadReq`





**Pydantic Fields:**

- `project_id`: ``
- `object_id`: ``
- `digest`: ``
- `metadata_only`: `typing.Optional[bool]`

---



## class `ObjReadRes`





**Pydantic Fields:**

- `obj`: ``

---



## class `ObjSchema`





**Pydantic Fields:**

- `project_id`: ``
- `object_id`: ``
- `created_at`: ``
- `deleted_at`: `typing.Optional[datetime.datetime]`
- `digest`: ``
- `version_index`: ``
- `is_latest`: ``
- `kind`: ``
- `base_object_class`: `typing.Optional[str]`
- `val`: `typing.Any`
- `wb_user_id`: `typing.Optional[str]`
- `size_bytes`: `typing.Optional[int]`

---



## class `ObjSchemaForInsert`





**Pydantic Fields:**

- `project_id`: ``
- `object_id`: ``
- `val`: `typing.Any`
- `builtin_object_class`: `typing.Optional[str]`
- `set_base_object_class`: `typing.Optional[str]`
- `wb_user_id`: `typing.Optional[str]`
---



### method `model_post_init`

```python
model_post_init(_ObjSchemaForInsert__context: Any) → None
```






---



## class `ObjectVersionFilter`





**Pydantic Fields:**

- `base_object_classes`: `typing.Optional[list[str]]`
- `object_ids`: `typing.Optional[list[str]]`
- `is_op`: `typing.Optional[bool]`
- `latest_only`: `typing.Optional[bool]`

---



## class `OpCreateReq`





**Pydantic Fields:**

- `op_obj`: ``

---



## class `OpCreateRes`





**Pydantic Fields:**

- `digest`: ``

---



## class `OpQueryReq`





**Pydantic Fields:**

- `project_id`: ``
- `filter`: `typing.Optional[OpVersionFilter]`

---



## class `OpQueryRes`





**Pydantic Fields:**

- `op_objs`: `list[ObjSchema]`

---



## class `OpReadReq`





**Pydantic Fields:**

- `project_id`: ``
- `name`: ``
- `digest`: ``

---



## class `OpReadRes`





**Pydantic Fields:**

- `op_obj`: ``

---



## class `OpVersionFilter`





**Pydantic Fields:**

- `op_names`: `typing.Optional[list[str]]`
- `latest_only`: `typing.Optional[bool]`

---



## class `OtelExportReq`





**Pydantic Fields:**

- `project_id`: ``
- `traces`: `typing.Any`
- `wb_user_id`: `typing.Optional[str]`

---



## class `OtelExportRes`





**Pydantic Fields:**

- `partial_success`: `typing.Optional[ExportTracePartialSuccess]`

---



## class `RefsReadBatchReq`





**Pydantic Fields:**

- `refs`: `list[str]`

---



## class `RefsReadBatchRes`





**Pydantic Fields:**

- `vals`: `list[typing.Any]`

---



## class `SortBy`





**Pydantic Fields:**

- `field`: ``
- `direction`: `typing.Literal['asc', 'desc']`

---



## class `StartedCallSchemaForInsert`





**Pydantic Fields:**

- `project_id`: ``
- `id`: `typing.Optional[str]`
- `op_name`: ``
- `display_name`: `typing.Optional[str]`
- `trace_id`: `typing.Optional[str]`
- `parent_id`: `typing.Optional[str]`
- `started_at`: ``
- `attributes`: `dict[str, typing.Any]`
- `inputs`: `dict[str, typing.Any]`
- `wb_user_id`: `typing.Optional[str]`
- `wb_run_id`: `typing.Optional[str]`

---



## class `SummaryInsertMap`








---



## class `SummaryMap`








---



## class `TableAppendSpec`





**Pydantic Fields:**

- `append`: ``

---



## class `TableAppendSpecPayload`





**Pydantic Fields:**

- `row`: `dict[str, typing.Any]`

---



## class `TableCreateReq`





**Pydantic Fields:**

- `table`: ``

---



## class `TableCreateRes`





**Pydantic Fields:**

- `digest`: ``
- `row_digests`: `list[str]`

---



## class `TableInsertSpec`





**Pydantic Fields:**

- `insert`: ``

---



## class `TableInsertSpecPayload`





**Pydantic Fields:**

- `index`: ``
- `row`: `dict[str, typing.Any]`

---



## class `TablePopSpec`





**Pydantic Fields:**

- `pop`: ``

---



## class `TablePopSpecPayload`





**Pydantic Fields:**

- `index`: ``

---



## class `TableQueryReq`





**Pydantic Fields:**

- `project_id`: ``
- `digest`: ``
- `filter`: `typing.Optional[TableRowFilter]`
- `limit`: `typing.Optional[int]`
- `offset`: `typing.Optional[int]`
- `sort_by`: `typing.Optional[list[SortBy]]`

---



## class `TableQueryRes`





**Pydantic Fields:**

- `rows`: `list[TableRowSchema]`

---



## class `TableQueryStatsBatchReq`





**Pydantic Fields:**

- `project_id`: ``
- `digests`: `typing.Optional[list[str]]`
- `include_storage_size`: `typing.Optional[bool]`

---



## class `TableQueryStatsBatchRes`





**Pydantic Fields:**

- `tables`: `list[TableStatsRow]`

---



## class `TableQueryStatsReq`





**Pydantic Fields:**

- `project_id`: ``
- `digest`: ``

---



## class `TableQueryStatsRes`





**Pydantic Fields:**

- `count`: ``

---



## class `TableRowFilter`





**Pydantic Fields:**

- `row_digests`: `typing.Optional[list[str]]`

---



## class `TableRowSchema`





**Pydantic Fields:**

- `digest`: ``
- `val`: `typing.Any`
- `original_index`: `typing.Optional[int]`

---



## class `TableSchemaForInsert`





**Pydantic Fields:**

- `project_id`: ``
- `rows`: `list[dict[str, typing.Any]]`

---



## class `TableStatsRow`





**Pydantic Fields:**

- `count`: ``
- `digest`: ``
- `storage_size_bytes`: `typing.Optional[int]`

---



## class `TableUpdateReq`





**Pydantic Fields:**

- `project_id`: ``
- `base_digest`: ``
- `updates`: `list[typing.Union[TableAppendSpec, TablePopSpec, TableInsertSpec]]`

---



## class `TableUpdateRes`





**Pydantic Fields:**

- `digest`: ``
- `updated_row_digests`: `list[str]`

---



## class `TraceServerInterface`







---



### method `actions_execute_batch`

```python
actions_execute_batch(req: ActionsExecuteBatchReq) → ActionsExecuteBatchRes
```





---



### method `call_end`

```python
call_end(req: CallEndReq) → CallEndRes
```





---



### method `call_read`

```python
call_read(req: CallReadReq) → CallReadRes
```





---



### method `call_start`

```python
call_start(req: CallStartReq) → CallStartRes
```





---



### method `call_start_batch`

```python
call_start_batch(req: CallCreateBatchReq) → CallCreateBatchRes
```





---



### method `call_update`

```python
call_update(req: CallUpdateReq) → CallUpdateRes
```





---



### method `calls_delete`

```python
calls_delete(req: CallsDeleteReq) → CallsDeleteRes
```





---



### method `calls_query`

```python
calls_query(req: CallsQueryReq) → CallsQueryRes
```





---



### method `calls_query_stats`

```python
calls_query_stats(req: CallsQueryStatsReq) → CallsQueryStatsRes
```





---



### method `calls_query_stream`

```python
calls_query_stream(req: CallsQueryReq) → Iterator[CallSchema]
```





---



### method `completions_create`

```python
completions_create(req: CompletionsCreateReq) → CompletionsCreateRes
```





---



### method `cost_create`

```python
cost_create(req: CostCreateReq) → CostCreateRes
```





---



### method `cost_purge`

```python
cost_purge(req: CostPurgeReq) → CostPurgeRes
```





---



### method `cost_query`

```python
cost_query(req: CostQueryReq) → CostQueryRes
```





---



### method `ensure_project_exists`

```python
ensure_project_exists(entity: str, project: str) → EnsureProjectExistsRes
```





---



### method `feedback_create`

```python
feedback_create(req: FeedbackCreateReq) → FeedbackCreateRes
```





---



### method `feedback_purge`

```python
feedback_purge(req: FeedbackPurgeReq) → FeedbackPurgeRes
```





---



### method `feedback_query`

```python
feedback_query(req: FeedbackQueryReq) → FeedbackQueryRes
```





---



### method `feedback_replace`

```python
feedback_replace(req: FeedbackReplaceReq) → FeedbackReplaceRes
```





---



### method `file_content_read`

```python
file_content_read(req: FileContentReadReq) → FileContentReadRes
```





---



### method `file_create`

```python
file_create(req: FileCreateReq) → FileCreateRes
```





---



### method `files_stats`

```python
files_stats(req: FilesStatsReq) → FilesStatsRes
```





---



### method `obj_create`

```python
obj_create(req: ObjCreateReq) → ObjCreateRes
```





---



### method `obj_delete`

```python
obj_delete(req: ObjDeleteReq) → ObjDeleteRes
```





---



### method `obj_read`

```python
obj_read(req: ObjReadReq) → ObjReadRes
```





---



### method `objs_query`

```python
objs_query(req: ObjQueryReq) → ObjQueryRes
```





---



### method `op_create`

```python
op_create(req: OpCreateReq) → OpCreateRes
```





---



### method `op_read`

```python
op_read(req: OpReadReq) → OpReadRes
```





---



### method `ops_query`

```python
ops_query(req: OpQueryReq) → OpQueryRes
```





---



### method `otel_export`

```python
otel_export(req: OtelExportReq) → OtelExportRes
```





---



### method `refs_read_batch`

```python
refs_read_batch(req: RefsReadBatchReq) → RefsReadBatchRes
```





---



### method `table_create`

```python
table_create(req: TableCreateReq) → TableCreateRes
```





---



### method `table_query`

```python
table_query(req: TableQueryReq) → TableQueryRes
```





---



### method `table_query_stats`

```python
table_query_stats(req: TableQueryStatsReq) → TableQueryStatsRes
```





---



### method `table_query_stats_batch`

```python
table_query_stats_batch(req: TableQueryStatsBatchReq) → TableQueryStatsBatchRes
```





---



### method `table_query_stream`

```python
table_query_stream(req: TableQueryReq) → Iterator[TableRowSchema]
```





---



### method `table_update`

```python
table_update(req: TableUpdateReq) → TableUpdateRes
```






---



## class `TraceStatus`
An enumeration. 





---



## class `WeaveSummarySchema`

[Source](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace_server/weave.trace_server.trace_server_interface)

<!--- Docs: Python SDK -->
<!--- Weave.Trace Server.Interface.Query -->

# Weave.Trace Server.Interface.Query

# weave.trace_server.interface.query


This file contains the interface definition for the Trace Server Query model. It
is heavily inspired by the MongoDB query language, but is a subset of the full
MongoDB query language. In particular, we have made the following
simplifications:

* We only support the "aggregation" operators, not the "query" operators. This is
    purely for simplicity and because the "aggregation" operators are more powerful.
    The Mongo docs language has evolved over time and the primary query language
    is column-oriented. However, the more expressive aggregation language can be
    used for both direct queries, but also for column comparison and
    calculations. We can add support for the "query" operators in the future if
    needed.

* We only support a subset of the operators / shorthand forms for now. We can add
    more operators in the future as needed.

    * One notable omission here is the lack of support for "$field" as a shorthand for
        the "getField"  operator.

* We have _added_ a `$contains` operator which is not in the MongoDB query
    language. This is a simple substring match operator.


---


# API Overview



## Classes

- [`query.AndOperation`](#class-andoperation)
- [`query.ContainsOperation`](#class-containsoperation)
- [`query.ContainsSpec`](#class-containsspec)
- [`query.ConvertOperation`](#class-convertoperation)
- [`query.ConvertSpec`](#class-convertspec)
- [`query.EqOperation`](#class-eqoperation)
- [`query.GetFieldOperator`](#class-getfieldoperator)
- [`query.GtOperation`](#class-gtoperation)
- [`query.GteOperation`](#class-gteoperation)
- [`query.InOperation`](#class-inoperation)
- [`query.LiteralOperation`](#class-literaloperation)
- [`query.NotOperation`](#class-notoperation)
- [`query.OrOperation`](#class-oroperation)
- [`query.Query`](#class-query)




---




## class `AndOperation`





**Pydantic Fields:**

- `$and`: `list['Operand']`

---



## class `ContainsOperation`





**Pydantic Fields:**

- `$contains`: ``

---



## class `ContainsSpec`





**Pydantic Fields:**

- `input`: `typing.Union[LiteralOperation, GetFieldOperator, ConvertOperation, AndOperation, OrOperation, NotOperation, EqOperation, GtOperation, GteOperation, InOperation, ContainsOperation]`
- `substr`: `typing.Union[LiteralOperation, GetFieldOperator, ConvertOperation, AndOperation, OrOperation, NotOperation, EqOperation, GtOperation, GteOperation, InOperation, ContainsOperation]`
- `case_insensitive`: `typing.Optional[bool]`

---



## class `ConvertOperation`





**Pydantic Fields:**

- `$convert`: ``

---



## class `ConvertSpec`





**Pydantic Fields:**

- `input`: `typing.Union[LiteralOperation, GetFieldOperator, ConvertOperation, AndOperation, OrOperation, NotOperation, EqOperation, GtOperation, GteOperation, InOperation, ContainsOperation]`
- `to`: `typing.Literal['double', 'string', 'int', 'bool', 'exists']`

---



## class `EqOperation`





**Pydantic Fields:**

- `$eq`: `tuple['Operand', 'Operand']`

---



## class `GetFieldOperator`





**Pydantic Fields:**

- `$getField`: ``

---



## class `GtOperation`





**Pydantic Fields:**

- `$gt`: `tuple['Operand', 'Operand']`

---



## class `GteOperation`





**Pydantic Fields:**

- `$gte`: `tuple['Operand', 'Operand']`

---



## class `InOperation`





**Pydantic Fields:**

- `$in`: `tuple['Operand', list['Operand']]`

---



## class `LiteralOperation`





**Pydantic Fields:**

- `$literal`: `typing.Union[str, int, float, bool, dict[str, 'LiteralOperation'], list['LiteralOperation'], NoneType]`

---



## class `NotOperation`





**Pydantic Fields:**

- `$not`: `tuple['Operand']`

---



## class `OrOperation`





**Pydantic Fields:**

- `$or`: `list['Operand']`

---



## class `Query`





**Pydantic Fields:**

- `$expr`: `typing.Union[AndOperation, OrOperation, NotOperation, EqOperation, GtOperation, GteOperation, InOperation, ContainsOperation]`

[Source](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace_server/interface/weave.trace_server.interface.query)



<!--- Docs: Quickstart -->
<!--- Quickstart -->

# Quickstart

# Track LLM inputs & outputs



Follow these steps to track your first call or 

## 1. Install Weave and create an API Key

**Install weave**

First install the weave library:


  
    ```bash
    pip install weave
    ```
  
  
    ```bash
    pnpm install weave
    ```
  


**Get your API key**

Then, create a Weights & Biases (W&B) account at https://wandb.ai and copy your API key from https://wandb.ai/authorize

## 2. Log a trace to a new project

To get started with tracking your first project with Weave:

- Import the `weave` library
- Call `weave.init('project-name')` to start tracking
  - You will be prompted to log in with your API key if you are not yet logged in on your machine.
  - To log to a specific W&B Team name, replace `project-name` with `team-name/project-name`
  - **NOTE:** In automated environments, you can define the environment variable `WANDB_API_KEY` with your API key to login without prompting.
- Add the `@weave.op()` decorator to the python functions you want to track

_In this example, we're using openai so you will need to add an OpenAI [API key](https://platform.openai.com/docs/quickstart/step-2-setup-your-api-key)._


  
    ```python
    import weave
    from openai import OpenAI

    client = OpenAI()

    # Weave will track the inputs, outputs and code of this function
    @weave.op()
    def extract_dinos(sentence: str) -> dict:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": """In JSON format extract a list of `dinosaurs`, with their `name`,
    their `common_name`, and whether its `diet` is a herbivore or carnivore"""
                },
                {
                    "role": "user",
                    "content": sentence
                }
                ],
                response_format={ "type": "json_object" }
            )
        return response.choices[0].message.content


    # Initialise the weave project
    weave.init('jurassic-park')

    sentence = """I watched as a Tyrannosaurus rex (T. rex) chased after a Triceratops (Trike), \
    both carnivore and herbivore locked in an ancient dance. Meanwhile, a gentle giant \
    Brachiosaurus (Brachi) calmly munched on treetops, blissfully unaware of the chaos below."""

    result = extract_dinos(sentence)
    print(result)
    ```
    When you call the `extract_dinos` function Weave will output a link to view your trace.

  
  
    ```typescript
        // highlight-next-line
    
    // highlight-next-line
    const openai = weave.wrapOpenAI(new OpenAI());

    async function extractDinos(input: string) {
      const response = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'user',
            content: `In JSON format extract a list of 'dinosaurs', with their 'name', their 'common_name', and whether its 'diet' is a herbivore or carnivore: ${input}`,
          },
        ],
      });
      return response.choices[0].message.content;
    }
    // highlight-next-line
    const extractDinosOp = weave.op(extractDinos);

    async function main() {
      // highlight-next-line
      await weave.init('examples');
      const result = await extractDinosOp(
        'I watched as a Tyrannosaurus rex (T. rex) chased after a Triceratops (Trike), both carnivore and herbivore locked in an ancient dance. Meanwhile, a gentle giant Brachiosaurus (Brachi) calmly munched on treetops, blissfully unaware of the chaos below.'
      );
      console.log(result);
    }

    main();

    ```
    When you call the `extractDinos` function Weave will output a link to view your trace.

  


## 3. Automated LLM library logging

Calls made to OpenAI, Anthropic and [many more LLM libraries](./guides/integrations/index.md) are automatically tracked with Weave, with **LLM metadata**, **token usage** and **cost** being logged automatically. If your LLM library isn't currently one of our integrations you can track calls to other LLMs libraries or frameworks easily by wrapping them with `@weave.op()`.

## 4. See traces of your application in your project

🎉 Congrats! Now, every time you call this function, weave will automatically capture the input & output data and log any changes made to the code.



## What's next?

- Follow the [Tracking flows and app metadata](/tutorial-tracing_2) to start tracking and the data flowing through your app.

[Source](https://weave-docs.wandb.ai/quickstart)



<!--- Docs: Service API -->
<!--- "Refs Read Batch" -->

# "Refs Read Batch"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Refs Read Batch"}
>


<MethodEndpoint
  method={"post"}
  path={"/refs/read_batch"}
>
  




Refs Read Batch

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"refs"}
          required={true}
          schemaName={"string[]"}
          qualifierMessage={undefined}
          schema={{"items":{"type":"string"},"type":"array","title":"Refs"}}
        >
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={"vals"}
                        required={true}
                        schemaName={"undefined[]"}
                        qualifierMessage={undefined}
                        schema={{"items":{},"type":"array","title":"Vals"}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"vals\": [\n    null\n  ]\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/refs-read-batch-refs-read-batch-post.api)

<!--- Docs: Service API -->
<!--- "Objs Query" -->

# "Objs Query"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Objs Query"}
>


<MethodEndpoint
  method={"post"}
  path={"/objs/query"}
>
  




Objs Query

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id","description":"The ID of the project to query","examples":["user/project"]}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                filter
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Filter criteria for the query. See `ObjectVersionFilter`
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"ObjectVersionFilter"}
                  value={"0-item-properties"}
                >
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          base_object_classes
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        <div
                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                        >
                          
                          
                          Filter objects by their base classes
                          
                          
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          object_ids
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        <div
                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                        >
                          
                          
                          Filter objects by their IDs
                          
                          
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          is_op
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        <div
                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                        >
                          
                          
                          Filter objects based on whether they are weave.ops or not. `True` will only return ops, `False` will return non-ops, and `None` will return all objects
                          
                          
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              boolean
                              
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          latest_only
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        <div
                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                        >
                          
                          
                          If True, return only the latest version of each object. `False` and `None` will return all versions
                          
                          
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              boolean
                              
                              
                            
                          
                        
                      
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                limit
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Maximum number of results to return
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    integer
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                offset
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Number of results to skip before returning
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    integer
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                sort_by
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Sorting criteria for the query results. Currently only supports 'object_id' and 'created_at'.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                    >
                      Array [
                    
                  <SchemaItem
                    collapsible={false}
                    name={"field"}
                    required={true}
                    schemaName={"Field (string)"}
                    qualifierMessage={undefined}
                    schema={{"type":"string","title":"Field"}}
                  >
                    
                  <SchemaItem
                    collapsible={false}
                    name={"direction"}
                    required={true}
                    schemaName={"Direction (string)"}
                    qualifierMessage={"**Possible values:** [`asc`, `desc`]"}
                    schema={{"type":"string","enum":["asc","desc"],"title":"Direction"}}
                  >
                    
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                    >
                      ]
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                metadata_only
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                If true, the `val` column is not read from the database and is empty.All other fields are returned.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    boolean
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                include_storage_size
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                If true, the `size_bytes` column is returned.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    boolean
                    
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                objs
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              <span
                                className={"openapi-schema__divider"}
                              >
                                
                              <span
                                className={"openapi-schema__required"}
                              >
                                required
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={false}
                              name={"project_id"}
                              required={true}
                              schemaName={"Project Id (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Project Id"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"object_id"}
                              required={true}
                              schemaName={"Object Id (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Object Id"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"created_at"}
                              required={true}
                              schemaName={"date-time"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","format":"date-time","title":"Created At"}}
                            >
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    deleted_at
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        string
                                        
                                        
                                      
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"digest"}
                              required={true}
                              schemaName={"Digest (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Digest"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"version_index"}
                              required={true}
                              schemaName={"Version Index (integer)"}
                              qualifierMessage={undefined}
                              schema={{"type":"integer","title":"Version Index"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"is_latest"}
                              required={true}
                              schemaName={"Is Latest (integer)"}
                              qualifierMessage={undefined}
                              schema={{"type":"integer","title":"Is Latest"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"kind"}
                              required={true}
                              schemaName={"Kind (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Kind"}}
                            >
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    base_object_class
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  <strong
                                    style={{"fontSize":"var(--ifm-code-font-size)","color":"var(--openapi-required)"}}
                                  >
                                     required
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        string
                                        
                                        
                                      
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"val"}
                              required={true}
                              schemaName={"Val"}
                              qualifierMessage={undefined}
                              schema={{"title":"Val"}}
                            >
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    wb_user_id
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  <div
                                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                  >
                                    
                                    
                                    Do not set directly. Server will automatically populate this field.
                                    
                                    
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        string
                                        
                                        
                                      
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    size_bytes
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        integer
                                        
                                        
                                      
                                    
                                  
                                
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"objs\": [\n    {\n      \"project_id\": \"string\",\n      \"object_id\": \"string\",\n      \"created_at\": \"2025-04-30T23:50:38.691Z\",\n      \"deleted_at\": \"2025-04-30T23:50:38.691Z\",\n      \"digest\": \"string\",\n      \"version_index\": 0,\n      \"is_latest\": 0,\n      \"kind\": \"string\",\n      \"base_object_class\": \"string\",\n      \"wb_user_id\": \"string\",\n      \"size_bytes\": 0\n    }\n  ]\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/objs-query-objs-query-post.api)

<!--- Docs: Service API -->
<!--- "Call Start" -->

# "Call Start"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Call Start"}
>


<MethodEndpoint
  method={"post"}
  path={"/call/start"}
>
  




Call Start

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              <span
                className={"openapi-schema__container"}
              >
                <strong
                  className={"openapi-schema__property"}
                >
                  start
                <span
                  className={"openapi-schema__name"}
                >
                   object
                <span
                  className={"openapi-schema__divider"}
                >
                  
                <span
                  className={"openapi-schema__required"}
                >
                  required
                
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <SchemaItem
                collapsible={false}
                name={"project_id"}
                required={true}
                schemaName={"Project Id (string)"}
                qualifierMessage={undefined}
                schema={{"type":"string","title":"Project Id"}}
              >
                
              <SchemaItem
                collapsible={true}
                className={"schemaItem"}
              >
                <details
                  style={{}}
                  className={"openapi-markdown__details"}
                >
                  <summary
                    style={{}}
                  >
                    
                      id
                    <span
                      style={{"opacity":"0.6"}}
                    >
                       object
                    
                  <div
                    style={{"marginLeft":"1rem"}}
                  >
                    
                  
                    <span
                      className={"badge badge--info"}
                    >
                      anyOf
                    
                      <TabItem
                        label={"MOD1"}
                        value={"0-item-properties"}
                      >
                        <div
                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                        >
                          
                          
                          string
                          
                          
                        
                      
                    
                  
                
              <SchemaItem
                collapsible={false}
                name={"op_name"}
                required={true}
                schemaName={"Op Name (string)"}
                qualifierMessage={undefined}
                schema={{"type":"string","title":"Op Name"}}
              >
                
              <SchemaItem
                collapsible={true}
                className={"schemaItem"}
              >
                <details
                  style={{}}
                  className={"openapi-markdown__details"}
                >
                  <summary
                    style={{}}
                  >
                    
                      display_name
                    <span
                      style={{"opacity":"0.6"}}
                    >
                       object
                    
                  <div
                    style={{"marginLeft":"1rem"}}
                  >
                    
                  
                    <span
                      className={"badge badge--info"}
                    >
                      anyOf
                    
                      <TabItem
                        label={"MOD1"}
                        value={"0-item-properties"}
                      >
                        <div
                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                        >
                          
                          
                          string
                          
                          
                        
                      
                    
                  
                
              <SchemaItem
                collapsible={true}
                className={"schemaItem"}
              >
                <details
                  style={{}}
                  className={"openapi-markdown__details"}
                >
                  <summary
                    style={{}}
                  >
                    
                      trace_id
                    <span
                      style={{"opacity":"0.6"}}
                    >
                       object
                    
                  <div
                    style={{"marginLeft":"1rem"}}
                  >
                    
                  
                    <span
                      className={"badge badge--info"}
                    >
                      anyOf
                    
                      <TabItem
                        label={"MOD1"}
                        value={"0-item-properties"}
                      >
                        <div
                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                        >
                          
                          
                          string
                          
                          
                        
                      
                    
                  
                
              <SchemaItem
                collapsible={true}
                className={"schemaItem"}
              >
                <details
                  style={{}}
                  className={"openapi-markdown__details"}
                >
                  <summary
                    style={{}}
                  >
                    
                      parent_id
                    <span
                      style={{"opacity":"0.6"}}
                    >
                       object
                    
                  <div
                    style={{"marginLeft":"1rem"}}
                  >
                    
                  
                    <span
                      className={"badge badge--info"}
                    >
                      anyOf
                    
                      <TabItem
                        label={"MOD1"}
                        value={"0-item-properties"}
                      >
                        <div
                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                        >
                          
                          
                          string
                          
                          
                        
                      
                    
                  
                
              <SchemaItem
                collapsible={false}
                name={"started_at"}
                required={true}
                schemaName={"date-time"}
                qualifierMessage={undefined}
                schema={{"type":"string","format":"date-time","title":"Started At"}}
              >
                
              <SchemaItem
                collapsible={false}
                name={"attributes"}
                required={true}
                schemaName={"object"}
                qualifierMessage={undefined}
                schema={{"type":"object","title":"Attributes"}}
              >
                
              <SchemaItem
                collapsible={false}
                name={"inputs"}
                required={true}
                schemaName={"object"}
                qualifierMessage={undefined}
                schema={{"type":"object","title":"Inputs"}}
              >
                
              <SchemaItem
                collapsible={true}
                className={"schemaItem"}
              >
                <details
                  style={{}}
                  className={"openapi-markdown__details"}
                >
                  <summary
                    style={{}}
                  >
                    
                      wb_user_id
                    <span
                      style={{"opacity":"0.6"}}
                    >
                       object
                    
                  <div
                    style={{"marginLeft":"1rem"}}
                  >
                    <div
                      style={{"marginTop":".5rem","marginBottom":".5rem"}}
                    >
                      
                      
                      Do not set directly. Server will automatically populate this field.
                      
                      
                    
                  
                    <span
                      className={"badge badge--info"}
                    >
                      anyOf
                    
                      <TabItem
                        label={"MOD1"}
                        value={"0-item-properties"}
                      >
                        <div
                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                        >
                          
                          
                          string
                          
                          
                        
                      
                    
                  
                
              <SchemaItem
                collapsible={true}
                className={"schemaItem"}
              >
                <details
                  style={{}}
                  className={"openapi-markdown__details"}
                >
                  <summary
                    style={{}}
                  >
                    
                      wb_run_id
                    <span
                      style={{"opacity":"0.6"}}
                    >
                       object
                    
                  <div
                    style={{"marginLeft":"1rem"}}
                  >
                    
                  
                    <span
                      className={"badge badge--info"}
                    >
                      anyOf
                    
                      <TabItem
                        label={"MOD1"}
                        value={"0-item-properties"}
                      >
                        <div
                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                        >
                          
                          
                          string
                          
                          
                        
                      
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={"id"}
                        required={true}
                        schemaName={"Id (string)"}
                        qualifierMessage={undefined}
                        schema={{"type":"string","title":"Id"}}
                      >
                        
                      <SchemaItem
                        collapsible={false}
                        name={"trace_id"}
                        required={true}
                        schemaName={"Trace Id (string)"}
                        qualifierMessage={undefined}
                        schema={{"type":"string","title":"Trace Id"}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"id\": \"string\",\n  \"trace_id\": \"string\"\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/call-start-call-start-post.api)

<!--- Docs: Service API -->
<!--- "Table Update" -->

# "Table Update"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Table Update"}
>


<MethodEndpoint
  method={"post"}
  path={"/table/update"}
>
  




Table Update

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id"}}
        >
          
        <SchemaItem
          collapsible={false}
          name={"base_digest"}
          required={true}
          schemaName={"Base Digest (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Base Digest"}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              <span
                className={"openapi-schema__container"}
              >
                <strong
                  className={"openapi-schema__property"}
                >
                  updates
                <span
                  className={"openapi-schema__name"}
                >
                   object[]
                <span
                  className={"openapi-schema__divider"}
                >
                  
                <span
                  className={"openapi-schema__required"}
                >
                  required
                
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
                <div
                  style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                >
                  Array [
                
              
                <span
                  className={"badge badge--info"}
                >
                  anyOf
                
                  <TabItem
                    label={"TableAppendSpec"}
                    value={"0-item-properties"}
                  >
                    <SchemaItem
                      collapsible={true}
                      className={"schemaItem"}
                    >
                      <details
                        style={{}}
                        className={"openapi-markdown__details"}
                      >
                        <summary
                          style={{}}
                        >
                          <span
                            className={"openapi-schema__container"}
                          >
                            <strong
                              className={"openapi-schema__property"}
                            >
                              append
                            <span
                              className={"openapi-schema__name"}
                            >
                               object
                            <span
                              className={"openapi-schema__divider"}
                            >
                              
                            <span
                              className={"openapi-schema__required"}
                            >
                              required
                            
                          
                        <div
                          style={{"marginLeft":"1rem"}}
                        >
                          <SchemaItem
                            collapsible={false}
                            name={"row"}
                            required={true}
                            schemaName={"object"}
                            qualifierMessage={undefined}
                            schema={{"type":"object","title":"Row"}}
                          >
                            
                          
                        
                      
                    
                  <TabItem
                    label={"TablePopSpec"}
                    value={"1-item-properties"}
                  >
                    <SchemaItem
                      collapsible={true}
                      className={"schemaItem"}
                    >
                      <details
                        style={{}}
                        className={"openapi-markdown__details"}
                      >
                        <summary
                          style={{}}
                        >
                          <span
                            className={"openapi-schema__container"}
                          >
                            <strong
                              className={"openapi-schema__property"}
                            >
                              pop
                            <span
                              className={"openapi-schema__name"}
                            >
                               object
                            <span
                              className={"openapi-schema__divider"}
                            >
                              
                            <span
                              className={"openapi-schema__required"}
                            >
                              required
                            
                          
                        <div
                          style={{"marginLeft":"1rem"}}
                        >
                          <SchemaItem
                            collapsible={false}
                            name={"index"}
                            required={true}
                            schemaName={"Index (integer)"}
                            qualifierMessage={undefined}
                            schema={{"type":"integer","title":"Index"}}
                          >
                            
                          
                        
                      
                    
                  <TabItem
                    label={"TableInsertSpec"}
                    value={"2-item-properties"}
                  >
                    <SchemaItem
                      collapsible={true}
                      className={"schemaItem"}
                    >
                      <details
                        style={{}}
                        className={"openapi-markdown__details"}
                      >
                        <summary
                          style={{}}
                        >
                          <span
                            className={"openapi-schema__container"}
                          >
                            <strong
                              className={"openapi-schema__property"}
                            >
                              insert
                            <span
                              className={"openapi-schema__name"}
                            >
                               object
                            <span
                              className={"openapi-schema__divider"}
                            >
                              
                            <span
                              className={"openapi-schema__required"}
                            >
                              required
                            
                          
                        <div
                          style={{"marginLeft":"1rem"}}
                        >
                          <SchemaItem
                            collapsible={false}
                            name={"index"}
                            required={true}
                            schemaName={"Index (integer)"}
                            qualifierMessage={undefined}
                            schema={{"type":"integer","title":"Index"}}
                          >
                            
                          <SchemaItem
                            collapsible={false}
                            name={"row"}
                            required={true}
                            schemaName={"object"}
                            qualifierMessage={undefined}
                            schema={{"type":"object","title":"Row"}}
                          >
                            
                          
                        
                      
                    
                  
                
              
                <div
                  style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                >
                  ]
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={"digest"}
                        required={true}
                        schemaName={"Digest (string)"}
                        qualifierMessage={undefined}
                        schema={{"type":"string","title":"Digest"}}
                      >
                        
                      <SchemaItem
                        collapsible={false}
                        name={"updated_row_digests"}
                        required={false}
                        schemaName={"string[]"}
                        qualifierMessage={undefined}
                        schema={{"items":{"type":"string"},"type":"array","title":"Updated Row Digests","description":"The digests of the rows that were updated"}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"digest\": \"string\",\n  \"updated_row_digests\": [\n    \"string\"\n  ]\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/table-update-table-update-post.api)

<!--- Docs: Service API -->
<!--- "Table Query Stats Batch" -->

# "Table Query Stats Batch"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Table Query Stats Batch"}
>


<MethodEndpoint
  method={"post"}
  path={"/table/query_stats_batch"}
>
  




Table Query Stats Batch

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id","description":"The ID of the project","examples":["my_entity/my_project"]}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                digests
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                The digests of the tables to query
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                    >
                      Array [
                    
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                    >
                      ]
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                include_storage_size
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                If true, the `storage_size_bytes` column is returned.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    boolean
                    
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                tables
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              <span
                                className={"openapi-schema__divider"}
                              >
                                
                              <span
                                className={"openapi-schema__required"}
                              >
                                required
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={false}
                              name={"count"}
                              required={true}
                              schemaName={"Count (integer)"}
                              qualifierMessage={undefined}
                              schema={{"type":"integer","title":"Count"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"digest"}
                              required={true}
                              schemaName={"Digest (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Digest"}}
                            >
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    storage_size_bytes
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        integer
                                        
                                        
                                      
                                    
                                  
                                
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"tables\": [\n    {\n      \"count\": 0,\n      \"digest\": \"string\",\n      \"storage_size_bytes\": 0\n    }\n  ]\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/table-query-stats-batch-table-query-stats-batch-post.api)

<!--- Docs: Service API -->
<!--- "Feedback Purge" -->

# "Feedback Purge"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Feedback Purge"}
>


<MethodEndpoint
  method={"post"}
  path={"/feedback/purge"}
>
  




Permanently delete feedback.

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id","examples":["entity/project"]}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              <span
                className={"openapi-schema__container"}
              >
                <strong
                  className={"openapi-schema__property"}
                >
                  query
                <span
                  className={"openapi-schema__name"}
                >
                   object
                <span
                  className={"openapi-schema__divider"}
                >
                  
                <span
                  className={"openapi-schema__required"}
                >
                  required
                
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <SchemaItem
                collapsible={false}
                name={"$expr"}
                required={true}
                schemaName={"object"}
                qualifierMessage={undefined}
                schema={{"title":"$Expr","type":"object"}}
              >
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={""}
                        required={false}
                        schemaName={"object"}
                        qualifierMessage={undefined}
                        schema={{}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/feedback-purge-feedback-purge-post.api)

<!--- Docs: Service API -->
<!--- "Table Query" -->

# "Table Query"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Table Query"}
>


<MethodEndpoint
  method={"post"}
  path={"/table/query"}
>
  




Table Query

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id","description":"The ID of the project","examples":["my_entity/my_project"]}}
        >
          
        <SchemaItem
          collapsible={false}
          name={"digest"}
          required={true}
          schemaName={"Digest (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Digest","description":"The digest of the table to query","examples":["aonareimsvtl13apimtalpa4435rpmgnaemrpgmarltarstaorsnte134avrims"]}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                filter
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Optional filter to apply to the query. See `TableRowFilter` for more details.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"TableRowFilter"}
                  value={"0-item-properties"}
                >
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          row_digests
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        <div
                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                        >
                          
                          
                          List of row digests to filter by
                          
                          
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                limit
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Maximum number of rows to return
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    integer
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                offset
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Number of rows to skip before starting to return rows
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    integer
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                sort_by
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                List of fields to sort by. Fields can be dot-separated to access dictionary values. No sorting uses the default table order (insertion order).
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                    >
                      Array [
                    
                  <SchemaItem
                    collapsible={false}
                    name={"field"}
                    required={true}
                    schemaName={"Field (string)"}
                    qualifierMessage={undefined}
                    schema={{"type":"string","title":"Field"}}
                  >
                    
                  <SchemaItem
                    collapsible={false}
                    name={"direction"}
                    required={true}
                    schemaName={"Direction (string)"}
                    qualifierMessage={"**Possible values:** [`asc`, `desc`]"}
                    schema={{"type":"string","enum":["asc","desc"],"title":"Direction"}}
                  >
                    
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                    >
                      ]
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                rows
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              <span
                                className={"openapi-schema__divider"}
                              >
                                
                              <span
                                className={"openapi-schema__required"}
                              >
                                required
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={false}
                              name={"digest"}
                              required={true}
                              schemaName={"Digest (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Digest"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"val"}
                              required={true}
                              schemaName={"Val"}
                              qualifierMessage={undefined}
                              schema={{"title":"Val"}}
                            >
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    original_index
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        integer
                                        
                                        
                                      
                                    
                                  
                                
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"rows\": [\n    {\n      \"digest\": \"string\",\n      \"original_index\": 0\n    }\n  ]\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/table-query-table-query-post.api)

<!--- Docs: Service API -->
<!--- "Calls Query Stream" -->

# "Calls Query Stream"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Calls Query Stream"}
>


<MethodEndpoint
  method={"post"}
  path={"/calls/stream_query"}
>
  




Calls Query Stream

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<details
  style={{"marginBottom":"1rem"}}
  className={"openapi-markdown__details"}
  data-collapsed={false}
  open={true}
>
  <summary
    style={{}}
  >
    <h3
      className={"openapi-markdown__details-summary-header-params"}
    >
      Header Parameters
    
  
    
      <ParamsItem
        className={"paramsItem"}
        param={{"name":"accept","in":"header","required":false,"schema":{"type":"string","default":"application/jsonl","title":"Accept"}}}
      >
        
      
    
  
<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id"}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                filter
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"CallsFilter"}
                  value={"0-item-properties"}
                >
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          op_names
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          input_refs
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          output_refs
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          parent_ids
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          trace_ids
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          call_ids
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          trace_roots_only
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              boolean
                              
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          wb_user_ids
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          wb_run_ids
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                limit
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    integer
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                offset
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    integer
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                sort_by
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                    >
                      Array [
                    
                  <SchemaItem
                    collapsible={false}
                    name={"field"}
                    required={true}
                    schemaName={"Field (string)"}
                    qualifierMessage={undefined}
                    schema={{"type":"string","title":"Field"}}
                  >
                    
                  <SchemaItem
                    collapsible={false}
                    name={"direction"}
                    required={true}
                    schemaName={"Direction (string)"}
                    qualifierMessage={"**Possible values:** [`asc`, `desc`]"}
                    schema={{"type":"string","enum":["asc","desc"],"title":"Direction"}}
                  >
                    
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                    >
                      ]
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                query
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"Query"}
                  value={"0-item-properties"}
                >
                  <SchemaItem
                    collapsible={false}
                    name={"$expr"}
                    required={true}
                    schemaName={"object"}
                    qualifierMessage={undefined}
                    schema={{"title":"$Expr","type":"object"}}
                  >
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                include_costs
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Beta, subject to change. If true, the response will include any model costs for each call.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    boolean
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                include_feedback
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Beta, subject to change. If true, the response will include feedback for each call.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    boolean
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                include_storage_size
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Beta, subject to change. If true, the response will include the storage size for a call.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    boolean
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                include_total_storage_size
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Beta, subject to change. If true, the response will include the total storage size for a trace.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    boolean
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                columns
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                    >
                      Array [
                    
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                    >
                      ]
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                expand_columns
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Columns to expand, i.e. refs to other objects
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                    >
                      Array [
                    
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                    >
                      ]
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      any
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/calls-query-stream-calls-stream-query-post.api)

<!--- Docs: Service API -->
<!--- "Cost Create" -->

# "Cost Create"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Cost Create"}
>


<MethodEndpoint
  method={"post"}
  path={"/cost/create"}
>
  




Cost Create

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id","examples":["entity/project"]}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              <span
                className={"openapi-schema__container"}
              >
                <strong
                  className={"openapi-schema__property"}
                >
                  costs
                <span
                  className={"openapi-schema__name"}
                >
                   object
                <span
                  className={"openapi-schema__divider"}
                >
                  
                <span
                  className={"openapi-schema__required"}
                >
                  required
                
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <SchemaItem
                collapsible={true}
                className={"schemaItem"}
              >
                <details
                  style={{}}
                  className={"openapi-markdown__details"}
                >
                  <summary
                    style={{}}
                  >
                    <span
                      className={"openapi-schema__container"}
                    >
                      <strong
                        className={"openapi-schema__property"}
                      >
                        property name*
                      <span
                        className={"openapi-schema__name"}
                      >
                         CostCreateInput
                      
                    
                  <div
                    style={{"marginLeft":"1rem"}}
                  >
                    <SchemaItem
                      collapsible={false}
                      name={"prompt_token_cost"}
                      required={true}
                      schemaName={"Prompt Token Cost (number)"}
                      qualifierMessage={undefined}
                      schema={{"type":"number","title":"Prompt Token Cost"}}
                    >
                      
                    <SchemaItem
                      collapsible={false}
                      name={"completion_token_cost"}
                      required={true}
                      schemaName={"Completion Token Cost (number)"}
                      qualifierMessage={undefined}
                      schema={{"type":"number","title":"Completion Token Cost"}}
                    >
                      
                    <SchemaItem
                      collapsible={true}
                      className={"schemaItem"}
                    >
                      <details
                        style={{}}
                        className={"openapi-markdown__details"}
                      >
                        <summary
                          style={{}}
                        >
                          
                            prompt_token_cost_unit
                          <span
                            style={{"opacity":"0.6"}}
                          >
                             object
                          
                        <div
                          style={{"marginLeft":"1rem"}}
                        >
                          <div
                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                          >
                            
                            
                            The unit of the cost for the prompt tokens
                            
                            
                          
                        
                          <span
                            className={"badge badge--info"}
                          >
                            anyOf
                          
                            <TabItem
                              label={"MOD1"}
                              value={"0-item-properties"}
                            >
                              <div
                                style={{"marginTop":".5rem","marginBottom":".5rem"}}
                              >
                                
                                
                                string
                                
                                
                              
                            
                          
                        
                      
                    <SchemaItem
                      collapsible={true}
                      className={"schemaItem"}
                    >
                      <details
                        style={{}}
                        className={"openapi-markdown__details"}
                      >
                        <summary
                          style={{}}
                        >
                          
                            completion_token_cost_unit
                          <span
                            style={{"opacity":"0.6"}}
                          >
                             object
                          
                        <div
                          style={{"marginLeft":"1rem"}}
                        >
                          <div
                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                          >
                            
                            
                            The unit of the cost for the completion tokens
                            
                            
                          
                        
                          <span
                            className={"badge badge--info"}
                          >
                            anyOf
                          
                            <TabItem
                              label={"MOD1"}
                              value={"0-item-properties"}
                            >
                              <div
                                style={{"marginTop":".5rem","marginBottom":".5rem"}}
                              >
                                
                                
                                string
                                
                                
                              
                            
                          
                        
                      
                    <SchemaItem
                      collapsible={true}
                      className={"schemaItem"}
                    >
                      <details
                        style={{}}
                        className={"openapi-markdown__details"}
                      >
                        <summary
                          style={{}}
                        >
                          
                            effective_date
                          <span
                            style={{"opacity":"0.6"}}
                          >
                             object
                          
                        <div
                          style={{"marginLeft":"1rem"}}
                        >
                          <div
                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                          >
                            
                            
                            The date after which the cost is effective for, will default to the current date if not provided
                            
                            
                          
                        
                          <span
                            className={"badge badge--info"}
                          >
                            anyOf
                          
                            <TabItem
                              label={"MOD1"}
                              value={"0-item-properties"}
                            >
                              <div
                                style={{"marginTop":".5rem","marginBottom":".5rem"}}
                              >
                                
                                
                                string
                                
                                
                              
                            
                          
                        
                      
                    <SchemaItem
                      collapsible={true}
                      className={"schemaItem"}
                    >
                      <details
                        style={{}}
                        className={"openapi-markdown__details"}
                      >
                        <summary
                          style={{}}
                        >
                          
                            provider_id
                          <span
                            style={{"opacity":"0.6"}}
                          >
                             object
                          
                        <div
                          style={{"marginLeft":"1rem"}}
                        >
                          <div
                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                          >
                            
                            
                            The provider of the LLM, e.g. 'openai' or 'mistral'. If not provided, the provider_id will be set to 'default'
                            
                            
                          
                        
                          <span
                            className={"badge badge--info"}
                          >
                            anyOf
                          
                            <TabItem
                              label={"MOD1"}
                              value={"0-item-properties"}
                            >
                              <div
                                style={{"marginTop":".5rem","marginBottom":".5rem"}}
                              >
                                
                                
                                string
                                
                                
                              
                            
                          
                        
                      
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                wb_user_id
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Do not set directly. Server will automatically populate this field.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={"ids"}
                        required={true}
                        schemaName={"array[]"}
                        qualifierMessage={"**Possible values:** `>= 2`, `<= 2`"}
                        schema={{"items":{"prefixItems":[{"type":"string"},{"type":"string"}],"type":"array","maxItems":2,"minItems":2},"type":"array","title":"Ids"}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"ids\": [\n    [\n      null\n    ]\n  ]\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/cost-create-cost-create-post.api)

<!--- Docs: Service API -->
<!--- "Read Root" -->

# "Read Root"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Read Root"}
>


<MethodEndpoint
  method={"get"}
  path={"/health"}
>
  




Read Root


  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      any

[Source](https://weave-docs.wandb.ai/reference/service-api/read-root-health-get.api)

<!--- Docs: Service API -->
<!--- "Calls Delete" -->

# "Calls Delete"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Calls Delete"}
>


<MethodEndpoint
  method={"post"}
  path={"/calls/delete"}
>
  




Calls Delete

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id"}}
        >
          
        <SchemaItem
          collapsible={false}
          name={"call_ids"}
          required={true}
          schemaName={"string[]"}
          qualifierMessage={undefined}
          schema={{"items":{"type":"string"},"type":"array","title":"Call Ids"}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                wb_user_id
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Do not set directly. Server will automatically populate this field.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={""}
                        required={false}
                        schemaName={"object"}
                        qualifierMessage={undefined}
                        schema={{}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/calls-delete-calls-delete-post.api)

<!--- Docs: Service API -->
<!--- "Call Update" -->

# "Call Update"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Call Update"}
>


<MethodEndpoint
  method={"post"}
  path={"/call/update"}
>
  




Call Update

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id"}}
        >
          
        <SchemaItem
          collapsible={false}
          name={"call_id"}
          required={true}
          schemaName={"Call Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Call Id"}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                display_name
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                wb_user_id
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Do not set directly. Server will automatically populate this field.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={""}
                        required={false}
                        schemaName={"object"}
                        qualifierMessage={undefined}
                        schema={{}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/call-update-call-update-post.api)

<!--- Docs: Service API -->
<!--- "Read Version" -->

# "Read Version"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Read Version"}
>


<MethodEndpoint
  method={"get"}
  path={"/version"}
>
  




Read Version


  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      any

[Source](https://weave-docs.wandb.ai/reference/service-api/read-version-version-get.api)

<!--- Docs: Service API -->
<!--- "Table Query Stats" -->

# "Table Query Stats"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Table Query Stats"}
>


<MethodEndpoint
  method={"post"}
  path={"/table/query_stats"}
>
  




Table Query Stats

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id","description":"The ID of the project","examples":["my_entity/my_project"]}}
        >
          
        <SchemaItem
          collapsible={false}
          name={"digest"}
          required={true}
          schemaName={"Digest (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Digest","description":"The digest of the table to query"}}
        >
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={"count"}
                        required={true}
                        schemaName={"Count (integer)"}
                        qualifierMessage={undefined}
                        schema={{"type":"integer","title":"Count"}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"count\": 0\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/table-query-stats-table-query-stats-post.api)

<!--- Docs: Service API -->
<!--- "FastAPI" -->

# "FastAPI"

<span
  className={"theme-doc-version-badge badge badge--secondary"}
  children={"Version: 0.1.0"}
>


<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"FastAPI"}
>






<div
  style={{"marginBottom":"2rem"}}
>
  <Heading
    id={"authentication"}
    as={"h2"}
    className={"openapi-tabs__heading"}
    children={"Authentication"}
  >
  <SchemaTabs
    className={"openapi-tabs__security-schemes"}
  >
    <TabItem
      label={"HTTP: Basic Auth"}
      value={"HTTPBasic"}
    >
      
      
      
      
      
        
          
            
              
                Security Scheme Type:
              
                http
              
            
              
                HTTP Authorization Scheme:
              
                basic

[Source](https://weave-docs.wandb.ai/reference/service-api/fastapi.info)

<!--- Docs: Service API -->
<!--- "Obj Read" -->

# "Obj Read"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Obj Read"}
>


<MethodEndpoint
  method={"post"}
  path={"/obj/read"}
>
  




Obj Read

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id"}}
        >
          
        <SchemaItem
          collapsible={false}
          name={"object_id"}
          required={true}
          schemaName={"Object Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Object Id"}}
        >
          
        <SchemaItem
          collapsible={false}
          name={"digest"}
          required={true}
          schemaName={"Digest (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Digest"}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                metadata_only
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                If true, the `val` column is not read from the database and is empty.All other fields are returned.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    boolean
                    
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                obj
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object
                              <span
                                className={"openapi-schema__divider"}
                              >
                                
                              <span
                                className={"openapi-schema__required"}
                              >
                                required
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            <SchemaItem
                              collapsible={false}
                              name={"project_id"}
                              required={true}
                              schemaName={"Project Id (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Project Id"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"object_id"}
                              required={true}
                              schemaName={"Object Id (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Object Id"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"created_at"}
                              required={true}
                              schemaName={"date-time"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","format":"date-time","title":"Created At"}}
                            >
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    deleted_at
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        string
                                        
                                        
                                      
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"digest"}
                              required={true}
                              schemaName={"Digest (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Digest"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"version_index"}
                              required={true}
                              schemaName={"Version Index (integer)"}
                              qualifierMessage={undefined}
                              schema={{"type":"integer","title":"Version Index"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"is_latest"}
                              required={true}
                              schemaName={"Is Latest (integer)"}
                              qualifierMessage={undefined}
                              schema={{"type":"integer","title":"Is Latest"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"kind"}
                              required={true}
                              schemaName={"Kind (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Kind"}}
                            >
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    base_object_class
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  <strong
                                    style={{"fontSize":"var(--ifm-code-font-size)","color":"var(--openapi-required)"}}
                                  >
                                     required
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        string
                                        
                                        
                                      
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"val"}
                              required={true}
                              schemaName={"Val"}
                              qualifierMessage={undefined}
                              schema={{"title":"Val"}}
                            >
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    wb_user_id
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  <div
                                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                  >
                                    
                                    
                                    Do not set directly. Server will automatically populate this field.
                                    
                                    
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        string
                                        
                                        
                                      
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    size_bytes
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        integer
                                        
                                        
                                      
                                    
                                  
                                
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"obj\": {\n    \"project_id\": \"string\",\n    \"object_id\": \"string\",\n    \"created_at\": \"2025-04-30T23:50:38.689Z\",\n    \"deleted_at\": \"2025-04-30T23:50:38.689Z\",\n    \"digest\": \"string\",\n    \"version_index\": 0,\n    \"is_latest\": 0,\n    \"kind\": \"string\",\n    \"base_object_class\": \"string\",\n    \"wb_user_id\": \"string\",\n    \"size_bytes\": 0\n  }\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/obj-read-obj-read-post.api)

<!--- Docs: Service API -->
<!--- "Table Create" -->

# "Table Create"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Table Create"}
>


<MethodEndpoint
  method={"post"}
  path={"/table/create"}
>
  




Table Create

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              <span
                className={"openapi-schema__container"}
              >
                <strong
                  className={"openapi-schema__property"}
                >
                  table
                <span
                  className={"openapi-schema__name"}
                >
                   object
                <span
                  className={"openapi-schema__divider"}
                >
                  
                <span
                  className={"openapi-schema__required"}
                >
                  required
                
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <SchemaItem
                collapsible={false}
                name={"project_id"}
                required={true}
                schemaName={"Project Id (string)"}
                qualifierMessage={undefined}
                schema={{"type":"string","title":"Project Id"}}
              >
                
              <SchemaItem
                collapsible={false}
                name={"rows"}
                required={true}
                schemaName={"object[]"}
                qualifierMessage={undefined}
                schema={{"items":{"type":"object"},"type":"array","title":"Rows"}}
              >
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={"digest"}
                        required={true}
                        schemaName={"Digest (string)"}
                        qualifierMessage={undefined}
                        schema={{"type":"string","title":"Digest"}}
                      >
                        
                      <SchemaItem
                        collapsible={false}
                        name={"row_digests"}
                        required={false}
                        schemaName={"string[]"}
                        qualifierMessage={undefined}
                        schema={{"items":{"type":"string"},"type":"array","title":"Row Digests","description":"The digests of the rows that were created"}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"digest\": \"string\",\n  \"row_digests\": [\n    \"string\"\n  ]\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/table-create-table-create-post.api)

<!--- Docs: Service API -->
<!--- "Server Info" -->

# "Server Info"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Server Info"}
>


<MethodEndpoint
  method={"get"}
  path={"/server_info"}
>
  




Server Info


  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={"min_required_weave_python_version"}
                        required={true}
                        schemaName={"Min Required Weave Python Version (string)"}
                        qualifierMessage={undefined}
                        schema={{"type":"string","title":"Min Required Weave Python Version"}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"min_required_weave_python_version\": \"string\"\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/server-info-server-info-get.api)

<!--- Docs: Service API -->
<!--- "Obj Create" -->

# "Obj Create"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Obj Create"}
>


<MethodEndpoint
  method={"post"}
  path={"/obj/create"}
>
  




Obj Create

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              <span
                className={"openapi-schema__container"}
              >
                <strong
                  className={"openapi-schema__property"}
                >
                  obj
                <span
                  className={"openapi-schema__name"}
                >
                   object
                <span
                  className={"openapi-schema__divider"}
                >
                  
                <span
                  className={"openapi-schema__required"}
                >
                  required
                
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <SchemaItem
                collapsible={false}
                name={"project_id"}
                required={true}
                schemaName={"Project Id (string)"}
                qualifierMessage={undefined}
                schema={{"type":"string","title":"Project Id"}}
              >
                
              <SchemaItem
                collapsible={false}
                name={"object_id"}
                required={true}
                schemaName={"Object Id (string)"}
                qualifierMessage={undefined}
                schema={{"type":"string","title":"Object Id"}}
              >
                
              <SchemaItem
                collapsible={false}
                name={"val"}
                required={true}
                schemaName={"Val"}
                qualifierMessage={undefined}
                schema={{"title":"Val"}}
              >
                
              <SchemaItem
                collapsible={true}
                className={"schemaItem"}
              >
                <details
                  style={{}}
                  className={"openapi-markdown__details"}
                >
                  <summary
                    style={{}}
                  >
                    
                      builtin_object_class
                    <span
                      style={{"opacity":"0.6"}}
                    >
                       object
                    
                  <div
                    style={{"marginLeft":"1rem"}}
                  >
                    
                  
                    <span
                      className={"badge badge--info"}
                    >
                      anyOf
                    
                      <TabItem
                        label={"MOD1"}
                        value={"0-item-properties"}
                      >
                        <div
                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                        >
                          
                          
                          string
                          
                          
                        
                      
                    
                  
                
              <SchemaItem
                collapsible={true}
                className={"schemaItem"}
              >
                <details
                  style={{}}
                  className={"openapi-markdown__details"}
                >
                  <summary
                    style={{}}
                  >
                    
                      set_base_object_class
                    <span
                      style={{"opacity":"0.6"}}
                    >
                       object
                    
                  <div
                    style={{"marginLeft":"1rem"}}
                  >
                    
                  
                    <span
                      className={"badge badge--info"}
                    >
                      anyOf
                    
                      <TabItem
                        label={"MOD1"}
                        value={"0-item-properties"}
                      >
                        <div
                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                        >
                          
                          
                          string
                          
                          
                        
                      
                    
                  
                
              <SchemaItem
                collapsible={true}
                className={"schemaItem"}
              >
                <details
                  style={{}}
                  className={"openapi-markdown__details"}
                >
                  <summary
                    style={{}}
                  >
                    
                      wb_user_id
                    <span
                      style={{"opacity":"0.6"}}
                    >
                       object
                    
                  <div
                    style={{"marginLeft":"1rem"}}
                  >
                    <div
                      style={{"marginTop":".5rem","marginBottom":".5rem"}}
                    >
                      
                      
                      Do not set directly. Server will automatically populate this field.
                      
                      
                    
                  
                    <span
                      className={"badge badge--info"}
                    >
                      anyOf
                    
                      <TabItem
                        label={"MOD1"}
                        value={"0-item-properties"}
                      >
                        <div
                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                        >
                          
                          
                          string
                          
                          
                        
                      
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={"digest"}
                        required={true}
                        schemaName={"Digest (string)"}
                        qualifierMessage={undefined}
                        schema={{"type":"string","title":"Digest"}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"digest\": \"string\"\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/obj-create-obj-create-post.api)

<!--- Docs: Service API -->
<!--- "Feedback Create" -->

# "Feedback Create"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Feedback Create"}
>


<MethodEndpoint
  method={"post"}
  path={"/feedback/create"}
>
  




Add feedback to a call or object.

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id","examples":["entity/project"]}}
        >
          
        <SchemaItem
          collapsible={false}
          name={"weave_ref"}
          required={true}
          schemaName={"Weave Ref (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Weave Ref","examples":["weave:///entity/project/object/name:digest"]}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                creator
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={false}
          name={"feedback_type"}
          required={true}
          schemaName={"Feedback Type (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Feedback Type","examples":["custom"]}}
        >
          
        <SchemaItem
          collapsible={false}
          name={"payload"}
          required={true}
          schemaName={"object"}
          qualifierMessage={undefined}
          schema={{"type":"object","title":"Payload","examples":[{"key":"value"}]}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                annotation_ref
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                runnable_ref
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                call_ref
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                trigger_ref
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                wb_user_id
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Do not set directly. Server will automatically populate this field.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={"id"}
                        required={true}
                        schemaName={"Id (string)"}
                        qualifierMessage={undefined}
                        schema={{"type":"string","title":"Id"}}
                      >
                        
                      <SchemaItem
                        collapsible={false}
                        name={"created_at"}
                        required={true}
                        schemaName={"date-time"}
                        qualifierMessage={undefined}
                        schema={{"type":"string","format":"date-time","title":"Created At"}}
                      >
                        
                      <SchemaItem
                        collapsible={false}
                        name={"wb_user_id"}
                        required={true}
                        schemaName={"Wb User Id (string)"}
                        qualifierMessage={undefined}
                        schema={{"type":"string","title":"Wb User Id"}}
                      >
                        
                      <SchemaItem
                        collapsible={false}
                        name={"payload"}
                        required={true}
                        schemaName={"object"}
                        qualifierMessage={undefined}
                        schema={{"type":"object","title":"Payload"}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"id\": \"string\",\n  \"created_at\": \"2025-04-30T23:50:38.708Z\",\n  \"wb_user_id\": \"string\",\n  \"payload\": {}\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/feedback-create-feedback-create-post.api)

<!--- Docs: Service API -->
<!--- "Call End" -->

# "Call End"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Call End"}
>


<MethodEndpoint
  method={"post"}
  path={"/call/end"}
>
  




Call End

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              <span
                className={"openapi-schema__container"}
              >
                <strong
                  className={"openapi-schema__property"}
                >
                  end
                <span
                  className={"openapi-schema__name"}
                >
                   object
                <span
                  className={"openapi-schema__divider"}
                >
                  
                <span
                  className={"openapi-schema__required"}
                >
                  required
                
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <SchemaItem
                collapsible={false}
                name={"project_id"}
                required={true}
                schemaName={"Project Id (string)"}
                qualifierMessage={undefined}
                schema={{"type":"string","title":"Project Id"}}
              >
                
              <SchemaItem
                collapsible={false}
                name={"id"}
                required={true}
                schemaName={"Id (string)"}
                qualifierMessage={undefined}
                schema={{"type":"string","title":"Id"}}
              >
                
              <SchemaItem
                collapsible={false}
                name={"ended_at"}
                required={true}
                schemaName={"date-time"}
                qualifierMessage={undefined}
                schema={{"type":"string","format":"date-time","title":"Ended At"}}
              >
                
              <SchemaItem
                collapsible={true}
                className={"schemaItem"}
              >
                <details
                  style={{}}
                  className={"openapi-markdown__details"}
                >
                  <summary
                    style={{}}
                  >
                    
                      exception
                    <span
                      style={{"opacity":"0.6"}}
                    >
                       object
                    
                  <div
                    style={{"marginLeft":"1rem"}}
                  >
                    
                  
                    <span
                      className={"badge badge--info"}
                    >
                      anyOf
                    
                      <TabItem
                        label={"MOD1"}
                        value={"0-item-properties"}
                      >
                        <div
                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                        >
                          
                          
                          string
                          
                          
                        
                      
                    
                  
                
              <SchemaItem
                collapsible={false}
                name={"output"}
                required={false}
                schemaName={"object"}
                qualifierMessage={undefined}
                schema={{"title":"Output","type":"object"}}
              >
                
              <SchemaItem
                collapsible={true}
                className={"schemaItem"}
              >
                <details
                  style={{}}
                  className={"openapi-markdown__details"}
                >
                  <summary
                    style={{}}
                  >
                    <span
                      className={"openapi-schema__container"}
                    >
                      <strong
                        className={"openapi-schema__property"}
                      >
                        summary
                      <span
                        className={"openapi-schema__name"}
                      >
                         object
                      <span
                        className={"openapi-schema__divider"}
                      >
                        
                      <span
                        className={"openapi-schema__required"}
                      >
                        required
                      
                    
                  <div
                    style={{"marginLeft":"1rem"}}
                  >
                    <SchemaItem
                      collapsible={true}
                      className={"schemaItem"}
                    >
                      <details
                        style={{}}
                        className={"openapi-markdown__details"}
                      >
                        <summary
                          style={{}}
                        >
                          <span
                            className={"openapi-schema__container"}
                          >
                            <strong
                              className={"openapi-schema__property"}
                            >
                              usage
                            <span
                              className={"openapi-schema__name"}
                            >
                               object
                            
                          
                        <div
                          style={{"marginLeft":"1rem"}}
                        >
                          <SchemaItem
                            collapsible={true}
                            className={"schemaItem"}
                          >
                            <details
                              style={{}}
                              className={"openapi-markdown__details"}
                            >
                              <summary
                                style={{}}
                              >
                                <span
                                  className={"openapi-schema__container"}
                                >
                                  <strong
                                    className={"openapi-schema__property"}
                                  >
                                    property name*
                                  <span
                                    className={"openapi-schema__name"}
                                  >
                                     LLMUsageSchema
                                  
                                
                              <div
                                style={{"marginLeft":"1rem"}}
                              >
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        prompt_tokens
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            integer
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        input_tokens
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            integer
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        completion_tokens
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            integer
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        output_tokens
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            integer
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        requests
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            integer
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        total_tokens
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            integer
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                
                              
                            
                          
                        
                      
                    <SchemaItem
                      name={"property name*"}
                      required={false}
                      schemaName={"any"}
                      qualifierMessage={undefined}
                      schema={{"properties":{"usage":{"additionalProperties":{"properties":{"prompt_tokens":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Prompt Tokens"},"input_tokens":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Input Tokens"},"completion_tokens":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Completion Tokens"},"output_tokens":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Output Tokens"},"requests":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Requests"},"total_tokens":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Total Tokens"}},"type":"object","title":"LLMUsageSchema"},"type":"object","title":"Usage"}},"additionalProperties":true,"type":"object","title":"SummaryInsertMap"}}
                      collapsible={false}
                      discriminator={false}
                    >
                      
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={""}
                        required={false}
                        schemaName={"object"}
                        qualifierMessage={undefined}
                        schema={{}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/call-end-call-end-post.api)

<!--- Docs: Service API -->
<!--- "File Content" -->

# "File Content"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"File Content"}
>


<MethodEndpoint
  method={"post"}
  path={"/file/content"}
>
  




File Content

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id"}}
        >
          
        <SchemaItem
          collapsible={false}
          name={"digest"}
          required={true}
          schemaName={"Digest (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Digest"}}
        >
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      any
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/file-content-file-content-post.api)

<!--- Docs: Service API -->
<!--- "Cost Purge" -->

# "Cost Purge"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Cost Purge"}
>


<MethodEndpoint
  method={"post"}
  path={"/cost/purge"}
>
  




Cost Purge

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id","examples":["entity/project"]}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              <span
                className={"openapi-schema__container"}
              >
                <strong
                  className={"openapi-schema__property"}
                >
                  query
                <span
                  className={"openapi-schema__name"}
                >
                   object
                <span
                  className={"openapi-schema__divider"}
                >
                  
                <span
                  className={"openapi-schema__required"}
                >
                  required
                
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <SchemaItem
                collapsible={false}
                name={"$expr"}
                required={true}
                schemaName={"object"}
                qualifierMessage={undefined}
                schema={{"title":"$Expr","type":"object"}}
              >
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={""}
                        required={false}
                        schemaName={"object"}
                        qualifierMessage={undefined}
                        schema={{}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/cost-purge-cost-purge-post.api)

<!--- Docs: Service API -->
<!--- "Export Trace" -->

# "Export Trace"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Export Trace"}
>


<MethodEndpoint
  method={"post"}
  path={"/otel/v1/traces"}
>
  




Export Trace


  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      any
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/export-trace-otel-v-1-traces-post.api)

<!--- Docs: Service API -->
<!--- "Feedback Query" -->

# "Feedback Query"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Feedback Query"}
>


<MethodEndpoint
  method={"post"}
  path={"/feedback/query"}
>
  




Query for feedback.

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id","examples":["entity/project"]}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                fields
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                    >
                      Array [
                    
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                    >
                      ]
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                query
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"Query"}
                  value={"0-item-properties"}
                >
                  <SchemaItem
                    collapsible={false}
                    name={"$expr"}
                    required={true}
                    schemaName={"object"}
                    qualifierMessage={undefined}
                    schema={{"title":"$Expr","type":"object"}}
                  >
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                sort_by
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                    >
                      Array [
                    
                  <SchemaItem
                    collapsible={false}
                    name={"field"}
                    required={true}
                    schemaName={"Field (string)"}
                    qualifierMessage={undefined}
                    schema={{"type":"string","title":"Field"}}
                  >
                    
                  <SchemaItem
                    collapsible={false}
                    name={"direction"}
                    required={true}
                    schemaName={"Direction (string)"}
                    qualifierMessage={"**Possible values:** [`asc`, `desc`]"}
                    schema={{"type":"string","enum":["asc","desc"],"title":"Direction"}}
                  >
                    
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                    >
                      ]
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                limit
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    integer
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                offset
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    integer
                    
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={"result"}
                        required={true}
                        schemaName={"object[]"}
                        qualifierMessage={undefined}
                        schema={{"items":{"type":"object"},"type":"array","title":"Result"}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"result\": [\n    {}\n  ]\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/feedback-query-feedback-query-post.api)

<!--- Docs: Service API -->
<!--- "Call Read" -->

# "Call Read"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Call Read"}
>


<MethodEndpoint
  method={"post"}
  path={"/call/read"}
>
  




Call Read

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id"}}
        >
          
        <SchemaItem
          collapsible={false}
          name={"id"}
          required={true}
          schemaName={"Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Id"}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                include_costs
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    boolean
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                include_storage_size
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    boolean
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                include_total_storage_size
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    boolean
                    
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            
                              call
                            <span
                              style={{"opacity":"0.6"}}
                            >
                               object
                            <strong
                              style={{"fontSize":"var(--ifm-code-font-size)","color":"var(--openapi-required)"}}
                            >
                               required
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                          
                            <span
                              className={"badge badge--info"}
                            >
                              anyOf
                            
                              <TabItem
                                label={"CallSchema"}
                                value={"0-item-properties"}
                              >
                                <SchemaItem
                                  collapsible={false}
                                  name={"id"}
                                  required={true}
                                  schemaName={"Id (string)"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"string","title":"Id"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={false}
                                  name={"project_id"}
                                  required={true}
                                  schemaName={"Project Id (string)"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"string","title":"Project Id"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={false}
                                  name={"op_name"}
                                  required={true}
                                  schemaName={"Op Name (string)"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"string","title":"Op Name"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        display_name
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            string
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={false}
                                  name={"trace_id"}
                                  required={true}
                                  schemaName={"Trace Id (string)"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"string","title":"Trace Id"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        parent_id
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            string
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={false}
                                  name={"started_at"}
                                  required={true}
                                  schemaName={"date-time"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"string","format":"date-time","title":"Started At"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={false}
                                  name={"attributes"}
                                  required={true}
                                  schemaName={"object"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"object","title":"Attributes"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={false}
                                  name={"inputs"}
                                  required={true}
                                  schemaName={"object"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"object","title":"Inputs"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        ended_at
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            string
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        exception
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            string
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={false}
                                  name={"output"}
                                  required={false}
                                  schemaName={"object"}
                                  qualifierMessage={undefined}
                                  schema={{"title":"Output","type":"object"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={false}
                                  name={"summary"}
                                  required={false}
                                  schemaName={"object"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"object"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        wb_user_id
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            string
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        wb_run_id
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            string
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        deleted_at
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            string
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        storage_size_bytes
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            integer
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        total_storage_size_bytes
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            integer
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"call\": {}\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/call-read-call-read-post.api)

<!--- Docs: Service API -->
<!--- "Calls Query Stats" -->

# "Calls Query Stats"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Calls Query Stats"}
>


<MethodEndpoint
  method={"post"}
  path={"/calls/query_stats"}
>
  




Calls Query Stats

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id"}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                filter
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"CallsFilter"}
                  value={"0-item-properties"}
                >
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          op_names
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          input_refs
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          output_refs
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          parent_ids
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          trace_ids
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          call_ids
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          trace_roots_only
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              boolean
                              
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          wb_user_ids
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  <SchemaItem
                    collapsible={true}
                    className={"schemaItem"}
                  >
                    <details
                      style={{}}
                      className={"openapi-markdown__details"}
                    >
                      <summary
                        style={{}}
                      >
                        
                          wb_run_ids
                        <span
                          style={{"opacity":"0.6"}}
                        >
                           object
                        
                      <div
                        style={{"marginLeft":"1rem"}}
                      >
                        
                      
                        <span
                          className={"badge badge--info"}
                        >
                          anyOf
                        
                          <TabItem
                            label={"MOD1"}
                            value={"0-item-properties"}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <div
                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                            >
                              
                              
                              string
                              
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                query
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"Query"}
                  value={"0-item-properties"}
                >
                  <SchemaItem
                    collapsible={false}
                    name={"$expr"}
                    required={true}
                    schemaName={"object"}
                    qualifierMessage={undefined}
                    schema={{"title":"$Expr","type":"object"}}
                  >
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                limit
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    integer
                    
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={"count"}
                        required={true}
                        schemaName={"Count (integer)"}
                        qualifierMessage={undefined}
                        schema={{"type":"integer","title":"Count"}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"count\": 0\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/calls-query-stats-calls-query-stats-post.api)

<!--- Docs: Service API -->
<!--- "File Create" -->

# "File Create"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"File Create"}
>


<MethodEndpoint
  method={"post"}
  path={"/file/create"}
>
  




File Create

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"multipart/form-data"}
    value={"multipart/form-data-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id"}}
        >
          
        <SchemaItem
          collapsible={false}
          name={"file"}
          required={true}
          schemaName={"binary"}
          qualifierMessage={undefined}
          schema={{"type":"string","format":"binary","title":"File"}}
        >
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={"digest"}
                        required={true}
                        schemaName={"Digest (string)"}
                        qualifierMessage={undefined}
                        schema={{"type":"string","title":"Digest"}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"digest\": \"string\"\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/file-create-file-create-post.api)

<!--- Docs: Service API -->
<!--- "Cost Query" -->

# "Cost Query"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Cost Query"}
>


<MethodEndpoint
  method={"post"}
  path={"/cost/query"}
>
  




Cost Query

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id","examples":["entity/project"]}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                fields
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                    >
                      Array [
                    
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                    >
                      ]
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                query
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"Query"}
                  value={"0-item-properties"}
                >
                  <SchemaItem
                    collapsible={false}
                    name={"$expr"}
                    required={true}
                    schemaName={"object"}
                    qualifierMessage={undefined}
                    schema={{"title":"$Expr","type":"object"}}
                  >
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                sort_by
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                    >
                      Array [
                    
                  <SchemaItem
                    collapsible={false}
                    name={"field"}
                    required={true}
                    schemaName={"Field (string)"}
                    qualifierMessage={undefined}
                    schema={{"type":"string","title":"Field"}}
                  >
                    
                  <SchemaItem
                    collapsible={false}
                    name={"direction"}
                    required={true}
                    schemaName={"Direction (string)"}
                    qualifierMessage={"**Possible values:** [`asc`, `desc`]"}
                    schema={{"type":"string","enum":["asc","desc"],"title":"Direction"}}
                  >
                    
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                    >
                      ]
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                limit
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    integer
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                offset
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    integer
                    
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                results
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              <span
                                className={"openapi-schema__divider"}
                              >
                                
                              <span
                                className={"openapi-schema__required"}
                              >
                                required
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    id
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        string
                                        
                                        
                                      
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    llm_id
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        string
                                        
                                        
                                      
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    prompt_token_cost
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        number
                                        
                                        
                                      
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    completion_token_cost
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        number
                                        
                                        
                                      
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    prompt_token_cost_unit
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        string
                                        
                                        
                                      
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    completion_token_cost_unit
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        string
                                        
                                        
                                      
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    effective_date
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        string
                                        
                                        
                                      
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  
                                    provider_id
                                  <span
                                    style={{"opacity":"0.6"}}
                                  >
                                     object
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                
                                  <span
                                    className={"badge badge--info"}
                                  >
                                    anyOf
                                  
                                    <TabItem
                                      label={"MOD1"}
                                      value={"0-item-properties"}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        string
                                        
                                        
                                      
                                    
                                  
                                
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"results\": [\n    {\n      \"id\": \"string\",\n      \"llm_id\": \"string\",\n      \"prompt_token_cost\": 0,\n      \"completion_token_cost\": 0,\n      \"prompt_token_cost_unit\": \"string\",\n      \"completion_token_cost_unit\": \"string\",\n      \"effective_date\": \"2025-04-30T23:50:38.705Z\",\n      \"provider_id\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/cost-query-cost-query-post.api)

<!--- Docs: Service API -->
<!--- "Call Start Batch" -->

# "Call Start Batch"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Call Start Batch"}
>


<MethodEndpoint
  method={"post"}
  path={"/call/upsert_batch"}
>
  




Call Start Batch

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              <span
                className={"openapi-schema__container"}
              >
                <strong
                  className={"openapi-schema__property"}
                >
                  batch
                <span
                  className={"openapi-schema__name"}
                >
                   object[]
                <span
                  className={"openapi-schema__divider"}
                >
                  
                <span
                  className={"openapi-schema__required"}
                >
                  required
                
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
                <div
                  style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                >
                  Array [
                
              
                <span
                  className={"badge badge--info"}
                >
                  anyOf
                
                  <TabItem
                    label={"CallBatchStartMode"}
                    value={"0-item-properties"}
                  >
                    <SchemaItem
                      collapsible={false}
                      name={"mode"}
                      required={false}
                      schemaName={"Mode (string)"}
                      qualifierMessage={undefined}
                      schema={{"type":"string","title":"Mode","default":"start"}}
                    >
                      
                    <SchemaItem
                      collapsible={true}
                      className={"schemaItem"}
                    >
                      <details
                        style={{}}
                        className={"openapi-markdown__details"}
                      >
                        <summary
                          style={{}}
                        >
                          <span
                            className={"openapi-schema__container"}
                          >
                            <strong
                              className={"openapi-schema__property"}
                            >
                              req
                            <span
                              className={"openapi-schema__name"}
                            >
                               object
                            <span
                              className={"openapi-schema__divider"}
                            >
                              
                            <span
                              className={"openapi-schema__required"}
                            >
                              required
                            
                          
                        <div
                          style={{"marginLeft":"1rem"}}
                        >
                          <SchemaItem
                            collapsible={true}
                            className={"schemaItem"}
                          >
                            <details
                              style={{}}
                              className={"openapi-markdown__details"}
                            >
                              <summary
                                style={{}}
                              >
                                <span
                                  className={"openapi-schema__container"}
                                >
                                  <strong
                                    className={"openapi-schema__property"}
                                  >
                                    start
                                  <span
                                    className={"openapi-schema__name"}
                                  >
                                     object
                                  <span
                                    className={"openapi-schema__divider"}
                                  >
                                    
                                  <span
                                    className={"openapi-schema__required"}
                                  >
                                    required
                                  
                                
                              <div
                                style={{"marginLeft":"1rem"}}
                              >
                                <SchemaItem
                                  collapsible={false}
                                  name={"project_id"}
                                  required={true}
                                  schemaName={"Project Id (string)"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"string","title":"Project Id"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        id
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            string
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={false}
                                  name={"op_name"}
                                  required={true}
                                  schemaName={"Op Name (string)"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"string","title":"Op Name"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        display_name
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            string
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        trace_id
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            string
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        parent_id
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            string
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={false}
                                  name={"started_at"}
                                  required={true}
                                  schemaName={"date-time"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"string","format":"date-time","title":"Started At"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={false}
                                  name={"attributes"}
                                  required={true}
                                  schemaName={"object"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"object","title":"Attributes"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={false}
                                  name={"inputs"}
                                  required={true}
                                  schemaName={"object"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"object","title":"Inputs"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        wb_user_id
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      <div
                                        style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                      >
                                        
                                        
                                        Do not set directly. Server will automatically populate this field.
                                        
                                        
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            string
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        wb_run_id
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            string
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                
                              
                            
                          
                        
                      
                    
                  <TabItem
                    label={"CallBatchEndMode"}
                    value={"1-item-properties"}
                  >
                    <SchemaItem
                      collapsible={false}
                      name={"mode"}
                      required={false}
                      schemaName={"Mode (string)"}
                      qualifierMessage={undefined}
                      schema={{"type":"string","title":"Mode","default":"end"}}
                    >
                      
                    <SchemaItem
                      collapsible={true}
                      className={"schemaItem"}
                    >
                      <details
                        style={{}}
                        className={"openapi-markdown__details"}
                      >
                        <summary
                          style={{}}
                        >
                          <span
                            className={"openapi-schema__container"}
                          >
                            <strong
                              className={"openapi-schema__property"}
                            >
                              req
                            <span
                              className={"openapi-schema__name"}
                            >
                               object
                            <span
                              className={"openapi-schema__divider"}
                            >
                              
                            <span
                              className={"openapi-schema__required"}
                            >
                              required
                            
                          
                        <div
                          style={{"marginLeft":"1rem"}}
                        >
                          <SchemaItem
                            collapsible={true}
                            className={"schemaItem"}
                          >
                            <details
                              style={{}}
                              className={"openapi-markdown__details"}
                            >
                              <summary
                                style={{}}
                              >
                                <span
                                  className={"openapi-schema__container"}
                                >
                                  <strong
                                    className={"openapi-schema__property"}
                                  >
                                    end
                                  <span
                                    className={"openapi-schema__name"}
                                  >
                                     object
                                  <span
                                    className={"openapi-schema__divider"}
                                  >
                                    
                                  <span
                                    className={"openapi-schema__required"}
                                  >
                                    required
                                  
                                
                              <div
                                style={{"marginLeft":"1rem"}}
                              >
                                <SchemaItem
                                  collapsible={false}
                                  name={"project_id"}
                                  required={true}
                                  schemaName={"Project Id (string)"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"string","title":"Project Id"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={false}
                                  name={"id"}
                                  required={true}
                                  schemaName={"Id (string)"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"string","title":"Id"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={false}
                                  name={"ended_at"}
                                  required={true}
                                  schemaName={"date-time"}
                                  qualifierMessage={undefined}
                                  schema={{"type":"string","format":"date-time","title":"Ended At"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      
                                        exception
                                      <span
                                        style={{"opacity":"0.6"}}
                                      >
                                         object
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      
                                    
                                      <span
                                        className={"badge badge--info"}
                                      >
                                        anyOf
                                      
                                        <TabItem
                                          label={"MOD1"}
                                          value={"0-item-properties"}
                                        >
                                          <div
                                            style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                          >
                                            
                                            
                                            string
                                            
                                            
                                          
                                        
                                      
                                    
                                  
                                <SchemaItem
                                  collapsible={false}
                                  name={"output"}
                                  required={false}
                                  schemaName={"object"}
                                  qualifierMessage={undefined}
                                  schema={{"title":"Output","type":"object"}}
                                >
                                  
                                <SchemaItem
                                  collapsible={true}
                                  className={"schemaItem"}
                                >
                                  <details
                                    style={{}}
                                    className={"openapi-markdown__details"}
                                  >
                                    <summary
                                      style={{}}
                                    >
                                      <span
                                        className={"openapi-schema__container"}
                                      >
                                        <strong
                                          className={"openapi-schema__property"}
                                        >
                                          summary
                                        <span
                                          className={"openapi-schema__name"}
                                        >
                                           object
                                        <span
                                          className={"openapi-schema__divider"}
                                        >
                                          
                                        <span
                                          className={"openapi-schema__required"}
                                        >
                                          required
                                        
                                      
                                    <div
                                      style={{"marginLeft":"1rem"}}
                                    >
                                      <SchemaItem
                                        collapsible={true}
                                        className={"schemaItem"}
                                      >
                                        <details
                                          style={{}}
                                          className={"openapi-markdown__details"}
                                        >
                                          <summary
                                            style={{}}
                                          >
                                            <span
                                              className={"openapi-schema__container"}
                                            >
                                              <strong
                                                className={"openapi-schema__property"}
                                              >
                                                usage
                                              <span
                                                className={"openapi-schema__name"}
                                              >
                                                 object
                                              
                                            
                                          <div
                                            style={{"marginLeft":"1rem"}}
                                          >
                                            <SchemaItem
                                              collapsible={true}
                                              className={"schemaItem"}
                                            >
                                              <details
                                                style={{}}
                                                className={"openapi-markdown__details"}
                                              >
                                                <summary
                                                  style={{}}
                                                >
                                                  <span
                                                    className={"openapi-schema__container"}
                                                  >
                                                    <strong
                                                      className={"openapi-schema__property"}
                                                    >
                                                      property name*
                                                    <span
                                                      className={"openapi-schema__name"}
                                                    >
                                                       LLMUsageSchema
                                                    
                                                  
                                                <div
                                                  style={{"marginLeft":"1rem"}}
                                                >
                                                  <SchemaItem
                                                    collapsible={true}
                                                    className={"schemaItem"}
                                                  >
                                                    <details
                                                      style={{}}
                                                      className={"openapi-markdown__details"}
                                                    >
                                                      <summary
                                                        style={{}}
                                                      >
                                                        
                                                          prompt_tokens
                                                        <span
                                                          style={{"opacity":"0.6"}}
                                                        >
                                                           object
                                                        
                                                      <div
                                                        style={{"marginLeft":"1rem"}}
                                                      >
                                                        
                                                      
                                                        <span
                                                          className={"badge badge--info"}
                                                        >
                                                          anyOf
                                                        
                                                          <TabItem
                                                            label={"MOD1"}
                                                            value={"0-item-properties"}
                                                          >
                                                            <div
                                                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                                            >
                                                              
                                                              
                                                              integer
                                                              
                                                              
                                                            
                                                          
                                                        
                                                      
                                                    
                                                  <SchemaItem
                                                    collapsible={true}
                                                    className={"schemaItem"}
                                                  >
                                                    <details
                                                      style={{}}
                                                      className={"openapi-markdown__details"}
                                                    >
                                                      <summary
                                                        style={{}}
                                                      >
                                                        
                                                          input_tokens
                                                        <span
                                                          style={{"opacity":"0.6"}}
                                                        >
                                                           object
                                                        
                                                      <div
                                                        style={{"marginLeft":"1rem"}}
                                                      >
                                                        
                                                      
                                                        <span
                                                          className={"badge badge--info"}
                                                        >
                                                          anyOf
                                                        
                                                          <TabItem
                                                            label={"MOD1"}
                                                            value={"0-item-properties"}
                                                          >
                                                            <div
                                                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                                            >
                                                              
                                                              
                                                              integer
                                                              
                                                              
                                                            
                                                          
                                                        
                                                      
                                                    
                                                  <SchemaItem
                                                    collapsible={true}
                                                    className={"schemaItem"}
                                                  >
                                                    <details
                                                      style={{}}
                                                      className={"openapi-markdown__details"}
                                                    >
                                                      <summary
                                                        style={{}}
                                                      >
                                                        
                                                          completion_tokens
                                                        <span
                                                          style={{"opacity":"0.6"}}
                                                        >
                                                           object
                                                        
                                                      <div
                                                        style={{"marginLeft":"1rem"}}
                                                      >
                                                        
                                                      
                                                        <span
                                                          className={"badge badge--info"}
                                                        >
                                                          anyOf
                                                        
                                                          <TabItem
                                                            label={"MOD1"}
                                                            value={"0-item-properties"}
                                                          >
                                                            <div
                                                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                                            >
                                                              
                                                              
                                                              integer
                                                              
                                                              
                                                            
                                                          
                                                        
                                                      
                                                    
                                                  <SchemaItem
                                                    collapsible={true}
                                                    className={"schemaItem"}
                                                  >
                                                    <details
                                                      style={{}}
                                                      className={"openapi-markdown__details"}
                                                    >
                                                      <summary
                                                        style={{}}
                                                      >
                                                        
                                                          output_tokens
                                                        <span
                                                          style={{"opacity":"0.6"}}
                                                        >
                                                           object
                                                        
                                                      <div
                                                        style={{"marginLeft":"1rem"}}
                                                      >
                                                        
                                                      
                                                        <span
                                                          className={"badge badge--info"}
                                                        >
                                                          anyOf
                                                        
                                                          <TabItem
                                                            label={"MOD1"}
                                                            value={"0-item-properties"}
                                                          >
                                                            <div
                                                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                                            >
                                                              
                                                              
                                                              integer
                                                              
                                                              
                                                            
                                                          
                                                        
                                                      
                                                    
                                                  <SchemaItem
                                                    collapsible={true}
                                                    className={"schemaItem"}
                                                  >
                                                    <details
                                                      style={{}}
                                                      className={"openapi-markdown__details"}
                                                    >
                                                      <summary
                                                        style={{}}
                                                      >
                                                        
                                                          requests
                                                        <span
                                                          style={{"opacity":"0.6"}}
                                                        >
                                                           object
                                                        
                                                      <div
                                                        style={{"marginLeft":"1rem"}}
                                                      >
                                                        
                                                      
                                                        <span
                                                          className={"badge badge--info"}
                                                        >
                                                          anyOf
                                                        
                                                          <TabItem
                                                            label={"MOD1"}
                                                            value={"0-item-properties"}
                                                          >
                                                            <div
                                                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                                            >
                                                              
                                                              
                                                              integer
                                                              
                                                              
                                                            
                                                          
                                                        
                                                      
                                                    
                                                  <SchemaItem
                                                    collapsible={true}
                                                    className={"schemaItem"}
                                                  >
                                                    <details
                                                      style={{}}
                                                      className={"openapi-markdown__details"}
                                                    >
                                                      <summary
                                                        style={{}}
                                                      >
                                                        
                                                          total_tokens
                                                        <span
                                                          style={{"opacity":"0.6"}}
                                                        >
                                                           object
                                                        
                                                      <div
                                                        style={{"marginLeft":"1rem"}}
                                                      >
                                                        
                                                      
                                                        <span
                                                          className={"badge badge--info"}
                                                        >
                                                          anyOf
                                                        
                                                          <TabItem
                                                            label={"MOD1"}
                                                            value={"0-item-properties"}
                                                          >
                                                            <div
                                                              style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                                            >
                                                              
                                                              
                                                              integer
                                                              
                                                              
                                                            
                                                          
                                                        
                                                      
                                                    
                                                  
                                                
                                              
                                            
                                          
                                        
                                      <SchemaItem
                                        name={"property name*"}
                                        required={false}
                                        schemaName={"any"}
                                        qualifierMessage={undefined}
                                        schema={{"properties":{"usage":{"additionalProperties":{"properties":{"prompt_tokens":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Prompt Tokens"},"input_tokens":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Input Tokens"},"completion_tokens":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Completion Tokens"},"output_tokens":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Output Tokens"},"requests":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Requests"},"total_tokens":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Total Tokens"}},"type":"object","title":"LLMUsageSchema"},"type":"object","title":"Usage"}},"additionalProperties":true,"type":"object","title":"SummaryInsertMap"}}
                                        collapsible={false}
                                        discriminator={false}
                                      >
                                        
                                      
                                    
                                  
                                
                              
                            
                          
                        
                      
                    
                  
                
              
                <div
                  style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                >
                  ]
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                res
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              <span
                                className={"openapi-schema__divider"}
                              >
                                
                              <span
                                className={"openapi-schema__required"}
                              >
                                required
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            
                              <span
                                className={"badge badge--info"}
                              >
                                anyOf
                              
                                <TabItem
                                  label={"CallStartRes"}
                                  value={"0-item-properties"}
                                >
                                  <SchemaItem
                                    collapsible={false}
                                    name={"id"}
                                    required={true}
                                    schemaName={"Id (string)"}
                                    qualifierMessage={undefined}
                                    schema={{"type":"string","title":"Id"}}
                                  >
                                    
                                  <SchemaItem
                                    collapsible={false}
                                    name={"trace_id"}
                                    required={true}
                                    schemaName={"Trace Id (string)"}
                                    qualifierMessage={undefined}
                                    schema={{"type":"string","title":"Trace Id"}}
                                  >
                                    
                                  
                                <TabItem
                                  label={"CallEndRes"}
                                  value={"1-item-properties"}
                                >
                                  <SchemaItem
                                    collapsible={false}
                                    name={""}
                                    required={false}
                                    schemaName={"object"}
                                    qualifierMessage={undefined}
                                    schema={{}}
                                  >
                                    
                                  
                                
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"res\": [\n    {},\n    {}\n  ]\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/call-start-batch-call-upsert-batch-post.api)

<!--- Docs: Service API -->
<!--- "Feedback Replace" -->

# "Feedback Replace"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Feedback Replace"}
>


<MethodEndpoint
  method={"post"}
  path={"/feedback/replace"}
>
  




Feedback Replace

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id","examples":["entity/project"]}}
        >
          
        <SchemaItem
          collapsible={false}
          name={"weave_ref"}
          required={true}
          schemaName={"Weave Ref (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Weave Ref","examples":["weave:///entity/project/object/name:digest"]}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                creator
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={false}
          name={"feedback_type"}
          required={true}
          schemaName={"Feedback Type (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Feedback Type","examples":["custom"]}}
        >
          
        <SchemaItem
          collapsible={false}
          name={"payload"}
          required={true}
          schemaName={"object"}
          qualifierMessage={undefined}
          schema={{"type":"object","title":"Payload","examples":[{"key":"value"}]}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                annotation_ref
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                runnable_ref
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                call_ref
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                trigger_ref
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                wb_user_id
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                Do not set directly. Server will automatically populate this field.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                
              
            
          
        <SchemaItem
          collapsible={false}
          name={"feedback_id"}
          required={true}
          schemaName={"Feedback Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Feedback Id"}}
        >
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={"id"}
                        required={true}
                        schemaName={"Id (string)"}
                        qualifierMessage={undefined}
                        schema={{"type":"string","title":"Id"}}
                      >
                        
                      <SchemaItem
                        collapsible={false}
                        name={"created_at"}
                        required={true}
                        schemaName={"date-time"}
                        qualifierMessage={undefined}
                        schema={{"type":"string","format":"date-time","title":"Created At"}}
                      >
                        
                      <SchemaItem
                        collapsible={false}
                        name={"wb_user_id"}
                        required={true}
                        schemaName={"Wb User Id (string)"}
                        qualifierMessage={undefined}
                        schema={{"type":"string","title":"Wb User Id"}}
                      >
                        
                      <SchemaItem
                        collapsible={false}
                        name={"payload"}
                        required={true}
                        schemaName={"object"}
                        qualifierMessage={undefined}
                        schema={{"type":"object","title":"Payload"}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"id\": \"string\",\n  \"created_at\": \"2025-04-30T23:50:38.711Z\",\n  \"wb_user_id\": \"string\",\n  \"payload\": {}\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/feedback-replace-feedback-replace-post.api)

<!--- Docs: Service API -->
<!--- "Obj Delete" -->

# "Obj Delete"

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Obj Delete"}
>


<MethodEndpoint
  method={"post"}
  path={"/obj/delete"}
>
  




Obj Delete

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>


<MimeTabs
  className={"openapi-tabs__mime"}
>
  <TabItem
    label={"application/json"}
    value={"application/json-schema"}
  >
    <details
      style={{}}
      className={"openapi-markdown__details mime"}
      data-collapsed={false}
      open={true}
    >
      <summary
        style={{}}
        className={"openapi-markdown__details-summary-mime"}
      >
        <h3
          className={"openapi-markdown__details-summary-header-body"}
        >
          Body
        <strong
          className={"openapi-schema__required"}
        >
          required
        
      <div
        style={{"textAlign":"left","marginLeft":"1rem"}}
      >
        
      <ul
        style={{"marginLeft":"1rem"}}
      >
        <SchemaItem
          collapsible={false}
          name={"project_id"}
          required={true}
          schemaName={"Project Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Project Id"}}
        >
          
        <SchemaItem
          collapsible={false}
          name={"object_id"}
          required={true}
          schemaName={"Object Id (string)"}
          qualifierMessage={undefined}
          schema={{"type":"string","title":"Object Id"}}
        >
          
        <SchemaItem
          collapsible={true}
          className={"schemaItem"}
        >
          <details
            style={{}}
            className={"openapi-markdown__details"}
          >
            <summary
              style={{}}
            >
              
                digests
              <span
                style={{"opacity":"0.6"}}
              >
                 object
              
            <div
              style={{"marginLeft":"1rem"}}
            >
              <div
                style={{"marginTop":".5rem","marginBottom":".5rem"}}
              >
                
                
                List of digests to delete. If not provided, all digests for the object will be deleted.
                
                
              
            
              <span
                className={"badge badge--info"}
              >
                anyOf
              
                <TabItem
                  label={"MOD1"}
                  value={"0-item-properties"}
                >
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                    >
                      Array [
                    
                  <div
                    style={{"marginTop":".5rem","marginBottom":".5rem"}}
                  >
                    
                    
                    string
                    
                    
                  
                    <div
                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                    >
                      ]
                    
                  
                
              
            
          
        
      
    
  

  
    <ApiTabs
      label={undefined}
      id={undefined}
    >
      <TabItem
        label={"200"}
        value={"200"}
      >
        
          
          
          Successful Response
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={false}
                        name={"num_deleted"}
                        required={true}
                        schemaName={"Num Deleted (integer)"}
                        qualifierMessage={undefined}
                        schema={{"type":"integer","title":"Num Deleted"}}
                      >
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"num_deleted\": 0\n}"}
                    language={"json"}
                  >
                    
                  
                
              
            
          
        
      <TabItem
        label={"422"}
        value={"422"}
      >
        
          
          
          Validation Error
          
          
        
          <MimeTabs
            className={"openapi-tabs__mime"}
            schemaType={"response"}
          >
            <TabItem
              label={"application/json"}
              value={"application/json"}
            >
              <SchemaTabs
                className={"openapi-tabs__schema"}
              >
                <TabItem
                  label={"Schema"}
                  value={"Schema"}
                >
                  <details
                    style={{}}
                    className={"openapi-markdown__details response"}
                    data-collapsed={false}
                    open={true}
                  >
                    <summary
                      style={{}}
                      className={"openapi-markdown__details-summary-response"}
                    >
                      
                        Schema
                      
                    <div
                      style={{"textAlign":"left","marginLeft":"1rem"}}
                    >
                      
                    <ul
                      style={{"marginLeft":"1rem"}}
                    >
                      <SchemaItem
                        collapsible={true}
                        className={"schemaItem"}
                      >
                        <details
                          style={{}}
                          className={"openapi-markdown__details"}
                        >
                          <summary
                            style={{}}
                          >
                            <span
                              className={"openapi-schema__container"}
                            >
                              <strong
                                className={"openapi-schema__property"}
                              >
                                detail
                              <span
                                className={"openapi-schema__name"}
                              >
                                 object[]
                              
                            
                          <div
                            style={{"marginLeft":"1rem"}}
                          >
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                              >
                                Array [
                              
                            <SchemaItem
                              collapsible={true}
                              className={"schemaItem"}
                            >
                              <details
                                style={{}}
                                className={"openapi-markdown__details"}
                              >
                                <summary
                                  style={{}}
                                >
                                  <span
                                    className={"openapi-schema__container"}
                                  >
                                    <strong
                                      className={"openapi-schema__property"}
                                    >
                                      loc
                                    <span
                                      className={"openapi-schema__name"}
                                    >
                                       object[]
                                    <span
                                      className={"openapi-schema__divider"}
                                    >
                                      
                                    <span
                                      className={"openapi-schema__required"}
                                    >
                                      required
                                    
                                  
                                <div
                                  style={{"marginLeft":"1rem"}}
                                >
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}
                                    >
                                      Array [
                                    
                                  
                                    <span
                                      className={"badge badge--info"}
                                    >
                                      anyOf
                                    
                                      <TabItem
                                        label={"MOD1"}
                                        value={"0-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          string
                                          
                                          
                                        
                                      <TabItem
                                        label={"MOD2"}
                                        value={"1-item-properties"}
                                      >
                                        <div
                                          style={{"marginTop":".5rem","marginBottom":".5rem"}}
                                        >
                                          
                                          
                                          integer
                                          
                                          
                                        
                                      
                                    
                                  
                                    <div
                                      style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                                    >
                                      ]
                                    
                                  
                                
                              
                            <SchemaItem
                              collapsible={false}
                              name={"msg"}
                              required={true}
                              schemaName={"Message (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Message"}}
                            >
                              
                            <SchemaItem
                              collapsible={false}
                              name={"type"}
                              required={true}
                              schemaName={"Error Type (string)"}
                              qualifierMessage={undefined}
                              schema={{"type":"string","title":"Error Type"}}
                            >
                              
                            
                              <div
                                style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}
                              >
                                ]
                              
                            
                          
                        
                      
                    
                  
                <TabItem
                  label={"Example (from schema)"}
                  value={"Example (from schema)"}
                >
                  <ResponseSamples
                    responseExample={"{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}"}
                    language={"json"}
                  >

[Source](https://weave-docs.wandb.ai/reference/service-api/obj-delete-obj-delete-post.api)



<!--- Docs: Tools -->
<!--- Comparison -->

# Comparison

# Comparison

The Weave Comparison feature allows you to visually compare and diff code, traces, prompts, models, and model configurations.  You can compare two objects side-by-side or analyze a larger set of objects to identify differences, patterns, and trends.

This guide covers the steps to start a comparison and the available actions to tailor your comparison view, including baseline comparisons, numeric diff formatting, and more. 

## Access the Comparison view

1. In the sidebar, select the type of object you'd like to compare (e.g. **Traces**, **Models**, etc.).
2. Select the objects that you want to compare. The selection method varies depending on the type of object you are comparing:
   - For **Traces**, select traces to compare by checking the checkboxes in the appropriate rows in the Traces column.
   - For objects such as **Models**, navigate to the model Versions page and check the checkboxes next to the  versions that you want to compare.
3. Click **Compare** to open the Comparison view. Now, you can refine your view using the [available actions](#available-actions).

## Available actions

In the Comparison view, you have multiple actions available, depending on how many objects are being compared. Make sure to look at the [usage notes](#usage-notes).

- [Change the diff display](#change-the-diff-display)
- [Display side-by-side](#display-side-by-side)
- [Display in a unified view](#display-in-a-unified-view)
- [Set a baseline](#set-a-baseline)
- [Remove a baseline](#remove-a-baseline)
- [Change the comparison order](#change-the-comparison-order)
- [Change numeric diff display format](#change-numeric-diff-display-format)
- [Compare with baseline or previous](#compare-with-baseline-or-previous)
- [Compare a pair from a multi-object comparison](#compare-a-pair-from-a-multi-object-comparison)
- [Remove an object from comparison](#remove-an-object-from-comparison)

### Change the diff display

By default, **Diff only** is set to off. To filter the table rows so that only changed rows are displayed, toggle **Diff only** on. 

### Display side-by-side 

> This option is only available when comparing two objects, or a [pair from a multi-object comparison](#compare-a-pair-from-a-multi-object-comparison).

To compare each object side-by-side in separate columns, select **Side-by-side**. 



### Display in a unified view

> This option is only available when comparing two objects, or a [pair from a multi-object comparison](#compare-a-pair-from-a-multi-object-comparison).

To compare each object in a unified view, select **Unified**. 



### Set a baseline

By default, each object in the Comparison view is compared to the object to its left. However, you can set an object as the _baseline_, which means that all objects will be compared to the leftmost object in the view.
To set an object as baseline, do the following:

1. In the Comparison view topbar, mouse over the object that you want to set as the baseline.
2. Click the three dots to the right of the ID.
   
3. In the dropdown, select **Make baseline**. The UI refreshes so that the baseline object is furthest left in the topbar, and `Baseline` displays next to the ID.
    

### Remove a baseline

To remove an object as baseline, do the following:

1. In the Comparison view topbar, mouse over the baseline object.
2. Click the three dots to the right of the ID.
3. In the dropdown, select **Remove baseline**. Now, `Baseline` no longer displays next to the call ID.

### Change the comparison order

To change the comparison order, do the following:

1. In the Comparison view topbar, mouse over the ID that you want to reorder. 
2. Click the six dots to the left of the ID.
   
3. Drag the ID to the left or the right, depending on which object was selected. 
4. Place the ID in the desired ordering. The UI refreshes with an updated comparison ordering.

### Change numeric diff display format 

For numeric values such as `completion_tokens` and `total_tokens`, you can view the diff as either an integer or a percentage. Additionally, positive numeric values can be viewed as a multiplier. To change a numeric diff's display format, do the following:

1. In the Comparison table, find the numeric value that you want to update the diff display format for.
    
2. Click the diff value. The format automatically updates to either an integer or a percentage.
    

### Compare with baseline or previous

> This option is only available when comparing 3 or more objects.
> You can also [set](#set-a-baseline) or [remove an existing baseline by clicking the 3 dots to the right of the ID](#remove-a-baseline).

To perform a baseline comparison with 3 or more objects, do the following:

1. In the right hand corner of the Comparison view, click the dropdown. Depending on your current view configuration, the dropdown is either titled **Compare with previous** or **Compare with baseline**.
2. Depending on your current view configuration, select either **Compare with previous** or **Compare with baseline**.
   - **Compare with baseline**: Sets the leftmost object as the baseline. The table updates so that the leftmost column is the baseline.
   -  **Compare with previous**: No object is set as baseline.

### Compare a pair from a multi-object comparison

> This option is only available when comparing 3 or more objects.

When comparing 3 or more objects, you can compare a single object to a previous object or baseline. This changes the Comparison table view so that the view is identical to a two-object comparison. To compare a pair of objects from a multi-object comparison, do the following:

1. In the Comparison view topbar, find the ID that you want to compare to previous or baseline. 
2. To select the item, click the ID. The UI refreshes with a two-way comparison table.
    

To reset the view so that the first 6 objects selected for comparison are displayed in the table, click the ID again.

### Remove an object from comparison

> This option is only available when comparing 3 or more objects.

To remove an object from comparison, do the following:

1. In the Comparison view topbar, find the object that you want to remove from comparison.
2. Click the three dots to the right of the ID.
3. In the dropdown, select **Remove object from comparison**. The UI refreshes with an updated table that no longer includes the removed object.

## Usage notes

 - The Comparison feature is only available in the UI.
 - You can compare as many objects as you'd like. However, the UI only displays a maximum of 6. To view an object in the comparison table that is not visible when comparing more than 6 objects, either [change the comparison order](#change-the-comparison-order) so that the object is one of the first 6 objects from left to right, or [pair from a multi-object comparison](#compare-a-pair-from-a-multi-object-comparison) for easy viewing.

[Source](https://weave-docs.wandb.ai/guides/tools/comparison)

<!--- Docs: Tools -->
<!--- Deploy -->

# Deploy

# Deploy

## Deploy to GCP

> 💡 **Note**: `weave deploy` requires your machine to have `gcloud` installed and configured. `weave deploy gcp` will use pre-configured configuration when not directly specified by command line arguments.

Given a Weave ref to any Weave Model you can run:

```
weave deploy gcp 
```

to deploy a gcp cloud function that serves your model. The last line of the deployment will look like `Service URL: `. Visit `/docs` to interact with your model!

Run

```
weave deploy gcp --help
```

to see all command line options.

[Source](https://weave-docs.wandb.ai/guides/tools/deploy)

<!--- Docs: Tools -->
<!--- Playground -->

# Playground

# Playground

Evaluating LLM prompts and responses is challenging. The Weave Playground is designed to simplify the process of iterating on LLM prompts and responses, making it easier to experiment with different models and prompts. With features like prompt editing, message retrying, and model comparison, Playground helps you to quickly test and improve your LLM applications. Playground currently supports models from OpenAI, Anthropic, Google, Groq, Amazon Bedrock, and Microsoft Azure, as well as [custom providers](#add-a-custom-provider).

- **Quick access:** Open the Playground from the W&B sidebar for a fresh session or from the Call page to test an existing project.
- **Message controls:** Edit, retry, or delete messages directly within the chat.
- **Flexible messaging:** Add new messages as either user or system inputs, and send them to the LLM.
- **Customizable settings:** Configure your preferred LLM provider and adjust model settings.
- **Multi-LLM support:** Switch between models, with team-level API key management.
- **Compare models:** Compare how different models respond to prompts.
- **Custom providers:** Test OpenAI compatible API endpoints for custom models.
- **Saved models:** Create and configure a reusable model preset for your workflow

Get started with the Playground to optimize your LLM interactions and streamline your prompt engineering process and LLM application development.

- [Prerequisites](#prerequisites)
  - [Add provider credentials and information](#add-provider-credentials-and-information)
  - [Access the Playground](#access-the-playground)
- [Select an LLM](#select-an-llm)
- [Customize settings](#customize-settings)
- [Message controls](#add-retry-edit-and-delete-messages)
- [Compare LLMs](#compare-llms)
- [Custom providers](#custom-providers)
- [Saved models](#saved-models) 

## Prerequisites

Before you can use Playground, you must [add provider credentials](#add-provider-credentials-and-information), and [open the Playground UI](#access-the-playground).

### Add provider credentials and information

Playground currently supports models from OpenAI, Anthropic, Google, Groq, Amazon Bedrock, and Microsoft Azure. To use one of the available models, add the appropriate information to your team secrets in W&B settings.

- OpenAI: `OPENAI_API_KEY`
- Anthropic: `ANTHROPIC_API_KEY`
- Google: `GEMINI_API_KEY`
- Groq: `GROQ_API_KEY`
- Amazon Bedrock:
  - `AWS_ACCESS_KEY_ID`
  - `AWS_SECRET_ACCESS_KEY`
  - `AWS_REGION_NAME`
- Azure:
  - `AZURE_API_KEY`
  - `AZURE_API_BASE`
  - `AZURE_API_VERSION`
- X.AI:
  - `XAI_API_KEY`
- Deepseek
  - `DEEPSEEK_API_KEY`

### Access the Playground

There are two ways to access the Playground:

1. _Open a fresh Playground page with a simple system prompt_: In the sidebar, select **Playground**. Playground opens in the same tab.
2. _Open Playground for a specific call_:
   1. In the sidebar, select the **Traces** tab. A list of traces displays.
   2. In the list of traces, click the name of the call that you want to view. The call's details page opens.
   3. Click **Open chat in playground**. Playground opens in a new tab.



## Select an LLM

You can switch the LLM using the dropdown menu in the top left. The available models from various providers are listed below:

- [Amazon Bedrock](#amazon-bedrock)
- [Anthropic](#anthropic)
- [Azure](#azure)
- [Google](#google)
- [Groq](#groq)
- [OpenAI](#openai)
- [X.AI](#xai)
- [Deepseek](#deepseek)




### [Amazon Bedrock](../integrations/bedrock.md)

- ai21.j2-mid-v1
- ai21.j2-ultra-v1
- amazon.nova-micro-v1:0
- amazon.nova-lite-v1:0
- amazon.nova-pro-v1:0
- amazon.titan-text-lite-v1
- amazon.titan-text-express-v1
- mistral.mistral-7b-instruct-v0:2
- mistral.mixtral-8x7b-instruct-v0:1
- mistral.mistral-large-2402-v1:0
- mistral.mistral-large-2407-v1:0
- anthropic.claude-3-sonnet-20240229-v1:0
- anthropic.claude-3-5-sonnet-20240620-v1:0
- anthropic.claude-3-haiku-20240307-v1:0
- anthropic.claude-3-opus-20240229-v1:0
- anthropic.claude-v2
- anthropic.claude-v2:1
- anthropic.claude-instant-v1
- cohere.command-text-v14
- cohere.command-light-text-v14
- cohere.command-r-plus-v1:0
- cohere.command-r-v1:0
- meta.llama2-13b-chat-v1
- meta.llama2-70b-chat-v1
- meta.llama3-8b-instruct-v1:0
- meta.llama3-70b-instruct-v1:0
- meta.llama3-1-8b-instruct-v1:0
- meta.llama3-1-70b-instruct-v1:0
- meta.llama3-1-405b-instruct-v1:0

### [Anthropic](../integrations/anthropic.md)

- claude-3-7-sonnet-20250219
- claude-3-5-sonnet-20240620
- claude-3-5-sonnet-20241022
- claude-3-haiku-20240307
- claude-3-opus-20240229
- claude-3-sonnet-20240229

### [Azure](../integrations/azure.md)

- azure/o1-mini
- azure/o1-mini-2024-09-12
- azure/o1
- azure/o1-preview
- azure/o1-preview-2024-09-12
- azure/gpt-4o
- azure/gpt-4o-2024-08-06
- azure/gpt-4o-2024-11-20
- azure/gpt-4o-2024-05-13
- azure/gpt-4o-mini
- azure/gpt-4o-mini-2024-07-18

### [Google](../integrations/google.md)

- gemini/gemini-2.5-pro-preview-03-25
- gemini/gemini-2.0-pro-exp-02-05
- gemini/gemini-2.0-flash-exp
- gemini/gemini-2.0-flash-001
- gemini/gemini-2.0-flash-thinking-exp
- gemini/gemini-2.0-flash-thinking-exp-01-21
- gemini/gemini-2.0-flash
- gemini/gemini-2.0-flash-lite
- gemini/gemini-2.0-flash-lite-preview-02-05
- gemini/gemini-1.5-flash-001
- gemini/gemini-1.5-flash-002
- gemini/gemini-1.5-flash-8b-exp-0827
- gemini/gemini-1.5-flash-8b-exp-0924
- gemini/gemini-1.5-flash-latest
- gemini/gemini-1.5-flash
- gemini/gemini-1.5-pro-001
- gemini/gemini-1.5-pro-002
- gemini/gemini-1.5-pro-latest
- gemini/gemini-1.5-pro

### [Groq](../integrations/groq.md)

- groq/deepseek-r1-distill-llama-70b
- groq/llama-3.3-70b-versatile
- groq/llama-3.3-70b-specdec
- groq/llama-3.2-1b-preview
- groq/llama-3.2-3b-preview
- groq/llama-3.2-11b-vision-preview
- groq/llama-3.2-90b-vision-preview
- groq/llama-3.1-8b-instant
- groq/llama3-70b-8192
- groq/llama3-8b-8192
- groq/gemma2-9b-it

### [OpenAI](../integrations/openai.md)

- gpt-4.1-mini-2025-04-14
- gpt-4.1-mini
- gpt-4.1-2025-04-14
- gpt-4.1
- gpt-4.1-nano-2025-04-14
- gpt-4.1-nano
- o4-mini-2025-04-16
- o4-mini
- gpt-4.5-preview-2025-02-27
- gpt-4.5-preview
- o3-2025-04-16
- o3
- o3-mini-2025-01-31
- o3-mini
- gpt-4o-mini
- gpt-4o-2024-05-13
- gpt-4o-2024-08-06
- gpt-4o-mini-2024-07-18
- gpt-4o
- gpt-4o-2024-11-20
- o1-mini-2024-09-12
- o1-mini
- o1-preview-2024-09-12
- o1-preview
- o1-2024-12-17
- gpt-4-1106-preview
- gpt-4-32k-0314
- gpt-4-turbo-2024-04-09
- gpt-4-turbo-preview
- gpt-4-turbo
- gpt-4
- gpt-3.5-turbo-0125
- gpt-3.5-turbo-1106

### X.AI

- xai/grok-3-beta
- xai/grok-3-fast-beta
- xai/grok-3-fast-latest
- xai/grok-3-mini-beta
- xai/grok-3-mini-fast-beta
- xai/grok-3-mini-fast-latest
- xai/grok-beta
- xai/grok-2-1212
- xai/grok-2
- xai/grok-2-latest

### Deepseek

- deepseek/deepseek-reasoner
- deepseek/deepseek-chat



## Customize settings

### Adjust LLM parameters

You can experiment with different parameter values for your selected model. To adjust parameters, do the following:

1. In the upper right corner of the Playground UI, click **Chat settings** to open the parameter settings dropdown.
2. In the dropdown, adjust parameters as desired. You can also toggle Weave call tracking on or off, and [add a function](#add-a-function).
3. Click **Chat settings** to close the dropdown and save your changes.



### Add a function

You can test how different models use functions based on input it receives from the user. To add a function for testing in Playground, do the following:

1. In the upper right corner of the Playground UI, click **Chat settings** to open the parameter settings dropdown.
2. In the dropdown, click **+ Add function**.
3. In the pop-up, add your function information.
4. To save your changes and close the function pop-up, click the **x** in the upper right corner.
5. Click **Chat settings** to close the settings dropdown and save your changes.

### Adjust the number of trials

Playground allows you to generate multiple outputs for the same input by setting the number of trials. The default setting is `1`. To adjust the number of trials, do the following:

1. In the Playground UI, open the settings sidebar if it is not already open.
2. Adjust the **Number of trials**.

## Message controls

### Retry, edit, and delete messages

With Playground, you can retry, edit, and delete messages. To use this feature, hover over the message you want to edit, retry, or delete. Three buttons display: **Delete**, **Edit**, and **Retry**.

- **Delete**: Remove the message from the chat.
- **Edit**: Modify the message content.
- **Retry**: Delete all subsequent messages and retry the chat from the selected message.




### Add a new message

To add a new message to the chat, do the following:

1. In the chat box, select one of the available roles (**Assistant** or **User**)
2. Click **+ Add**.
3. To send a new message to the LLM, click the **Send** button. Alternatively, press the **Command** and **Enter** keys.



## Compare LLMs

Playground allows you to compare LLMs. To perform a comparison, do the following:

1. In the Playground UI, click **Compare**. A second chat opens next to the original chat.
2. In the second chat, you can:
   - [Select the LLM to compare](#select-an-llm)
   - [Adjust parameters](#adjust-llm-parameters)
   - [Add functions](#add-a-function)
3. In the message box, enter a message that you want to test with both models and press **Send**.

## Custom providers

### Add a custom provider

In addition to the [supported providers](#select-an-llm), you can use the Playground to test OpenAI compatible API endpoints for custom models. Examples include:

- Older versions of supported model providers
- Local models

To add a custom provider to the Playground, do the following:

1. In the upper left corner of the Playground UI, click the **Select a model** dropdown.
2. Select **+ Add AI provider**.
3. In the pop-up modal, enter the provider information:

   - _Provider name_: For example, `openai` or `ollama`.
   - _API key_: For example, an OpenAI API key.
   - _Base URL_: For example, `https://api.openai.com/v1/` or a ngrok URL `https://e452-2600-1700-45f0-3e10-2d3f-796b-d6f2-8ba7.ngrok-free.app`.
   - _Headers_ (optional): You can add multiple header keys and values.
   - _Models_: You can add multiple models for one provider. For example, `deepseek-r1` and `qwq`.
   - _Max tokens_ (optional): For each model, you can specify the max tokens that the model can generate in a response.

4. Once you've entered your provider information, click **Add provider**.
5. Select your new provider and available model(s) from the **Select a model** dropdown in the upper left corner of the Playground UI.

> 🚨 **Important**: Because of CORS restrictions, you can't call localhost or 127.0.0.1 URLs directly from the Playground. If you're running a local model server (such as Ollama), use a tunneling service like ngrok to expose it securely. For details, see [Use ngrok with Ollama](#use-ngrok-with-ollama).

Now, you can test the custom provider model(s) using standard Playground features. You can also [edit](#edit-a-custom-provider) or [remove](#remove-a-custom-provider) the custom provider.

### Edit a custom provider

To edit information for a [previously created custom provider](#add-a-custom-provider), do the following:

1. In the Weave sidebar, navigate to **Overview**.
2. From the top navigation menu, select **AI Providers**.
3. In the **Custom providers** table, find the custom provider you want to update.
4. In the **Last Updated** column of the entry for your custom provider, click the edit button (the pencil icon).
5. In the pop-up modal, edit the provider information.
6. Click **Save**.

### Remove a custom provider

To remove a [previously created custom provider](#add-a-custom-provider), do the following:

1. In the Weave sidebar, navigate to **Overview**.
2. From the top navigation menu, select **AI Providers**.
3. In the **Custom providers** table, find the custom provider you want to update.
4. In the **Last Updated** column of the entry for your custom provider, click the delete button (the trashcan icon).
5. In the pop-up modal, confirm that you want to delete the provider. This action cannot be undone.
6. Click **Delete**.

### Use ngrok with Ollama

To test a locally running Ollama model in the Playground, use ngrok to create a temporary public URL that bypasses CORS restrictions.

To set it up, do the following:

1. [Install ngrok](https://ngrok.com/docs/getting-started/#step-1-install) for your operating system.
2. Start your Ollama model:

   ```bash
   ollama run 
   ```

3. In a separate terminal, create an ngrok tunnel with the required CORS headers:

   ```bash
   ngrok http 11434 --response-header-add "Access-Control-Allow-Origin: *" --host-header rewrite
   ```

After ngrok starts, it will display a public URL, such as `https://xxxx-xxxx.ngrok-free.app`. Use this URL as the base URL when you add Ollama as a custom provider in the Playground.

The following diagram illustrates the data flow between your local environment, the ngrok proxy, and the W&B cloud services:

```mermaid
flowchart LR
    %% Style definitions
    classDef clientMachine fill:#FFD95CCC,stroke:#454B52,stroke-width:2px
    classDef proxy fill:#00CDDBCC,stroke:#454B52,stroke-width:2px
    classDef wandbCloud fill:#DE72FFCC,stroke:#454B52,stroke-width:2px
    classDef publicCloud fill:#FFCBADCC,stroke:#454B52,stroke-width:2px

    %% Subgraphs
    subgraph Client_Machine
        browser[Browser]
        llm_local[Local LLM Provider]
    end

    subgraph Proxy
        ngrok[Ngrok Proxy]
    end

    subgraph WandB_Cloud
        trace_server[Trace Server]
    end

    subgraph Public_Cloud
        llm_cloud[Public LLM Provider]
    end

    %% Apply styles to subgraphs
    class Client_Machine clientMachine
    class Proxy proxy
    class WandB_Cloud wandbCloud
    class Public_Cloud publicCloud

    %% Current Data Flow
    browser -->|Sends chat request| trace_server
    trace_server -->|Uses Public LLM| llm_cloud
    trace_server -->|Uses Local LLM| ngrok
    ngrok -->|Forwards to| llm_local
    llm_cloud -->|Returns response| trace_server
    llm_local -->|Returns response| ngrok
    ngrok -->|Forwards to| trace_server
    trace_server -->|Returns response| browser

    %% Future Possible Connection
    browser -.->|Future: Call local LLM directly| llm_local

    %% Link styles
    linkStyle default stroke:#454B52,stroke-width:2px
    linkStyle 8 stroke:#454B52,stroke-width:2px,stroke-dasharray:5
```

## Saved models

### Save a model

You can create and configure a reusable model preset for your workflow. Saving a model lets you quickly load it with your preferred settings, parameters, and function hooks.

1. From the LLM dropdown, select a provider.
2. From the provider list, select a model.
3. In the upper right corner of the Playground UI, click **Chat settings** to open the chat settings window.
4. In the chat settings window:
   - In the **Model Name** field, enter a name for your saved model. 
   - Adjust parameters as desired. You can also toggle Weave call tracking on or off, and [add a function](#add-a-function).
5. Click **Publish Model**. The model is saved and accesible from **Saved Models** in the LLM dropdown. You can now [use](#use-a-saved-model) and [update](#update-a-saved-model) the saved model.



### Use a saved model 

Quickly switch to a previously [saved model](#save-a-model) to maintain consistency across experiments or sessions. This allows you to pick up right where you left off.

1. From the LLM dropdown, select **Saved Models**.
2. From the list of saved models, click the saved model you want to load. The model loads and is ready for use in the Playground.



### Update a saved model

Edit an existing [saved model](#save-a-model) to fine-tune parameters or refresh its configuration. This ensures your saved models evolve alongside your use cases.

1. From the LLM dropdown, select **Saved Models**.
2. From the list of saved models, click the saved model you want to update. 
3. In the upper right corner of the Playground UI, click **Chat settings** to open the chat settings window.
4. In the chat settings window, adjust parameters as desired. You can also toggle Weave call tracking on or off, and [add a function](#add-a-function).
5. Click **Update model**. The model is updated and accesible from **Saved Models** in the LLM dropdown.

[Source](https://weave-docs.wandb.ai/guides/tools/playground)

<!--- Docs: Tools -->
<!--- Saved Views -->

# Saved Views

# Saved Views

In Weave, _saved views_ allow you to customize how you interact with traced function calls and evaluations. By defining a saved view, you can configure filters, sorting, and column visibility to quickly access relevant data.

You can create, modify, and save views directly in the Weave Python SDK or through the UI. The Python SDK provides fine-grained control for programmatic filtering and querying, while the UI makes it easy to explore and save different table configurations in the **Traces** and **Evals** tabs.

This guide covers:

- [How to create and modify Saved Views in the Python SDK](#saved-views-in-the-python-sdk).
- [How to create and interact with Saved Views in the Weave UI](#saved-views-in-the-ui).

## Saved views in the Python SDK

The `SavedView` class in Weave provides a way to save, filter, sort, and customize views of trace and evals data. 

### Initialize a `SavedView`

Initialize a `SavedView` instance in your Weave project:

```python
import weave
client = weave.init()

view = weave.SavedView()
```

### Visualize the `SavedView` as a grid

Use `.to_grid()` to represent the saved view as a grid. Specify the maximum number of rows to display with `limit`.

```python
view.to_grid(limit=5)
```

Display the grid representation using `.show()`:

```python
view.to_grid().show()
```

### Set displayed columns

Use `.set_columns()` to set the columns to be displayed in the view. Specify one or more columns to be displayed.

```python
view.set_columns("id", "op_name")
```

### Add columns

Use `.add_column()` to add one or more new columns to the view. Specify one or more columns to be added.

```python
# Add a column with the field specifier and label "Created"
view.add_column("Created")
# Optionally, you can add a second argument to specify a different label name for the new column. By default, the field specifier is use for the label.
```

### Sort columns

Use `.sort_by()` to sort results based on a specific column. Specify the column name to be sorted and the sort order (`asc` or `desc`).

```python
view.sort_by("started_at", "desc")
```

### Filter by operation name

In Weave, every trace or eval is associated with an operation name.
Use `.filter_op()` to filter the `SavedView` to only include calls where that specific operation was executed. 

```python
view.filter_op("Evaluation.predict_and_score")
```


### Filter by operator and condition

Use `.add_filter()` to apply a custom filter to the view. Define the filter using one of the [supported filter operators](#filter-operators) and a condition.

```python
view.add_filter("output.model_latency", ">=", 5)
```

#### Filter operators

| Operator | Description | Example |
|----------|-------------|---------|
| `"contains"` | Checks if a string contains a substring. | `view.add_filter("output.status", "contains", "error")` |
| `"equals"` | Checks if a string is exactly equal to a given value. | `view.add_filter("input.category", "equals", "Alice")` |
| `"in"` | Checks if a string is in a list of values. | `view.add_filter("category", "in", ["A", "B", "C"])` |
| `"="` | Checks if a number is equal to a value. | `view.add_filter("output.score", "=", 80)` |
| `"≠", "!="` | Checks if a number is not equal to a value. | `view.add_filter("metrics.loss", "!=", 0.5)` |
| `"<"` | Checks if a number is less than a value. | `view.add_filter("age", "<", 30)` |
| `"≤", "<="` | Checks if a number is less than or equal to a value. | `view.add_filter("metric.value", "<=", 100)` |
| `">"` | Checks if a number is greater than a value. | `view.add_filter("output.score", ">", 90)` |
| `"≥", ">="` | Checks if a number is greater than or equal to a value. | `view.add_filter("output.model_latency", ">=", 5)` |
| `"is"` | Checks if a boolean field is `True` or `False`. | `view.add_filter("is_active", "is", True)` |
| `"after"` | Checks if a date is after a given timestamp. | `view.add_filter("started_at", "after", "2024-01-01")` |
| `"before"` | Checks if a date is before a given timestamp. | `view.add_filter("ended_at", "before", "2024-12-31")` |
| `"is empty"` | Checks if a field is empty (`None` or `""`). | `view.add_filter("comments", "is empty", None)` |
| `"is not empty"` | Checks if a field is not empty. | `view.add_filter("attachments", "is not empty", None)` |

### Remove filters

Use `.remove_filter()` to remove a specific filter from the view by index or field name.

```python
view.remove_filter("output.model_latency")
```

Use `.remove_filters()` to remove all filters.

```python
view.remove_filters()
```

### Save the `SavedView`

Use `.save()` to publish the saved view to Weave.

```python
view.save()
```

### Retrieve function calls

Use `.get_calls()` to retrieve function calls that match the filters in the saved view. You can specify optional parameters such as `limit` and `offset`.

```python
calls = view.get_calls(limit=10)
```

## Saved views in the UI 

You can create, load, rename, and edit saved views in the Weave UI. For fine-grained control, use the [Python SDK](#saved-views-in-the-python-sdk).

### Create a saved view

1. Navigate to your **Traces** or **Evals** tab.
2. Adjust any of the following variables in your table configuration:
   - Filters
   - Sort order
   - Page size
   - Column visibility
   - Column pinning
3. Save the view using one of two options:
   - In the upper right-hand corner, click **Save view**. 
   - Click the hamburger menu to the left of **Save view**. In the dropdown menu, click **+ Save as new view**.

### Load a saved view

1. Navigate to your **Traces** or **Evals** tab.
2. Click the hamburger menu to the left of the tab title. A dropdown menu showing all saved views displays. 
3. Click the view that you want to access. The saved view displays in the **Traces** or **Evals** tab. 

### Rename a saved view

1. Follow the steps described in [Load a saved view](#load-a-saved-view).
2. In the upper lefthand corner of the **Traces** or **Evals** tab, click the view name.
3. Enter a new name for the view.
4. To save the new view name, press **Enter**.

### Edit a saved view

1. Follow the steps described in [Load a saved view](#load-a-saved-view).
2. Adjust your table configuration.
3. In the upper right-hand corner, click **Save view**. 

### Delete a saved view 

> 🚨 **Important**: You can delete a view if you believe it is no longer useful to you and your team. This cannot be undone.

1. Navigate to your **Traces** or **Evals** tab.
2. [Load the view](#load-a-saved-view) that you want to delete.
3. Click the hamburger menu to the left of **Save view**. 
4. In the dropdown menu, click **Delete view**.
5. In the pop-up modal, confirm by clicking **Delete view**. Alternatively, click **Cancel** to stop deletion.

### Return to the default view

1. Navigate to your **Traces** or **Evals** tab.
2. Click the hamburger menu to the right of the **Traces** or **Evals** tab. A dropdown menu showing all saved views displays. 
3. At the bottom on the menu, click **Traces** or **Evals**. The default view displays.

[Source](https://weave-docs.wandb.ai/guides/tools/saved-views)

<!--- Docs: Tools -->
<!--- Index -->

# Index

# Tools & Utilities

Weave is developing a set of tools and utilities to help with your workflow and deployment process for AI applications. These are currently in early alpha stages and subject to change. Here's an overview of what we're working on:

## Serve (experimental)

[Serve](/guides/tools/serve) is a feature to expose your Weave ops and models as API endpoints. We're exploring possibilities such as:

- Creating web services for your Weave components
- Integrating Weave components into existing applications
- Providing a way to test models in a more production-like setting

## Deploy (experimental)

[Deploy](/guides/tools/deploy) is another alpha-stage utility we're developing to help with deploying Weave ops and models. Some potential features we're considering include:

- Pushing models to cloud platforms
- Managing different deployment environments
- Exploring ways to automate parts of the deployment process

Please note that these tools are still in very early stages of development. They may not be fully functional, could change significantly, or might be discontinued. We recommend using them for experimental purposes only at this time.

[Source](https://weave-docs.wandb.ai/guides/tools/index)

<!--- Docs: Tools -->
<!--- Serve -->

# Serve

# Serve

Given a Weave ref to any Weave Model you can run:

```
weave serve 
```

to run a FastAPI server for that model. Visit [http://0.0.0.0:9996/docs](http://0.0.0.0:9996/docs) to query the model interactively.

## Install FastAPI

```bash
pip install fastapi uvicorn
```

## Serve Model

In a terminal, call:

```bash
weave serve 
```

Get your model ref by navigating to the model and copying it from the UI. It should look like:
`weave:///your_entity/project-name/YourModel:`

To use it, navigate to the Swagger UI link, click the predict endpoint and then click "Try it out!".

[Source](https://weave-docs.wandb.ai/guides/tools/serve)



<!--- Docs: Tracking -->
<!--- Costs -->

# Costs

# Costs

## Adding a custom cost


  
    You can add a custom cost by using the [`add_cost`](/reference/python-sdk/weave/trace/weave.trace.weave_client#method-add_cost) method.
    The three required fields are `llm_id`, `prompt_token_cost`, and `completion_token_cost`.
    `llm_id` is the name of the LLM (e.g. `gpt-4o`). `prompt_token_cost` and `completion_token_cost` are cost per token for the LLM (if the LLM prices were specified inper million tokens, make sure to convert the value).
    You can also set `effective_date` to a datetime, to make the cost effective at a specific date, this defaults to the current date.

    ```python
    import weave
    from datetime import datetime

    client = weave.init("my_custom_cost_model")

    client.add_cost(
        llm_id="your_model_name",
        prompt_token_cost=0.01,
        completion_token_cost=0.02
    )

    client.add_costs(
        llm_id="your_model_name",
        prompt_token_cost=10,
        completion_token_cost=20,
        # If for example I want to raise the price of the model after a certain date
        effective_date=datetime(2025, 4, 22),
    )
    ```

  
  

    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```

  


## Querying for costs


  
    You can query for costs by using the [`query_costs`](/reference/python-sdk/weave/trace/weave.trace.weave_client#method-query_costs) method.
    There are a few ways to query for costs, you can pass in a singular cost id, or a list of LLM model names.

    ```python
    import weave

    client = weave.init("my_custom_cost_model")

    costs = client.query_costs(llm_ids=["your_model_name"])

    cost = client.query_costs(costs[0].id)
    ```

  
  

    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```

  


## Purging a custom cost


  
    You can purge a custom cost by using the [`purge_costs`](/reference/python-sdk/weave/trace/weave.trace.weave_client#method-purge_costs) method. You pass in a list of cost ids, and the costs with those ids are purged.

    ```python
    import weave

    client = weave.init("my_custom_cost_model")

    costs = client.query_costs(llm_ids=["your_model_name"])
    client.purge_costs([cost.id for cost in costs])
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


## Calculating costs for a Project


  
    You can calculate costs for a project by using our `calls_query` and adding `include_costs=True` with a little bit of setup.

    ```python
    import weave

    weave.init("project_costs")
    @weave.op()
    def get_costs_for_project(project_name: str):
        total_cost = 0
        requests = 0

        client = weave.init(project_name)
        # Fetch all the calls in the project
        calls = list(
            client.get_calls(filter={"trace_roots_only": True}, include_costs=True)
        )

        for call in calls:
            # If the call has costs, we add them to the total cost
            if call.summary["weave"] is not None and call.summary["weave"].get("costs", None) is not None:
                for k, cost in call.summary["weave"]["costs"].items():
                    requests += cost["requests"]
                    total_cost += cost["prompt_tokens_total_cost"]
                    total_cost += cost["completion_tokens_total_cost"]

        # We return the total cost, requests, and calls
        return {
            "total_cost": total_cost,
            "requests": requests,
            "calls": len(calls),
        }

    # Since we decorated our function with @weave.op(),
    # our totals are stored in weave for historic cost total calculations
    get_costs_for_project("my_custom_cost_model")
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


## Setting up a custom model with custom costs

Try our cookbook for a [Setting up costs with a custom model](/reference/gen_notebooks/custom_model_cost) or Open in Colab

[Source](https://weave-docs.wandb.ai/guides/tracking/costs)

<!--- Docs: Tracking -->
<!--- Ops -->

# Ops

# Ops

A Weave op is a versioned function that automatically logs all calls.


  
    To create an op, decorate a python function with `weave.op()`

    ```python showLineNumbers
    import weave

    @weave.op()
    def track_me(v):
        return v + 5

    weave.init('intro-example')
    track_me(15)
    ```

    Calling an op will create a new op version if the code has changed from the last call, and log the inputs and outputs of the function.

    :::note
    Functions decorated with `@weave.op()` will behave normally (without code versioning and tracking), if you don't call `weave.init('your-project-name')` before calling them.
    :::

    Ops can be [served](/guides/tools/serve) or [deployed](/guides/tools/deploy) using the Weave toolbelt.

  
  
    To create an op, wrap a typescript function with `weave.op`

    ```typescript showLineNumbers
    import * as weave from 'weave'

    function trackMe(v: number) {
        return v + 5
    }

    const trackMeOp = weave.op(trackMe)
    trackMeOp(15)


    // You can also do this inline, which may be more convenient
    const trackMeInline = weave.op((v: number) => v + 5)
    trackMeInline(15)
    ```

  


## Customize display names


  
    You can customize the op's display name by setting the `name` parameter in the `@weave.op` decorator:

    ```python
    @weave.op(name="custom_name")
    def func():
        ...
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


## Customize logged inputs and outputs


  
    If you want to change the data that is logged to weave without modifying the original function (e.g. to hide sensitive data), you can pass `postprocess_inputs` and `postprocess_output` to the op decorator.

    `postprocess_inputs` takes in a dict where the keys are the argument names and the values are the argument values, and returns a dict with the transformed inputs.

    `postprocess_output` takes in any value which would normally be returned by the function and returns the transformed output.

    ```py
    from dataclasses import dataclass
    from typing import Any
    import weave

    @dataclass
    class CustomObject:
        x: int
        secret_password: str

    def postprocess_inputs(inputs: dict[str, Any]) -> dict[str, Any]:
        return {k:v for k,v in inputs.items() if k != "hide_me"}

    def postprocess_output(output: CustomObject) -> CustomObject:
        return CustomObject(x=output.x, secret_password="REDACTED")

    @weave.op(
        postprocess_inputs=postprocess_inputs,
        postprocess_output=postprocess_output,
    )
    def func(a: int, hide_me: str) -> CustomObject:
        return CustomObject(x=a, secret_password=hide_me)

    weave.init('hide-data-example') # 🐝
    func(a=1, hide_me="password123")
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


## Control sampling rate


  
    You can control how frequently an op's calls are traced by setting the `tracing_sample_rate` parameter in the `@weave.op` decorator. This is useful for high-frequency ops where you only need to trace a subset of calls.

     Note that sampling rates are only applied to root calls. If an op has a sample rate, but is called by another op first, then that sampling rate will be ignored.

    ```python
    @weave.op(tracing_sample_rate=0.1)  # Only trace ~10% of calls
    def high_frequency_op(x: int) -> int:
        return x + 1

    @weave.op(tracing_sample_rate=1.0)  # Always trace (default)
    def always_traced_op(x: int) -> int:
        return x + 1
    ```

    When an op's call is not sampled:
    - The function executes normally
    - No trace data is sent to Weave
    - Child ops are also not traced for that call

    The sampling rate must be between 0.0 and 1.0 inclusive.

  
  
    ```plaintext
    This feature is not available in TypeScript yet. Stay tuned!
    ```
  


## Control call link output

If you want to suppress the printing of call links during logging, you can set the `WEAVE_PRINT_CALL_LINK` environment variable to `false`. This can be useful if you want to reduce output verbosity and reduce clutter in your logs.

```bash
export WEAVE_PRINT_CALL_LINK=false
```

## Deleting an op


  
    To delete a version of an op, call `.delete()` on the op ref.

    ```python
    weave.init('intro-example')
    my_op_ref = weave.ref('track_me:v1')
    my_op_ref.delete()
    ```

    Trying to access a deleted op will result in an error.

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```

[Source](https://weave-docs.wandb.ai/guides/tracking/ops)

<!--- Docs: Tracking -->
<!--- Faqs -->

# Faqs

# FAQs

The following page provides answers to common questions about Weave tracing.

## What information does Weave capture for a function?

A function can be designated as a Weave [Op](/guides/tracking/ops) either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.

- **Code capture** - Weave captures a representation of the Op's source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.

- **Function name, inputs, and outputs** - The name of the function will be captured but can be [overridden](/guides/tracking/tracing/#call-display-name). A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you [customize the logging](/guides/tracking/ops#customize-logged-inputs-and-outputs) of inputs and outputs - you can specify a function to add/remove/modify what is logged.

- **Op call hierarchy** - When an Op is called within the context of another Op executing, this relationship is captured, even in cases
  where there is an intermediate non-Op function executing. This relationship between Op calls is used to provide a "Trace tree".

- **Execution status and exceptions** - Weave tracks whether a function is executing, finished, or errored. If an exception occurs during execution the error message and a stack track is recorded.

- **System information** - Weave may capture information about which operating system the client is running on including detailed version information.

- **Client information** - Weave may capture information about the Weave client itself, such as the programming language in use and detailed version information for that language and the Weave client library.

- **Timing** - The execution start and end time is captured and also used for latency calculations.

- **Token usage** - In some [integrations](/guides/integrations/) LLM token usage counts may be automatically logged.

- **User and run context** - Logging is associated with a W&B user account. That will be captured along with any wandb Run context.

- **Derived information** - Weave may compute derived information from the raw information logged, for example a cost estimate may be calculated based on token usage and knowledge of the model used. Weave also aggregates some information over calls.

- **Additional information you choose** - You can choose to log [custom metadata with `weave.attributes`](/guides/core-types/models#track-production-calls) as part of your call or attach [feedback](/guides/tracking/feedback#add-feedback-to-a-call) to a call.

## How can I disable code capture?

You can disable code capture during Weave client initialization: `weave.init("entity/project", settings={"capture_code": False})`.
You can also use the [environment variable](/guides/core-types/env-vars) `WEAVE_CAPTURE_CODE=false`.

## How can I disable system information capture?

You can disable system information capture during Weave client initialization: `weave.init("entity/project", settings={"capture_system_info": False})`.

## How can I disable client information capture?

You can disable client information capture during Weave client initialization: `weave.init("entity/project", settings={"capture_client_info": False})`.

## How do I render Python datetime values in the UI?

Use Python’s `datetime.datetime` (with timezone info), and publish the object using `weave.publish(...)`. Weave recognizes this type and renders it as a timestamp.

## How do I render Markdown in the UI?

Wrap your string with `weave.Markdown(...)` before saving, and use `weave.publish(...)` to store it. Weave uses the object’s type to determine rendering, and `weave.Markdown` maps to a known UI renderer.  The value will be shown as a formatted Markdown object in the UI.

## Will Weave affect my function's execution speed?

The overhead of Weave logging is typically negligible compared to making a call to an LLM.
To minimize Weave's impact on the speed of your Op's execution, its network activity happens on a background thread.
When your program is exiting it may appear to pause while any remaining enqueued data is logged.

## How is Weave data ingestion calculated?

We define ingested bytes as bytes that we receive, process, and store on your behalf. This includes trace metadata, LLM inputs/outputs, and any other information you explicitly log to Weave, but does not include communication overhead (e.g., HTTP headers) or any other data that is not placed in long-term storage. We count bytes as "ingested" only once at the time they are received and stored.

## What is pairwise evaluation and how do I do it?

When [scoring](../evaluation/scorers.md) models in a Weave [evaluation](../core-types/evaluations.md), absolute value metrics (e.g. `9/10` for Model A and `8/10` for Model B) are typically harder to assign than relative ones (e.g. Model A performs better than Model B). _Pairwise evaluation_ allows you to compare the outputs of two models by ranking them relative to each other. This approach is particularly useful when you want to determine which model performs better for subjective tasks such as text generation, summarization, or question answering. With pairwise evaluation, you can obtain a relative preference ranking that reveals which model is best for specific inputs.

> 🚨 **Important**: This approach is a workaround and may change in future releases. We are actively working on a more robust API to support pairwise evaluations. Stay tuned for updates!

The following code sample demonstrates how to implement a pairwise evaluation in Weave by creating a [class-based scorer](../evaluation/scorers.md#class-based-scorers) called `PreferenceScorer`. The `PreferenceScorer` compares two models, `ModelA` and `ModelB`, and returns a relative score of the model outputs based on explicit hints in the input text.

```python
from weave import Model, Evaluation, Scorer, Dataset
from weave.flow.model import ApplyModelError, apply_model_async

class ModelA(Model):
    @weave.op
    def predict(self, input_text: str):
        if "Prefer model A" in input_text:
            return {"response": "This is a great answer from Model A"}
        return {"response": "Meh, whatever"}

class ModelB(Model):
    @weave.op
    def predict(self, input_text: str):
        if "Prefer model B" in input_text:
            return {"response": "This is a thoughtful answer from Model B"}
        return {"response": "I don't know"}

class PreferenceScorer(Scorer):
    @weave.op
    async def _get_other_model_output(self, example: dict) -> Any:
        """Get output from the other model for comparison.
        Args:
            example: The input example data to run through the other model
        Returns:
            The output from the other model
        """

        other_model_result = await apply_model_async(
            self.other_model,
            example,
            None,
        )

        if isinstance(other_model_result, ApplyModelError):
            return None

        return other_model_result.model_output

    @weave.op
    async def score(self, output: dict, input_text: str) -> dict:
        """Compare the output of the primary model with the other model.
        Args:
            output (dict): The output from the primary model.
            input_text (str): The input text used to generate the outputs.
        Returns:
            dict: A flat dictionary containing the comparison result and reason.
        """
        other_output = await self._get_other_model_output(
            {"input_text": input_text}
        )
        if other_output is None:
            return {"primary_is_better": False, "reason": "Other model failed"}

        if "Prefer model A" in input_text:
            primary_is_better = True
            reason = "Model A gave a great answer"
        else:
            primary_is_better = False
            reason = "Model B is preferred for this type of question"

        return {"primary_is_better": primary_is_better, "reason": reason}

dataset = Dataset(
    rows=[
        {"input_text": "Prefer model A: Question 1"},  # Model A wins
        {"input_text": "Prefer model A: Question 2"},  # Model A wins
        {"input_text": "Prefer model B: Question 3"},  # Model B wins
        {"input_text": "Prefer model B: Question 4"},  # Model B wins
    ]
)

model_a = ModelA()
model_b = ModelB()
pref_scorer = PreferenceScorer(other_model=model_b)
evaluation = Evaluation(dataset=dataset, scorers=[pref_scorer])
evaluation.evaluate(model_a)
```

[Source](https://weave-docs.wandb.ai/guides/tracking/faqs)

<!--- Docs: Tracking -->
<!--- Otel -->

# Otel

# Send OpenTelemetry Traces

## Overview
Weave supports ingestion of OpenTelemetry compatible trace data through a dedicated endpoint. This endpoint allows you to send OTLP (OpenTelemetry Protocol) formatted trace data directly to your Weave project.

## Endpoint details

**Path**: `/otel/v1/traces`
**Method**: POST
**Content-Type**: `application/x-protobuf`

## Authentication
Standard W&B authentication is used. You must have write permissions to the project where you're sending trace data.

## Required Headers
- `project_id: /`
- `Authorization=Basic `

## Examples:

You must modify the following fields before you can run the code samples below:
1. `WANDB_API_KEY`: You can get this from [https://wandb.ai/authorize](https://wandb.ai/authorize).
2. Entity: You can only log traces to the project under an entity that you have access to. You can find your entity name by visiting your W&N dashboard at [https://wandb.ai/home], and checking the **Teams** field in the left sidebar.
3. Project Name: Choose a fun name!
4. `OPENAI_API_KEY`: You can obtain this from the [OpenAI dashboard](https://platform.openai.com/api-keys).

### OpenInference Instrumentation:

This example shows how to use the OpenAI instrumentation. There are many more available which you can find in the official repository: https://github.com/Arize-ai/openinference

First, install the required dependencies:

```bash
pip install openai openinference-instrumentation-openai opentelemetry-exporter-otlp-proto-http
```

Next, paste the following code into a python file such as `openinference_example.py`

```python
import base64
import openai
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk import trace as trace_sdk
from opentelemetry.sdk.trace.export import ConsoleSpanExporter, SimpleSpanProcessor
from openinference.instrumentation.openai import OpenAIInstrumentor

OPENAI_API_KEY="YOUR_OPENAI_API_KEY"
WANDB_BASE_URL = "https://trace.wandb.ai"
PROJECT_ID = "/"

OTEL_EXPORTER_OTLP_ENDPOINT = f"{WANDB_BASE_URL}/otel/v1/traces"

# Can be found at https://wandb.ai/authorize
WANDB_API_KEY = ""
AUTH = base64.b64encode(f"api:{WANDB_API_KEY}".encode()).decode()

OTEL_EXPORTER_OTLP_HEADERS = {
    "Authorization": f"Basic {AUTH}",
    "project_id": PROJECT_ID,
}

tracer_provider = trace_sdk.TracerProvider()

# Configure the OTLP exporter
exporter = OTLPSpanExporter(
    endpoint=OTEL_EXPORTER_OTLP_ENDPOINT,
    headers=OTEL_EXPORTER_OTLP_HEADERS,
)

# Add the exporter to the tracer provider
tracer_provider.add_span_processor(SimpleSpanProcessor(exporter))

# Optionally, print the spans to the console.
tracer_provider.add_span_processor(SimpleSpanProcessor(ConsoleSpanExporter()))

OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)

def main():
    client = openai.OpenAI(api_key=OPENAI_API_KEY)
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": "Describe OTEL in a single sentence."}],
        max_tokens=20,
        stream=True,
        stream_options={"include_usage": True},
    )
    for chunk in response:
        if chunk.choices and (content := chunk.choices[0].delta.content):
            print(content, end="")

if __name__ == "__main__":
    main()
```

Finally, once you have set the fields specified above to their correct values, run the code:

```bash
python openinference_example.py
```

### OpenLLMetry Instrumentation:

The following example shows how to use the OpenAI instrumentation. Additional examples are available at [https://github.com/traceloop/openllmetry/tree/main/packages](https://github.com/traceloop/openllmetry/tree/main/packages).

First install the required dependencies:

```bash
pip install openai opentelemetry-instrumentation-openai opentelemetry-exporter-otlp-proto-http
```

Next, paste the following code into a python file such as `openllmetry_example.py`. Note that this is the same code as above, except the `OpenAIInstrumentor` is imported from `opentelemetry.instrumentation.openai` instead of `openinference.instrumentation.openai`

```python
import base64
import openai
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk import trace as trace_sdk
from opentelemetry.sdk.trace.export import ConsoleSpanExporter, SimpleSpanProcessor
from opentelemetry.instrumentation.openai import OpenAIInstrumentor

OPENAI_API_KEY="YOUR_OPENAI_API_KEY"
WANDB_BASE_URL = "https://trace.wandb.ai"
PROJECT_ID = "/"

OTEL_EXPORTER_OTLP_ENDPOINT = f"{WANDB_BASE_URL}/otel/v1/traces"

# Can be found at https://wandb.ai/authorize
WANDB_API_KEY = ""
AUTH = base64.b64encode(f"api:{WANDB_API_KEY}".encode()).decode()

OTEL_EXPORTER_OTLP_HEADERS = {
    "Authorization": f"Basic {AUTH}",
    "project_id": PROJECT_ID,
}

tracer_provider = trace_sdk.TracerProvider()

# Configure the OTLP exporter
exporter = OTLPSpanExporter(
    endpoint=OTEL_EXPORTER_OTLP_ENDPOINT,
    headers=OTEL_EXPORTER_OTLP_HEADERS,
)

# Add the exporter to the tracer provider
tracer_provider.add_span_processor(SimpleSpanProcessor(exporter))

# Optionally, print the spans to the console.
tracer_provider.add_span_processor(SimpleSpanProcessor(ConsoleSpanExporter()))

OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)

def main():
    client = openai.OpenAI(api_key=OPENAI_API_KEY)
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": "Describe OTEL in a single sentence."}],
        max_tokens=20,
        stream=True,
        stream_options={"include_usage": True},
    )
    for chunk in response:
        if chunk.choices and (content := chunk.choices[0].delta.content):
            print(content, end="")

if __name__ == "__main__":
    main()
```

Finally, once you have set the fields specified above to their correct values, run the code:

```bash
python openllmetry_example.py
```

### Without Instrumentation

If you would prefer to use OTEL directly instead of an instrumentation package, you may do so. Span attributes will be parsed according to the OpenTelemetry semantic conventions described at [https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-spans/](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-spans/).

First, install the required dependencies:

```bash
pip install openai opentelemetry-sdk opentelemetry-api opentelemetry-exporter-otlp-proto-http
```

Next, paste the following code into a python file such as `opentelemetry_example.py`

```python
import json
import base64
import openai
from opentelemetry import trace
from opentelemetry.sdk import trace as trace_sdk
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace.export import ConsoleSpanExporter, SimpleSpanProcessor

OPENAI_API_KEY = "YOUR_OPENAI_API_KEY"
WANDB_BASE_URL = "https://trace.wandb.ai"
PROJECT_ID = "/"

OTEL_EXPORTER_OTLP_ENDPOINT = f"{WANDB_BASE_URL}/otel/v1/traces"

# Can be found at https://wandb.ai/authorize
WANDB_API_KEY = ""
AUTH = base64.b64encode(f"api:{WANDB_API_KEY}".encode()).decode()

OTEL_EXPORTER_OTLP_HEADERS = {
    "Authorization": f"Basic {AUTH}",
    "project_id": PROJECT_ID,
}

tracer_provider = trace_sdk.TracerProvider()

# Configure the OTLP exporter
exporter = OTLPSpanExporter(
    endpoint=OTEL_EXPORTER_OTLP_ENDPOINT,
    headers=OTEL_EXPORTER_OTLP_HEADERS,
)

# Add the exporter to the tracer provider
tracer_provider.add_span_processor(SimpleSpanProcessor(exporter))

# Optionally, print the spans to the console.
tracer_provider.add_span_processor(SimpleSpanProcessor(ConsoleSpanExporter()))

trace.set_tracer_provider(tracer_provider)
# Creates a tracer from the global tracer provider
tracer = trace.get_tracer(__name__)
tracer.start_span('name=standard-span')

def my_function():
    with tracer.start_as_current_span("outer_span") as outer_span:
        client = openai.OpenAI()
        input_messages=[{"role": "user", "content": "Describe OTEL in a single sentence."}]
        # This will only appear in the side panel
        outer_span.set_attribute("input.value", json.dumps(input_messages))
        # This follows conventions and will appear in the dashboard
        outer_span.set_attribute("gen_ai.system", 'openai')
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=input_messages,
            max_tokens=20,
            stream=True,
            stream_options={"include_usage": True},
        )
        out = ""
        for chunk in response:
            if chunk.choices and (content := chunk.choices[0].delta.content):
                out += content
        # This will only appear in the side panel
        outer_span.set_attribute("output.value", json.dumps({"content": out}))

if __name__ == "__main__":
    my_function()
```

Finally, once you have set the fields specified above to their correct values, run the code:

```bash
python opentelemetry_example.py
```

The span attribute prefixes `gen_ai` and `openinference` are used to determine which convention to use, if any, when interpreting the trace. If neither key is detected, then all span attributes are visible in the trace view. The full span is available in the side panel when you select a trace.

[Source](https://weave-docs.wandb.ai/guides/tracking/otel)

<!--- Docs: Tracking -->
<!--- Video -->

# Video

# Video Support

Weave automatically logs videos using [`moviepy`](https://zulko.github.io/moviepy/). This allows you to pass video inputs and outputs to traced functions, and Weave will automatically handle uploading and storing video data.

> 💡 **Note**: Video support is currently only available in Python.

## Supported video types

Weave recognizes `moviepy` video clip objects, such as:

- A `VideoFileClip` loaded from a video file
- In-memory clips like `ImageClip`, `ColorClip`, and `TextClip`

### Direct upload of file-based clips

If your clip is a `VideoFileClip` and has a valid filename with a supported extension, Weave will upload the file directly.

**Supported file extensions:**

- `.mp4`
- `.webm`
- `.gif`

### In-memory clip support

If the video object is in memory (no file on disk), Weave will encode it as an `.mp4` file and handle the upload automatically. This applies to clips of the following type:

- `ImageClip`
- `ColorClip`
- `TextClip`

## Example: Trace a video function

The following code sample demonstrates how to trace a video processing function in Weave. The code sample:

1. Initializes a Weave project `video-test`.
2. Defines a `get_video` function tracked as a `weave.op` that extracts a 1 second subclip of the loaded `VideoFileClip` as a `VideoClip`.
3. Uploads and tracks the clip in Weave.
4. Automatically generates a dummy MP4 video if none is found.

Before you can use the code sample, complete the prerequisites:

1. Install `weave` and `moviepy==1.0.3`.
2. Create a W&B account.

> 🚨 **Important**: To avoid thread-safety issues, always pass the path to `VideoFileClip` objects instead of creating them outside the Weave `op`.

```python
import os
import weave
from moviepy import VideoFileClip, ColorClip, VideoClip

# Update to your project name, or create a new project named 'video-test'
weave.init('video-test')

@weave.op
def get_video(clip: VideoFileClip) -> VideoClip:
    """Process a video by path rather than by passing the clip directly.

    This ensures that the VideoFileClip is created and managed within the
    Weave op's thread context, avoiding thread-safety issues.
    """
    new_clip = clip.subclip(0, 1)
    return new_clip

if __name__ == "__main__":
    os.makedirs("videos", exist_ok=True)

    # Update the path to point to your MP4 file
    video_path = './videos/example.mp4'

    # Generate a dummy video if it doesn't exist
    # Dummy video contents: A red square that displays for 5 seconds
    if not os.path.isfile(video_path):
        print("No video found. Creating dummy video...")
        dummy_clip = ColorClip(size=(640, 480), color=(255, 0, 0), duration=5)
        dummy_clip.write_videofile(video_path, fps=24)

    clip = VideoFileClip(video_path, has_mask=False, audio=True)
    get_video(clip) 
```

When the code sample runs successfully, you can view your video by clicking the link in the **Traces** table of your project.

[Source](https://weave-docs.wandb.ai/guides/tracking/video)

<!--- Docs: Tracking -->
<!--- Objects -->

# Objects

# Objects

## Publishing an object

Weave's serialization layer saves and versions objects.


  

    ```python
    import weave
    # Initialize tracking to the project 'intro-example'
    weave.init('intro-example')
    # Save a list, giving it the name 'cat-names'
    weave.publish(['felix', 'jimbo', 'billie'], 'cat-names')
    ```

  
  
    Publishing in TypeScript is still early, so not all objects are fully supported yet.

    ```typescript
    import * as weave from 'weave'

    // Initialize tracking to the project 'intro-example'
    const client = await weave.init('intro-example')

    // Save an array, giving it the name 'cat-names'
    client.publish(['felix', 'jimbo', 'billie'], 'cat-names')
    ```

  


Saving an object with a name will create the first version of that object if it doesn't exist.

## Getting an object back


  
    `weave.publish` returns a Ref. You can call `.get()` on any Ref to get the object back.

    You can construct a ref and then fetch the object back.

    ```python
    weave.init('intro-example')
    cat_names = weave.ref('cat-names').get()
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


## Deleting an object


  
    To delete a version of an object, call `.delete()` on the object ref.

    ```python
    weave.init('intro-example')
    cat_names_ref = weave.ref('cat-names:v1')
    cat_names_ref.delete()
    ```

    Trying to access a deleted object will result in an error. Resolving an object that has a reference to a deleted object will return a `DeletedRef` object in place of the deleted object.

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


## Ref styles

A fully qualified weave object ref uri looks like this:

```
weave://///object/:
```

- _entity_: wandb entity (username or team)
- _project_: wandb project
- _object_name_: object name
- _object_version_: either a version hash, a string like v0, v1..., or an alias like ":latest". All objects have the ":latest" alias.

Refs can be constructed with a few different styles

- `weave.ref()`: requires `weave.init()` to have been called. Refers to the ":latest" version
- `weave.ref(:)`: requires `weave.init()` to have been called.
- `weave.ref()`: can be constructed without calling weave.init

[Source](https://weave-docs.wandb.ai/guides/tracking/objects)

<!--- Docs: Tracking -->
<!--- Trace Tree -->

# Trace Tree

# Navigate the Trace View

The Weave Trace view is designed to help you make sense of complex execution paths in your LLM and agentic apps. Whether you're debugging an agentic app with dozens of nested calls, or tracking the flow of a single model prediction, the Trace view provides a clear breakdown, while also providing alternate ways to view and understand your application flow.

This guide describes how to move through the trace stack, filter and search for ops, switch between visual representations, and more.

## Get started

To enter the Trace view:
1. Navigate to the **Traces** tab.
2. Click on any trace to open the Trace view. The Trace view pops out and displays a hierarchical breakdown of the trace execution.

## Traces page overview

The Traces page is composed of three core panels:

- _Left sidebar_: A sortable, paginated list of all trace runs for the project.
- _Center panel_: Interactive [trace view](#trace-view-navigation) showing the stack and ops hierarchy for a selected trace. 
- _Right panel_: Detailed view for a selected op (Call, Code, Feedback, Scores, Summary, Use).



## Trace view navigation

- _Breadcrumbs_: At the top of the center panel, navigate up and down the trace stack via the breadcrumb trail.
- _Stack arrows_: Use the `↑` and `↓` buttons to move up and down the stack.
- _Double-click_: Double-click on an op to focus the view exclusively on that substack.
- _"Jump to Top" Button_: Return to the root of the trace stack.

### Filter and search

- _Filter an op by name_: Use the input bar above the trace tree to search for ops of a specific type (e.g., `tool`, `openai.response.create`).
- _Filter persistence_: Selecting ops across traces retains the sub-path context for easier comparison.



### Scrubbers and contextual navigation

The panel below the tree includes multiple scrubbers for navigating across calls:

- **Timeline**: Chronological order of events.
- **Peers**: Ops sharing the same type.
- **Siblings**: Ops with the same parent.
- **Stack**: Traverse up/down the call stack.

To view the available scrubbers, click the **^** button at the bottom of the panel.

Each scrubber has a slider and **>** jump buttons to move step-by-step.



### Alternate trace tree views

You can switch between multiple visual representations of the trace tree depending on your needs. To switch to an alternate trace view, click one of available options (default trace view, code composition, flame graph, graph view) in the upper right corner 

#### Traces (default)

The default view showing, stack hierarchy, cost per op, execution time, and status indicators.

#### Code view

In the code view, boxes represent ops and their nested calls. This is helpful for visualizing flow of function calls. In this view, you can click on a box to drill into that op and filter the call path.



#### Flame graph

The flame graph view provides a timeline-based visualization of execution depth and duration. This is helpful for when trying to understand performance diagnostics over time. You can click into frames to isolate sub-traces.



#### Graph view

The graph view shows hierarchical relationships between ops. This is useful for understanding parent/child relationships.

## Usage tips and tricks

- Use the **"Filter by op name”** search bar at the top of the trace tree view to quickly isolate relevant tool or LLM calls.
- Switch between views based on your debugging need. Use **Code View** for call logic, **Flame Graph** for to understand performance over time, and **Graph View** to understand structure.

[Source](https://weave-docs.wandb.ai/guides/tracking/trace-tree)

<!--- Docs: Tracking -->
<!--- Index -->

# Index

# Tracing

Weave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to "track insights between commits."

## Key Tracing Features

Weave's tracing functionality comprises three main components:

### Calls

[Calls](/guides/tracking/tracing) trace function calls, inputs, and outputs, enabling you to:

- Analyze data flow through your application
- Debug complex interactions between components
- Optimize application performance based on call patterns

### Ops

[Ops](/guides/tracking/ops) are automatically versioned and tracked functions (which produce Calls) that allow you to:

- Monitor function performance and behavior
- Maintain a record of function modifications
- Ensure experiment reproducibility

### Objects

[Objects](/guides/tracking/objects) form Weave's extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:

- Track changes in data structures over time
- Maintain a clear history of object modifications
- Easily revert to previous versions when needed

By leveraging these tracing capabilities, you can gain deeper insights into your application's behavior, streamline your development process, and build more robust AI-powered systems.

## FAQs

For answers to common questions about Weave tracing, see the [FAQs page](./faqs.md)

[Source](https://weave-docs.wandb.ai/guides/tracking/index)

<!--- Docs: Tracking -->
<!--- Tracing -->

# Tracing

import { DesktopWindow } from '../../../src/components/DesktopImage'


# Tracing Basics

<DesktopWindow 
  images={[
    TracingCallsMacroImage,
    BasicCallImage,
    TracingCallsFilterImage,
  ]}
  alt="Screenshot of Weave Calls"
  title="Weave Calls"
/>

:::info[Calls]
Calls are the fundamental building block in Weave. They represent a single execution of a function, including:
- Inputs (arguments)
- Outputs (return value) 
- Metadata (duration, exceptions, LLM usage, etc.)

Calls are similar to spans in the [OpenTelemetry](https://opentelemetry.io) data model. A Call can:
- Belong to a Trace (a collection of calls in the same execution context)
- Have parent and child Calls, forming a tree structure
:::

## Creating Calls

There are three main ways to create Calls in Weave:

### 1. Automatic tracking of LLM libraries



  
    Weave automatically tracks [calls to common LLM libraries](../integrations/index.md) like `openai`, `anthropic`, `cohere`, and `mistral`. Simply call [`weave.init('project_name')`](../../reference/python-sdk/weave/index.md#function-init) at the start of your program:

    > 🌟 **Tip**:     You can control Weave's default tracking behavior [using the `autopatch_settings` argument in `weave.init`](#configure-autopatching).
    :::

    ```python showLineNumbers
    import weave

    from openai import OpenAI
    client = OpenAI()

    # Initialize Weave Tracing
    weave.init('intro-example')

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {
                "role": "user",
                "content": "How are you?"
            }
        ],
        temperature=0.8,
        max_tokens=64,
        top_p=1,
    )
    ```

  
  
    Weave automatically tracks [calls to common LLM libraries](../integrations/index.md) like `openai`. Simply call [`await weave.init('project_name')`](../../reference/typescript-sdk/weave/functions/init.md) and wrap your OpenAI client with [`weave.wrapOpenAI`](../../reference/typescript-sdk/weave/functions/wrapOpenAI.md) at the start of your program:

    ```typescript showLineNumbers
    import OpenAI from 'openai'
    import * as weave from 'weave'

    const client = weave.wrapOpenAI(new OpenAI())

    // Initialize Weave Tracing
    await weave.init('intro-example')

    const response = await client.chat.completions.create({
      model: 'gpt-4',
      messages: [
        {
          role: 'user',
          content: 'How are you?',
        },
      ],
      temperature: 0.8,
      max_tokens: 64,
      top_p: 1,
    });
    ```

  


### 2. Decorating and wrapping functions

However, often LLM applications have additional logic (such as pre/post processing, prompts, etc.) that you want to track.


  
    Weave allows you to manually track these calls using the [`@weave.op`](../../reference/python-sdk/weave/index.md#function-op) decorator. For example:

    ```python showLineNumbers
    import weave

    # Initialize Weave Tracing
    weave.init('intro-example')

    # Decorate your function
    @weave.op
    def my_function(name: str):
        return f"Hello, {name}!"

    # Call your function -- Weave will automatically track inputs and outputs
    print(my_function("World"))
    ```

    You can also track [methods on classes](#4-track-class-and-object-methods).

  
  
    Weave allows you to manually track these calls by wrapping your function with [`weave.op`](../../reference/typescript-sdk/weave/functions/op.md). For example:

    ```typescript showLineNumbers
    import * as weave from 'weave'

    await weave.init('intro-example')

    function myFunction(name: string) {
        return `Hello, ${name}!`
    }

    const myFunctionOp = weave.op(myFunction)
    ```

    You can also define the wrapping inline:

    ```typescript
    const myFunctionOp = weave.op((name: string) => `Hello, ${name}!`)
    ```

    This works for both functions as well as methods on classes:

    ```typescript
    class MyClass {
        constructor() {
            this.myMethod = weave.op(this.myMethod)
        }

        myMethod(name: string) {
            return `Hello, ${name}!`
        }
    }
    ```
  



#### Getting a handle to the call object during execution


  
    Sometimes it is useful to get a handle to the `Call` object itself. You can do this by calling the `op.call` method, which returns both the result and the `Call` object. For example:

    ```python showLineNumbers
    result, call = my_function.call("World")
    ```

    Then, `call` can be used to set / update / fetch additional properties (most commonly used to get the ID of the call to be used for feedback).

    > 💡 **Note**:     If your op is a method on a class, you need to pass the instance as the first argument to the op (see example below).
    :::

    ```python showLineNumbers
    # Notice that we pass the `instance` as the first argument.
    print(instance.my_method.call(instance, "World"))
    ```


    ```python showLineNumbers
    import weave

    # Initialize Weave Tracing
    weave.init("intro-example")

    class MyClass:
        # Decorate your method
        @weave.op
        def my_method(self, name: str):
            return f"Hello, {name}!"

    instance = MyClass()

    # Call your method -- Weave will automatically track inputs and outputs
    instance.my_method.call(instance, "World")
    ```
  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  




#### Call display name


  
    Sometimes you may want to override the display name of a call. You can achieve this in one of four ways:

    1. Change the display name at the time of calling the op:

    ```python showLineNumbers
    result = my_function("World", __weave={"display_name": "My Custom Display Name"})
    ```

    :::note

    Using the `__weave` dictionary sets the call display name which will take precedence over the Op display name.

    :::

    2. Change the display name on a per-call basis. This uses the [`Op.call`](../../reference/python-sdk/weave/trace/weave.trace.op.md#function-call) method to return a `Call` object, which you can then use to set the display name using [`Call.set_display_name`](../../reference/python-sdk/weave/trace/weave.trace.weave_client.md#method-set_display_name).
    ```python showLineNumbers
    result, call = my_function.call("World")
    call.set_display_name("My Custom Display Name")
    ```

    3. Change the display name for all Calls of a given Op:

    ```python showLineNumbers
    @weave.op(call_display_name="My Custom Display Name")
    def my_function(name: str):
        return f"Hello, {name}!"
    ```

    4. The `call_display_name` can also be a function that takes in a `Call` object and returns a string.  The `Call` object will be passed automatically when the function is called, so you can use it to dynamically generate names based on the function's name, call inputs, fields, etc.

    1. One common use case is just appending a timestamp to the function's name.

        ```py
        from datetime import datetime

        @weave.op(call_display_name=lambda call: f"{call.func_name}__{datetime.now()}")
        def func():
            return ...
        ```

    2. You can also log custom metadata using `.attributes`

        ```py
        def custom_attribute_name(call):
            model = call.attributes["model"]
            revision = call.attributes["revision"]
            now = call.attributes["date"]

            return f"{model}__{revision}__{now}"

        @weave.op(call_display_name=custom_attribute_name)
        def func():
            return ...

        with weave.attributes(
            {
                "model": "finetuned-llama-3.1-8b",
                "revision": "v0.1.2",
                "date": "2024-08-01",
            }
        ):
            func()  # the display name will be "finetuned-llama-3.1-8b__v0.1.2__2024-08-01"


            with weave.attributes(
                {
                    "model": "finetuned-gpt-4o",
                    "revision": "v0.1.3",
                    "date": "2024-08-02",
                }
            ):
                func()  # the display name will be "finetuned-gpt-4o__v0.1.3__2024-08-02"
        ```


    **Technical Note:** "Calls" are produced by "Ops". An Op is a function or method that is decorated with `@weave.op`. 
    By default, the Op's name is the function name, and the associated calls will have the same display name. The above example shows how to override the display name for all Calls of a given Op.  Sometimes, users wish to override the name of the Op itself. This can be achieved in one of two ways:

    1. Set the `name` property of the Op before any calls are logged
    ```python showLineNumbers
    my_function.name = "My Custom Op Name"
    ```

    2. Set the `name` option on the op decorator
    ```python showLineNumbers
    @weave.op(name="My Custom Op Name)
    ```
  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  






#### Attributes


  
    When calling tracked functions, you can add additional metadata to the call by using [`weave.attributes`](../../reference/python-sdk/weave/index.md#function-attributes) context manager. In the example below, we add an `env` attribute to the call specified as `'production'`.

    ```python showLineNumbers
    # ... continued from above ...

    # Add additional attributes to the call
    with weave.attributes({'env': 'production'}):
        print(my_function.call("World"))
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


### 3. Manual Call tracking

You can also manually create Calls using the API directly.


    

        ```python showLineNumbers
        import weave

        # Initialize Weave Tracing
        client = weave.init('intro-example')

        def my_function(name: str):
            # Start a call
            call = client.create_call(op="my_function", inputs={"name": name})

            # ... your function code ...

            # End a call
            client.finish_call(call, output="Hello, World!")

        # Call your function
        print(my_function("World"))
        ```

    
    

    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```

    

    
    * Start a call: [POST `/call/start`](../../reference/service-api/call-start-call-start-post.api.mdx)
    * End a call: [POST `/call/end`](../../reference/service-api/call-end-call-end-post.api.mdx)
    ```bash
    curl -L 'https://trace.wandb.ai/call/start' \
    -H 'Content-Type: application/json' \
    -H 'Accept: application/json' \
    -d '{
        "start": {
            "project_id": "string",
            "id": "string",
            "op_name": "string",
            "display_name": "string",
            "trace_id": "string",
            "parent_id": "string",
            "started_at": "2024-09-08T20:07:34.849Z",
            "attributes": {},
            "inputs": {},
            "wb_run_id": "string"
        }
    }
    ```
    


### 4. Track class and object methods

You can also track class and object methods.


    
    Track any method on a class using `weave.op`.

    ```python showLineNumbers
    import weave

    # Initialize Weave Tracing
    weave.init("intro-example")

    class MyClass:
        # Decorate your method
        @weave.op
        def my_method(self, name: str):
            return f"Hello, {name}!"

    instance = MyClass()

    # Call your method -- Weave will automatically track inputs and outputs
    print(instance.my_method("World"))
    ```

    
    

    :::important
    **Using decorators in TypeScript**

    To use the `@weave.op` decorator with your TypeScript code, make sure your environment is properly configured:

    - **TypeScript v5.0 or newer**: Decorators are supported out of the box and no additional configuration is required.
    - **TypeScript older than v5.0**: Enable experimental support for decorators. For more details, see the [official TypeScript documentation on decorators](https://www.typescriptlang.org/docs/handbook/decorators.html).
    :::
    
    #### Decorate a class method

    Use `@weave.op` to trace instance methods.

    ```typescript
    class Foo {
        @weave.op
        async predict(prompt: string) {
            return "bar"
        }
    }
    ```

    #### Decorate a static class method

    Apply `@weave.op` to static methods to monitor utility functions within a class.

    ```typescript
    class MathOps {
        @weave.op
        static square(n: number): number {
            return n * n;
        }
    }
    ```

    



## Viewing Calls

    
    To view a call in the web app:
    1. Navigate to your project's "Traces" tab
    2. Find the call you want to view in the list
    3. Click on the call to open its details page
    
    The details page will show the call's inputs, outputs, runtime, and any additional metadata.
    
    
    
    
    To view a call using the Python API, you can use the [`get_call`](../../reference/python-sdk/weave/trace/weave.trace.weave_client#method-get_call) method:

    ```python
    import weave

    # Initialize the client
    client = weave.init("your-project-name")

    # Get a specific call by its ID
    call = client.get_call("call-uuid-here")

    print(call)
    ```

    
    
    ```typescript showLineNumbers
    import * as weave from 'weave'

    // Initialize the client
    const client = await weave.init('intro-example')

    // Get a specific call by its ID
    const call = await client.getCall('call-uuid-here')

    console.log(call)
    ```
    

    
    To view a call using the Service API, you can make a request to the [`/call/read`](../../reference/service-api/call-read-call-read-post.api.mdx) endpoint.

    ```bash
    curl -L 'https://trace.wandb.ai/call/read' \
    -H 'Content-Type: application/json' \
    -H 'Accept: application/json' \
    -d '{
        "project_id": "string",
        "id": "string",
    }'
    ```
    



## Updating Calls

Calls are mostly immutable once created, however, there are a few mutations which are supported:
* [Set Display Name](#set-display-name)
* [Add Feedback](#add-feedback)
* [Delete a Call](#delete-a-call)

All of these mutations can be performed from the UI by navigating to the call detail page:



### Set display name


    
    In order to set the display name of a call, you can use the [`Call.set_display_name`](../../reference/python-sdk/weave/trace/weave.trace.weave_client.md#method-set_display_name) method.

    ```python showLineNumbers
    import weave

    # Initialize the client
    client = weave.init("your-project-name")

    # Get a specific call by its ID
    call = client.get_call("call-uuid-here")

    # Set the display name of the call
    call.set_display_name("My Custom Display Name")
    ```
    
    
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
    
    
    To set the display name of a call using the Service API, you can make a request to the [`/call/update`](../../reference/service-api/call-update-call-update-post.api.mdx) endpoint.

    ```bash
    curl -L 'https://trace.wandb.ai/call/update' \
    -H 'Content-Type: application/json' \
    -H 'Accept: application/json' \
    -d '{
        "project_id": "string",
        "call_id": "string",
        "display_name": "string",
    }'
    ```
    


### Add feedback 

Please see the [Feedback Documentation](./feedback.md) for more details.

### Delete a Call


    
    To delete a Call using the Python API, you can use the [`Call.delete`](../../reference/python-sdk/weave/trace/weave.trace.weave_client.md#method-delete) method.

    ```python showLineNumbers
    import weave

    # Initialize the client
    client = weave.init("your-project-name")

    # Get a specific call by its ID
    call = client.get_call("call-uuid-here")
    
    # Delete the call
    call.delete()
    ```

    
    
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
    
    
    To delete a call using the Service API, you can make a request to the [`/calls/delete`](../../reference/service-api/calls-delete-calls-delete-post.api.mdx) endpoint.

    ```bash
    curl -L 'https://trace.wandb.ai/calls/delete' \
    -H 'Content-Type: application/json' \
    -H 'Accept: application/json' \
    -d '{
        "project_id": "string",
        "call_ids": [
            "string"
        ],
    }'
    ```
    


### Delete multiple Calls


    
    To delete batches of Calls using the Python API, pass a list of Call IDs to `delete_calls()`.

    :::important
    - The maximum amount of Calls that can be deleted is `1000`.
    - Deleting a Call also deletes all of its children.
    :::

    ```python showLineNumbers
    import weave

    # Initialize the client
    client = weave.init("my-project")

    # Get all calls from client 
    all_calls = client.get_calls()

    # Get list of first 1000 Call objects
    first_1000_calls = all_calls[:1000]

    # Get list of first 1000 Call IDs
    first_1000_calls_ids = [c.id for c in first_1000_calls]

    # Delete first 1000 Call objects by ID
    client.delete_calls(call_ids=first_1000_calls_ids)
    ```

    
    
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
    


## Querying and exporting Calls

<DesktopWindow 
  images={[
    TracingCallsFilterImage,
  ]}
  alt="Screenshot of many calls"
  title="Weave Calls"
/>

The `/calls` page of your project ("Traces" tab) contains a table view of all the Calls in your project. From there, you can:
* Sort
* Filter
* Export



The Export Modal (shown above) allows you to export your data in a number of formats, as well as shows the Python & CURL equivalents for the selected calls!
The easiest way to get started is to construct a view in the UI, then learn more about the export API via the generated code snippets.



    
    To fetch calls using the Python API, you can use the [`client.get_calls`](../../reference/python-sdk/weave/trace/weave.trace.weave_client.md#method-get_calls) method:

    ```python
    import weave

    # Initialize the client
    client = weave.init("your-project-name")

    # Fetch calls
    calls = client.get_calls(filter=...)
    ```

    
    
    To fetch calls using the TypeScript API, you can use the [`client.getCalls`](../../reference/typescript-sdk/weave/classes/WeaveClient#getcalls) method.
    ```typescript
    import * as weave from 'weave'

    // Initialize the client
    const client = await weave.init('intro-example')

    // Fetch calls
    const calls = await client.getCalls(filter=...)
    ```
    
    
    The most powerful query layer is at the Service API. To fetch calls using the Service API, you can make a request to the [`/calls/stream_query`](../../reference/service-api/calls-query-stream-calls-stream-query-post.api.mdx) endpoint.

    ```bash
    curl -L 'https://trace.wandb.ai/calls/stream_query' \
    -H 'Content-Type: application/json' \
    -H 'Accept: application/json' \
    -d '{
    "project_id": "string",
    "filter": {
        "op_names": [
            "string"
        ],
        "input_refs": [
            "string"
        ],
        "output_refs": [
            "string"
        ],
        "parent_ids": [
            "string"
        ],
        "trace_ids": [
            "string"
        ],
        "call_ids": [
            "string"
        ],
        "trace_roots_only": true,
        "wb_user_ids": [
            "string"
        ],
        "wb_run_ids": [
            "string"
        ]
    },
    "limit": 100,
    "offset": 0,
    "sort_by": [
        {
        "field": "string",
        "direction": "asc"
        }
    ],
    "query": {
        "$expr": {}
    },
    "include_costs": true,
    "include_feedback": true,
    "columns": [
        "string"
    ],
    "expand_columns": [
        "string"
    ]
    }'
    ```
    


{/* ## Compare calls
info[Comming Soon] */}

### Call schema

Please see the [schema](../../reference/python-sdk/weave/trace_server/weave.trace_server.trace_server_interface#class-callschema) for a complete list of fields.


| Property | Type | Description |
|----------|------|-------------|
| id | string (uuid) | Unique identifier for the call |
| project_id | string (optional) | Associated project identifier |
| op_name | string | Name of the operation (can be a reference) |
| display_name | string (optional) | User-friendly name for the call |
| trace_id | string (uuid) | Identifier for the trace this call belongs to |
| parent_id | string (uuid) | Identifier of the parent call |
| started_at | datetime | Timestamp when the call started |
| attributes | Dict[str, Any] | User-defined metadata about the call |
| inputs | Dict[str, Any] | Input parameters for the call |
| ended_at | datetime (optional) | Timestamp when the call ended |
| exception | string (optional) | Error message if the call failed |
| output | Any (optional) | Result of the call |
| summary | Optional[SummaryMap] | Post-execution summary information |
| wb_user_id | Optional[str] | Associated Weights & Biases user ID |
| wb_run_id | Optional[str] | Associated Weights & Biases run ID |
| deleted_at | datetime (optional) | Timestamp of call deletion, if applicable |

The table above outlines the key properties of a Call in Weave. Each property plays a crucial role in tracking and managing function calls:

- The `id`, `trace_id`, and `parent_id` fields help in organizing and relating calls within the system.
- Timing information (`started_at`, `ended_at`) allows for performance analysis.
- The `attributes` and `inputs` fields provide context for the call, while `output` and `summary` capture the results.
- Integration with Weights & Biases is facilitated through `wb_user_id` and `wb_run_id`.

This comprehensive set of properties enables detailed tracking and analysis of function calls throughout your project.


Calculated Fields:
    * Cost
    * Duration
    * Status

## Saved views 

You can save your Trace table configurations, filters, and sorts as _saved views_ for quick access to your preferred setup. You can configure and access saved views via the UI and the Python SDK. For more information, see [Saved Views](/guides/tools/saved-views.md).

## View a W&B run in the Traces table

With Weave, you can trace function calls in your code and link them directly to the [W&B runs](https://docs.wandb.ai/guides/runs/) in which they were executed. 
When you trace a function with @weave.op() and call it inside a wandb.init() context, Weave automatically associates the trace with the W&B run. 
Links to any associated runs are shown in the Traces table.

### Python example

The following Python code shows how traced operations are linked to W&B
runs when executed inside a `wandb.init()` context. These traces appear in the
Weave UI and are associated with the corresponding run.

```python 
import wandb
import weave

def example_wandb(projname):
    # Split projname into entity and project
    entity, project = projname.split("/", 1)

    # Initialize Weave context for tracing
    weave.init(projname)

    # Define a traceable operation
    @weave.op()
    def say(message: str) -> str:
        return f"I said: {message}"

    # First W&B run
    with wandb.init(
        entity=entity,
        project=project,
        notes="Experiment 1",
        tags=["baseline", "paper1"],
    ) as run:
        say("Hello, world!")
        say("How are you!")
        run.log({"messages": 2})

    # Second W&B run
    with wandb.init(
        entity=entity,
        project=project,
        notes="Experiment 2",
        tags=["baseline", "paper1"],
    ) as run:
        say("Hello, world from experiment 2!")
        say("How are you!")
        run.log({"messages": 2})


if __name__ == "__main__":
    # Replace this with your actual W&B username/project
    example_wandb("your-username/your-project")
```

To use the code sample:

1. In the terminal, install dependencies:

   ```bash
   pip install wandb weave
   ```

2. Log in to W&B:

   ```bash
   wandb login
   ```

3. In the script, replace `your-username/your-project` with your actual W&B entity/project.
4. Run the script:

   ```bash
   python weave_trace_with_wandb.py
   ```
5. Visit [https://weave.wandb.ai](https://weave.wandb.ai) and select your project.
6. In the **Traces** tab, view the trace output. Links to any associated runs are shown in the Traces table.

## Configure autopatching

By default, Weave automatically patches and tracks calls to common LLM libraries like `openai`, `anthropic`, `cohere`, and `mistral`.
You can control this behavior using the `autopatch_settings` argument in `weave.init`.

### Disable all autopatching

```python showLineNumbers
weave.init(..., autopatch_settings={"disable_autopatch": True})
```

### Disable a specific integration

```python showLineNumbers
weave.init(..., autopatch_settings={"openai": {"enabled": False}})
```

### Post-process inputs and outputs 

You can also customize how post-process inputs and outputs (e.g. for PII data) are handled during autopatching:

```python showLineNumbers
def redact_inputs(inputs: dict) -> dict:
    if "email" in inputs:
        inputs["email"] = "[REDACTED]"
    return inputs

weave.init(
    ...,
    autopatch_settings={
        "openai": {
            "op_settings": {
                "postprocess_inputs": redact_inputs,
            }
        }
    }
)
```

For more details, see [How to use Weave with PII data](../../reference/gen_notebooks/pii.md).

## FAQs

### How do I stop large traces from being truncated?

For more information, see [Trace data is truncated](../troubleshooting.md#trace-data-is-truncated) in the [Troubleshooting guide](../troubleshooting.md).

### How do I disable tracing?

#### Environment variable

In situations where you want to unconditionally disable tracing for the entire program, you can set the environment variable `WEAVE_DISABLED=true`.

#### Client initialization

Sometimes, you may want to conditionally enable tracing for a specific initialization based on some condition. In this case, you can initialize the client with the `disabled` flag in init settings.

```python
import weave

# Initialize the client
client = weave.init(..., settings={"disabled": True})
```

#### Context manager

Finally, you may want to conditionally disable tracing for a single function based on some application logic. In this case, you can use the context manager `with set_tracing_enabled(False)` which can be imported from `weave.trace.context.call_context`.

```python
import weave
from weave.trace.context.call_context import set_tracing_enabled

client = weave.init(...)

@weave.op
def my_op():
    ...

with set_tracing_enabled(False):
    my_op()
```

### How do I capture information about a Call?

Typically you would call an op directly:

```python
@weave.op
def my_op():
    ...

my_op()
```

However, you can also get access to the call object directly by invoking the `call` method on the op:

```python
@weave.op
def my_op():
    ...

output, call = my_op.call()
```

From here, the `call` object will have all the information about the call, including the inputs, outputs, and other metadata.

[Source](https://weave-docs.wandb.ai/guides/tracking/tracing)

<!--- Docs: Tracking -->
<!--- Feedback -->

# Feedback

# Feedback

Efficiently evaluating LLM applications requires robust tooling to collect and analyze feedback. Weave provides an integrated feedback system, allowing users to provide call feedback directly through the UI or programmatically via the SDK. Various feedback types are supported, including emoji reactions, textual comments, and structured data, enabling teams to:

- Build evaluation datasets for performance monitoring.
- Identify and resolve LLM content issues effectively.
- Gather examples for advanced tasks like fine-tuning.

This guide covers how to use Weave’s feedback functionality in both the UI and SDK, query and manage feedback, and use human annotations for detailed evaluations.

- [Provide feedback in the UI](#provide-feedback-in-the-ui)
- [Provide feedback via the SDK](#provide-feedback-via-the-sdk)
- [Add human annotations](#add-human-annotations)

## Provide feedback in the UI

In the Weave UI, you can add and view feedback [from the call details page](#from-the-call-details-page) or [using the icons](#use-the-icons).

### From the call details page

1. In the sidebar, navigate to **Traces**.
2. Find the row for the call that you want to add feedback to.
3. Open the call details page.
4. Select the **Feedback** column for the call.
5. Add, view, or delete feedback:
   - _[Add and view feedback using the icons](#use-the-icons)_ located in the upper right corner of the call details feedback view.
   - _View and delete feedback from the call details feedback table._ Delete feedback by clicking the trashcan icon in the rightmost column of the appropriate feedback row.



### Use the icons

You can add or remove a reaction, and add a note using the icons that are located in both the call table and individual call details pages.

- _Call table_: Located in **Feedback** column in the appropriate row in the call table.
- _Call details page_: Located in the upper right corner of each call details page.

To add a reaction:

1. Click the emoji icon.
2. Add a thumbs up, thumbs down, or click the **+** icon for more emojis.

To remove a reaction:

1. Hover over the emoji reaction you want to remove.
2. Click the reaction to remove it.

> You can also delete feedback from the [**Feedback** column on the call details page.](#from-the-call-details-page).

To add a comment:

1. Click the comment bubble icon.
2. In the text box, add your note.
3. To save the note, press the **Enter** key. You can add additional notes.

> 🚨 **Important**: The maximum number of characters in a feedback note is 1024. If a note exceeds this limit, it will not be created.



## Provide feedback via the SDK

> You can find SDK usage examples for feedback in the UI under the **Use** tab in the call details page.

You can use the Weave SDK to programmatically add, remove, and query feedback on calls.

### Query a project's feedback

You can query the feedback for your Weave project using the SDK. The SDK supports the following feedback query operations:

- `client.get_feedback()`: Returns all feedback in a project.
- `client.get_feedback("")`: Return a specific feedback object specified by `` as a collection.
- `client.get_feedback(reaction="")`: Returns all feedback objects for a specific reaction type.

You can also get additional information for each feedback object in `client.get_feedback()`:

- `id`: The feedback object ID.
- `created_at`: The creation time information for the feedback object.
- `feedback_type`: The type of feedback (reaction, note, custom).
- `payload`: The feedback payload


  
    ```python
    import weave
    client = weave.init('intro-example')

    # Get all feedback in a project
    all_feedback = client.get_feedback()

    # Fetch a specific feedback object by id.
    # The API returns a collection, which is expected to contain at most one item.
    one_feedback = client.get_feedback("")[0]

    # Find all feedback objects with a specific reaction. You can specify offset and limit.
    thumbs_up = client.get_feedback(reaction="👍", limit=10)

    # After retrieval, view the details of individual feedback objects.
    for f in client.get_feedback():
        print(f.id)
        print(f.created_at)
        print(f.feedback_type)
        print(f.payload)
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


### Add feedback to a call

You can add feedback to a call using the call's UUID. To use the UUID to get a particular call, [retrieve it during or after call execution](#retrieve-the-call-uuid). The SDK supports the following operations for adding feedback to a call:

- `call.feedback.add_reaction("")`: Add one of the supported `` (emojis), such as 👍.
- `call.feedback.add_note("")`: Add a note.
- `call.feedback.add("", )`: Add a custom feedback `` specified by ``.

> 🚨 **Important**: The maximum number of characters in a feedback note is 1024. If a note exceeds this limit, it will not be created.


  
    ```python
    import weave
    client = weave.init('intro-example')

    call = client.get_call("")

    # Adding an emoji reaction
    call.feedback.add_reaction("👍")

    # Adding a note
    call.feedback.add_note("this is a note")

    # Adding custom key/value pairs.
    # The first argument is a user-defined "type" string.
    # Feedback must be JSON serializable and less than 1 KB when serialized.
    call.feedback.add("correctness", { "value": 5 })
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


#### Retrieve the call UUID

For scenarios where you need to add feedback immediately after a call, you can retrieve the call UUID programmatically during or after the call execution.

- [During call execution](#during-call-execution)
- [After call execution](#after-call-execution)

##### During call execution

To retrieve the UUID during call execution, get the current call, and return the ID.


  
    ```python

    import weave
    weave.init("uuid")

    @weave.op()
    def simple_operation(input_value):
        # Perform some simple operation
        output = f"Processed {input_value}"
        # Get the current call ID
        current_call = weave.require_current_call()
        call_id = current_call.id
        return output, call_id
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


##### After call execution

Alternatively, you can use `call()` method to execute the operation and retrieve the ID after call execution:


  
    ```python
    import weave
    weave.init("uuid")

    @weave.op()
    def simple_operation(input_value):
        return f"Processed {input_value}"

    # Execute the operation and retrieve the result and call ID
    result, call = simple_operation.call("example input")
    call_id = call.id
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


### Delete feedback from a call

You can delete feedback from a particular call by specifying a UUID.


  
    ```python
    call.feedback.purge("")
    ```
  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


## Add human annotations

Human annotations are supported in the Weave UI. To make human annotations, you must first create a Human Annotation scorer using either the [UI](#create-a-human-annotation-scorer-in-the-ui) or the [API](#create-a-human-annotation-scorer-using-the-api). Then, you can [use the scorer in the UI to make annotations](#use-the-human-annotation-scorer-in-the-ui), and [modify your annotation scorers using the API](#modify-a-human-annotation-scorer-using-the-api).

### Create a human annotation scorer in the UI

To create a human annotation scorer in the UI, do the following:

1. In the sidebar, navigate to **Scorers**.
2. In the upper right corner, click **+ Create scorer**.
3. In the configuration page, set:
   - `Scorer type` to `Human annotation`
   - `Name`
   - `Description`
   - `Type`, which determines the type of feedback that will be collected, such as `boolean` or `integer`.
4. Click **Create scorer**. Now, you can [use your scorer to make annotations](#use-the-human-annotation-scorer-in-the-ui).

In the following example, a human annotator is asked to select which type of document the LLM ingested. As such, the `Type` selected for the score configuration is an `enum` containing the possible document types.



### Use the human annotation scorer in the UI

Once you [create a human annotation scorer](#create-a-human-annotation-scorer-in-the-ui), it will automatically display in the **Feedback** sidebar of the call details page with the configured options. To use the scorer, do the following:

1. In the sidebar, navigate to **Traces**
2. Find the row for the call that you want to add a human annotation to.
3. Open the call details page.
4. In the upper right corner, click the **Show feedback** button.

   

   Your available human annotation scorers display in the sidebar.

   

5. Make an annotation.
6. Click **Save**.
7. In the call details page, click **Feedback** to view the calls table. The new annotation displays in the table. You can also view the annotations in the **Annotations** column in the call table in **Traces**.

   > Refresh the call table to view the most up-to-date information.



### Create a human annotation scorer using the API

Human annotation scorers can also be created through the API. Each scorer is its own object, which is created and updated independently. To create a human annotation scorer programmatically, do the following:

1. Import the `AnnotationSpec` class from `weave.flow.annotation_spec`
2. Use the `publish` method from `weave` to create the scorer.

In the following example, two scorers are created. The first scorer, `Temperature`, is used to score the perceived temperature of the LLM call. The second scorer, `Tone`, is used to score the tone of the LLM response. Each scorer is created using `save` with an associated object ID (`temperature-scorer` and `tone-scorer`).


  
    ```python
    import weave
    from weave.flow.annotation_spec import AnnotationSpec

    client = weave.init("feedback-example")

    spec1 = AnnotationSpec(
      name="Temperature",
      description="The perceived temperature of the llm call",
      field_schema={
        "type": "number",
        "minimum": -1,
        "maximum": 1,
      }
    )
    spec2 = AnnotationSpec(
      name="Tone",
      description="The tone of the llm response",
      field_schema={
        "type": "string",
        "enum": ["Aggressive", "Neutral", "Polite", "N/A"],
      },
    )
    weave.publish(spec1, "temperature-scorer")
    weave.publish(spec2, "tone-scorer")
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


### Modify a human annotation scorer using the API

Expanding on [creating a human annotation scorer using the API](#create-a-human-annotation-scorer-using-the-api), the following example creates an updated version of the `Temperature` scorer, by using the original object ID (`temperature-scorer`) on `publish`. The result is an updated object, with a history of all versions.

> You can view human annotation scorer object history in the **Scorers** tab under **Human annotations**.


  
    ```python
    import weave
    from weave.flow.annotation_spec import AnnotationSpec

    client = weave.init("feedback-example")

    # create a new version of the scorer
    spec1 = AnnotationSpec(
      name="Temperature",
      description="The perceived temperature of the llm call",
      field_schema={
        "type": "integer",  # <<- change type to integer
        "minimum": -1,
        "maximum": 1,
      }
    )
    weave.publish(spec1, "temperature-scorer")
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  




### Use a human annotation scorer using the API

The feedback API allows you to use a human annotation scorer by specifying a specially constructed name and an `annotation_ref` field. You can obtain the `annotation_spec_ref` from the UI by selecting the appropriate tab, or during the creation of the `AnnotationSpec`.


  
    ```python
    import weave

    client = weave.init("feedback-example")

    call = client.get_call("")
    annotation_spec = weave.ref("")

    call.feedback.add(
      feedback_type="wandb.annotation." + annotation_spec.name,
      payload={"value": 1},
      annotation_ref=annotation_spec.uri(),
    )
    ```

[Source](https://weave-docs.wandb.ai/guides/tracking/feedback)

<!--- Docs: Tracking -->
<!--- Redact Pii -->

# Redact Pii

# Redacting PII

> 🚨 **Important**: This feature is only accessible via the Python SDK.

Some organizations process Personally Identifiable Information (PII) such as names, phone numbers, and email addresses in their Large Language Model (LLM) workflows. Storing this data in Weights & Biases (W&B) Weave poses compliance and security risks.

The _Sensitive Data Protection_ feature allows you to automatically redact Personally Identifiable Information (PII) from a [trace](../tracking/index.md) before it is sent to Weave servers. This feature integrates [Microsoft Presidio](https://microsoft.github.io/presidio/) into the Weave Python SDK, which means that you can control redaction settings at the SDK level.

The Sensitive Data Protection feature introduces the following functionality to the Python SDK:

- A `redact_pii` setting, which can be toggled on or off in the `weave.init` call to enable PII redaction.
- Automatic redaction of [common entities](#entities-redacted-by-default) when `redact_pii = True`.
- Customizable redaction fields using the configurable `redact_pii_fields` setting.

## Enable PII redaction

To get started with the Sensitive Data Protection feature in Weave, complete the following steps:

1. Install the required dependencies:

    ```bash
    pip install presidio-analyzer presidio-anonymizer
    ```

2. Modify your `weave.init` call to enable redaction. When `redact_pii=True`, [common entities are redacted by default](#entities-redacted-by-default):

    ```python
    import weave

    weave.init("my-project", settings={"redact_pii": True})
    ```

3. (Optional) Customize redaction fields using the `redact_pii_fields` parameter:

    ```python
    weave.init("my-project", settings={"redact_pii": True, "redact_pii_fields":["CREDIT_CARD", "US_SSN"]})
    ```

    For a full list of the entities that can be detected and redacted, see [PII entities supported by Presidio](https://microsoft.github.io/presidio/supported_entities/).

## Entities redacted by default

The following entities are automatically redacted when PII redaction is enabled:

- `CREDIT_CARD`
- `CRYPTO`
- `EMAIL_ADDRESS`
- `ES_NIF`
- `FI_PERSONAL_IDENTITY_CODE`
- `IBAN_CODE`
- `IN_AADHAAR`
- `IN_PAN`
- `IP_ADDRESS`
- `LOCATION`
- `PERSON`
- `PHONE_NUMBER`
- `UK_NHS`
- `UK_NINO`
- `US_BANK_NUMBER`
- `US_DRIVER_LICENSE`
- `US_PASSPORT`
- `US_SSN`

## Redacting sensitive keys with `REDACT_KEYS`

In addition to PII redaction, the Weave SDK also supports redaction of custom keys using `REDACT_KEYS`. This is useful when you want to protect additional sensitive data that might not fall under the PII category but needs to be kept private. Examples include:

- API keys
- Authentication headers
- Tokens
- Internal IDs
- Config values

### Pre-defined `REDACT_KEYS`

Weave automatically redacts the following sensitive keys by default:

```json
[
  "api_key",
  "auth_headers",
  "authorization"
]
```

### Adding your own keys

You can extend this list with your own custom keys that you want to redact from traces:

```python
import weave

client = weave.init("my-project")

# Add custom keys to redact
weave.trace.sanitize.REDACT_KEYS.add("client_id")
weave.trace.sanitize.REDACT_KEYS.add("whatever_else")

client_id = "123"
whatever_else = "456"

@weave.op()
def test():
    a = client_id
    b = whatever_else
    return 1
```

When viewed in the Weave UI, the values of `client_id` and `whatever_else` will appear as `"REDACTED"`:

```python
client_id = "REDACTED"
whatever_else = "REDACTED"
```

## Usage information

- This feature is only available in the Python SDK.
- Enabling redaction increases processing time due to the Presidio dependency.

[Source](https://weave-docs.wandb.ai/guides/tracking/redact-pii)



<!--- Docs: Tutorials -->
<!--- Tutorial Eval -->

# Tutorial Eval

# Tutorial: Build an Evaluation pipeline

To iterate on an application, we need a way to evaluate if it's improving. To do so, a common practice is to test it against the same set of examples when there is a change. Weave has a first-class way to track evaluations with `Model` & `Evaluation` classes. We have built the APIs to make minimal assumptions to allow for the flexibility to support a wide array of use-cases.



## 1. Build a `Model`


  

`Model`s store and version information about your system, such as prompts, temperatures, and more.
Weave automatically captures when they are used and updates the version when there are changes.

`Model`s are declared by subclassing `Model` and implementing a `predict` function definition, which takes one example and returns the response.

> 🚨 **Important**: **Known Issue**: If you are using Google Colab, remove `async` from the following examples.


    ```python
    import json
    import openai
    import weave
    class ExtractFruitsModel(weave.Model):
        model_name: str
        prompt_template: str
        @weave.op()
        async def predict(self, sentence: str) -> dict:
            client = openai.AsyncClient()

            response = await client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "user", "content": self.prompt_template.format(sentence=sentence)}
                ],
            )
            result = response.choices[0].message.content
            if result is None:
                raise ValueError("No response from model")
            parsed = json.loads(result)
            return parsed
    ```

    You can instantiate `Model` objects as normal like this:

    ```python
    import asyncio
    import weave

    weave.init('intro-example')

    model = ExtractFruitsModel(model_name='gpt-3.5-turbo-1106',
                            prompt_template='Extract fields ("fruit": , "color": , "flavor": ) from the following text, as json: {sentence}')
    sentence = "There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy."
    print(asyncio.run(model.predict(sentence)))
    # if you're in a Jupyter Notebook, run:
    # await model.predict(sentence)
    ```

> 💡 **Note**: Checkout the [Models](/guides/core-types/models) guide to learn more.

  
  

    `weave.Model` is not supported in TypeScript yet.  Instead, you can just wrap your model-like function with `weave.op`

    ```typescript
    // highlight-next-line
    const model = weave.op(async function myModel({datasetRow}) {
      const prompt = `Extract fields ("fruit": , "color": , "flavor") from the following text, as json: ${datasetRow.sentence}`;
      const response = await openaiClient.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [{role: 'user', content: prompt}],
        response_format: {type: 'json_object'},
      });
      const result = response?.choices?.[0]?.message?.content;
      if (result == null) {
        throw new Error('No response from model');
      }
      return JSON.parse(result);
    });
    ```

  


## 2. Collect some examples


  

    ```python
    sentences = [
        "There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.",
        "Pounits are a bright green color and are more savory than sweet.",
        "Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them."
    ]
    labels = [
        {'fruit': 'neoskizzles', 'color': 'purple', 'flavor': 'candy'},
        {'fruit': 'pounits', 'color': 'bright green', 'flavor': 'savory'},
        {'fruit': 'glowls', 'color': 'pale orange', 'flavor': 'sour and bitter'}
    ]
    examples = [
        {'id': '0', 'sentence': sentences[0], 'target': labels[0]},
        {'id': '1', 'sentence': sentences[1], 'target': labels[1]},
        {'id': '2', 'sentence': sentences[2], 'target': labels[2]}
    ]
    ```

  
  
  
    ```typescript
    const sentences = [
      'There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.',
      'Pounits are a bright green color and are more savory than sweet.',
      'Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.',
    ];
    const labels = [
      {fruit: 'neoskizzles', color: 'purple', flavor: 'candy'},
      {fruit: 'pounits', color: 'bright green', flavor: 'savory'},
      {fruit: 'glowls', color: 'pale orange', flavor: 'sour and bitter'},
    ];
    const examples = [
      {id: '0', sentence: sentences[0], target: labels[0]},
      {id: '1', sentence: sentences[1], target: labels[1]},
      {id: '2', sentence: sentences[2], target: labels[2]},
    ];
    const dataset = new weave.Dataset({
      id: 'Fruit Dataset',
      rows: examples,
    });
    ```
  


## 3. Evaluate a `Model`


  

`Evaluation`s assess a `Model`s performance on a set of examples using a list of specified scoring functions or `weave.scorer.Scorer` classes.

Here, we'll use a default scoring class `MultiTaskBinaryClassificationF1` and we'll also define our own `fruit_name_score` scoring function.

Here `sentence` is passed to the model's predict function, and `target` is used in the scoring function, these are inferred based on the argument names of the `predict` and scoring functions. The `fruit` key needs to be outputted by the model's predict function and must also be existing as a column in the dataset (or outputted by the `preprocess_model_input` function if defined).

    ```python
    import weave
    from weave.scorers import MultiTaskBinaryClassificationF1

    weave.init('intro-example')

    @weave.op()
    def fruit_name_score(target: dict, output: dict) -> dict:
        return {'correct': target['fruit'] == output['fruit']}
    evaluation = weave.Evaluation(
        dataset=examples,
        scorers=[
            MultiTaskBinaryClassificationF1(class_names=["fruit", "color", "flavor"]),
            fruit_name_score
        ],
    )
    print(asyncio.run(evaluation.evaluate(model)))
    # if you're in a Jupyter Notebook, run:
    # await evaluation.evaluate(model)
    ```

  
  
`Evaluation`s assess a model's performance on a set of examples using a list of specified scoring functions.

For this example, we'll define a few simple scoring functions.

Here, `sentence` is passed to the model and `...` is used in the scoring function. These are defined...

    ```typescript
        
    const client = await weave.init('intro-example');
    const openaiClient = weave.wrapOpenAI(new OpenAI());

    const fruitNameScorer = weave.op(
      ({modelOutput, datasetRow}) => datasetRow.target.fruit == modelOutput.fruit,
      {name: 'fruitNameScore'}
    );

    const evaluation = new weave.Evaluation({
      dataset: ds,
      scorers: [fruitNameScorer],
    });

    const results = await evaluation.evaluate(model);
    console.log(JSON.stringify(results, null, 2));
    ```

  


In some applications we want to create custom `Scorer` classes - where for example a standardized `LLMJudge` class should be created with specific parameters (e.g. chat model, prompt), specific scoring of each row, and specific calculation of an aggregate score. See the tutorial on defining a `Scorer` class in the next chapter on [Model-Based Evaluation of RAG applications](/tutorial-rag#optional-defining-a-scorer-class) for more information.

## 4. Pulling it all together


  
  
    ```python
    import json
    import asyncio
    import weave
    from weave.scorers import MultiTaskBinaryClassificationF1
    import openai

    # We create a model class with one predict function.
    # All inputs, predictions and parameters are automatically captured for easy inspection.
    class ExtractFruitsModel(weave.Model):
        model_name: str
        prompt_template: str
        @weave.op()
        async def predict(self, sentence: str) -> dict:
            client = openai.AsyncClient()

            response = await client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "user", "content": self.prompt_template.format(sentence=sentence)}
                ],
                response_format={ "type": "json_object" }
            )
            result = response.choices[0].message.content
            if result is None:
                raise ValueError("No response from model")
            parsed = json.loads(result)
            return parsed

    # We call init to begin capturing data in the project, intro-example.
    weave.init('intro-example')

    # We create our model with our system prompt.
    model = ExtractFruitsModel(name='gpt4',
                            model_name='gpt-4-0125-preview',
                            prompt_template='Extract fields ("fruit": , "color": , "flavor") from the following text, as json: {sentence}')
    sentences = ["There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.",
    "Pounits are a bright green color and are more savory than sweet.",
    "Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them."]
    labels = [
        {'fruit': 'neoskizzles', 'color': 'purple', 'flavor': 'candy'},
        {'fruit': 'pounits', 'color': 'bright green', 'flavor': 'savory'},
        {'fruit': 'glowls', 'color': 'pale orange', 'flavor': 'sour and bitter'}
    ]
    examples = [
        {'id': '0', 'sentence': sentences[0], 'target': labels[0]},
        {'id': '1', 'sentence': sentences[1], 'target': labels[1]},
        {'id': '2', 'sentence': sentences[2], 'target': labels[2]}
    ]
    # If you have already published the Dataset, you can run:
    # dataset = weave.ref('example_labels').get()

    # We define a scoring function to compare our model predictions with a ground truth label.
    @weave.op()
    def fruit_name_score(target: dict, output: dict) -> dict:
        return {'correct': target['fruit'] == output['fruit']}

    # Finally, we run an evaluation of this model.
    # This will generate a prediction for each input example, and then score it with each scoring function.
    evaluation = weave.Evaluation(
        name='fruit_eval',
        dataset=examples, scorers=[MultiTaskBinaryClassificationF1(class_names=["fruit", "color", "flavor"]), fruit_name_score],
    )
    print(asyncio.run(evaluation.evaluate(model)))
    # if you're in a Jupyter Notebook, run:
    # await evaluation.evaluate(model)
    ```

  
  

    ```typescript
        import 'source-map-support/register';
    
    const sentences = [
      'There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.',
      'Pounits are a bright green color and are more savory than sweet.',
      'Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.',
      'There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.',
    ];
    const labels = [
      {fruit: 'neoskizzles', color: 'purple', flavor: 'candy'},
      {fruit: 'pounits', color: 'bright green', flavor: 'savory'},
      {fruit: 'glowls', color: 'pale orange', flavor: 'sour and bitter'},
    ];
    const examples = [
      {id: '0', sentence: sentences[0], target: labels[0]},
      {id: '1', sentence: sentences[1], target: labels[1]},
      {id: '2', sentence: sentences[2], target: labels[2]},
    ];
    const dataset = new weave.Dataset({
      id: 'Fruit Dataset',
      rows: examples,
    });

    const openaiClient = weave.wrapOpenAI(new OpenAI());

    const model = weave.op(async function myModel({datasetRow}) {
      const prompt = `Extract fields ("fruit": , "color": , "flavor") from the following text, as json: ${datasetRow.sentence}`;
      const response = await openaiClient.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [{role: 'user', content: prompt}],
        response_format: {type: 'json_object'},
      });
      const result = response?.choices?.[0]?.message?.content;
      if (result == null) {
        throw new Error('No response from model');
      }
      return JSON.parse(result);
    });

    const fruitNameScorer = weave.op(
      ({modelOutput, datasetRow}) => datasetRow.target.fruit == modelOutput.fruit,
      {name: 'fruitNameScore'}
    );

    async function main() {
      await weave.init('examples');
      const evaluation = new weave.Evaluation({
        dataset,
        scorers: [fruitNameScorer],
      });

      const results = await evaluation.evaluate({model});
      console.log(JSON.stringify(results, null, 2));
    }

    main();

    ```

  


## What's next?

- Follow the [Model-Based Evaluation of RAG applications](/tutorial-rag) to evaluate a RAG app using an LLM judge.

[Source](https://weave-docs.wandb.ai/tutorial-eval)

<!--- Docs: Tutorials -->
<!--- Tutorial Rag -->

# Tutorial Rag

# Tutorial: Model-Based Evaluation of RAG applications

Retrieval Augmented Generation (RAG) is a common way of building Generative AI applications that have access to custom knowledge bases.

In this example, we'll show an example that has a retrieval step to get documents. By tracking this, you can debug your app and see what documents were pulled into the LLM context.
We'll also show how to evaluate it using an LLM judge.



Check out the [RAG++ course](https://www.wandb.courses/courses/rag-in-production?utm_source=wandb_docs&utm_medium=code&utm_campaign=weave_docs) for a more advanced dive into practical RAG techniques for engineers, where you'll learn production-ready solutions from Weights & Biases, Cohere and Weaviate to optimize performance, cut costs, and enhance the accuracy and relevance of your applications.

## 1. Build a knowledge base

First, we compute the embeddings for our articles. You would typically do this once with your articles and put the embeddings & metadata in a database, but here we're doing it every time we run our script for simplicity.


  
    ```python
    from openai import OpenAI
    import weave
    from weave import Model
    import numpy as np
    import json
    import asyncio

    articles = [
        "Novo Nordisk and Eli Lilly rival soars 32 percent after promising weight loss drug results Shares of Denmarks Zealand Pharma shot 32 percent higher in morning trade, after results showed success in its liver disease treatment survodutide, which is also on trial as a drug to treat obesity. The trial “tells us that the 6mg dose is safe, which is the top dose used in the ongoing [Phase 3] obesity trial too,” one analyst said in a note. The results come amid feverish investor interest in drugs that can be used for weight loss.",
        "Berkshire shares jump after big profit gain as Buffetts conglomerate nears $1 trillion valuation Berkshire Hathaway shares rose on Monday after Warren Buffetts conglomerate posted strong earnings for the fourth quarter over the weekend. Berkshires Class A and B shares jumped more than 1.5%, each. Class A shares are higher by more than 17% this year, while Class B has gained more than 18%. Berkshire was last valued at $930.1 billion, up from $905.5 billion where it closed on Friday, according to FactSet. Berkshire on Saturday posted fourth-quarter operating earnings of $8.481 billion, about 28 percent higher than the $6.625 billion from the year-ago period, driven by big gains in its insurance business. Operating earnings refers to profits from businesses across insurance, railroads and utilities. Meanwhile, Berkshires cash levels also swelled to record levels. The conglomerate held $167.6 billion in cash in the fourth quarter, surpassing the $157.2 billion record the conglomerate held in the prior quarter.",
        "Highmark Health says its combining tech from Google and Epic to give doctors easier access to information Highmark Health announced it is integrating technology from Google Cloud and the health-care software company Epic Systems. The integration aims to make it easier for both payers and providers to access key information they need, even if its stored across multiple points and formats, the company said. Highmark is the parent company of a health plan with 7 million members, a provider network of 14 hospitals and other entities",
        "Rivian and Lucid shares plunge after weak EV earnings reports Shares of electric vehicle makers Rivian and Lucid fell Thursday after the companies reported stagnant production in their fourth-quarter earnings after the bell Wednesday. Rivian shares sank about 25 percent, and Lucids stock dropped around 17 percent. Rivian forecast it will make 57,000 vehicles in 2024, slightly less than the 57,232 vehicles it produced in 2023. Lucid said it expects to make 9,000 vehicles in 2024, more than the 8,428 vehicles it made in 2023.",
        "Mauritius blocks Norwegian cruise ship over fears of a potential cholera outbreak Local authorities on Sunday denied permission for the Norwegian Dawn ship, which has 2,184 passengers and 1,026 crew on board, to access the Mauritius capital of Port Louis, citing “potential health risks.” The Mauritius Ports Authority said Sunday that samples were taken from at least 15 passengers on board the cruise ship. A spokesperson for the U.S.-headquartered Norwegian Cruise Line Holdings said Sunday that 'a small number of guests experienced mild symptoms of a stomach-related illness' during Norwegian Dawns South Africa voyage.",
        "Intuitive Machines lands on the moon in historic first for a U.S. company Intuitive Machines Nova-C cargo lander, named Odysseus after the mythological Greek hero, is the first U.S. spacecraft to soft land on the lunar surface since 1972. Intuitive Machines is the first company to pull off a moon landing — government agencies have carried out all previously successful missions. The company's stock surged in extended trading Thursday, after falling 11 percent in regular trading.",
        "Lunar landing photos: Intuitive Machines Odysseus sends back first images from the moon Intuitive Machines cargo moon lander Odysseus returned its first images from the surface. Company executives believe the lander caught its landing gear sideways on the moon's surface while touching down and tipped over. Despite resting on its side, the company's historic IM-1 mission is still operating on the moon.",
    ]

    def docs_to_embeddings(docs: list) -> list:
        openai = OpenAI()
        document_embeddings = []
        for doc in docs:
            response = (
                openai.embeddings.create(input=doc, model="text-embedding-3-small")
                .data[0]
                .embedding
            )
            document_embeddings.append(response)
        return document_embeddings

    article_embeddings = docs_to_embeddings(articles) # Note: you would typically do this once with your articles and put the embeddings & metadata in a database
    ```

  
  
    ```typescript
    require('dotenv').config();
        
    interface Article {
        text: string;
        embedding?: number[];
    }

    const articles: Article[] = [
        { 
            text: `Novo Nordisk and Eli Lilly rival soars 32 percent...` // truncated for brevity
        },
        // ... other articles
    ];

    function cosineSimilarity(a: number[], b: number[]): number {
        const dotProduct = a.reduce((sum, val, i) => sum + val * b[i], 0);
        const magnitudeA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));
        const magnitudeB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));
        return dotProduct / (magnitudeA * magnitudeB);
    }

    const docsToEmbeddings = weave.op(async function(docs: Article[]): Promise {
        const openai = new OpenAI();
        const enrichedDocs = await Promise.all(docs.map(async (doc) => {
            const response = await openai.embeddings.create({
                input: doc.text,
                model: "text-embedding-3-small"
            });
            return {
                ...doc,
                embedding: response.data[0].embedding
            };
        }));
        return enrichedDocs;
    });
    ```
  


## 2. Create a RAG app

Next, we wrap our retrieval function `get_most_relevant_document` with a `weave.op()` decorator and we create our `Model` class. We call `weave.init('rag-qa')` to begin tracking all the inputs and outputs of our functions for later inspection.


  
    ```python
    from openai import OpenAI
    import weave
    from weave import Model
    import numpy as np
    import asyncio
    @weave.op()
    def get_most_relevant_document(query):
        openai = OpenAI()
        query_embedding = (
            openai.embeddings.create(input=query, model="text-embedding-3-small")
            .data[0]
            .embedding
        )
        similarities = [
            np.dot(query_embedding, doc_emb)
            / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb))
            for doc_emb in article_embeddings
        ]
        # Get the index of the most similar document
        most_relevant_doc_index = np.argmax(similarities)
        return articles[most_relevant_doc_index]
    class RAGModel(Model):
        system_message: str
        model_name: str = "gpt-3.5-turbo-1106"
        @weave.op()
        def predict(self, question: str) -> dict: # note: `question` will be used later to select data from our evaluation rows
            from openai import OpenAI
            context = get_most_relevant_document(question)
            client = OpenAI()
            query = f"""Use the following information to answer the subsequent question. If the answer cannot be found, write "I don't know."
            Context:
            \"\"\"
            {context}
            \"\"\"
            Question: {question}"""
            response = client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": self.system_message},
                    {"role": "user", "content": query},
                ],
                temperature=0.0,
                response_format={"type": "text"},
            )
            answer = response.choices[0].message.content
            return {'answer': answer, 'context': context}
    weave.init('rag-qa')
    model = RAGModel(
        system_message="You are an expert in finance and answer questions related to finance, financial services, and financial markets. When responding based on provided information, be sure to cite the source."
    )
    model.predict("What significant result was reported about Zealand Pharma's obesity trial?")
    ```

  
  
    ```typescript
    class RAGModel {
        private openai: OpenAI;
        private systemMessage: string;
        private modelName: string;
        private articleEmbeddings: Article[];

        constructor(config: {
            systemMessage: string;
            modelName?: string;
            articleEmbeddings: Article[];
        }) {
            this.openai = weave.wrapOpenAI(new OpenAI());
            this.systemMessage = config.systemMessage;
            this.modelName = config.modelName || "gpt-3.5-turbo-1106";
            this.articleEmbeddings = config.articleEmbeddings;
            this.predict = weave.op(this, this.predict);
        }

        async predict(question: string): Promise<{
            answer: string;
            context: string;
        }> {
            const context = await this.getMostRelevantDocument(question);
            
            const response = await this.openai.chat.completions.create({
                model: this.modelName,
                messages: [
                    { role: "system", content: this.systemMessage },
                    { role: "user", content: `Use the following information...` }
                ],
                temperature: 0
            });

            return {
                answer: response.choices[0].message.content || "",
                context
            };
        }
    }
    ```
  


## 3. Evaluating with an LLM Judge

When there aren't simple ways to evaluate your application, one approach is to use an LLM to evaluate aspects of it. Here is an example of using an LLM judge to try to measure the context precision by prompting it to verify if the context was useful in arriving at the given answer. This prompt was augmented from the popular [RAGAS framework](https://docs.ragas.io/).

### Defining a scoring function

As we did in the [Build an Evaluation pipeline tutorial](/tutorial-eval), we'll define a set of example rows to test our app against and a scoring function. Our scoring function will take one row and evaluate it. The input arguments should match with the corresponding keys in our row, so `question` here will be taken from the row dictionary. `output` is the output of the model. The input to the model will be taken from the example based on its input argument, so `question` here too. We're using `async` functions so they run fast in parallel. If you need a quick introduction to async, you can find one [here](https://docs.python.org/3/library/asyncio.html).


  
    ```python
    from openai import OpenAI
    import weave
    import asyncio
    @weave.op()
    async def context_precision_score(question, output):
        context_precision_prompt = """Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as "1" if useful and "0" if not with json output.
        Output in only valid JSON format.

        question: {question}
        context: {context}
        answer: {answer}
        verdict: """
        client = OpenAI()

        prompt = context_precision_prompt.format(
            question=question,
            context=output['context'],
            answer=output['answer'],
        )

        response = client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}],
            response_format={ "type": "json_object" }
        )
        response_message = response.choices[0].message
        response = json.loads(response_message.content)
        return {
            "verdict": int(response["verdict"]) == 1,
        }

    questions = [
        {"question": "What significant result was reported about Zealand Pharma's obesity trial?"},
        {"question": "How much did Berkshire Hathaway's cash levels increase in the fourth quarter?"},
        {"question": "What is the goal of Highmark Health's integration of Google Cloud and Epic Systems technology?"},
        {"question": "What were Rivian and Lucid's vehicle production forecasts for 2024?"},
        {"question": "Why was the Norwegian Dawn cruise ship denied access to Mauritius?"},
        {"question": "Which company achieved the first U.S. moon landing since 1972?"},
        {"question": "What issue did Intuitive Machines' lunar lander encounter upon landing on the moon?"}
    ]
    evaluation = weave.Evaluation(dataset=questions, scorers=[context_precision_score])
    asyncio.run(evaluation.evaluate(model)) # note: you'll need to define a model to evaluate
    ```

  
  
    ```typescript
    const contextPrecisionScore = weave.op(async function(args: {
        datasetRow: QuestionRow;
        modelOutput: { answer: string; context: string; }
    }): Promise {
        const openai = new OpenAI();
        
        const prompt = `Given question, answer and context verify if the context was useful...`;

        const response = await openai.chat.completions.create({
            model: "gpt-4-turbo-preview",
            messages: [{ role: "user", content: prompt }],
            response_format: { type: "json_object" }
        });

        const result = JSON.parse(response.choices[0].message.content || "{}");
        return {
            verdict: parseInt(result.verdict) === 1
        };
    });

    const evaluation = new weave.Evaluation({
        dataset: createQuestionDataset(),
        scorers: [contextPrecisionScore]
    });

    await evaluation.evaluate({
        model: weave.op((args: { datasetRow: QuestionRow }) => 
            model.predict(args.datasetRow.question)
        )
    });
    ```
  


### Optional: Defining a `Scorer` class

In some applications we want to create custom evaluation classes - where for example a standardized `LLMJudge` class should be created with specific parameters (e.g. chat model, prompt), specific scoring of each row, and specific calculation of an aggregate score. In order to do that Weave defines a list of ready-to-use `Scorer` classes and also makes it easy to create a custom `Scorer` - in the following we'll see how to create a custom `class CorrectnessLLMJudge(Scorer)`.

On a high-level the steps to create custom Scorer are quite simple:

1. Define a custom class that inherits from `weave.flow.scorer.Scorer`
2. Overwrite the `score` function and add a `@weave.op()` if you want to track each call of the function
   - this function has to define an `output` argument where the prediction of the model will be passed to. We define it as type `Optional[dict]` in case the mode might return "None".
   - the rest of the arguments can either be a general `Any` or `dict` or can select specific columns from the dataset that is used to evaluate the model using the `weave.Evaluate` class - they have to have the exact same names as the column names or keys of a single row after being passed to `preprocess_model_input` if that is used.
3. _Optional:_ Overwrite the `summarize` function to customize the calculation of the aggregate score. By default Weave uses the `weave.flow.scorer.auto_summarize` function if you don't define a custom function.
   - this function has to have a `@weave.op()` decorator.


  
    ```python
    from weave import Scorer
    from weave import WeaveList

    class CorrectnessLLMJudge(Scorer):
        prompt: str
        model_name: str
        device: str

        @weave.op()
        async def score(self, output: Optional[dict], query: str, answer: str) -> Any:
            """Score the correctness of the predictions by comparing the pred, query, target.
            Args:
                - output: the dict that will be provided by the model that is evaluated
                - query: the question asked - as defined in the dataset
                - answer: the target answer - as defined in the dataset
            Returns:
                - single dict {metric name: single evaluation value}"""

            # get_model is defined as general model getter based on provided params (OpenAI,HF...)
            eval_model = get_model(
                model_name = self.model_name,
                prompt = self.prompt
                device = self.device,
            )
            # async evaluation to speed up evaluation - this doesn't have to be async
            grade = await eval_model.async_predict(
                {
                    "query": query,
                    "answer": answer,
                    "result": output.get("result"),
                }
            )
            # output parsing - could be done more reobustly with pydantic
            evaluation = "incorrect" not in grade["text"].strip().lower()

            # the column name displayed in Weave
            return {"correct": evaluation}

        @weave.op()
        def summarize(self, score_rows: WeaveList) -> Optional[dict]:
            """Aggregate all the scores that are calculated for each row by the scoring function.
            Args:
                - score_rows: a WeaveList object, nested dict of metrics and scores
            Returns:
                - nested dict with the same structure as the input"""

            # if nothing is provided the weave.flow.scorer.auto_summarize function is used
            # return auto_summarize(score_rows)

            valid_data = [x.get("correct") for x in score_rows if x.get("correct") is not None]
            count_true = list(valid_data).count(True)
            int_data = [int(x) for x in valid_data]

            sample_mean = np.mean(int_data) if int_data else 0
            sample_variance = np.var(int_data) if int_data else 0
            sample_error = np.sqrt(sample_variance / len(int_data)) if int_data else 0

            # the extra "correct" layer is not necessary but adds structure in the UI
            return {
                "correct": {
                    "true_count": count_true,
                    "true_fraction": sample_mean,
                    "stderr": sample_error,
                }
            }
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


To use this as a scorer, you would initialize it and pass it to `scorers` argument in your `Evaluation like this:


  
    ```python
    evaluation = weave.Evaluation(dataset=questions, scorers=[CorrectnessLLMJudge()])
    ```
  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


## 4. Pulling it all together

To get the same result for your RAG apps:

- Wrap LLM calls & retrieval step functions with `weave.op()`
- (optional) Create a `Model` subclass with `predict` function and app details
- Collect examples to evaluate
- Create scoring functions that score one example
- Use `Evaluation` class to run evaluations on your examples

**NOTE:** Sometimes the async execution of Evaluations will trigger a rate limit on the models of OpenAI, Anthropic, etc. To prevent that you can set an environment variable to limit the amount of parallel workers e.g. `WEAVE_PARALLELISM=3`.

Here, we show the code in it's entirety.


  
    ```python
    from openai import OpenAI
    import weave
    from weave import Model
    import numpy as np
    import json
    import asyncio

    # Examples we've gathered that we want to use for evaluations
    articles = [
        "Novo Nordisk and Eli Lilly rival soars 32 percent after promising weight loss drug results Shares of Denmarks Zealand Pharma shot 32 percent higher in morning trade, after results showed success in its liver disease treatment survodutide, which is also on trial as a drug to treat obesity. The trial “tells us that the 6mg dose is safe, which is the top dose used in the ongoing [Phase 3] obesity trial too,” one analyst said in a note. The results come amid feverish investor interest in drugs that can be used for weight loss.",
        "Berkshire shares jump after big profit gain as Buffetts conglomerate nears $1 trillion valuation Berkshire Hathaway shares rose on Monday after Warren Buffetts conglomerate posted strong earnings for the fourth quarter over the weekend. Berkshires Class A and B shares jumped more than 1.5%, each. Class A shares are higher by more than 17% this year, while Class B has gained more than 18%. Berkshire was last valued at $930.1 billion, up from $905.5 billion where it closed on Friday, according to FactSet. Berkshire on Saturday posted fourth-quarter operating earnings of $8.481 billion, about 28 percent higher than the $6.625 billion from the year-ago period, driven by big gains in its insurance business. Operating earnings refers to profits from businesses across insurance, railroads and utilities. Meanwhile, Berkshires cash levels also swelled to record levels. The conglomerate held $167.6 billion in cash in the fourth quarter, surpassing the $157.2 billion record the conglomerate held in the prior quarter.",
        "Highmark Health says its combining tech from Google and Epic to give doctors easier access to information Highmark Health announced it is integrating technology from Google Cloud and the health-care software company Epic Systems. The integration aims to make it easier for both payers and providers to access key information they need, even if it's stored across multiple points and formats, the company said. Highmark is the parent company of a health plan with 7 million members, a provider network of 14 hospitals and other entities",
        "Rivian and Lucid shares plunge after weak EV earnings reports Shares of electric vehicle makers Rivian and Lucid fell Thursday after the companies reported stagnant production in their fourth-quarter earnings after the bell Wednesday. Rivian shares sank about 25 percent, and Lucids stock dropped around 17 percent. Rivian forecast it will make 57,000 vehicles in 2024, slightly less than the 57,232 vehicles it produced in 2023. Lucid said it expects to make 9,000 vehicles in 2024, more than the 8,428 vehicles it made in 2023.",
        "Mauritius blocks Norwegian cruise ship over fears of a potential cholera outbreak Local authorities on Sunday denied permission for the Norwegian Dawn ship, which has 2,184 passengers and 1,026 crew on board, to access the Mauritius capital of Port Louis, citing “potential health risks.” The Mauritius Ports Authority said Sunday that samples were taken from at least 15 passengers on board the cruise ship. A spokesperson for the U.S.-headquartered Norwegian Cruise Line Holdings said Sunday that 'a small number of guests experienced mild symptoms of a stomach-related illness' during Norwegian Dawns South Africa voyage.",
        "Intuitive Machines lands on the moon in historic first for a U.S. company Intuitive Machines Nova-C cargo lander, named Odysseus after the mythological Greek hero, is the first U.S. spacecraft to soft land on the lunar surface since 1972. Intuitive Machines is the first company to pull off a moon landing — government agencies have carried out all previously successful missions. The company's stock surged in extended trading Thursday, after falling 11 percent in regular trading.",
        "Lunar landing photos: Intuitive Machines Odysseus sends back first images from the moon Intuitive Machines cargo moon lander Odysseus returned its first images from the surface. Company executives believe the lander caught its landing gear sideways on the surface of the moon while touching down and tipped over. Despite resting on its side, the company's historic IM-1 mission is still operating on the moon.",
    ]

    def docs_to_embeddings(docs: list) -> list:
        openai = OpenAI()
        document_embeddings = []
        for doc in docs:
            response = (
                openai.embeddings.create(input=doc, model="text-embedding-3-small")
                .data[0]
                .embedding
            )
            document_embeddings.append(response)
        return document_embeddings

    article_embeddings = docs_to_embeddings(articles) # Note: you would typically do this once with your articles and put the embeddings & metadata in a database

    # We've added a decorator to our retrieval step
    @weave.op()
    def get_most_relevant_document(query):
        openai = OpenAI()
        query_embedding = (
            openai.embeddings.create(input=query, model="text-embedding-3-small")
            .data[0]
            .embedding
        )
        similarities = [
            np.dot(query_embedding, doc_emb)
            / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb))
            for doc_emb in article_embeddings
        ]
        # Get the index of the most similar document
        most_relevant_doc_index = np.argmax(similarities)
        return articles[most_relevant_doc_index]

    # We create a Model subclass with some details about our app, along with a predict function that produces a response
    class RAGModel(Model):
        system_message: str
        model_name: str = "gpt-3.5-turbo-1106"
        @weave.op()
        def predict(self, question: str) -> dict: # note: `question` will be used later to select data from our evaluation rows
            from openai import OpenAI
            context = get_most_relevant_document(question)
            client = OpenAI()
            query = f"""Use the following information to answer the subsequent question. If the answer cannot be found, write "I don't know."
            Context:
            \"\"\"
            {context}
            \"\"\"
            Question: {question}"""
            response = client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": self.system_message},
                    {"role": "user", "content": query},
                ],
                temperature=0.0,
                response_format={"type": "text"},
            )
            answer = response.choices[0].message.content
            return {'answer': answer, 'context': context}
    weave.init('rag-qa')
    model = RAGModel(
        system_message="You are an expert in finance and answer questions related to finance, financial services, and financial markets. When responding based on provided information, be sure to cite the source."
    )

    # Here is our scoring function uses our question and output to product a score
    @weave.op()
    async def context_precision_score(question, output):
        context_precision_prompt = """Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as "1" if useful and "0" if not with json output.
        Output in only valid JSON format.

        question: {question}
        context: {context}
        answer: {answer}
        verdict: """
        client = OpenAI()

        prompt = context_precision_prompt.format(
            question=question,
            context=output['context'],
            answer=output['answer'],
        )

        response = client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}],
            response_format={ "type": "json_object" }
        )
        response_message = response.choices[0].message
        response = json.loads(response_message.content)
        return {
            "verdict": int(response["verdict"]) == 1,
        }

    questions = [
        {"question": "What significant result was reported about Zealand Pharma's obesity trial?"},
        {"question": "How much did Berkshire Hathaway's cash levels increase in the fourth quarter?"},
        {"question": "What is the goal of Highmark Health's integration of Google Cloud and Epic Systems technology?"},
        {"question": "What were Rivian and Lucid's vehicle production forecasts for 2024?"},
        {"question": "Why was the Norwegian Dawn cruise ship denied access to Mauritius?"},
        {"question": "Which company achieved the first U.S. moon landing since 1972?"},
        {"question": "What issue did Intuitive Machines' lunar lander encounter upon landing on the moon?"}
    ]

    # We define an Evaluation object and pass our example questions along with scoring functions
    evaluation = weave.Evaluation(dataset=questions, scorers=[context_precision_score])
    asyncio.run(evaluation.evaluate(model))
    ```

  
  
    ```typescript
    require('dotenv').config();
        
    interface Article {
        text: string;
        embedding?: number[];
    }

    const articles: Article[] = [
        { 
            text: `Novo Nordisk and Eli Lilly rival soars 32 percent after promising weight loss drug results Shares of Denmarks Zealand Pharma shot 32 percent higher in morning trade, after results showed success in its liver disease treatment survodutide, which is also on trial as a drug to treat obesity. The trial tells us that the 6mg dose is safe, which is the top dose used in the ongoing [Phase 3] obesity trial too, one analyst said in a note. The results come amid feverish investor interest in drugs that can be used for weight loss.`
        },
        { 
            text: `Berkshire shares jump after big profit gain as Buffetts conglomerate nears $1 trillion valuation Berkshire Hathaway shares rose on Monday after Warren Buffetts conglomerate posted strong earnings for the fourth quarter over the weekend. Berkshires Class A and B shares jumped more than 1.5%, each. Class A shares are higher by more than 17% this year, while Class B has gained more than 18%. Berkshire was last valued at $930.1 billion, up from $905.5 billion where it closed on Friday, according to FactSet. Berkshire on Saturday posted fourth-quarter operating earnings of $8.481 billion, about 28 percent higher than the $6.625 billion from the year-ago period, driven by big gains in its insurance business. Operating earnings refers to profits from businesses across insurance, railroads and utilities. Meanwhile, Berkshires cash levels also swelled to record levels. The conglomerate held $167.6 billion in cash in the fourth quarter, surpassing the $157.2 billion record the conglomerate held in the prior quarter.`
        },
        { 
            text: `Highmark Health says its combining tech from Google and Epic to give doctors easier access to information Highmark Health announced it is integrating technology from Google Cloud and the health-care software company Epic Systems. The integration aims to make it easier for both payers and providers to access key information they need, even if its stored across multiple points and formats, the company said. Highmark is the parent company of a health plan with 7 million members, a provider network of 14 hospitals and other entities`
        }
    ];

    function cosineSimilarity(a: number[], b: number[]): number {
        const dotProduct = a.reduce((sum, val, i) => sum + val * b[i], 0);
        const magnitudeA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));
        const magnitudeB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));
        return dotProduct / (magnitudeA * magnitudeB);
    }

    const docsToEmbeddings = weave.op(async function(docs: Article[]): Promise {
        const openai = new OpenAI();
        const enrichedDocs = await Promise.all(docs.map(async (doc) => {
            const response = await openai.embeddings.create({
                input: doc.text,
                model: "text-embedding-3-small"
            });
            return {
                ...doc,
                embedding: response.data[0].embedding
            };
        }));
        return enrichedDocs;
    });

    class RAGModel {
        private openai: OpenAI;
        private systemMessage: string;
        private modelName: string;
        private articleEmbeddings: Article[];

        constructor(config: {
            systemMessage: string;
            modelName?: string;
            articleEmbeddings: Article[];
        }) {
            this.openai = weave.wrapOpenAI(new OpenAI());
            this.systemMessage = config.systemMessage;
            this.modelName = config.modelName || "gpt-3.5-turbo-1106";
            this.articleEmbeddings = config.articleEmbeddings;
            this.predict = weave.op(this, this.predict);
        }

        private async getMostRelevantDocument(query: string): Promise {
            const queryEmbedding = await this.openai.embeddings.create({
                input: query,
                model: "text-embedding-3-small"
            });

            const similarities = this.articleEmbeddings.map(doc => {
                if (!doc.embedding) return 0;
                return cosineSimilarity(queryEmbedding.data[0].embedding, doc.embedding);
            });

            const mostRelevantIndex = similarities.indexOf(Math.max(...similarities));
            return this.articleEmbeddings[mostRelevantIndex].text;
        }

        async predict(question: string): Promise<{
            answer: string;
            context: string;
        }> {
            const context = await this.getMostRelevantDocument(question);
            
            const response = await this.openai.chat.completions.create({
                model: this.modelName,
                messages: [
                    { role: "system", content: this.systemMessage },
                    { 
                        role: "user", 
                        content: `Use the following information to answer the subsequent question. If the answer cannot be found, write "I don't know."
                        Context:
                        """
                        ${context}
                        """
                        Question: ${question}`
                    }
                ],
                temperature: 0
            });

            return {
                answer: response.choices[0].message.content || "",
                context
            };
        }
    }

    interface ScorerResult {
        verdict: boolean;
    }

    interface QuestionRow {
        question: string;
    }

    function createQuestionDataset(): weave.Dataset {
        return new weave.Dataset({
            id: 'rag-questions',
            rows: [
                { question: "What significant result was reported about Zealand Pharma's obesity trial?" },
                { question: "How much did Berkshire Hathaway's cash levels increase in the fourth quarter?" },
                { question: "What is the goal of Highmark Health's integration of Google Cloud and Epic Systems technology?" }
            ]
        });
    }

    const contextPrecisionScore = weave.op(async function(args: {
        datasetRow: QuestionRow;
        modelOutput: { answer: string; context: string; }
    }): Promise {
        const openai = new OpenAI();
        
        const prompt = `Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as "1" if useful and "0" if not with json output.
        Output in only valid JSON format.

        question: ${args.datasetRow.question}
        context: ${args.modelOutput.context}
        answer: ${args.modelOutput.answer}
        verdict: `;

        const response = await openai.chat.completions.create({
            model: "gpt-4-turbo-preview",
            messages: [{ role: "user", content: prompt }],
            response_format: { type: "json_object" }
        });

        const result = JSON.parse(response.choices[0].message.content || "{}");
        return {
            verdict: parseInt(result.verdict) === 1
        };
    });

    async function main() {
        await weave.init('rag-qa-ts');
        
        const articleEmbeddings = await docsToEmbeddings(articles);
        
        const model = new RAGModel({
            systemMessage: "You are an expert in finance and answer questions related to finance, financial services, and financial markets. When responding based on provided information, be sure to cite the source.",
            articleEmbeddings
        });

        const evaluation = new weave.Evaluation({
            dataset: createQuestionDataset(),
            scorers: [contextPrecisionScore]
        });

        const results = await evaluation.evaluate({
            model: weave.op((args: { datasetRow: QuestionRow }) => 
                model.predict(args.datasetRow.question)
            )
        });
        
        console.log('Evaluation results:', results);
    }

    if (require.main === module) {
        main().catch(console.error);
    }
    ```
  


## Conclusion

We've learned how to build observability into different steps of our applications, like the retrieval step in this example.
We've also learned how to build more complex scoring functions, like an LLM judge, for doing automatic evaluation of application responses.

[Source](https://weave-docs.wandb.ai/tutorial-rag)

<!--- Docs: Tutorials -->
<!--- Tutorial Weave Models -->

# Tutorial Weave Models

# Tutorial: App versioning

Tracking the [inputs, outputs, metadata](/quickstart) as well as [data flowing through your app](/tutorial-tracing_2) is critical to understanding the performance of your system. However **versioning your app over time** is also critical to understand how modifications to your code or application parameters change your outputs. Weave's `Model` class is how these changes can be tracked in Weave.

In this tutorial you'll learn:

- How to use Weave `Model` to track and version your application and its parameters.
- How to export, modify and re-use a Weave `Model` already logged.

## Using `weave.Model`

> 🚨 **Important**: The `weave.Model` class is currently only supported in Python.


Using Weave `Model`s means that parameters such as model vendor ids, prompts, temperature, and more are stored and versioned when they change.

To create a `Model` in Weave, you need the following:

- a class that inherits from `weave.Model`
- type definitions on all class fields
- a typed `invoke` function with the `@weave.op()` decorator

When you change the class fields or the code that defines your model, **these changes will be logged and the version will be updated**. This ensures that you can compare the generations across different versions of your app.

In the example below, the **model name, temperature and system prompt will be tracked and versioned**:


  
    ```python
    import json
    from openai import OpenAI

    import weave

    @weave.op()
    def extract_dinos(wmodel: weave.Model, sentence: str) -> dict:
        response = wmodel.client.chat.completions.create(
            model=wmodel.model_name,
            temperature=wmodel.temperature,
            messages=[
                {
                    "role": "system",
                    "content": wmodel.system_prompt
                },
                {
                    "role": "user",
                    "content": sentence
                }
                ],
                response_format={ "type": "json_object" }
            )
        return response.choices[0].message.content

    # Sub-class with a weave.Model
    class ExtractDinos(weave.Model):
        client: OpenAI = None
        model_name: str
        temperature: float
        system_prompt: str

        # Ensure your function is called `invoke` or `predict`
        @weave.op()
        def invoke(self, sentence: str) -> dict:
            dino_data  = extract_dinos(self, sentence)
            return json.loads(dino_data)
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


Now you can instantiate and call the model with `invoke`:


  
    ```python
    weave.init('jurassic-park')
    client = OpenAI()

    system_prompt = """Extract any dinosaur `name`, their `common_name`, \
    names and whether its `diet` is a herbivore or carnivore, in JSON format."""
    dinos = ExtractDinos(
        client=client,
        model_name='gpt-4o',
        temperature=0.4,
        system_prompt=system_prompt
    )

    sentence = """I watched as a Tyrannosaurus rex (T. rex) chased after a Triceratops (Trike), \
    both carnivore and herbivore locked in an ancient dance. Meanwhile, a gentle giant \
    Brachiosaurus (Brachi) calmly munched on treetops, blissfully unaware of the chaos below."""
    result = dinos.invoke(sentence)
    print(result)
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


Now after calling `.invoke` you can see the trace in Weave **now tracks the model parameters as well as the code** for the model functions that have been decorated with `weave.op()`. You can see the model is also versioned, "v21" in this case, and if you click on the model **you can see all of the calls** that have used that version of the model



**A note on using `weave.Model`:**

- You can use `predict` instead of `invoke` for the name of the function in your Weave `Model` if you prefer.
- If you want other class methods to be tracked by weave they need to be wrapped in `weave.op()`
- Parameters starting with an underscore are ignored by weave and won't be logged

## Exporting and re-using a logged `weave.Model`

Because Weave stores and versions Models that have been invoked, it is possible to export and re-use these models.

**Get the Model ref**
In the Weave UI you can get the Model ref for a particular version

**Using the Model**
Once you have the URI of the Model object, you can export and re-use it. Note that the exported model is already initialised and ready to use:


  
    ```python
    # the exported weave model is already initialised and ready to be called
    new_dinos = weave.ref("weave:///morgan/jurassic-park/object/ExtractDinos:ey4udBU2MU23heQFJenkVxLBX4bmDsFk7vsGcOWPjY4").get()

    # set the client to the openai client again
    new_dinos.client = client

    new_sentence = """I also saw an Ankylosaurus grazing on giant ferns"""
    new_result = new_dinos.invoke(new_sentence)
    print(new_result)
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


Here you can now see the name Model version (v21) was used with the new input:



## What's next?

- Follow the [Build an Evaluation pipeline tutorial](/tutorial-eval) to start iteratively improving your applications.

[Source](https://weave-docs.wandb.ai/tutorial-weave_models)

<!--- Docs: Tutorials -->
<!--- Tutorial Tracing 2 -->

# Tutorial Tracing 2

# Tutorial: Track Application Logic

In the [Track LLM inputs & outputs](/quickstart) tutorial, the basics of tracking the inputs and outputs of your LLMs was covered.

In this tutorial you will learn how to:

- **Track data** as it flows through your application
- **Track metadata** at call time

## Tracking nested function calls

LLM-powered applications can contain multiple LLMs calls and additional data processing and validation logic that is important to monitor. Even deep nested call structures common in many apps, Weave will keep track of the parent-child relationships in nested functions as long as `weave.op()` is added to every function you'd like to track.

Building on our [basic tracing example](/quickstart), we will now add additional logic to count the returned items from our LLM and wrap them all in a higher level function. We'll then add `weave.op()` to trace every function, its call order and its parent-child relationship:


  

    ```python
    import weave
    import json
    from openai import OpenAI

    client = OpenAI()
    @weave.op()
    def extract_dinos(sentence: str) -> dict:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": """Extract any dinosaur `name`, their `common_name`, \
    names and whether its `diet` is a herbivore or carnivore, in JSON format."""
                },
                {
                    "role": "user",
                    "content": sentence
                }
                ],
                response_format={ "type": "json_object" }
            )
        return response.choices[0].message.content
    @weave.op()
    def count_dinos(dino_data: dict) -> int:
        # count the number of items in the returned list
        k = list(dino_data.keys())[0]
        return len(dino_data[k])
    @weave.op()
    def dino_tracker(sentence: str) -> dict:
        # extract dinosaurs using a LLM
        dino_data = extract_dinos(sentence)

        # count the number of dinosaurs returned
        dino_data = json.loads(dino_data)
        n_dinos = count_dinos(dino_data)
        return {"n_dinosaurs": n_dinos, "dinosaurs": dino_data}
    weave.init('jurassic-park')

    sentence = """I watched as a Tyrannosaurus rex (T. rex) chased after a Triceratops (Trike), \
    both carnivore and herbivore locked in an ancient dance. Meanwhile, a gentle giant \
    Brachiosaurus (Brachi) calmly munched on treetops, blissfully unaware of the chaos below."""

    result = dino_tracker(sentence)
    print(result)
    ```
    **Nested functions**

    When you run the above code you will see the the inputs and outputs from the two nested functions (`extract_dinos` and `count_dinos`), as well as the automatically-logged OpenAI trace.

    

  
  

    ```typescript
        
    const openai = weave.wrapOpenAI(new OpenAI());

    const extractDinos = weave.op(async (sentence: string) => {
      const response = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'system',
            content:
              'Extract any dinosaur `name`, their `common_name`, names and whether its `diet` is a herbivore or carnivore, in JSON format.',
          },
          {role: 'user', content: sentence},
        ],
        response_format: {type: 'json_object'},
      });
      return response.choices[0].message.content;
    });

    const countDinos = weave.op(async (dinoData: string) => {
      const parsed = JSON.parse(dinoData);
      return Object.keys(parsed).length;
    });

    const dinoTracker = weave.op(async (sentence: string) => {
      const dinoData = await extractDinos(sentence);
      const nDinos = await countDinos(dinoData);
      return {nDinos, dinoData};
    });

    async function main() {
      await weave.init('jurassic-park');

      const sentence = `I watched as a Tyrannosaurus rex (T. rex) chased after a Triceratops (Trike),
            both carnivore and herbivore locked in an ancient dance. Meanwhile, a gentle giant
            Brachiosaurus (Brachi) calmly munched on treetops, blissfully unaware of the chaos below.`;

      const result = await dinoTracker(sentence);
      console.log(result);
    }

    main();

    ```

    **Nested functions**

    When you run the above code you will see the the inputs and outputs from the two nested functions (`extractDinos` and `countDinos`), as well as the automatically-logged OpenAI trace.

    
    

  


## Tracking metadata

Tracking metadata can be done easily by using the `weave.attributes` context manager and passing it a dictionary of the metadata to track at call time.

Continuing our example from above:


  
    ```python
    import weave

    weave.init('jurassic-park')

    sentence = """I watched as a Tyrannosaurus rex (T. rex) chased after a Triceratops (Trike), \
    both carnivore and herbivore locked in an ancient dance. Meanwhile, a gentle giant \
    Brachiosaurus (Brachi) calmly munched on treetops, blissfully unaware of the chaos below."""

    # track metadata alongside our previously defined function
    with weave.attributes({'user_id': 'lukas', 'env': 'production'}):
        result = dino_tracker(sentence)
    ```

  
  
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  


> 💡 **Note**: It's recommended to use metadata tracking to track metadata at run time, e.g. user ids or whether or not the call is part of the development process or is in production etc.

To track system settings, such as a System Prompt, we recommend using [weave Models](guides/core-types/models)

## What's next?

- Follow the [App Versioning tutorial](/tutorial-weave_models) to capture, version and organize ad-hoc prompt, model, and application changes.

[Source](https://weave-docs.wandb.ai/tutorial-tracing_2)



<!--- Docs: TypeScript SDK -->
<!--- Readme -->

# Readme

**weave** • **Docs**

***

# weave

## Classes

- [Dataset](classes/Dataset.md)
- [Evaluation](classes/Evaluation.md)
- [WeaveClient](classes/WeaveClient.md)
- [WeaveObject](classes/WeaveObject.md)

## Interfaces

- [CallSchema](interfaces/CallSchema.md)
- [CallsFilter](interfaces/CallsFilter.md)

## Type Aliases

- [Op](type-aliases/Op.md)

## Functions

- [init](functions/init.md)
- [login](functions/login.md)
- [op](functions/op.md)
- [requireCurrentCallStackEntry](functions/requireCurrentCallStackEntry.md)
- [requireCurrentChildSummary](functions/requireCurrentChildSummary.md)
- [weaveAudio](functions/weaveAudio.md)
- [weaveImage](functions/weaveImage.md)
- [wrapOpenAI](functions/wrapOpenAI.md)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/README)

<!--- Docs: TypeScript SDK -->
<!--- Weaveclient -->

# Weaveclient

[**weave**](../README.md) • **Docs**

***

[weave](../README.md) / WeaveClient

# Class: WeaveClient

## Constructors

### new WeaveClient()

> **new WeaveClient**(`traceServerApi`, `wandbServerApi`, `projectId`, `settings`): [`WeaveClient`](WeaveClient.md)

#### Parameters

• **traceServerApi**: `Api`\

• **wandbServerApi**: `WandbServerApi`

• **projectId**: `string`

• **settings**: `Settings` = `...`

#### Returns

[`WeaveClient`](WeaveClient.md)

#### Defined in

[weaveClient.ts:82](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L82)

## Properties

### projectId

> **projectId**: `string`

#### Defined in

[weaveClient.ts:85](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L85)

***

### settings

> **settings**: `Settings`

#### Defined in

[weaveClient.ts:86](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L86)

***

### traceServerApi

> **traceServerApi**: `Api`\

#### Defined in

[weaveClient.ts:83](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L83)

## Methods

### createCall()

> **createCall**(`opRef`, `params`, `parameterNames`, `thisArg`, `currentCall`, `parentCall`, `startTime`, `displayName`?): `Promise`\

#### Parameters

• **opRef**: `any`

• **params**: `any`[]

• **parameterNames**: `ParameterNamesOption`

• **thisArg**: `any`

• **currentCall**: `CallStackEntry`

• **parentCall**: `undefined` \| `CallStackEntry`

• **startTime**: `Date`

• **displayName?**: `string`

#### Returns

`Promise`\

#### Defined in

[weaveClient.ts:610](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L610)

***

### finishCall()

> **finishCall**(`result`, `currentCall`, `parentCall`, `summarize`, `endTime`, `startCallPromise`): `Promise`\

#### Parameters

• **result**: `any`

• **currentCall**: `CallStackEntry`

• **parentCall**: `undefined` \| `CallStackEntry`

• **summarize**: `undefined` \| (`result`) => `Record`\

• **endTime**: `Date`

• **startCallPromise**: `Promise`\

#### Returns

`Promise`\

#### Defined in

[weaveClient.ts:648](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L648)

***

### finishCallWithException()

> **finishCallWithException**(`error`, `currentCall`, `parentCall`, `endTime`, `startCallPromise`): `Promise`\

#### Parameters

• **error**: `any`

• **currentCall**: `CallStackEntry`

• **parentCall**: `undefined` \| `CallStackEntry`

• **endTime**: `Date`

• **startCallPromise**: `Promise`\

#### Returns

`Promise`\

#### Defined in

[weaveClient.ts:677](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L677)

***

### get()

> **get**(`ref`): `Promise`\

#### Parameters

• **ref**: `ObjectRef`

#### Returns

`Promise`\

#### Defined in

[weaveClient.ts:229](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L229)

***

### getCalls()

> **getCalls**(`filter`, `includeCosts`, `limit`): `Promise`\

#### Parameters

• **filter**: [`CallsFilter`](../interfaces/CallsFilter.md) = `{}`

• **includeCosts**: `boolean` = `false`

• **limit**: `number` = `1000`

#### Returns

`Promise`\

#### Defined in

[weaveClient.ts:172](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L172)

***

### getCallsIterator()

> **getCallsIterator**(`filter`, `includeCosts`, `limit`): `AsyncIterableIterator`\

#### Parameters

• **filter**: [`CallsFilter`](../interfaces/CallsFilter.md) = `{}`

• **includeCosts**: `boolean` = `false`

• **limit**: `number` = `1000`

#### Returns

`AsyncIterableIterator`\

#### Defined in

[weaveClient.ts:184](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L184)

***

### getCallStack()

> **getCallStack**(): `CallStack`

#### Returns

`CallStack`

#### Defined in

[weaveClient.ts:537](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L537)

***

### publish()

> **publish**(`obj`, `objId`?): `Promise`\

#### Parameters

• **obj**: `any`

• **objId?**: `string`

#### Returns

`Promise`\

#### Defined in

[weaveClient.ts:160](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L160)

***

### pushNewCall()

> **pushNewCall**(): `object`

#### Returns

`object`

##### currentCall

> **currentCall**: `CallStackEntry`

##### newStack

> **newStack**: `CallStack`

##### parentCall?

> `optional` **parentCall**: `CallStackEntry`

#### Defined in

[weaveClient.ts:541](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L541)

***

### runWithCallStack()

> **runWithCallStack**\(`callStack`, `fn`): `T`

#### Type Parameters

• **T**

#### Parameters

• **callStack**: `CallStack`

• **fn**

#### Returns

`T`

#### Defined in

[weaveClient.ts:545](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L545)

***

### saveOp()

> **saveOp**(`op`, `objId`?): `Promise`\

#### Parameters

• **op**: [`Op`](../type-aliases/Op.md)\ `any`\>

• **objId?**: `string`

#### Returns

`Promise`\

#### Defined in

[weaveClient.ts:575](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L575)

***

### waitForBatchProcessing()

> **waitForBatchProcessing**(): `Promise`\

#### Returns

`Promise`\

#### Defined in

[weaveClient.ts:103](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L103)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/classes/WeaveClient)

<!--- Docs: TypeScript SDK -->
<!--- Dataset -->

# Dataset

[**weave**](../README.md) • **Docs**

***

[weave](../README.md) / Dataset

# Class: Dataset\

Dataset object with easy saving and automatic versioning

## Example

```ts
// Create a dataset
const dataset = new Dataset({
  id: 'grammar-dataset',
  rows: [
    { id: '0', sentence: "He no likes ice cream.", correction: "He doesn't like ice cream." },
    { id: '1', sentence: "She goed to the store.", correction: "She went to the store." },
    { id: '2', sentence: "They plays video games all day.", correction: "They play video games all day." }
  ]
})

// Access a specific example
const exampleLabel = dataset.getRow(2).sentence;

// Save the dataset
const ref = await dataset.save()
```

## Extends

- [`WeaveObject`](WeaveObject.md)

## Type Parameters

• **R** *extends* `DatasetRow`

## Constructors

### new Dataset()

> **new Dataset**\(`parameters`): [`Dataset`](Dataset.md)\

#### Parameters

• **parameters**: `DatasetParameters`\

#### Returns

[`Dataset`](Dataset.md)\

#### Overrides

[`WeaveObject`](WeaveObject.md).[`constructor`](WeaveObject.md#constructors)

#### Defined in

[dataset.ts:51](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/dataset.ts#L51)

## Properties

### \_\_savedRef?

> `optional` **\_\_savedRef**: `ObjectRef` \| `Promise`\

#### Inherited from

[`WeaveObject`](WeaveObject.md).[`__savedRef`](WeaveObject.md#__savedref)

#### Defined in

[weaveObject.ts:49](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L49)

***

### \_baseParameters

> `protected` **\_baseParameters**: `WeaveObjectParameters`

#### Inherited from

[`WeaveObject`](WeaveObject.md).[`_baseParameters`](WeaveObject.md#_baseparameters)

#### Defined in

[weaveObject.ts:51](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L51)

***

### rows

> **rows**: `Table`\

#### Defined in

[dataset.ts:49](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/dataset.ts#L49)

## Accessors

### description

> `get` **description**(): `undefined` \| `string`

#### Returns

`undefined` \| `string`

#### Inherited from

[`WeaveObject`](WeaveObject.md).[`description`](WeaveObject.md#description)

#### Defined in

[weaveObject.ts:89](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L89)

***

### id

> `get` **id**(): `string`

#### Returns

`string`

#### Inherited from

[`WeaveObject`](WeaveObject.md).[`id`](WeaveObject.md#id)

#### Defined in

[weaveObject.ts:85](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L85)

***

### length

> `get` **length**(): `number`

#### Returns

`number`

#### Defined in

[dataset.ts:64](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/dataset.ts#L64)

## Methods

### \[asyncIterator\]()

> **\[asyncIterator\]**(): `AsyncIterator`\

#### Returns

`AsyncIterator`\

#### Defined in

[dataset.ts:68](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/dataset.ts#L68)

***

### className()

> **className**(): `any`

#### Returns

`any`

#### Inherited from

[`WeaveObject`](WeaveObject.md).[`className`](WeaveObject.md#classname)

#### Defined in

[weaveObject.ts:53](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L53)

***

### getRow()

> **getRow**(`index`): `R`

#### Parameters

• **index**: `number`

#### Returns

`R`

#### Defined in

[dataset.ts:74](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/dataset.ts#L74)

***

### save()

> **save**(): `Promise`\

#### Returns

`Promise`\

#### Defined in

[dataset.ts:60](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/dataset.ts#L60)

***

### saveAttrs()

> **saveAttrs**(): `object`

#### Returns

`object`

#### Inherited from

[`WeaveObject`](WeaveObject.md).[`saveAttrs`](WeaveObject.md#saveattrs)

#### Defined in

[weaveObject.ts:57](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L57)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/classes/Dataset)

<!--- Docs: TypeScript SDK -->
<!--- Weaveobject -->

# Weaveobject

[**weave**](../README.md) • **Docs**

***

[weave](../README.md) / WeaveObject

# Class: WeaveObject

## Extended by

- [`Dataset`](Dataset.md)
- [`Evaluation`](Evaluation.md)

## Constructors

### new WeaveObject()

> **new WeaveObject**(`_baseParameters`): [`WeaveObject`](WeaveObject.md)

#### Parameters

• **\_baseParameters**: `WeaveObjectParameters`

#### Returns

[`WeaveObject`](WeaveObject.md)

#### Defined in

[weaveObject.ts:51](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L51)

## Properties

### \_\_savedRef?

> `optional` **\_\_savedRef**: `ObjectRef` \| `Promise`\

#### Defined in

[weaveObject.ts:49](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L49)

***

### \_baseParameters

> `protected` **\_baseParameters**: `WeaveObjectParameters`

#### Defined in

[weaveObject.ts:51](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L51)

## Accessors

### description

> `get` **description**(): `undefined` \| `string`

#### Returns

`undefined` \| `string`

#### Defined in

[weaveObject.ts:89](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L89)

***

### id

> `get` **id**(): `string`

#### Returns

`string`

#### Defined in

[weaveObject.ts:85](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L85)

## Methods

### className()

> **className**(): `any`

#### Returns

`any`

#### Defined in

[weaveObject.ts:53](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L53)

***

### saveAttrs()

> **saveAttrs**(): `object`

#### Returns

`object`

#### Defined in

[weaveObject.ts:57](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L57)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/classes/WeaveObject)

<!--- Docs: TypeScript SDK -->
<!--- Evaluation -->

# Evaluation

[**weave**](../README.md) • **Docs**

***

[weave](../README.md) / Evaluation

# Class: Evaluation\

Sets up an evaluation which includes a set of scorers and a dataset.

Calling evaluation.evaluate(model) will pass in rows form a dataset into a model matching
the names of the columns of the dataset to the argument names in model.predict.

Then it will call all of the scorers and save the results in weave.

## Example

```ts
// Collect your examples into a dataset
const dataset = new weave.Dataset({
  id: 'my-dataset',
  rows: [
    { question: 'What is the capital of France?', expected: 'Paris' },
    { question: 'Who wrote "To Kill a Mockingbird"?', expected: 'Harper Lee' },
    { question: 'What is the square root of 64?', expected: '8' },
  ],
});

// Define any custom scoring function
const scoringFunction = weave.op(function isEqual({ modelOutput, datasetRow }) {
  return modelOutput == datasetRow.expected;
});

// Define the function to evaluate
const model = weave.op(async function alwaysParisModel({ question }) {
  return 'Paris';
});

// Start evaluating
const evaluation = new weave.Evaluation({
  id: 'my-evaluation',
  dataset: dataset,
  scorers: [scoringFunction],
});

const results = await evaluation.evaluate({ model });
```

## Extends

- [`WeaveObject`](WeaveObject.md)

## Type Parameters

• **R** *extends* `DatasetRow`

• **E** *extends* `DatasetRow`

• **M**

## Constructors

### new Evaluation()

> **new Evaluation**\(`parameters`): [`Evaluation`](Evaluation.md)\

#### Parameters

• **parameters**: `EvaluationParameters`\

#### Returns

[`Evaluation`](Evaluation.md)\

#### Overrides

[`WeaveObject`](WeaveObject.md).[`constructor`](WeaveObject.md#constructors)

#### Defined in

[evaluation.ts:148](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/evaluation.ts#L148)

## Properties

### \_\_savedRef?

> `optional` **\_\_savedRef**: `ObjectRef` \| `Promise`\

#### Inherited from

[`WeaveObject`](WeaveObject.md).[`__savedRef`](WeaveObject.md#__savedref)

#### Defined in

[weaveObject.ts:49](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L49)

***

### \_baseParameters

> `protected` **\_baseParameters**: `WeaveObjectParameters`

#### Inherited from

[`WeaveObject`](WeaveObject.md).[`_baseParameters`](WeaveObject.md#_baseparameters)

#### Defined in

[weaveObject.ts:51](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L51)

## Accessors

### description

> `get` **description**(): `undefined` \| `string`

#### Returns

`undefined` \| `string`

#### Inherited from

[`WeaveObject`](WeaveObject.md).[`description`](WeaveObject.md#description)

#### Defined in

[weaveObject.ts:89](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L89)

***

### id

> `get` **id**(): `string`

#### Returns

`string`

#### Inherited from

[`WeaveObject`](WeaveObject.md).[`id`](WeaveObject.md#id)

#### Defined in

[weaveObject.ts:85](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L85)

## Methods

### className()

> **className**(): `any`

#### Returns

`any`

#### Inherited from

[`WeaveObject`](WeaveObject.md).[`className`](WeaveObject.md#classname)

#### Defined in

[weaveObject.ts:53](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L53)

***

### evaluate()

> **evaluate**(`__namedParameters`): `Promise`\\>

#### Parameters

• **\_\_namedParameters**

• **\_\_namedParameters.maxConcurrency?**: `number` = `5`

• **\_\_namedParameters.model**: `WeaveCallable`\ `Promise`\\>

• **\_\_namedParameters.nTrials?**: `number` = `1`

#### Returns

`Promise`\\>

#### Defined in

[evaluation.ts:163](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/evaluation.ts#L163)

***

### predictAndScore()

> **predictAndScore**(`__namedParameters`): `Promise`\

#### Parameters

• **\_\_namedParameters**

• **\_\_namedParameters.columnMapping?**: `ColumnMapping`\

• **\_\_namedParameters.example**: `R`

• **\_\_namedParameters.model**: `WeaveCallable`\ `Promise`\\>

#### Returns

`Promise`\

##### model\_latency

> **model\_latency**: `number` = `modelLatency`

##### model\_output

> **model\_output**: `any` = `modelOutput`

##### model\_success

> **model\_success**: `boolean` = `!modelError`

##### scores

> **scores**: `object`

###### Index Signature

 \[`key`: `string`\]: `any`

#### Defined in

[evaluation.ts:232](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/evaluation.ts#L232)

***

### saveAttrs()

> **saveAttrs**(): `object`

#### Returns

`object`

#### Inherited from

[`WeaveObject`](WeaveObject.md).[`saveAttrs`](WeaveObject.md#saveattrs)

#### Defined in

[weaveObject.ts:57](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L57)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/classes/Evaluation)

<!--- Docs: TypeScript SDK -->
<!--- Op -->

# Op

[**weave**](../README.md) • **Docs**

***

[weave](../README.md) / Op

# Type Alias: Op\

> **Op**\: `object` & `T`

## Type declaration

### \_\_boundThis?

> `optional` **\_\_boundThis**: [`WeaveObject`](../classes/WeaveObject.md)

### \_\_isOp

> **\_\_isOp**: `true`

### \_\_name

> **\_\_name**: `string`

### \_\_savedRef?

> `optional` **\_\_savedRef**: `OpRef` \| `Promise`\

### \_\_wrappedFunction

> **\_\_wrappedFunction**: `T`

## Type Parameters

• **T** *extends* (...`args`) => `any`

## Defined in

[opType.ts:6](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/opType.ts#L6)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/type-aliases/Op)

<!--- Docs: TypeScript SDK -->
<!--- Requirecurrentcallstackentry -->

# Requirecurrentcallstackentry

[**weave**](../README.md) • **Docs**

***

[weave](../README.md) / requireCurrentCallStackEntry

# Function: requireCurrentCallStackEntry()

> **requireCurrentCallStackEntry**(): `CallStackEntry`

## Returns

`CallStackEntry`

## Defined in

[clientApi.ts:119](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/clientApi.ts#L119)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/requireCurrentCallStackEntry)

<!--- Docs: TypeScript SDK -->
<!--- Weaveaudio -->

# Weaveaudio

[**weave**](../README.md) • **Docs**

***

[weave](../README.md) / weaveAudio

# Function: weaveAudio()

> **weaveAudio**(`options`): `WeaveAudio`

Create a new WeaveAudio object

## Parameters

• **options**: `WeaveAudioInput`

The options for this media type
   - data: The raw audio data as a Buffer
   - audioType: (Optional) The type of audio file, currently only 'wav' is supported

## Returns

`WeaveAudio`

## Example

```ts
const audioBuffer = fs.readFileSync('path/to/audio.wav');
const weaveAudio = weaveAudio({ data: audioBuffer });
```

## Defined in

[media.ts:62](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/media.ts#L62)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/weaveAudio)

<!--- Docs: TypeScript SDK -->
<!--- Weaveimage -->

# Weaveimage

[**weave**](../README.md) • **Docs**

***

[weave](../README.md) / weaveImage

# Function: weaveImage()

> **weaveImage**(`options`): `WeaveImage`

Create a new WeaveImage object

## Parameters

• **options**: `WeaveImageInput`

The options for this media type
   - data: The raw image data as a Buffer
   - imageType: (Optional) The type of image file, currently only 'png' is supported

## Returns

`WeaveImage`

## Example

```ts
const imageBuffer = fs.readFileSync('path/to/image.png');
const weaveImage = weaveImage({ data: imageBuffer });
```

## Defined in

[media.ts:28](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/media.ts#L28)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/weaveImage)

<!--- Docs: TypeScript SDK -->
<!--- Op -->

# Op

[**weave**](../README.md) • **Docs**

***

[weave](../README.md) / op

# Function: op()

## op(fn, options)

> **op**\(`fn`, `options`?): [`Op`](../type-aliases/Op.md)\ `Promise`\\>\>\>

A wrapper to weave op-ify a function or method that works on sync and async functions.

Wrapped functions:
 1. Take the same inputs and return the same outputs as the original function.
 2. Will automatically track calls in the Weave UI.

If you don't call `weave.init` then the function will behave as if it were not wrapped.

### Type Parameters

• **T** *extends* (...`args`) => `any`

### Parameters

• **fn**: `T`

The function to wrap

• **options?**: `OpOptions`\

Optional configs like call and param naming

### Returns

[`Op`](../type-aliases/Op.md)\ `Promise`\\>\>\>

The wrapped function

### Example

```ts
// Basic usage

const client = await weave.init({ project: 'my-project' });
const oaiClient = weave.wrapOpenAI(new OpenAI());

const extract = weave.op(async function extract() {
  return await oaiClient.chat.completions.create({
    model: 'gpt-4-turbo',
    messages: [{ role: 'user', content: 'Create a user as JSON' }],
  });
});

await extract();

// You can also wrap methods by passing the object as the first argument.
// This will bind the method to the object and wrap it with op.
class MyModel {
  private oaiClient: OpenAI;

  constructor() {
    this.oaiClient = weave.wrapOpenAI(new OpenAI());
    this.invoke = weave.op(this, this.invoke);
  }

  async invoke() {
    return await this.oaiClient.chat.completions.create({
      model: 'gpt-4-turbo',
      messages: [{ role: 'user', content: 'Create a user as JSON' }],
    });
  }
}

const model = new MyModel();
const res = await model.invoke();
```

### Defined in

[op.ts:58](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/op.ts#L58)

## op(thisArg, fn, options)

> **op**\(`thisArg`, `fn`, `options`?): [`Op`](../type-aliases/Op.md)\ `Promise`\\>\>\>

### Type Parameters

• **T** *extends* (...`args`) => `any`

### Parameters

• **thisArg**: `any`

• **fn**: `T`

• **options?**: `OpOptions`\

### Returns

[`Op`](../type-aliases/Op.md)\ `Promise`\\>\>\>

### Defined in

[op.ts:62](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/op.ts#L62)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/op)

<!--- Docs: TypeScript SDK -->
<!--- Login -->

# Login

[**weave**](../README.md) • **Docs**

***

[weave](../README.md) / login

# Function: login()

> **login**(`apiKey`, `host`?): `Promise`\

Log in to Weights & Biases (W&B) using the provided API key.
This function saves the credentials to your netrc file for future use.

## Parameters

• **apiKey**: `string`

Your W&B API key.

• **host?**: `string` = `defaultHost`

(Optional) The host name (usually only needed if you're using a custom W&B server).

## Returns

`Promise`\

## Throws

If the API key is not specified or if the connection to the weave trace server cannot be verified.

## Defined in

[clientApi.ts:22](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/clientApi.ts#L22)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/login)

<!--- Docs: TypeScript SDK -->
<!--- Init -->

# Init

[**weave**](../README.md) • **Docs**

***

[weave](../README.md) / init

# Function: init()

> **init**(`project`, `settings`?): `Promise`\

Initialize the Weave client, which is required for weave tracing to work.

## Parameters

• **project**: `string`

The W&B project name (can be project or entity/project).

• **settings?**: `Settings`

(Optional) Weave tracing settings

## Returns

`Promise`\

A promise that resolves to the initialized Weave client.

## Throws

If the initialization fails

## Defined in

[clientApi.ts:57](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/clientApi.ts#L57)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/init)

<!--- Docs: TypeScript SDK -->
<!--- Wrapopenai -->

# Wrapopenai

[**weave**](../README.md) • **Docs**

***

[weave](../README.md) / wrapOpenAI

# Function: wrapOpenAI()

> **wrapOpenAI**\(`openai`): `T`

Wraps the OpenAI API to enable function tracing for OpenAI calls.

## Type Parameters

• **T** *extends* `OpenAIAPI`

## Parameters

• **openai**: `T`

## Returns

`T`

## Example

```ts
const openai = wrapOpenAI(new OpenAI());
const result = await openai.chat.completions.create({
  model: 'gpt-3.5-turbo',
  messages: [{ role: 'user', content: 'Hello, world!' }]
});
```

## Defined in

[integrations/openai.ts:159](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/integrations/openai.ts#L159)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/wrapOpenAI)

<!--- Docs: TypeScript SDK -->
<!--- Requirecurrentchildsummary -->

# Requirecurrentchildsummary

[**weave**](../README.md) • **Docs**

***

[weave](../README.md) / requireCurrentChildSummary

# Function: requireCurrentChildSummary()

> **requireCurrentChildSummary**(): `object`

## Returns

`object`

## Defined in

[clientApi.ts:131](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/clientApi.ts#L131)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/requireCurrentChildSummary)

<!--- Docs: TypeScript SDK -->
<!--- Callsfilter -->

# Callsfilter

[**weave**](../README.md) • **Docs**

***

[weave](../README.md) / CallsFilter

# Interface: CallsFilter

CallsFilter

## Properties

### call\_ids?

> `optional` **call\_ids**: `null` \| `string`[]

Call Ids

#### Defined in

[generated/traceServerApi.ts:197](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L197)

***

### input\_refs?

> `optional` **input\_refs**: `null` \| `string`[]

Input Refs

#### Defined in

[generated/traceServerApi.ts:189](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L189)

***

### op\_names?

> `optional` **op\_names**: `null` \| `string`[]

Op Names

#### Defined in

[generated/traceServerApi.ts:187](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L187)

***

### output\_refs?

> `optional` **output\_refs**: `null` \| `string`[]

Output Refs

#### Defined in

[generated/traceServerApi.ts:191](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L191)

***

### parent\_ids?

> `optional` **parent\_ids**: `null` \| `string`[]

Parent Ids

#### Defined in

[generated/traceServerApi.ts:193](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L193)

***

### trace\_ids?

> `optional` **trace\_ids**: `null` \| `string`[]

Trace Ids

#### Defined in

[generated/traceServerApi.ts:195](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L195)

***

### trace\_roots\_only?

> `optional` **trace\_roots\_only**: `null` \| `boolean`

Trace Roots Only

#### Defined in

[generated/traceServerApi.ts:199](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L199)

***

### wb\_run\_ids?

> `optional` **wb\_run\_ids**: `null` \| `string`[]

Wb Run Ids

#### Defined in

[generated/traceServerApi.ts:203](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L203)

***

### wb\_user\_ids?

> `optional` **wb\_user\_ids**: `null` \| `string`[]

Wb User Ids

#### Defined in

[generated/traceServerApi.ts:201](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L201)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/interfaces/CallsFilter)

<!--- Docs: TypeScript SDK -->
<!--- Callschema -->

# Callschema

[**weave**](../README.md) • **Docs**

***

[weave](../README.md) / CallSchema

# Interface: CallSchema

CallSchema

## Properties

### attributes

> **attributes**: `object`

Attributes

#### Defined in

[generated/traceServerApi.ts:119](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L119)

***

### deleted\_at?

> `optional` **deleted\_at**: `null` \| `string`

Deleted At

#### Defined in

[generated/traceServerApi.ts:134](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L134)

***

### display\_name?

> `optional` **display\_name**: `null` \| `string`

Display Name

#### Defined in

[generated/traceServerApi.ts:108](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L108)

***

### ended\_at?

> `optional` **ended\_at**: `null` \| `string`

Ended At

#### Defined in

[generated/traceServerApi.ts:123](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L123)

***

### exception?

> `optional` **exception**: `null` \| `string`

Exception

#### Defined in

[generated/traceServerApi.ts:125](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L125)

***

### id

> **id**: `string`

Id

#### Defined in

[generated/traceServerApi.ts:102](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L102)

***

### inputs

> **inputs**: `object`

Inputs

#### Defined in

[generated/traceServerApi.ts:121](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L121)

***

### op\_name

> **op\_name**: `string`

Op Name

#### Defined in

[generated/traceServerApi.ts:106](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L106)

***

### output?

> `optional` **output**: `null`

Output

#### Defined in

[generated/traceServerApi.ts:127](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L127)

***

### parent\_id?

> `optional` **parent\_id**: `null` \| `string`

Parent Id

#### Defined in

[generated/traceServerApi.ts:112](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L112)

***

### project\_id

> **project\_id**: `string`

Project Id

#### Defined in

[generated/traceServerApi.ts:104](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L104)

***

### started\_at

> **started\_at**: `string`

Started At

#### Format

date-time

#### Defined in

[generated/traceServerApi.ts:117](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L117)

***

### summary?

> `optional` **summary**: `object`

#### Defined in

[generated/traceServerApi.ts:128](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L128)

***

### trace\_id

> **trace\_id**: `string`

Trace Id

#### Defined in

[generated/traceServerApi.ts:110](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L110)

***

### wb\_run\_id?

> `optional` **wb\_run\_id**: `null` \| `string`

Wb Run Id

#### Defined in

[generated/traceServerApi.ts:132](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L132)

***

### wb\_user\_id?

> `optional` **wb\_user\_id**: `null` \| `string`

Wb User Id

#### Defined in

[generated/traceServerApi.ts:130](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L130)

[Source](https://weave-docs.wandb.ai/reference/typescript-sdk/weave/interfaces/CallSchema)



<!--- Optional: Example Notebooks -->
<!--- Scorers as Guardrails -->

# Scorers as Guardrails

:::tip[This is a notebook]

Open in Colab

View in Github

:::





# Scorers as Guardrails

Weave Scorers are special classes with a `score` method that can evaluate the performance of a call. They can range from quite simple rules to complex LLMs as judges. 

In this notebook, we will explore how to use Scorers as guardrails to prevent your LLM from generating harmful or inappropriate content.



```python
%pip install weave --quiet
```


```python
"""
Example demonstrating how to implement guardrails in Weave.
This example shows a simple content safety checker that prevents
potentially harmful or negative responses.
"""

import weave

# Initialize Weave with a descriptive project name
weave.init("content-safety-guardrails")


class ContentSafetyScorer(weave.Scorer):
    """A scorer that evaluates content safety based on presence of specified phrases."""

    unsafe_phrases: list[str]
    case_sensitive: bool = False

    @weave.op
    def score(self, output: str) -> bool:
        """
        Evaluate output safety based on presence of unsafe phrases.

        Args:
            output: The text output to evaluate

        Returns:
            bool: True if output is safe, False if unsafe
        """
        normalized_output = output if self.case_sensitive else output.lower()

        for phrase in self.unsafe_phrases:
            normalized_phrase = phrase if self.case_sensitive else phrase.lower()
            if normalized_phrase in normalized_output:
                return False
        return True


@weave.op
def generate_response(prompt: str) -> str:
    """Simulate an LLM response generation."""
    if "test" in prompt.lower():
        return "I'm sorry, I cannot process that request."
    elif "help" in prompt.lower():
        return "I'd be happy to help you with that!"
    else:
        return "Here's what you requested: " + prompt


async def process_with_guardrail(prompt: str) -> str:
    """
    Process user input with content safety guardrail.
    Returns the response if safe, or a fallback message if unsafe.
    """
    # Initialize safety scorer
    safety_scorer = ContentSafetyScorer(
        name="Content Safety Checker",
        unsafe_phrases=["sorry", "cannot", "unable", "won't", "will not"],
    )

    # Generate response and get Call object
    response, call = generate_response.call(prompt)

    # Apply safety scoring
    evaluation = await call.apply_scorer(safety_scorer)

    # Return response or fallback based on safety check
    if evaluation.result:
        return response
    else:
        return "I cannot provide that response."
```


```python
"""Example usage of the guardrail system."""
test_prompts = [
    "Please help me with my homework",
    "Can you run a test for me?",
    "Tell me a joke",
]

print("Testing content safety guardrails:\n")

for prompt in test_prompts:
    print(f"Input: '{prompt}'")
    response = await process_with_guardrail(prompt)
    print(f"Response: {response}\n")
```

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/scorers_as_guardrails)

<!--- Optional: Example Notebooks -->
<!--- Intro To Weave Hello Eval -->

# Intro To Weave Hello Eval

:::tip[This is a notebook]

Open in Colab

View in Github

:::


# Introduction to Evaluations



Weave is a toolkit for developing AI-powered applications.

You can use Weave to:
- Log and debug language model inputs, outputs, and traces.
- Build rigorous, apples-to-apples evaluations for language model use cases.
- Organize all the information generated across the LLM workflow, from experimentation to evaluations to production.

This notebook demonstrates how to evaluate a model or function using Weave’s Evaluation API. Evaluation is a core concept in Weave that helps you measure and iterate on your application by running it against a dataset of examples and scoring the outputs using custom-defined functions. You'll define a simple model, create a labeled dataset, track scoring functions with `@weave.op`, and run an evaluation that automatically tracks results in the Weave UI. This forms the foundation for more advanced workflows like LLM fine-tuning, regression testing, or model comparison.

To get started, complete the prerequisites. Then, define a Weave `Model` with a `predict` method, create a labeled dataset and scoring function, and run an evaluation using `weave.Evaluation.evaluate()`.

## 🔑 Prerequisites

Before you can run a Weave evaluation, complete the following prerequisites.

1. Install the W&B Weave SDK and log in with your [API key](https://wandb.ai/settings#api).
2. Install the OpenAI SDK and log in with your [API key](https://platform.openai.com/api-keys).
3. Initialize your W&B project.


```python
# Install dependancies and imports
!pip install wandb weave openai -q

import os
from getpass import getpass

from openai import OpenAI
from pydantic import BaseModel

import weave

# 🔑 Setup your API keys
# Running this cell will prompt you for your API key with `getpass` and will not echo to the terminal.
#####
print("---")
print(
    "You can find your Weights and Biases API key here: https://wandb.ai/settings#api"
)
os.environ["WANDB_API_KEY"] = getpass("Enter your Weights and Biases API key: ")
print("---")
print("You can generate your OpenAI API key here: https://platform.openai.com/api-keys")
os.environ["OPENAI_API_KEY"] = getpass("Enter your OpenAI API key: ")
print("---")
#####

# 🏠 Enter your W&B project name
weave_client = weave.init("MY_PROJECT_NAME")  # 🐝 Your W&B project name
```

## 🐝 Run your first evaluation

The following code sample shows how to evaluate an LLM using Weave’s `Model` and `Evaluation` APIs. First, define a Weave model by subclassing `weave.Model`, specifying the model name and prompt format, and tracking a `predict` method with `@weave.op`. The `predict` method sends a prompt to OpenAI and parses the response into a structured output using a Pydantic schema (`FruitExtract`). Then, create a small evaluation dataset consisting of input sentences and expected targets. Next, define a custom scoring function (also tracked using `@weave.op`) that compares the model’s output to the target label. Finally,  wrap everything in a `weave.Evaluation`, specifying your dataset and scorers, and call `evaluate()` to run the evaluation pipeline asynchronously.


```python
# 1. Construct a Weave model
class FruitExtract(BaseModel):
    fruit: str
    color: str
    flavor: str


class ExtractFruitsModel(weave.Model):
    model_name: str
    prompt_template: str

    @weave.op()
    def predict(self, sentence: str) -> dict:
        client = OpenAI()

        response = client.beta.chat.completions.parse(
            model=self.model_name,
            messages=[
                {
                    "role": "user",
                    "content": self.prompt_template.format(sentence=sentence),
                }
            ],
            response_format=FruitExtract,
        )
        result = response.choices[0].message.parsed
        return result


model = ExtractFruitsModel(
    name="gpt4o",
    model_name="gpt-4o",
    prompt_template='Extract fields ("fruit": , "color": , "flavor": ) as json, from the following text : {sentence}',
)

# 2. Collect some samples
sentences = [
    "There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.",
    "Pounits are a bright green color and are more savory than sweet.",
    "Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.",
]
labels = [
    {"fruit": "neoskizzles", "color": "purple", "flavor": "candy"},
    {"fruit": "pounits", "color": "green", "flavor": "savory"},
    {"fruit": "glowls", "color": "orange", "flavor": "sour, bitter"},
]
examples = [
    {"id": "0", "sentence": sentences[0], "target": labels[0]},
    {"id": "1", "sentence": sentences[1], "target": labels[1]},
    {"id": "2", "sentence": sentences[2], "target": labels[2]},
]


# 3. Define a scoring function for your evaluation
@weave.op()
def fruit_name_score(target: dict, output: FruitExtract) -> dict:
    target_flavors = [f.strip().lower() for f in target["flavor"].split(",")]
    output_flavors = [f.strip().lower() for f in output.flavor.split(",")]
    # Check if any target flavor is present in the output flavors
    matches = any(tf in of for tf in target_flavors for of in output_flavors)
    return {"correct": matches}


# 4. Run your evaluation
evaluation = weave.Evaluation(
    name="fruit_eval",
    dataset=examples,
    scorers=[fruit_name_score],
)
await evaluation.evaluate(model)
```

## 🚀 Looking for more examples?

- Learn how to build an [evlauation pipeline end-to-end](https://weave-docs.wandb.ai/tutorial-eval). 
- Learn how to evaluate a [RAG application by building](https://weave-docs.wandb.ai/tutorial-rag).

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/Intro_to_Weave_Hello_Eval)

<!--- Optional: Example Notebooks -->
<!--- Service API -->

# Service API

:::tip[This is a notebook]

Open in Colab

View in Github

:::





# Use the Service API to Log and Query Traces

In the following guide, you will learn how to use the Weave Service API to log traces. Specifically, you will use the Service API to:

1. [Create a mock of a simple LLM call and response, and log it to Weave.](#simple-trace)
2. [Create a mock of a more complex LLM call and response, and log it to Weave.](#complex-trace)
3. [Run a sample lookup query on the logged traces.](#run-a-lookup-query)

> **View logged traces**
>
> You can view all of the Weave traces created when you run the code in this guide by going to the **Traces** tab in your Weave project (specified by `team_id\project_id`), and selecting the name of the trace.

Before beginning, complete the [prerequisites](#prerequisites-set-variables-and-endpoints)

## Prerequisites: Set variables and endpoints

The following code sets the URL endpoints that will be used to access the Service API:

- [`https://trace.wandb.ai/call/start`](https://weave-docs.wandb.ai/reference/service-api/call-start-call-start-post)
- [`https://trace.wandb.ai/call/end`](https://weave-docs.wandb.ai/reference/service-api/call-end-call-end-post)
- [`https://trace.wandb.ai/calls/stream_query`](https://weave-docs.wandb.ai/reference/service-api/calls-query-stream-calls-stream-query-post)

Additionally, you must set the following variables:

- `project_id`: The name of the W&B project that you want to log your traces to.
- `team_id`: Your W&B team name.
- `wandb_token`: Your [W&B authorization token](https://wandb.ai/authorize).


```python
import datetime
import json

import requests

# Headers and URLs
headers = {"Content-Type": "application/json"}
url_start = "https://trace.wandb.ai/call/start"
url_end = "https://trace.wandb.ai/call/end"
url_stream_query = "https://trace.wandb.ai/calls/stream_query"

# W&B variables
team_id = ""
project_id = ""
wandb_token = ""
```

## Simple trace
The following sections walk you through creating a simple trace.

1. [Start a simple trace](#start-a-simple-trace)
2. [End a simple trace](#end-a-simple-trace)

### Start a simple trace 

The following code creates a sample LLM call `payload_start` and logs it to Weave using the `url_start` endpoint. The `payload_start` object mimics a call to OpenAI's `gpt-4o` with the query `Why is the sky blue?`.

On success, this code will output a message indicating that the trace was started:

```
Call started. ID: 01939cdc-38d2-7d61-940d-dcca0a56c575, Trace ID: 01939cdc-38d2-7d61-940d-dcd0e76c5f34
```


```python
## ------------
## Start trace
## ------------
payload_start = {
    "start": {
        "project_id": f"{team_id}/{project_id}",
        "op_name": "simple_trace",
        "started_at": datetime.datetime.now().isoformat(),
        "inputs": {
            # Use this "messages" style to generate the chat UI in the expanded trace.
            "messages": [{"role": "user", "content": "Why is the sky blue?"}],
            "model": "gpt-4o",
        },
        "attributes": {},
    }
}
response = requests.post(
    url_start, headers=headers, json=payload_start, auth=("api", wandb_token)
)
if response.status_code == 200:
    data = response.json()
    call_id = data.get("id")
    trace_id = data.get("trace_id")
    print(f"Call started. ID: {call_id}, Trace ID: {trace_id}")
else:
    print("Start request failed with status:", response.status_code)
    print(response.text)
    exit()
```

### End a simple trace

To complete the simple trace, the following code creates a sample LLM call `payload_end` and logs it to Weave using the `url_end` endpoint. The `payload_end` object mimics the response from OpenAI's `gpt-4o` given the query `Why is the sky blue?`. The object is formatted so that pricing summary information and the chat completion are generated in trace view in the Weave Dashboard.

On success, this code will output a message indicating that the trace completed:

```
Call ended.
```


```python
## ------------
## End trace
## ------------
payload_end = {
    "end": {
        "project_id": f"{team_id}/{project_id}",
        "id": call_id,
        "ended_at": datetime.datetime.now().isoformat(),
        "output": {
            # Use this "choices" style to add the completion to the chat UI in the expanded trace.
            "choices": [
                {
                    "message": {
                        "content": "It’s due to Rayleigh scattering, where shorter blue wavelengths of sunlight scatter in all directions."
                    }
                },
            ]
        },
        # Format the summary like this to generate the pricing summary information in the traces table.
        "summary": {
            "usage": {
                "gpt-4o": {
                    "prompt_tokens": 10,
                    "completion_tokens": 20,
                    "total_tokens": 30,
                    "requests": 1,
                }
            }
        },
    }
}
response = requests.post(
    url_end, headers=headers, json=payload_end, auth=("api", wandb_token)
)
if response.status_code == 200:
    print("Call ended.")
else:
    print("End request failed with status:", response.status_code)
    print(response.text)
```

## Complex trace
The following sections walk you through creating a more complex trace with child spans, similar to a mult-operation RAG lookup.

1. [Start a complex trace](#complex-trace)
2. [Add a child span: RAG document lookup](#add-a-child-span-to-a-complex-trace-rag-document-lookup)
3. [Add a child span: LLM completion call](#add-a-child-span-to-a-complex-trace-llm-completion-call)
4. [End a complex trace](#end-a-complex-trace)

### Start a complex trace 

The following code demonstrates how to create a more complex trace with multiple spans. An example of this would be a Retrieval-Augmented Generation (RAG) lookup followed by an LLM call. The first part initializes a parent trace(`payload_parent_start`) that represents the overall operation. In this case, the operation is  processing the user query `Can you summarize the key points of this document?`.

The `payload_parent_start` object mimics the initial step in a multi-step workflow, logging the the operation in Weave using the `url_start` endpoint.

On success, this code will output a message indicating that the parent call was logged:

```
Parent call started. ID: 01939d26-0844-7c43-94bb-cdc471b6d65f, Trace ID: 01939d26-0844-7c43-94bb-cdd97dc296c8
```


```python
## ------------
## Start trace (parent)
## ------------

# Parent call: Start
payload_parent_start = {
    "start": {
        "project_id": f"{team_id}/{project_id}",
        "op_name": "complex_trace",
        "started_at": datetime.datetime.now().isoformat(),
        "inputs": {"question": "Can you summarize the key points of this document?"},
        "attributes": {},
    }
}
response = requests.post(
    url_start, headers=headers, json=payload_parent_start, auth=("api", wandb_token)
)
if response.status_code == 200:
    data = response.json()
    parent_call_id = data.get("id")
    trace_id = data.get("trace_id")
    print(f"Parent call started. ID: {parent_call_id}, Trace ID: {trace_id}")
else:
    print("Parent start request failed with status:", response.status_code)
    print(response.text)
    exit()
```

### Add a child span to a complex trace: RAG document lookup

The following code demonstrates how to add a child span to the parent trace started in the previous step. This step models a the RAG document lookup sub-operation in the overarching workflow.

The child trace is initiated with the `payload_child_start` object, which includes:
- `trace_id`: Links this child span to the parent trace.
- `parent_id`: Associates the child span with the parent operation.
- `inputs`: Logs the search query, e.g., 
  `"This is a search query of the documents I'm looking for."`

On a successful call to the `url_start` endpoint, the code outputs a message indicating that the child call was started and completed:

```
Child call started. ID: 01939d32-23d6-75f2-9128-36a4a806f179
Child call ended.
```


```python
## ------------
## Child span:
## Ex. RAG Document lookup
## ------------

# Child call: Start
payload_child_start = {
    "start": {
        "project_id": f"{team_id}/{project_id}",
        "op_name": "rag_document_lookup",
        "trace_id": trace_id,
        "parent_id": parent_call_id,
        "started_at": datetime.datetime.now().isoformat(),
        "inputs": {
            "document_search": "This is a search query of the documents I'm looking for."
        },
        "attributes": {},
    }
}
response = requests.post(
    url_start, headers=headers, json=payload_child_start, auth=("api", wandb_token)
)
if response.status_code == 200:
    data = response.json()
    child_call_id = data.get("id")
    print(f"Child call started. ID: {child_call_id}")
else:
    print("Child start request failed with status:", response.status_code)
    print(response.text)
    exit()

# Child call: End
payload_child_end = {
    "end": {
        "project_id": f"{team_id}/{project_id}",
        "id": child_call_id,
        "ended_at": datetime.datetime.now().isoformat(),
        "output": {
            "document_results": "This will be the RAG'd document text which will be returned from the search query."
        },
        "summary": {},
    }
}
response = requests.post(
    url_end, headers=headers, json=payload_child_end, auth=("api", wandb_token)
)
if response.status_code == 200:
    print("Child call ended.")
else:
    print("Child end request failed with status:", response.status_code)
    print(response.text)
```

### Add a child span to a complex trace: LLM completion call

The following code demonstrates how to add another child span to the parent trace, representing an LLM completion call. This step models the AI's response generation based on document context retrieved in the previous RAG operation.

The LLM completion trace is initiated with the `payload_child_start` object, which includes:
- `trace_id`: Links this child span to the parent trace.
- `parent_id`: Associates the child span with the overarching workflow.
- `inputs`: Logs the input messages for the LLM, including the user query and the appended document context.
- `model`: Specifies the model used for the operation (`gpt-4o`).

On success, the code outputs a message indicating the LLM child span trace has started and ended:

```
Child call started. ID: 0245acdf-83a9-4c90-90df-dcb2b89f234a
```

Once the operation completes, the `payload_child_end` object ends the trace by logging the LLM-generated response in the `output` field. Usage summary information is also logged.

On success, the code outputs a message indicating the LLM child span trace has started and ended:

```
Child call started. ID: 0245acdf-83a9-4c90-90df-dcb2b89f234a
Child call ended.
```


```python
## ------------
## Child span:
## Create an LLM completion call
## ------------

# Child call: Start
payload_child_start = {
    "start": {
        "project_id": f"{team_id}/{project_id}",
        "op_name": "llm_completion",
        "trace_id": trace_id,
        "parent_id": parent_call_id,
        "started_at": datetime.datetime.now().isoformat(),
        "inputs": {
            "messages": [
                {
                    "role": "user",
                    "content": "With the following document context, could you help me answer:\n Can you summarize the key points of this document?\n [+ appended document context]",
                }
            ],
            "model": "gpt-4o",
        },
        "attributes": {},
    }
}
response = requests.post(
    url_start, headers=headers, json=payload_child_start, auth=("api", wandb_token)
)
if response.status_code == 200:
    data = response.json()
    child_call_id = data.get("id")
    print(f"Child call started. ID: {child_call_id}")
else:
    print("Child start request failed with status:", response.status_code)
    print(response.text)
    exit()

# Child call: End
payload_child_end = {
    "end": {
        "project_id": f"{team_id}/{project_id}",
        "id": child_call_id,
        "ended_at": datetime.datetime.now().isoformat(),
        "output": {
            "choices": [
                {"message": {"content": "This is the response generated by the LLM."}},
            ]
        },
        "summary": {
            "usage": {
                "gpt-4o": {
                    "prompt_tokens": 10,
                    "completion_tokens": 20,
                    "total_tokens": 30,
                    "requests": 1,
                }
            }
        },
    }
}
response = requests.post(
    url_end, headers=headers, json=payload_child_end, auth=("api", wandb_token)
)
if response.status_code == 200:
    print("Child call ended.")
else:
    print("Child end request failed with status:", response.status_code)
    print(response.text)
```

### End a complex trace

The following code demonstrates how to finalize the parent trace, marking the completion of the entire workflow. This step aggregates the results of all child spans (e.g., RAG lookup and LLM completion) and logs the final output and metadata.

The trace is finalized using the `payload_parent_end` object, which includes:
- `id`: The `parent_call_id` from the initial parent trace start.
- `output`: Represents the final output of the entire workflow. 
- `summary`: Consolidates usage data for the entire workflow.
- `prompt_tokens`: Total tokens used for all prompts.
- `completion_tokens`: Total tokens generated in all responses.
- `total_tokens`: Combined token count for the workflow.
- `requests`: Total number of requests made (in this case, `1`).

On success, the code outputs:

```
Parent call ended.
```


```python
## ------------
## End trace
## ------------

# Parent call: End
payload_parent_end = {
    "end": {
        "project_id": f"{team_id}/{project_id}",
        "id": parent_call_id,
        "ended_at": datetime.datetime.now().isoformat(),
        "output": {
            "choices": [
                {"message": {"content": "This is the response generated by the LLM."}},
            ]
        },
        "summary": {
            "usage": {
                "gpt-4o": {
                    "prompt_tokens": 10,
                    "completion_tokens": 20,
                    "total_tokens": 30,
                    "requests": 1,
                }
            }
        },
    }
}
response = requests.post(
    url_end, headers=headers, json=payload_parent_end, auth=("api", wandb_token)
)
if response.status_code == 200:
    print("Parent call ended.")
else:
    print("Parent end request failed with status:", response.status_code)
    print(response.text)
```

## Run a lookup query
The following code demonstrates how to query the traces created in previous examples, filtering only for traces where the `inputs.model` field is equal to `gpt-4o`.

The `query_payload` object includes:
- `project_id`: Identifies the team and project to query.
- `filter`: Ensures the query returns only **trace roots** (top-level traces).
- `query`: Defines the filter logic using the `$expr` operator:
  - `$getField`: Retrieves the `inputs.model` field.
  - `$literal`: Matches traces where `inputs.model` equals `"gpt-4o"`.
- `limit`: Limits the query to 10,000 results.
- `offset`: Starts the query at the first result.
- `sort_by`: Orders results by the `started_at` timestamp in descending order.
- `include_feedback`: Excludes feedback data from the results.

On a successful query, the response will include trace data matching the query parameters:

```
{'id': '01939cf3-541f-76d3-ade3-50cfae068b39', 'project_id': 'cool-new-team/uncategorized', 'op_name': 'simple_trace', 'display_name': None, 'trace_id': '01939cf3-541f-76d3-ade3-50d5cfabe2db', 'parent_id': None, 'started_at': '2024-12-06T17:10:12.590000Z', 'attributes': {}, 'inputs': {'messages': [{'role': 'user', 'content': 'Why is the sky blue?'}], 'model': 'gpt-4o'}, 'ended_at': '2024-12-06T17:47:08.553000Z', 'exception': None, 'output': {'choices': [{'message': {'content': 'It’s due to Rayleigh scattering, where shorter blue wavelengths of sunlight scatter in all directions.'}}]}, 'summary': {'usage': {'gpt-4o': {'prompt_tokens': 10, 'completion_tokens': 20, 'requests': 1, 'total_tokens': 30}}, 'weave': {'status': 'success', 'trace_name': 'simple_trace', 'latency_ms': 2215963}}, 'wb_user_id': 'VXNlcjoyMDk5Njc0', 'wb_run_id': None, 'deleted_at': None}
```





```python
query_payload = {
    "project_id": f"{team_id}/{project_id}",
    "filter": {"trace_roots_only": True},
    "query": {
        "$expr": {"$eq": [{"$getField": "inputs.model"}, {"$literal": "gpt-4o"}]}
    },
    "limit": 10000,
    "offset": 0,
    "sort_by": [{"field": "started_at", "direction": "desc"}],
    "include_feedback": False,
}
response = requests.post(
    url_stream_query, headers=headers, json=query_payload, auth=("api", wandb_token)
)
if response.status_code == 200:
    print("Query successful!")
    try:
        data = response.json()
        print(data)
    except json.JSONDecodeError as e:
        # Alternate decode
        json_objects = response.text.strip().split("\n")
        parsed_data = [json.loads(obj) for obj in json_objects]
        print(parsed_data)
else:
    print(f"Query failed with status code: {response.status_code}")
    print(response.text)
```

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/weave_via_service_api)

<!--- Optional: Example Notebooks -->
<!--- Custom Model Cost -->

# Custom Model Cost

:::tip[This is a notebook]

Open in Colab

View in Github

:::





# Setting up a custom cost model

Weave calculates costs based on the number of tokens used and the model used.
Weave grabs this usage and model from the output and associates them with the call.

Let's set up a simple custom model, that calculates its own token usage, and stores that in weave.

## Set up the environment

We install and import all needed packages.
We set `WANDB_API_KEY` in our env so that we may easily login with `wandb.login()` (this should be given to the colab as a secret).

We set the project in W&B we want to log this into in `name_of_wandb_project`.

**_NOTE:_** `name_of_wandb_project` may also be in the format of `{team_name}/{project_name}` to specify a team to log the traces into.

We then fetch a weave client by calling `weave.init()`


```python
%pip install wandb weave datetime --quiet
```


```python
import os

import wandb
from google.colab import userdata

import weave

os.environ["WANDB_API_KEY"] = userdata.get("WANDB_API_KEY")
name_of_wandb_project = "custom-cost-model"

wandb.login()
```


```python
weave_client = weave.init(name_of_wandb_project)
```

## Setting up a model with weave



```python
from weave import Model


class YourModel(Model):
    attribute1: str
    attribute2: int

    def simple_token_count(self, text: str) -> int:
        return len(text) // 3

    # This is a custom op that we are defining
    # It takes in a string, and outputs a dict with the usage counts, model name, and the output
    @weave.op()
    def custom_model_generate(self, input_data: str) -> dict:
        # Model logic goes here
        # Here is where you would have a custom generate function
        prediction = self.attribute1 + " " + input_data

        # Usage counts
        prompt_tokens = self.simple_token_count(input_data)
        completion_tokens = self.simple_token_count(prediction)

        # We return a dictionary with the usage counts, model name, and the output
        # Weave will automatically associate this with the trace
        # This object {usage, model, output} matches the output of a OpenAI Call
        return {
            "usage": {
                "input_tokens": prompt_tokens,
                "output_tokens": completion_tokens,
                "total_tokens": prompt_tokens + completion_tokens,
            },
            "model": "your_model_name",
            "output": prediction,
        }

    # In our predict function we call our custom generate function, and return the output.
    @weave.op()
    def predict(self, input_data: str) -> dict:
        # Here is where you would do any post processing of the data
        outputs = self.custom_model_generate(input_data)
        return outputs["output"]
```

## Add a custom cost

Here we add a custom cost, and now that we have a custom cost, and our calls have usage, we can fetch the calls with `include_cost` and our calls with have costs under `summary.weave.costs`.


```python
model = YourModel(attribute1="Hello", attribute2=1)
model.predict("world")

# We then add a custom cost to our project
weave_client.add_cost(
    llm_id="your_model_name", prompt_token_cost=0.1, completion_token_cost=0.2
)

# We can then query for the calls, and with include_costs=True
# we receive the costs back attached to the calls
calls = weave_client.get_calls(filter={"trace_roots_only": True}, include_costs=True)

list(calls)
```

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/custom_model_cost)

<!--- Optional: Example Notebooks -->
<!--- Log Feedback from Production -->

# Log Feedback from Production

:::tip[This is a notebook]

Open in Colab

View in Github

:::






It is often hard to automatically evaluate a generated LLM response so, depending on your risk tolerance, you can gather direct user feedback to find areas to improve.

In this tutorial, we'll use a custom chatbot as an example app from which to collect user feedback.
We'll use Streamlit to build the interface and we'll capture the LLM interactions and feedback in Weave.

## Setup


```python
!pip install weave openai streamlit wandb
!pip install set-env-colab-kaggle-dotenv -q # for env var
```


```python
# Add a .env file with your OpenAI and WandB API keys
from set_env import set_env

_ = set_env("OPENAI_API_KEY")
_ = set_env("WANDB_API_KEY")
```

Next, create a file called `chatbot.py` with the following contents:


```python
# chatbot.py

import openai
import streamlit as st
import wandb
from set_env import set_env

import weave

_ = set_env("OPENAI_API_KEY")
_ = set_env("WANDB_API_KEY")
wandb.login()
weave_client = weave.init("feedback-example")
oai_client = openai.OpenAI()


def init_states():
    """Set up session_state keys if they don't exist yet."""
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    if "calls" not in st.session_state:
        st.session_state["calls"] = []
    if "session_id" not in st.session_state:
        st.session_state["session_id"] = "123abc"
@weave.op
def chat_response(full_history):
    """
    Calls the OpenAI API in streaming mode given the entire conversation history so far.
    full_history is a list of dicts: [{"role":"user"|"assistant","content":...}, ...]
    """
    stream = oai_client.chat.completions.create(
        model="gpt-4", messages=full_history, stream=True
    )
    response_text = st.write_stream(stream)
    return {"response": response_text}


def render_feedback_buttons(call_idx):
    """Renders thumbs up/down and text feedback for the call."""
    col1, col2, col3 = st.columns([1, 1, 4])

    # Thumbs up button
    with col1:
        if st.button("👍", key=f"thumbs_up_{call_idx}"):
            st.session_state.calls[call_idx].feedback.add_reaction("👍")
            st.success("Thanks for the feedback!")

    # Thumbs down button
    with col2:
        if st.button("👎", key=f"thumbs_down_{call_idx}"):
            st.session_state.calls[call_idx].feedback.add_reaction("👎")
            st.success("Thanks for the feedback!")

    # Text feedback
    with col3:
        feedback_text = st.text_input("Feedback", key=f"feedback_input_{call_idx}")
        if st.button("Submit Feedback", key=f"submit_feedback_{call_idx}"):
            if feedback_text:
                st.session_state.calls[call_idx].feedback.add_note(feedback_text)
                st.success("Feedback submitted!")


def display_old_messages():
    """Displays the conversation stored in st.session_state.messages with feedback buttons"""
    for idx, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

            # If it's an assistant message, show feedback form
            if message["role"] == "assistant":
                # Figure out index of this assistant message in st.session_state.calls
                assistant_idx = (
                    len(
                        [
                            m
                            for m in st.session_state.messages[: idx + 1]
                            if m["role"] == "assistant"
                        ]
                    )
                    - 1
                )
                # Render thumbs up/down & text feedback
                if assistant_idx < len(st.session_state.calls):
                    render_feedback_buttons(assistant_idx)


def display_chat_prompt():
    """Displays the chat prompt input box."""
    if prompt := st.chat_input("Ask me anything!"):
        # Immediately render new user message
        with st.chat_message("user"):
            st.markdown(prompt)

        # Save user message in session
        st.session_state.messages.append({"role": "user", "content": prompt})

        # Prepare chat history for the API
        full_history = [
            {"role": msg["role"], "content": msg["content"]}
            for msg in st.session_state.messages
        ]

        with st.chat_message("assistant"):
            # Attach Weave attributes for tracking of conversation instances
            with weave.attributes(
                {"session": st.session_state["session_id"], "env": "prod"}
            ):
                # Call the OpenAI API (stream)
                result, call = chat_response.call(full_history)

                # Store the assistant message
                st.session_state.messages.append(
                    {"role": "assistant", "content": result["response"]}
                )

                # Store the weave call object to link feedback to the specific response
                st.session_state.calls.append(call)

                # Render feedback buttons for the new message
                new_assistant_idx = (
                    len(
                        [
                            m
                            for m in st.session_state.messages
                            if m["role"] == "assistant"
                        ]
                    )
                    - 1
                )

                # Render feedback buttons
                if new_assistant_idx < len(st.session_state.calls):
                    render_feedback_buttons(new_assistant_idx)


def main():
    st.title("Chatbot with immediate feedback forms")
    init_states()
    display_old_messages()
    display_chat_prompt()


if __name__ == "__main__":
    main()
```

You can run this with `streamlit run chatbot.py`.

Now, you can interact with this application and click the feedback buttons after each response. 
Visit the Weave UI to see the attached feedback.

## Explanation

If we consider our decorated prediction function as:


```python
import weave

weave.init("feedback-example")
@weave.op
def predict(input_data):
    # Your prediction logic here
    some_result = "hello world"
    return some_result
```

We can use it as usual to deliver some model response to the user:


```python
with weave.attributes(
    {"session": "123abc", "env": "prod"}
):  # attach arbitrary attributes to the call alongside inputs & outputs
    result = predict(input_data="your data here")  # user question through the App UI
```

To attach feedback, you need the `call` object, which is obtained by using the `.call()` method *instead of calling the function as normal*:


```python
result, call = predict.call(input_data="your data here")
```

This call object is needed for attaching feedback to the specific response.
After making the call, the output of the operation is available using `result` above.


```python
call.feedback.add_reaction("👍")  # user reaction through the App UI
```

## Conclusion

In this tutorial, we built a chat UI with Streamlit which had inputs & outputs captured in Weave, alongside 👍👎 buttons to capture user feedback.

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/feedback_prod)

<!--- Optional: Example Notebooks -->
<!--- Intro To Weave Hello Trace -->

# Intro To Weave Hello Trace

:::tip[This is a notebook]

Open in Colab

View in Github

:::


# Introduction to Traces



Weave is a toolkit for developing AI-powered applications.

You can use Weave to:
- Log and debug language model inputs, outputs, and traces.
- Build rigorous, apples-to-apples evaluations for language model use cases.
- Organize all the information generated across the LLM workflow, from experimentation to evaluations to production.

Weave traces let you automatically capture the inputs, outputs, and internal structure of your Python functions—especially useful when working with LLMs. By decorating a function with `@weave.op`, Weave records a rich trace of how your function runs, including any nested operations or external API calls. This makes it easy to debug, understand, and visualize how your code is interacting with language models, all from within your notebook.

To get started, complete the prerequisites. Then, define a function with the `@weave.op` decorator to track LLM calls, run it on an example input, and Weave will automatically capture and visualize the trace.

## 🔑 Prerequisites

Before you can begin tracing in Weave, complete the following prerequisites.

1. Install the W&B Weave SDK and log in with your [API key](https://wandb.ai/settings#api).
2. Install the OpenAI SDK and log in with your [API key](https://platform.openai.com/api-keys).
3. Initialize your W&B project.



```python
# Install dependancies and imports
!pip install wandb weave openai -q

import json
import os
from getpass import getpass

from openai import OpenAI

import weave

# 🔑 Setup your API keys
# Running this cell will prompt you for your API key with `getpass` and will not echo to the terminal.
#####
print("---")
print(
    "You can find your Weights and Biases API key here: https://wandb.ai/settings#api"
)
os.environ["WANDB_API_KEY"] = getpass("Enter your Weights and Biases API key: ")
print("---")
print("You can generate your OpenAI API key here: https://platform.openai.com/api-keys")
os.environ["OPENAI_API_KEY"] = getpass("Enter your OpenAI API key: ")
print("---")
#####

# 🏠 Enter your W&B project name
weave_client = weave.init("MY_PROJECT_NAME")  # 🐝 Your W&B project name
```

## 🐝 Run your first trace

The following code sample shows how to capture and visualize a trace in Weave using the `@weave.op` decorator. It defines a function called `extract_fruit` that sends a prompt to OpenAI's GPT-4o to extract structured data (fruit, color, and flavor) from a sentence. By decorating the function with `@weave.op`, Weave automatically tracks the function execution, including inputs, outputs, and intermediate steps. When the function is called with a sample sentence, the full trace is saved and viewable in the Weave UI.


```python
@weave.op()  # 🐝 Decorator to track requests
def extract_fruit(sentence: str) -> dict:
    client = OpenAI()
    system_prompt = (
        "Parse sentences into a JSON dict with keys: fruit, color and flavor."
    )
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": sentence},
        ],
        temperature=0.7,
        response_format={"type": "json_object"},
    )
    extracted = response.choices[0].message.content
    return json.loads(extracted)


sentence = "There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy."
extract_fruit(sentence)
```

## 🚀 Looking for more examples?
- Check out the [Quickstart guide](https://weave-docs.wandb.ai/quickstart).
- Learn more about [advanced tracing topics](https://weave-docs.wandb.ai/tutorial-tracing_2).
- Learn more about [tracing in Weave](https://weave-docs.wandb.ai/guides/tracking/tracing)

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/Intro_to_Weave_Hello_Trace)

<!--- Optional: Example Notebooks -->
<!--- NotDiamond Custom Routing -->

# NotDiamond Custom Routing

:::tip[This is a notebook]

Open in Colab

View in Github

:::






# Custom Routing for LLM Prompts with Not Diamond

This notebook demonstrates how to use Weave with [Not Diamond's custom routing](https://docs.notdiamond.ai/docs/router-training-quickstart) to route LLM prompts to the most appropriate model based on evaluation results.

## Routing prompts

When building complex LLM workflows users may need to prompt different models according to accuracy, cost, or call latency.
Users can use [Not Diamond](https://www.notdiamond.ai/) to route prompts in these workflows to the right model for their needs, helping maximize accuracy while saving on model costs.

For any given distribution of data, rarely will one single model outperform every other model on every single query. By combining together multiple models into a "meta-model" that learns when to call each LLM, you can beat every individual model's performance and even drive down costs and latency in the process.

## Custom routing

You need three things to train a custom router for your prompts:

1. A set of LLM prompts: Prompts must be strings and should be representative of the prompts used in our application.
1. LLM responses: The responses from candidate LLMs for each input. Candidate LLMs can include both our supported LLMs and your own custom models.
1. Evaluation scores for responses to the inputs from candidate LLMs: Scores are numbers, and can be any metric that fit your needs.

By submitting these to the Not Diamond API you can then train a custom router tuned to each of your workflows.


## Setting up the training data

In practice, you will use your own Evaluations to train a custom router. For this example notebook, however, you will use LLM responses
for [the HumanEval dataset](https://github.com/openai/human-eval) to train a custom router for coding tasks.

We start by downloading the dataset we have prepared for this example, then parsing LLM responses into EvaluationResults for each model.



```python
!curl -L "https://drive.google.com/uc?export=download&id=1q1zNZHioy9B7M-WRjsJPkfvFosfaHX38" -o humaneval.csv
```


```python
import random

import weave
from weave.flow.dataset import Dataset
from weave.flow.eval import EvaluationResults
from weave.integrations.notdiamond.util import get_model_evals

pct_train = 0.8
pct_test = 1 - pct_train

# In practice, you will build an Evaluation on your dataset and call
# `evaluation.get_eval_results(model)`
model_evals = get_model_evals("./humaneval.csv")
model_train = {}
model_test = {}
for model, evaluation_results in model_evals.items():
    n_results = len(evaluation_results.rows)
    all_idxs = list(range(n_results))
    train_idxs = random.sample(all_idxs, k=int(n_results * pct_train))
    test_idxs = [idx for idx in all_idxs if idx not in train_idxs]

    model_train[model] = EvaluationResults(
        rows=weave.Table([evaluation_results.rows[idx] for idx in train_idxs])
    )
    model_test[model] = Dataset(
        rows=weave.Table([evaluation_results.rows[idx] for idx in test_idxs])
    )
    print(
        f"Found {len(train_idxs)} train rows and {len(test_idxs)} test rows for {model}."
    )
```

## Training a custom router

Now that you have EvaluationResults, you can train a custom router. Make sure you have [created an account](https://app.notdiamond.ai/keys) and
[generated an API key](https://app.notdiamond.ai/keys), then insert your API key below.





```python
import os

from weave.integrations.notdiamond.custom_router import train_router

api_key = os.getenv("NOTDIAMOND_API_KEY", "")

preference_id = train_router(
    model_evals=model_train,
    prompt_column="prompt",
    response_column="actual",
    language="en",
    maximize=True,
    api_key=api_key,
    # Leave this commented out to train your first custom router
    # Uncomment this to retrain your custom router in place
    # preference_id=preference_id,
)
```

You can then follow the training process for your custom router via the Not Diamond app.




Once your custom router has finished training, you can use it to route your prompts.



```python
from notdiamond import NotDiamond

import weave

weave.init("notdiamond-quickstart")

llm_configs = [
    "anthropic/claude-3-5-sonnet-20240620",
    "openai/gpt-4o-2024-05-13",
    "google/gemini-1.5-pro-latest",
    "openai/gpt-4-turbo-2024-04-09",
    "anthropic/claude-3-opus-20240229",
]
client = NotDiamond(api_key=api_key, llm_configs=llm_configs)

new_prompt = (
    """
You are a helpful coding assistant. Using the provided function signature, write the implementation for the function
in Python. Write only the function. Do not include any other text.

from typing import List


def has_close_elements(numbers: List[float], threshold: float) -> bool:
    """
    """ Check if in given list of numbers, are any two numbers closer to each other than
    given threshold.
    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)
    False
    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)
    True
    """
    """
"""
)
session_id, routing_target_model = client.model_select(
    messages=[{"role": "user", "content": new_prompt}],
    preference_id=preference_id,
)

print(f"Session ID: {session_id}")
print(f"Target Model: {routing_target_model}")
```

This example also used Not Diamond's compatibility with Weave auto-tracing. You can see the results in the Weave UI.




## Evaluating your custom router

Once you have trained your custom router, you can evaluate either its

- in-sample performance by submitting the training prompts, or
- out-of-sample performance by submitting new or held-out prompts

Below, we submit the test set to the custom router to evaluate its performance.



```python
from weave.integrations.notdiamond.custom_router import evaluate_router

eval_prompt_column = "prompt"
eval_response_column = "actual"

best_provider_model, nd_model = evaluate_router(
    model_datasets=model_test,
    prompt_column=eval_prompt_column,
    response_column=eval_response_column,
    api_key=api_key,
    preference_id=preference_id,
)
```


```python
@weave.op()
def is_correct(score: int, output: dict) -> dict:
    # We hack score, since we already have model responses
    return {"correct": score}


best_provider_eval = weave.Evaluation(
    dataset=best_provider_model.model_results.to_dict(orient="records"),
    scorers=[is_correct],
)
await best_provider_eval.evaluate(best_provider_model)

nd_eval = weave.Evaluation(
    dataset=nd_model.model_results.to_dict(orient="records"), scorers=[is_correct]
)
await nd_eval.evaluate(nd_model)
```

In this instance, the Not Diamond "meta-model" routes prompts across several different models.

Training the custom router via Weave will also run evaluations and upload results to the Weave UI. Once the custom router process is completed, you can review the results in the Weave UI.

In the UI we see that the Not Diamond "meta-model" outperforms the best-performing model by routing prompts to other models with higher likelihood of answering the prompt accurately.

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/notdiamond_custom_routing)

<!--- Optional: Example Notebooks -->
<!--- Handling and Redacting PII -->

# Handling and Redacting PII

:::tip[This is a notebook] Open in Colab View in Github ::: # How to use Weave with PII data In this guide, you'll learn how to use W&B Weave while ensuring your Personally Identifiable Information (PII) data remains private. The guide demonstrates the following methods to identify, redact and anonymize PII data: 1. __Regular expressions__ to identify PII data and redact it. 2. __Microsoft's [Presidio](https://microsoft.github.io/presidio/)__, a python-based data protection SDK. This tool provides redaction and replacement functionalities. 3. __[Faker](https://faker.readthedocs.io/en/master/)__, a Python library to generate fake data, combined with Presidio to anonymize PII data. Additionally, you'll learn how to use _`weave.op` input/output logging customization_ and _`autopatch_settings`_ to integrate PII redaction and anonymization into the workflow. For more information, see [Customize logged inputs and outputs](https://weave-docs.wandb.ai/guides/tracking/ops/#customize-logged-inputs-and-outputs). To get started, do the following: 1. Review the [Overview](#overview) section. 2. Complete the [prerequisites](#prerequisites). 3. Review the [available methods](#redaction-methods-overview) for identifying, redacting and anonymizing PII data. 4. [Apply the methods to Weave calls](#apply-the-methods-to-weave-calls). ## Overview The following section provides an overview of input and output logging using `weave.op`, as well as best practices for working with PII data in Weave. ### Customize input and output logging using `weave.op` Weave Ops allow you to define input and output postprocessing functions. Using these functions, you can modify the data that is passed to your LLM call or logged to Weave. In the following example, two postprocessing functions are defined and passed as arguments to `weave.op()`. ```python from dataclasses import dataclass from typing import Any import weave # Inputs Wrapper Class @dataclass class CustomObject: x: int secret_password: str # First we define functions for input and output postprocessing: def postprocess_inputs(inputs: dict[str, Any]) -> dict[str, Any]: return {k:v for k,v in inputs.items() if k != "hide_me"} def postprocess_output(output: CustomObject) -> CustomObject: return CustomObject(x=output.x, secret_password="REDACTED") # Then, when we use the `@weave.op` decorator, we pass these processing functions as arguments to the decorator: @weave.op( postprocess_inputs=postprocess_inputs, postprocess_output=postprocess_output, ) def some_llm_call(a: int, hide_me: str) -> CustomObject: return CustomObject(x=a, secret_password=hide_me) ``` ### Best practices for using Weave with PII data Before using Weave with PII data, review the best practices for using Weave with PII data. #### During testing - Log anonymized data to check PII detection - Track PII handling processes with Weave Traces - Measure anonymization performance without exposing real PII #### In production - Never log raw PII - Encrypt sensitive fields before logging #### Encryption tips - Use reversible encryption for data you need to decrypt later - Apply one-way hashing for unique IDs you don't need to reverse - Consider specialized encryption for data you need to analyze while encrypted ## Prerequisites 1. First, install the required packages. ```python %%capture # @title required python packages: !pip install cryptography !pip install presidio_analyzer !pip install presidio_anonymizer !python -m spacy download en_core_web_lg # Presidio uses spacy NLP engine !pip install Faker # we'll use Faker to replace PII data with fake data !pip install weave # To leverage Traces !pip install set-env-colab-kaggle-dotenv -q # for env var !pip install anthropic # to use sonnet !pip install cryptography # to encrypt our data ``` 2. Set up your API keys. You can find your API keys at the following links. - [W&B](https://wandb.ai/authorize) - [Anthropic](https://console.anthropic.com/settings/keys). ```python %%capture # @title Make sure to set up set up your API keys correctly # See: https://pypi.org/project/set-env-colab-kaggle-dotenv/ for usage instructions. from set_env import set_env _ = set_env("ANTHROPIC_API_KEY") _ = set_env("WANDB_API_KEY") ``` 3. Initialize your Weave project. ```python import weave # Start a new Weave project WEAVE_PROJECT = "pii_cookbook" weave.init(WEAVE_PROJECT) ``` 4. Load the demo PII dataset, which contains 10 text blocks. ```python import requests url = "https://raw.githubusercontent.com/wandb/weave/master/docs/notebooks/10_pii_data.json" response = requests.get(url) pii_data = response.json() print('PII data first sample: "' + pii_data[0]["text"] + '"') ``` ## Redaction methods overview Once you've completed the [setup](#setup), you can To detect and protect our PII data, we'll identify and redact PII data and optionally anonymize it using the following methods: 1. __Regular expressions__ to identify PII data and redact it. 2. __Microsoft [Presidio](https://microsoft.github.io/presidio/)__, a Python-based data protection SDK that provides redaction and replacement functionality. 3. __[Faker](https://faker.readthedocs.io/en/master/)__, a Python library for generating fake data. ### Method 1: Filter using regular expressions [Regular expressions (regex)](https://docs.python.org/3/library/re.html) are the simplest method to identify and redact PII data. Regex allows you to define patterns that can match various formats of sensitive information like phone numbers, email addresses, and social security numbers. Using regex, you can scan through large volumes of text and replace or redact information without the need for more complex NLP techniques. ```python import re # Define a function to clean PII data using regex def redact_with_regex(text): # Phone number pattern # \b : Word boundary # \d{3} : Exactly 3 digits # [-.]? : Optional hyphen or dot # \d{3} : Another 3 digits # [-.]? : Optional hyphen or dot # \d{4} : Exactly 4 digits # \b : Word boundary text = re.sub(r"\b\d{3}[-.]?\d{3}[-.]?\d{4}\b", "", text) # Email pattern # \b : Word boundary # [A-Za-z0-9._%+-]+ : One or more characters that can be in an email username # @ : Literal @ symbol # [A-Za-z0-9.-]+ : One or more characters that can be in a domain name # \. : Literal dot # [A-Z|a-z]{2,} : Two or more uppercase or lowercase letters (TLD) # \b : Word boundary text = re.sub( r"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b", "", text ) # SSN pattern # \b : Word boundary # \d{3} : Exactly 3 digits # - : Literal hyphen # \d{2} : Exactly 2 digits # - : Literal hyphen # \d{4} : Exactly 4 digits # \b : Word boundary text = re.sub(r"\b\d{3}-\d{2}-\d{4}\b", "", text) # Simple name pattern (this is not comprehensive) # \b : Word boundary # [A-Z] : One uppercase letter # [a-z]+ : One or more lowercase letters # \s : One whitespace character # [A-Z] : One uppercase letter # [a-z]+ : One or more lowercase letters # \b : Word boundary text = re.sub(r"\b[A-Z][a-z]+ [A-Z][a-z]+\b", "", text) return text ``` Let's test the function with a sample text: ```python # Test the function test_text = "My name is John Doe, my email is john.doe@example.com, my phone is 123-456-7890, and my SSN is 123-45-6789." cleaned_text = redact_with_regex(test_text) print(f"Raw text:\n\t{test_text}") print(f"Redacted text:\n\t{cleaned_text}") ``` ### Method 2: Redact using Microsoft Presidio The next method involves complete removal of PII data using [Microsoft Presidio](https://microsoft.github.io/presidio/). Presidio redacts PII and replaces it with a placeholder representing the PII type. For example, Presidio replaces `Alex` in `"My name is Alex"` with ``. Presidio comes with a built-in support for [common entities](https://microsoft.github.io/presidio/supported_entities/). In the below example, we redact all entities that are a `PHONE_NUMBER`, `PERSON`, `LOCATION`, `EMAIL_ADDRESS` or `US_SSN`. The Presidio process is encapsulated in a function. ```python from presidio_analyzer import AnalyzerEngine from presidio_anonymizer import AnonymizerEngine # Set up the Analyzer, which loads an NLP module (spaCy model by default) and other PII recognizers. analyzer = AnalyzerEngine() # Set up the Anonymizer, which will use the analyzer results to anonymize the text. anonymizer = AnonymizerEngine() # Encapsulate the Presidio redaction process into a function def redact_with_presidio(text): # Analyze the text to identify PII data results = analyzer.analyze( text=text, entities=["PHONE_NUMBER", "PERSON", "LOCATION", "EMAIL_ADDRESS", "US_SSN"], language="en", ) # Anonymize the identified PII data anonymized_text = anonymizer.anonymize(text=text, analyzer_results=results) return anonymized_text.text ``` Let's test the function with a sample text: ```python text = "My phone number is 212-555-5555 and my name is alex" # Test the function anonymized_text = redact_with_presidio(text) print(f"Raw text:\n\t{text}") print(f"Redacted text:\n\t{anonymized_text}") ``` ### Method 3: Anonymize with replacement using Faker and Presidio Instead of redacting text, you can anonymize it by using MS Presidio to swap PII like names and phone numbers with fake data generated using the [Faker](https://faker.readthedocs.io/en/master/) Python library. For example, suppose you have the following data: `"My name is Raphael and I like to fish. My phone number is 212-555-5555"` Once the data has been processed using Presidio and Faker, it might look like: `"My name is Katherine Dixon and I like to fish. My phone number is 667.431.7379"` To effectively use Presidio and Faker together, we must supply references to our custom operators. These operators will direct Presidio to the Faker functions responsible for swapping PII with fake data. ```python from faker import Faker from presidio_anonymizer import AnonymizerEngine from presidio_anonymizer.entities import OperatorConfig fake = Faker() # Create faker functions (note that it has to receive a value) def fake_name(x): return fake.name() def fake_number(x): return fake.phone_number() # Create custom operator for the PERSON and PHONE_NUMBER" entities operators = { "PERSON": OperatorConfig("custom", {"lambda": fake_name}), "PHONE_NUMBER": OperatorConfig("custom", {"lambda": fake_number}), } text_to_anonymize = ( "My name is Raphael and I like to fish. My phone number is 212-555-5555" ) # Analyzer output analyzer_results = analyzer.analyze( text=text_to_anonymize, entities=["PHONE_NUMBER", "PERSON"], language="en" ) anonymizer = AnonymizerEngine() # do not forget to pass the operators from above to the anonymizer anonymized_results = anonymizer.anonymize( text=text_to_anonymize, analyzer_results=analyzer_results, operators=operators ) print(f"Raw text:\n\t{text_to_anonymize}") print(f"Anonymized text:\n\t{anonymized_results.text}") ``` Let's consolidate our code into a single class and expand the list of entities to include the additional ones identified earlier. ```python from faker import Faker from presidio_anonymizer import AnonymizerEngine from presidio_anonymizer.entities import OperatorConfig # A custom class for generating fake data that extends Faker class my_faker(Faker): # Create faker functions (note that it has to receive a value) def fake_address(x): return fake.address() def fake_ssn(x): return fake.ssn() def fake_name(x): return fake.name() def fake_number(x): return fake.phone_number() def fake_email(x): return fake.email() # Create custom operators for the entities operators = { "PERSON": OperatorConfig("custom", {"lambda": fake_name}), "PHONE_NUMBER": OperatorConfig("custom", {"lambda": fake_number}), "EMAIL_ADDRESS": OperatorConfig("custom", {"lambda": fake_email}), "LOCATION": OperatorConfig("custom", {"lambda": fake_address}), "US_SSN": OperatorConfig("custom", {"lambda": fake_ssn}), } def redact_and_anonymize_with_faker(self, text): anonymizer = AnonymizerEngine() analyzer_results = analyzer.analyze( text=text, entities=["PHONE_NUMBER", "PERSON", "LOCATION", "EMAIL_ADDRESS", "US_SSN"], language="en", ) anonymized_results = anonymizer.anonymize( text=text, analyzer_results=analyzer_results, operators=self.operators ) return anonymized_results.text ``` Let's test the function with a sample text: ```python faker = my_faker() text_to_anonymize = ( "My name is Raphael and I like to fish. My phone number is 212-555-5555" ) anonymized_text = faker.redact_and_anonymize_with_faker(text_to_anonymize) print(f"Raw text:\n\t{text_to_anonymize}") print(f"Anonymized text:\n\t{anonymized_text}") ``` ### Method 4: Use `autopatch_settings` You can use `autopatch_settings` to configure PII handling directly during initialization for one or more of the supported LLM integrations. The advantages of this method are: 1. PII handling logic is centralized and scoped at initialization, reducing the need for scattered custom logic. 2. PII processing workflows can be customized or disabled entirely for specific intergations. To use `autopatch_settings` to configure PII handling, define `postprocess_inputs` and/or `postprocess_output` in `op_settings` for any one of the supported LLM integrations. ```python def postprocess(inputs: dict) -> dict: if "SENSITIVE_KEY" in inputs: inputs["SENSITIVE_KEY"] = "REDACTED" return inputs client = weave.init( ..., autopatch_settings={ "openai": { "op_settings": { "postprocess_inputs": postprocess, "postprocess_output": ..., } }, "anthropic": { "op_settings": { "postprocess_inputs": ..., "postprocess_output": ..., } } }, ) ``` ## Apply the methods to Weave calls In the following examples, we will integrate our PII redaction and anonymization methods into Weave Models and preview the results in Weave Traces. First, we'll create a [Weave Model](https://wandb.github.io/weave/guides/core-types/models). A Weave Model is a combination of information like configuration settings, model weights, and code that defines how the model operates. In our model, we will include our predict function where the Anthropic API will be called. Anthropic's Claude Sonnet is used to perform sentiment analysis while tracing LLM calls using [Traces](https://wandb.github.io/weave/quickstart). Claude Sonnet will receive a block of text and output one of the following sentiment classifications: _positive_, _negative_, or _neutral_. Additionally, we will include our postprocessing functions to ensure that our PII data is redacted or anonymized before it is sent to the LLM. Once you run this code, you will receive a links to the Weave project page, as well as the specific trace (LLM calls) you ran. ### Regex method In the simplest case, we can use regex to identify and redact PII data from the original text. ```python import json from typing import Any import anthropic import weave # Define an input postprocessing function that applies our regex redaction for the model prediction Weave Op def postprocess_inputs_regex(inputs: dict[str, Any]) -> dict: inputs["text_block"] = redact_with_regex(inputs["text_block"]) return inputs # Weave model / predict function class sentiment_analysis_regex_pii_model(weave.Model): model_name: str system_prompt: str temperature: int @weave.op(

> Content truncated.

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/pii)

<!--- Optional: Example Notebooks -->
<!--- Prompt Optimization -->

# Prompt Optimization

:::tip[This is a notebook]

Open in Colab

View in Github

:::





# Optimizing LLM Workflows Using DSPy and Weave

The [BIG-bench (Beyond the Imitation Game Benchmark)](https://github.com/google/BIG-bench) is a collaborative benchmark intended to probe large language models and extrapolate their future capabilities consisting of more than 200 tasks. The [BIG-Bench Hard (BBH)](https://github.com/suzgunmirac/BIG-Bench-Hard) is a suite of 23 most challenging BIG-Bench tasks that can be quite difficult to be solved using the current generation of language models.

This tutorial demonstrates how we can improve the performance of our LLM workflow implemented  on the **causal judgement task** from the BIG-bench Hard benchmark and evaluate our prompting strategies. We will use [DSPy](https://dspy-docs.vercel.app/) for implementing our LLM workflow and optimizing our prompting strategy. We will also use [Weave](../../introduction.md) to track our LLM workflow and evaluate our prompting strategies.

## Installing the Dependencies

We need the following libraries for this tutorial:

- [DSPy](https://dspy-docs.vercel.app/) for building the LLM workflow and optimizing it.
- [Weave](../../introduction.md) to track our LLM workflow and evaluate our prompting strategies.
- [datasets](https://huggingface.co/docs/datasets/index) to access the Big-Bench Hard dataset from HuggingFace Hub.


```python
!pip install -qU dspy-ai weave datasets
```

Since we'll be using [OpenAI API](https://openai.com/index/openai-api/) as the LLM Vendor, we will also need an OpenAI API key. You can [sign up](https://platform.openai.com/signup) on the OpenAI platform to get your own API key.


```python
import os
from getpass import getpass

api_key = getpass("Enter you OpenAI API key: ")
os.environ["OPENAI_API_KEY"] = api_key
```

## Enable Tracking using Weave

Weave is currently integrated with DSPy, and including [`weave.init`](../../reference/python-sdk/weave/index.md) at the start of our code lets us automatically trace our DSPy functions which can be explored in the Weave UI. Check out the [Weave integration docs for DSPy](../../guides/integrations/dspy.md) to learn more.



```python
import weave

weave.init(project_name="dspy-bigbench-hard")
```

In this tutorial, we use a metadata class inherited from [`weave.Object`](../../guides/tracking/objects.md) to manage our metadata.


```python
class Metadata(weave.Object):
    dataset_address: str = "maveriq/bigbenchhard"
    big_bench_hard_task: str = "causal_judgement"
    num_train_examples: int = 50
    openai_model: str = "gpt-3.5-turbo"
    openai_max_tokens: int = 2048
    max_bootstrapped_demos: int = 8
    max_labeled_demos: int = 8


metadata = Metadata()
```

:::tip Object Versioning
The `Metadata` objects are automatically versioned and traced when functions consuming them are traced
:::

## Load the BIG-Bench Hard Dataset

We will load this dataset from HuggingFace Hub, split into training and validation sets, and [publish](../../guides/core-types/datasets.md) them on Weave, this will let us version the datasets, and also use [`weave.Evaluation`](../../guides/core-types/evaluations.md) to evaluate our prompting strategy.


```python
import dspy
from datasets import load_dataset


@weave.op()
def get_dataset(metadata: Metadata):
    # load the BIG-Bench Hard dataset corresponding to the task from Huggingface Hug
    dataset = load_dataset(metadata.dataset_address, metadata.big_bench_hard_task)[
        "train"
    ]

    # create the training and validation datasets
    rows = [{"question": data["input"], "answer": data["target"]} for data in dataset]
    train_rows = rows[0 : metadata.num_train_examples]
    val_rows = rows[metadata.num_train_examples :]

    # create the training and validation examples consisting of `dspy.Example` objects
    dspy_train_examples = [
        dspy.Example(row).with_inputs("question") for row in train_rows
    ]
    dspy_val_examples = [dspy.Example(row).with_inputs("question") for row in val_rows]

    # publish the datasets to the Weave, this would let us version the data and use for evaluation
    weave.publish(
        weave.Dataset(
            name=f"bigbenchhard_{metadata.big_bench_hard_task}_train", rows=train_rows
        )
    )
    weave.publish(
        weave.Dataset(
            name=f"bigbenchhard_{metadata.big_bench_hard_task}_val", rows=val_rows
        )
    )

    return dspy_train_examples, dspy_val_examples


dspy_train_examples, dspy_val_examples = get_dataset(metadata)
```



## The DSPy Program

[DSPy](https://dspy-docs.vercel.app) is a framework that pushes building new LM pipelines away from manipulating free-form strings and closer to programming (composing modular operators to build text transformation graphs) where a compiler automatically generates optimized LM invocation strategies and prompts from a program.

We will use the [`dspy.OpenAI`](https://dspy-docs.vercel.app/api/language_model_clients/OpenAI) abstraction to make LLM calls to [GPT3.5 Turbo](https://platform.openai.com/docs/models/gpt-3-5-turbo).


```python
system_prompt = """
You are an expert in the field of causal reasoning. You are to analyze the a given question carefully and answer in `Yes` or `No`.
You should also provide a detailed explanation justifying your answer.
"""

llm = dspy.OpenAI(model="gpt-3.5-turbo", system_prompt=system_prompt)
dspy.settings.configure(lm=llm)
```

### Writing the Causal Reasoning Signature

A [signature](https://dspy-docs.vercel.app/docs/building-blocks/signatures) is a declarative specification of input/output behavior of a [DSPy module](https://dspy-docs.vercel.app/docs/building-blocks/modules) which are task-adaptive components—akin to neural network layers—that abstract any particular text transformation.


```python
from pydantic import BaseModel, Field


class Input(BaseModel):
    query: str = Field(description="The question to be answered")


class Output(BaseModel):
    answer: str = Field(description="The answer for the question")
    confidence: float = Field(
        ge=0, le=1, description="The confidence score for the answer"
    )
    explanation: str = Field(description="The explanation for the answer")


class QuestionAnswerSignature(dspy.Signature):
    input: Input = dspy.InputField()
    output: Output = dspy.OutputField()


class CausalReasoningModule(dspy.Module):
    def __init__(self):
        self.prog = dspy.TypedPredictor(QuestionAnswerSignature)

    @weave.op()
    def forward(self, question) -> dict:
        return self.prog(input=Input(query=question)).output.dict()
```

Let's test our LLM workflow, i.e., the `CausalReasoningModule` on an example from the causal reasoning subset of Big-Bench Hard.


```python
import rich

baseline_module = CausalReasoningModule()

prediction = baseline_module(dspy_train_examples[0]["question"])
rich.print(prediction)
```



## Evaluating our DSPy Program

Now that we have a baseline prompting strategy, let's evaluate it on our validation set using [`weave.Evaluation`](../../guides/core-types/evaluations.md) on a simple metric that matches the predicted answer with the ground truth. Weave will take each example, pass it through your application and score the output on multiple custom scoring functions. By doing this, you'll have a view of the performance of your application, and a rich UI to drill into individual outputs and scores.

First, we need to create a simple weave evaluation scoring function that tells whether the answer from the baseline module's output is the same as the ground truth answer or not. Scoring functions need to have a `model_output` keyword argument, but the other arguments are user defined and are taken from the dataset examples. It will only take the necessary keys by using a dictionary key based on the argument name.


```python
@weave.op()
def weave_evaluation_scorer(answer: str, output: Output) -> dict:
    return {"match": int(answer.lower() == output["answer"].lower())}
```

Next, we can simply define the evaluation and run it.


```python
validation_dataset = weave.ref(
    f"bigbenchhard_{metadata.big_bench_hard_task}_val:v0"
).get()

evaluation = weave.Evaluation(
    name="baseline_causal_reasoning_module",
    dataset=validation_dataset,
    scorers=[weave_evaluation_scorer],
)

await evaluation.evaluate(baseline_module.forward)
```



> 💡 **Note**: If you're running from a python script, you can use the following code to run the evaluation:

```python
import asyncio
asyncio.run(evaluation.evaluate(baseline_module.forward))
```

:::warning
Running the evaluation causal reasoning dataset will cost approximately $0.24 in OpenAI credits.
:::

## Optimizing our DSPy Program

Now, that we have a baseline DSPy program, let us try to improve its performance for causal reasoning using a [DSPy teleprompter](https://dspy-docs.vercel.app/docs/building-blocks/optimizers) that can tune the parameters of a DSPy program to maximize the specified metrics. In this tutorial, we use the [BootstrapFewShot](https://dspy-docs.vercel.app/api/category/optimizers) teleprompter.


```python
from dspy.teleprompt import BootstrapFewShot


@weave.op()
def get_optimized_program(model: dspy.Module, metadata: Metadata) -> dspy.Module:
    @weave.op()
    def dspy_evaluation_metric(true, prediction, trace=None):
        return prediction["answer"].lower() == true.answer.lower()

    teleprompter = BootstrapFewShot(
        metric=dspy_evaluation_metric,
        max_bootstrapped_demos=metadata.max_bootstrapped_demos,
        max_labeled_demos=metadata.max_labeled_demos,
    )
    return teleprompter.compile(model, trainset=dspy_train_examples)


optimized_module = get_optimized_program(baseline_module, metadata)
```



:::warning
Running the evaluation causal reasoning dataset will cost approximately $0.04 in OpenAI credits.
:::

Now that we have our optimized program (the optimized prompting strategy), let's evaluate it once again on our validation set and compare it with our baseline DSPy program.


```python
evaluation = weave.Evaluation(
    name="optimized_causal_reasoning_module",
    dataset=validation_dataset,
    scorers=[weave_evaluation_scorer],
)

await evaluation.evaluate(optimized_module.forward)
```



When coomparing the evalution of the baseline program with the optimized one shows that the optimized program answers the causal reasoning questions with siginificantly more accuracy.

## Conclusion

In this tutorial, we learned how to use DSPy for prompt optimization alongside using Weave for tracking and evaluation to compare the original and optimized programs.

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/dspy_prompt_optimization)

<!--- Optional: Example Notebooks -->
<!--- Code Generation -->

# Code Generation

:::tip[This is a notebook]

Open in Colab

View in Github

:::



# Code Generation using Weave and OpenAI

Generating high-quality code with proper structure, documentation, and tests is a challenging task. This guide demonstrates how to implement a code generation pipeline. You'll learn to create a code generation pipeline that produces high-quality Python functions against the humaneval test suite.

We'll use Weave for evaluation comparison and tracking, and OpenAI's GPT models for code generation using structured outputs.



## Video Demonstration

For a visual demonstration of the code generation pipeline using Weave, Groq, and E2B check out this video:



This video provides a step-by-step walkthrough of the process, showcasing how Weave integrates with Groq to create a powerful code generation tool and then running the code in E2B, to validate the code. We use OpenAI in the following example, but you can use any LLM provider with Weave.

## Why use Weave?

In this tutorial, we'll use Weave to implement and evaluate a code generation pipeline. You'll learn how to:

1. **Track your LLM pipeline**: Log inputs, outputs, and intermediate steps of your code generation process.
2. **Evaluate LLM outputs**: Create and compare evaluations of your generated code with rich debugging tools and visualizations.

## Set up the environment

First, let's set up our environment and import the necessary libraries:


```python
!pip install -qU autopep8 autoflake weave isort openai set-env-colab-kaggle-dotenv datasets
```


```python
%%capture
# Temporary workaround to fix bug in openai:
# TypeError: Client.__init__() got an unexpected keyword argument 'proxies'
# See https://community.openai.com/t/error-with-openai-1-56-0-client-init-got-an-unexpected-keyword-argument-proxies/1040332/15
!pip install "httpx<0.28"
```


```python
import ast
import os
import re
import subprocess
import tempfile
import traceback

import autopep8
import isort
from autoflake import fix_code
from datasets import load_dataset
from openai import OpenAI
from pydantic import BaseModel
from set_env import set_env

import weave
from weave import Dataset, Evaluation

set_env("WANDB_API_KEY")
set_env("OPENAI_API_KEY")
```


```python
WEAVE_PROJECT = "codegen-cookbook-example"
weave.init(WEAVE_PROJECT)
```


```python
client = OpenAI()
```


```python
human_eval = load_dataset("openai_humaneval")
selected_examples = human_eval["test"][:3]
```

> 💡 **Note**: Weave automatically tracks OpenAI API calls, including inputs, outputs, and metadata. This means you don't need to add any additional logging code for your OpenAI interactions – Weave handles it seamlessly in the background.

## Leveraging Structured Outputs and Pydantic Models

In this code generation pipeline, we utilize OpenAI's [structured outputs mode](https://platform.openai.com/docs/guides/structured-outputs) and Pydantic models to ensure consistent and well-formatted responses from the language model. This approach offers several advantages:


1. **Type Safety**: By defining Pydantic models for our expected outputs, we enforce a strict structure for the generated code, program runners, and unit tests.
2. **Easier Parsing**: The structured output mode allows us to directly parse the model's response into our predefined Pydantic models, reducing the need for complex post-processing.
3. **Improved Reliability**: By specifying the exact format we expect, we reduce the likelihood of unexpected or malformed outputs from the language model.

Here's an example of how we define our Pydantic models and use them with OpenAI's structured outputs:


```python
class GeneratedCode(BaseModel):
    function_signature: str
    function_args_with_docstring_within_triple_quotes: str
    code_logic: str


class FormattedGeneratedCode(BaseModel):
    full_code: str
```

## Implementing a Code Formatter

To ensure consistent and clean code output, we implement a `CodeFormatter` class using Weave operations. This formatter applies various linting and styling rules to the generated code, program runner, and unit tests.


```python
class CodeFormatter(BaseModel):
    @weave.op()
    def lint_code(self, code: str) -> str:
        # Replace escaped newlines with actual newlines
        code = code.replace("\\n", "\n")

        # Remove unused imports and variables
        code = fix_code(
            code, remove_all_unused_imports=True, remove_unused_variables=True
        )

        # Sort imports
        code = isort.code(code)

        # Apply PEP 8 formatting
        code = autopep8.fix_code(code, options={"aggressive": 2})

        return code

    @weave.op()
    def add_imports(self, code: str) -> str:
        tree = ast.parse(code)
        from_imports = {}
        global_names = set()

        for node in ast.walk(tree):
            if isinstance(node, ast.Name):
                if node.id not in dir(__builtins__):
                    global_names.add(node.id)

        # Only add typing imports that are actually used
        typing_imports = global_names.intersection(
            {"List", "Dict", "Tuple", "Set", "Optional", "Union"}
        )
        if typing_imports:
            from_imports["typing"] = typing_imports

        # Remove names that are defined within the function
        function_def = next(
            node for node in tree.body if isinstance(node, ast.FunctionDef)
        )
        local_names = {arg.arg for arg in function_def.args.args}
        local_names.update(
            node.id
            for node in ast.walk(function_def)
            if isinstance(node, ast.Name) and isinstance(node.ctx, ast.Store)
        )

        global_names -= local_names
        global_names -= {"sorted"}  # Remove built-in functions

        # Construct the import statements
        import_statements = []
        for module, names in from_imports.items():
            names_str = ", ".join(sorted(names))
            import_statements.append(f"from {module} import {names_str}")

        return (
            "\n".join(import_statements) + ("\n\n" if import_statements else "") + code
        )

    @weave.op()
    def format_generated_code(
        self, generated_code: GeneratedCode
    ) -> FormattedGeneratedCode:
        # Combine the code parts
        full_code = f"{generated_code.function_signature}\n{generated_code.function_args_with_docstring_within_triple_quotes}\n{generated_code.code_logic}"

        # Ensure proper indentation
        lines = full_code.split("\n")
        indented_lines = []
        for i, line in enumerate(lines):
            if i == 0:  # Function signature
                indented_lines.append(line)
            elif i == 1:  # Function arguments (docstring)
                indented_lines.append("    " + line)
            else:  # Function body
                indented_lines.append("    " + line)
        full_code = "\n".join(indented_lines)

        # Lint the code
        full_code = self.lint_code(full_code)

        # Add imports
        cleaned_code = self.add_imports(full_code)

        return FormattedGeneratedCode(full_code=cleaned_code)
```

This `CodeFormatter` class provides several Weave operations to clean and format the generated code:
   - Replacing escaped newlines with actual newlines
   - Removing unused imports and variables
   - Sorting imports
   - Applying PEP 8 formatting
   - Adding missing imports

## Define the CodeGenerationPipeline



Now, let's implement the core code generation logic:

We're using a `weave.Model` so that it's automatically versioned when it changes. We're also keeping the `model_name` as an attribute so that we can experiment with it and easily diff & compare it in Weave. We're tracking our function calls with `@weave.op` so the inputs & outputs are logged to help with error tracking and debugging. 


```python
class CodeGenerationPipeline(weave.Model):
    model_name: str
    formatter: CodeFormatter

    def __init__(
        self, model_name: str = "gpt-4o", formatter: CodeFormatter = CodeFormatter()
    ):
        super().__init__(model_name=model_name, formatter=formatter)
        self.model_name = model_name
        self.formatter = formatter

    @weave.op()
    async def predict(self, prompt: str):
        generated_code = self.generate_code(prompt)
        formatted_generated_code = self.formatter.format_generated_code(generated_code)

        return formatted_generated_code.full_code

    @weave.op()
    def generate_code(self, prompt: str) -> GeneratedCode:
        completion = client.beta.chat.completions.parse(
            model=self.model_name,
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert Python code generator.",
                },
                {"role": "user", "content": prompt},
            ],
            response_format=GeneratedCode,
        )
        message = completion.choices[0].message
        if message.parsed:
            return message.parsed
        else:
            raise ValueError(message.refusal)
```

This `CodeGenerationPipeline` class encapsulates our code generation logic as a Weave Model, providing several key benefits:

1. Automatic experiment tracking: Weave captures inputs, outputs, and parameters for each run of the model.
2. Versioning: Changes to the model's attributes or code are automatically versioned, creating a clear history of how your code generation pipeline evolves over time.
3. Reproducibility: The versioning and tracking make it easy to reproduce any previous result or configuration of your code generation pipeline.
4. Hyperparameter management: Model attributes (like `model_name`) are clearly defined and tracked across different runs, facilitating experimentation.
5. Integration with Weave ecosystem: Using `weave.Model` allows seamless integration with other Weave tools, such as evaluations and serving capabilities.

## Implement evaluation metrics

To assess the quality of our generated code, we'll implement simple evaluation metrics using a `weave.Scorer` subclass. This will run `score` on every `model_output` from our dataset. `model_output` comes from the output of the `predict` function in our `weave.Model`. `prompt` is taken from our dataset `human-eval`.


```python
CODE_TEMPLATE = """
{model_output}

{test}

if __name__ == "__main__":
    check({entry_point})
"""
```


```python
@weave.op()
async def score_humaneval_test(test: str, entry_point: str, output: str):
    generated_code = output

    # Extract test cases from the test string
    test_cases = re.findall(r"assert.*", test)
    test_cases_str = "\n            ".join(test_cases)

    # Generate the full source code
    full_code = CODE_TEMPLATE.format(
        model_output=generated_code,
        test=test,
        test_cases=test_cases_str,
        entry_point=entry_point,
    )

    # Create a temporary file to store the code
    with tempfile.NamedTemporaryFile(delete=False, suffix=".py") as tmp_file:
        # Write the generated code to the temporary file
        tmp_file.write(full_code.encode())
        tmp_file_path = tmp_file.name

    try:
        # Run the temporary Python file as a subprocess with a timeout
        result = subprocess.run(
            ["python", tmp_file_path],
            capture_output=True,
            text=True,
            timeout=10,  # Timeout of 10 seconds
        )

        print(result)

        if result.returncode == 0:
            return {"correct": True}
        else:
            return {"correct": False, "error": result.stderr, "output": result.stdout}
    except subprocess.TimeoutExpired:
        return {"correct": False, "error": "TimeoutExpired"}
    except Exception as e:
        return {"correct": False, "error": traceback.format_exc()}
    finally:
        # Ensure the temporary file is removed after execution
        os.remove(tmp_file_path)
```

These evaluation functions run the generated code and return a boolean value indicating whether the code passed the test provided from the dataset.



## Create a Weave Dataset and run evaluation

To evaluate our pipeline, we'll create a Weave Dataset and run an evaluation:


```python
formatted_selected_examples = [
    {
        "task_id": task_id,
        "prompt": prompt,
        "canonical_solution": solution,
        "test": test,
        "entry_point": entry_point,
    }
    for task_id, prompt, solution, test, entry_point in zip(
        selected_examples["task_id"],
        selected_examples["prompt"],
        selected_examples["canonical_solution"],
        selected_examples["test"],
        selected_examples["entry_point"],
    )
]
```


```python
prompt_dataset = Dataset(
    name="humaneval_code_gen_example",
    rows=[
        {
            "prompt": example["prompt"],
            "test": example["test"],
            "entry_point": example["entry_point"],
        }
        for example in formatted_selected_examples
    ],
)
weave.publish(prompt_dataset)
```


```python
EVAL_RUN = True
```


```python
for model_name in ["gpt-4o-2024-08-06"]:
    pipeline = CodeGenerationPipeline(model_name=model_name)
    if not EVAL_RUN:
        dataset = prompt_dataset.rows[2]
        result = await pipeline.predict(dataset["prompt"])
        score_result = await score_humaneval_test(
            dataset["test"], dataset["entry_point"], result["generated_code"].full_code
        )
    else:
        evaluation = Evaluation(
            name="minimal_code_gen_evaluation",
            dataset=prompt_dataset,
            scorers=[score_humaneval_test],
        )
        results = await evaluation.evaluate(pipeline)
```

This code creates a dataset with our sample prompts, defines our humaneval test scorer, and runs an evaluation of our code generation pipeline.



## Conclusion

In this example, we've demonstrated how to implement a code generation pipeline using Weave and OpenAI's language models. We've shown how to:

1. Create Weave operations for each step of the code generation process
2. Wrap the pipeline in a Weave Model for easy tracking and evaluation
3. Implement custom evaluation metrics using Weave operations
4. Create a dataset and run an evaluation of the pipeline

Weave's seamless integration allows us to track inputs, outputs, and intermediate steps throughout the code generation process, making it easier to debug, optimize, and evaluate our LLM application.

For more information on Weave and its capabilities, check out the [Weave documentation](https://docs.wandb.ai/weave). You can extend this example to handle larger datasets, implement more sophisticated evaluation metrics, or integrate with other LLM workflows.

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/codegen)

<!--- Optional: Example Notebooks -->
<!--- Models And Weave Integration Demo -->

# Models And Weave Integration Demo

:::tip[This is a notebook]

Open in Colab

View in Github

:::


# Use Weave with W&B Models

This notebook demonstrates how to use W&B Weave with [W&B Models](https://docs.wandb.ai/guides/) using the scenario of two different teams working on an end-to-end implementation of a Retrieval-Augmented Generation (RAG) application, from fine-tuning the model to building an app around the model. Specifically, the Model Team fine-tunes a new Chat Model (Llama 3.2),and saves it to the [W&B Models Registry](https://docs.wandb.ai/guides/registry/). Then, the App Team retrieves the fine-tuned Chat Model from the Registry, and uses Weave to create and evaluate a RAG chatbot application

The guide walks you through the following steps, which are the same steps that the teams in the described scenario would follow:

1. Downloading a fine-tuned Llama 3.2 model registered in [W&B Models Registry](https://docs.wandb.ai/guides/registry/)
2. Implementing a RAG application using the fine-tuned Llama 3.2 model 
3. Tracking and evaluating the RAG application using Weave
4. Registering the improved RAG app to Registry

Find the public workspace for both W&B Models and W&B Weave [here](https://wandb.ai/wandb-smle/weave-cookboook-demo/weave/evaluations).








## Prerequisites

First, install the necessary libraries, set up API keys, log in to W&B, and create a new W&B project.

1. Install `weave`, `pandas`, `unsloth`, `wandb`, `litellm`, `pydantic`, `torch`, and `faiss-gpu` using `pip`.


```python
%%capture
!pip install weave wandb pandas pydantic litellm faiss-gpu
```


```python
%%capture
!pip install unsloth
# Also get the latest nightly Unsloth!
!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
```

2. Add the necessary API keys from your environment.


```python
import os

from google.colab import userdata

os.environ["WANDB_API_KEY"] = userdata.get("WANDB_API_KEY")  # W&B Models and Weave
os.environ["OPENAI_API_KEY"] = userdata.get(
    "OPENAI_API_KEY"
)  # OpenAI - for retrieval embeddings
os.environ["GEMINI_API_KEY"] = userdata.get(
    "GEMINI_API_KEY"
)  # Gemini - for the base chat model
```

3. Log in to W&B, and create a new project.


```python
import pandas as pd
import wandb

import weave

wandb.login()

PROJECT = "weave-cookboook-demo"
ENTITY = "wandb-smle"

weave.init(ENTITY + "/" + PROJECT)
```

##  Download `ChatModel` from Models Registry and implement `UnslothLoRAChatModel`

In our scenario, the Llama-3.2 model has already been fine-tuned by the Model Team using the `unsloth` library for performance optimization, and is [available in the W&B Models Registry](https://wandb.ai/wandb-smle/weave-cookboook-demo/weave/object-versions?filter=%7B%22objectName%22%3A%22RagModel%22%7D&peekPath=%2Fwandb-smle%2Fweave-rag-experiments%2Fobjects%2FChatModelRag%2Fversions%2F2mhdPb667uoFlXStXtZ0MuYoxPaiAXj3KyLS1kYRi84%3F%26). In this step, we'll retrieve the fine-tuned [`ChatModel`](https://wandb.ai/wandb-smle/weave-cookboook-demo/weave/object-versions?filter=%7B%22objectName%22%3A%22RagModel%22%7D&peekPath=%2Fwandb-smle%2Fweave-rag-experiments%2Fobjects%2FChatModelRag%2Fversions%2F2mhdPb667uoFlXStXtZ0MuYoxPaiAXj3KyLS1kYRi84%3F%26) from the Registry and convert it into a `weave.Model` to make it compatible with the [`RagModel`](https://wandb.ai/wandb-smle/weave-cookboook-demo/weave/object-versions?filter=%7B%22objectName%22%3A%22RagModel%22%7D&peekPath=%2Fwandb-smle%2Fweave-cookboook-demo%2Fobjects%2FRagModel%2Fversions%2FcqRaGKcxutBWXyM0fCGTR1Yk2mISLsNari4wlGTwERo%3F%26). 

> 🚨 **Important**: The `RagModel` referenced below is a top-level `weave.Model` that can be considered a complete RAG Application. It contains a `ChatModel`, vector database, and a prompt. The `ChatModel` is also a `weave.Model`, which contains code to download an artifact from the W&B Registry. `ChatModel` can be changed modularly to support any kind of other LLM chat model as part of the `RagModel`. For more information, [view the model in Weave](https://wandb.ai/wandb-smle/weave-cookboook-demo/weave/evaluations?peekPath=%2Fwandb-smle%2Fweave-cookboook-demo%2Fobjects%2FRagModel%2Fversions%2Fx7MzcgHDrGXYHHDQ9BA8N89qDwcGkdSdpxH30ubm8ZM%3F%26).

To load the `ChatModel`, `unsloth.FastLanguageModel` or `peft.AutoPeftModelForCausalLM` with adapters are used, enabling efficient integration into the app. After downloading the model from the Registry, you can set up the initialization and prediction logic by using the `model_post_init` method. The required code for this step is available in the **Use** tab of the Registry and can be copied directly into your implementation

The code below defines the `UnslothLoRAChatModel` class to manage, initialize, and use the fine-tuned Llama-3.2 model retrieved from the W&B Models Registry. `UnslothLoRAChatModel` uses `unsloth.FastLanguageModel` for optimized inference. The `model_post_init` method handles downloading and setting up the model, while the `predict` method processes user queries and generates responses. To adapt the code for your use case, update the `MODEL_REG_URL` with the correct Registry path for your fine-tuned model and adjust parameters like `max_seq_length` or `dtype` based on your hardware or requirements.



```python
from typing import Any

from pydantic import PrivateAttr
from unsloth import FastLanguageModel

import weave


class UnslothLoRAChatModel(weave.Model):
    """
    We define an extra ChatModel class to be able store and version more parameters than just the model name.
    Especially, relevant if we consider fine-tuning (locally or aaS) because of specific parameters.
    """

    chat_model: str
    cm_temperature: float
    cm_max_new_tokens: int
    cm_quantize: bool
    inference_batch_size: int
    dtype: Any
    device: str
    _model: Any = PrivateAttr()
    _tokenizer: Any = PrivateAttr()

    def model_post_init(self, __context):
        # we can simply paste this from the "Use" tab from the registry
        run = wandb.init(project=PROJECT, job_type="model_download")
        artifact = run.use_artifact(f"{self.chat_model}")
        model_path = artifact.download()

        # unsloth version (enable native 2x faster inference)
        self._model, self._tokenizer = FastLanguageModel.from_pretrained(
            model_name=model_path,
            max_seq_length=self.cm_max_new_tokens,
            dtype=self.dtype,
            load_in_4bit=self.cm_quantize,
        )
        FastLanguageModel.for_inference(self._model)

    @weave.op()
    async def predict(self, query: list[str]) -> dict:
        # add_generation_prompt = true - Must add for generation
        input_ids = self._tokenizer.apply_chat_template(
            query,
            tokenize=True,
            add_generation_prompt=True,
            return_tensors="pt",
        ).to("cuda")

        output_ids = self._model.generate(
            input_ids=input_ids,
            max_new_tokens=64,
            use_cache=True,
            temperature=1.5,
            min_p=0.1,
        )

        decoded_outputs = self._tokenizer.batch_decode(
            output_ids[0][input_ids.shape[1] :], skip_special_tokens=True
        )

        return "".join(decoded_outputs).strip()
```


```python
MODEL_REG_URL = "wandb32/wandb-registry-RAG Chat Models/Finetuned Llama-3.2:v3"

max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!
dtype = (
    None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+
)
load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.

new_chat_model = UnslothLoRAChatModel(
    name="UnslothLoRAChatModelRag",
    chat_model=MODEL_REG_URL,
    cm_temperature=1.0,
    cm_max_new_tokens=max_seq_length,
    cm_quantize=load_in_4bit,
    inference_batch_size=max_seq_length,
    dtype=dtype,
    device="auto",
)
```


```python
await new_chat_model.predict(
    [{"role": "user", "content": "What is the capital of Germany?"}]
)
```

## Integrate the new `ChatModel` version into `RagModel`

Building a RAG application from a fine-tuned chat model improves conversational AI by using tailored components without having to rebuild the entire pipeline. In this step, we retrieve the existing `RagModel` from our Weave project and update its `ChatModel` to use the newly fine-tuned model. This seamless swap means that other components like the vector database (VDB) and prompts remain untouched, preserving the application's overall structure while improving performance.

The code below retrieves the `RagModel` object using a reference from the Weave project. The `chat_model` attribute of the `RagModel` is then updated to use the new `UnslothLoRAChatModel` instance created in the previous step. After this, the updated `RagModel` is published to create a new version. Finally, the updated `RagModel` is used to run a sample prediction query, verifying that the new chat model is being used. 



```python
RagModel = weave.ref(
    "weave:///wandb-smle/weave-cookboook-demo/object/RagModel:cqRaGKcxutBWXyM0fCGTR1Yk2mISLsNari4wlGTwERo"
).get()
```


```python
RagModel.chat_model.chat_model
```


```python
await RagModel.predict("When was the first conference on climate change?")
```


```python
# MAGIC: exchange chat_model and publish new version (no need to worry about other RAG components)
RagModel.chat_model = new_chat_model
```


```python
RagModel.chat_model.chat_model
```


```python
# first publish new version so that in prediction we reference new version
PUB_REFERENCE = weave.publish(RagModel, "RagModel")
```


```python
await RagModel.predict("When was the first conference on climate change?")
```

## Run a `weave.Evaluation` 

In the next step, we evaluate the performance of our updated `RagModel` using an existing `weave.Evaluation`. This process ensures that the new fine-tuned chat model is performing as expected within the RAG application. To streamline integration and enable collaboration between the Models and Apps teams, we log evaluation results for both the model's W&B run and as part of the Weave workspace.

In Models:
- The evaluation summary is logged to the W&B run used to download the fine-tuned chat model. This includes summary metrics and graphs displayed in a [workspace view](https://wandb.ai/wandb-smle/weave-cookboook-demo/workspace?nw=eglm8z7o9) for analysis.
- The evaluation trace ID is added to the run's configuration, linking directly to the Weave page for easier traceability by the Model Team.

In Weave:
- The artifact or registry link for the `ChatModel` is stored as an input to the `RagModel`.
- The W&B run ID is saved as an extra column in the evaluation traces for better context.

The code below demonstrates how to retrieve an evaluation object, execute the evaluation using the updated `RagModel`, and log the results to both W&B and Weave. Ensure that the evaluation reference (`WEAVE_EVAL`) matches your project setup. 



```python
# MAGIC: we can simply get an evaluation with a eval dataset and scorers and use them
WEAVE_EVAL = "weave:///wandb-smle/weave-cookboook-demo/object/climate_rag_eval:ntRX6qn3Tx6w3UEVZXdhIh1BWGh7uXcQpOQnIuvnSgo"
climate_rag_eval = weave.ref(WEAVE_EVAL).get()
```


```python
with weave.attributes({"wandb-run-id": wandb.run.id}):
    # use .call attribute to retrieve both the result and the call in order to save eval trace to Models
    summary, call = await climate_rag_eval.evaluate.call(climate_rag_eval, RagModel)
```


```python
# log to models
wandb.run.log(pd.json_normalize(summary, sep="/").to_dict(orient="records")[0])
wandb.run.config.update(
    {"weave_url": f"https://wandb.ai/wandb-smle/weave-cookboook-demo/r/call/{call.id}"}
)
wandb.run.finish()
```

## Save the new RAG Model to the Registry

To make the updated `RagModel` available for future use by both the Models and Apps teams, we push it to the W&B Models Registry as a reference artifact.

The code below retrieves the `weave` object version and name for the updated `RagModel` and uses them to create reference links. A new artifact is then created in W&B with metadata containing the model's Weave URL. This artifact is logged to the W&B Registry and linked to a designated registry path.

Before running the code, ensure the `ENTITY` and `PROJECT` variables match your W&B setup, and the target registry path is correctly specified. This process finalizes the workflow by publishing the new `RagModel` to the W&B ecosystem for easy collaboration and reuse.



```python
MODELS_OBJECT_VERSION = PUB_REFERENCE.digest  # weave object version
MODELS_OBJECT_NAME = PUB_REFERENCE.name  # weave object name
```


```python
models_url = f"https://wandb.ai/{ENTITY}/{PROJECT}/weave/objects/{MODELS_OBJECT_NAME}/versions/{MODELS_OBJECT_VERSION}"
models_link = (
    f"weave:///{ENTITY}/{PROJECT}/object/{MODELS_OBJECT_NAME}:{MODELS_OBJECT_VERSION}"
)

with wandb.init(project=PROJECT, entity=ENTITY) as run:
    # create new Artifact
    artifact_model = wandb.Artifact(
        name="RagModel",
        type="model",
        description="Models Link from RagModel in Weave",
        metadata={"url": models_url},
    )
    artifact_model.add_reference(models_link, name="model", checksum=False)

    # log new artifact
    run.log_artifact(artifact_model, aliases=[MODELS_OBJECT_VERSION])

    # link to registry
    run.link_artifact(
        artifact_model, target_path="wandb32/wandb-registry-RAG Models/RAG Model"
    )
```

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/Models_and_Weave_Integration_Demo)

<!--- Optional: Example Notebooks -->
<!--- Introduction Notebook -->

# Introduction Notebook

:::tip[This is a notebook]

Open in Colab

View in Github

:::





# 🏃‍♀️ Quickstart

Get started using Weave to:
- Log and debug language model inputs, outputs, and traces
- Build rigorous, apples-to-apples evaluations for language model use cases
- Organize all the information generated across the LLM workflow, from experimentation to evaluations to production

See the full Weave documentation [here](https://wandb.me/weave).


## 🪄 Install `weave` library and login


Start by installing the library and logging in to your account.

In this example, we're using openai so you should [add an openai API key](https://platform.openai.com/docs/quickstart/step-2-setup-your-api-key).



```python
%%capture
!pip install weave openai set-env-colab-kaggle-dotenv
```


```python
# Set your OpenAI API key
from set_env import set_env

# Put your OPENAI_API_KEY in the secrets panel to the left 🗝️
_ = set_env("OPENAI_API_KEY")
# os.environ["OPENAI_API_KEY"] = "sk-..." # alternatively, put your key here

PROJECT = "weave-intro-notebook"
```

# Track inputs & outputs of functions

Weave allows users to track function calls: the code, inputs, outputs, and even LLM tokens & costs! In the following sections we will cover:

* Custom Functions
* Vendor Integrations
* Nested Function Calling
* Error Tracking

Note: in all cases, we will:

```python
import weave                    # import the weave library
weave.init('project-name')      # initialize tracking for a specific W&B project
```

## Track custom functions

Add the @weave.op decorator to the functions you want to track




```python
from openai import OpenAI

import weave

weave.init(PROJECT)

client = OpenAI()
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {
            "role": "system",
            "content": "You are a grammar checker, correct the following user input.",
        },
        {"role": "user", "content": "That was so easy, it was a piece of pie!"},
    ],
    temperature=0,
)
generation = response.choices[0].message.content
print(generation)
```

You can find your interactive dashboard by clicking any of the  👆 wandb links above.

## Vendor Integrations (OpenAI, Anthropic, Mistral, etc...)

Here, we're automatically tracking all calls to `openai`. We automatically track a lot of LLM libraries, but it's really easy to add support for whatever LLM you're using, as you'll see below. 




```python
import weave

weave.init(PROJECT)


@weave.op()
def strip_user_input(user_input):
    return user_input.strip()


result = strip_user_input("    hello    ")
print(result)
```

After adding `weave.op` and calling the function, visit the link and see it tracked within your project.

💡 We automatically track your code, have a look at the code tab!

## Track nested functions

Now that you've seen the basics, let's combine all of the above and track some deeply nested functions alongside LLM calls.






```python
from openai import OpenAI

import weave

weave.init(PROJECT)


@weave.op()
def strip_user_input(user_input):
    return user_input.strip()


@weave.op()
def correct_grammar(user_input):
    client = OpenAI()

    stripped = strip_user_input(user_input)
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": "You are a grammar checker, correct the following user input.",
            },
            {"role": "user", "content": stripped},
        ],
        temperature=0,
    )
    return response.choices[0].message.content


result = correct_grammar("   That was so easy, it was a piece of pie!    ")
print(result)
```

## Track Errors

Whenever your code crashes, weave will highlight what caused the issue. This is especially useful for finding things like JSON parsing issues that can occasionally happen when parsing data from LLM responses.




```python
import json

from openai import OpenAI

import weave

weave.init(PROJECT)


@weave.op()
def strip_user_input(user_input):
    return user_input.strip()


@weave.op()
def correct_grammar(user_input):
    client = OpenAI()

    stripped = strip_user_input(user_input)
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": "You are a grammar checker, correct the following user input.",
            },
            {"role": "user", "content": stripped},
        ],
        temperature=0,
        response_format={"type": "json_object"},
    )
    return json.loads(response.choices[0].message.content)


result = correct_grammar("   That was so easy, it was a piece of pie!    ")
print(result)
```

# Tracking Objects

Organizing experimentation is difficult when there are many moving pieces. You can capture and organize the experimental details of your app like your system prompt or the model you're using within `weave.Objects`. This helps organize and compare different iterations of your app. In this section, we will cover:

* General Object Tracking
* Tracking Models
* Tracking Datasets

## General Object Tracking

Many times, it is useful to track & version data, just like you track and version code. For example, here we define a `SystemPrompt(weave.Object)` object that can be shared between teammates




```python
import weave

weave.init(PROJECT)


class SystemPrompt(weave.Object):
    prompt: str


system_prompt = SystemPrompt(
    prompt="You are a grammar checker, correct the following user input."
)
weave.publish(system_prompt)
```

## Model Tracking

Models are so common of an object type, that we have a special class to represent them: `weave.Model`. The only requirement is that we define a `predict` method.




```python
from openai import OpenAI

import weave

weave.init(PROJECT)


class OpenAIGrammarCorrector(weave.Model):
    # Properties are entirely user-defined
    openai_model_name: str
    system_message: str

    @weave.op()
    def predict(self, user_input):
        client = OpenAI()
        response = client.chat.completions.create(
            model=self.openai_model_name,
            messages=[
                {"role": "system", "content": self.system_message},
                {"role": "user", "content": user_input},
            ],
            temperature=0,
        )
        return response.choices[0].message.content


corrector = OpenAIGrammarCorrector(
    openai_model_name="gpt-4o-mini",
    system_message="You are a grammar checker, correct the following user input.",
)

result = corrector.predict("     That was so easy, it was a piece of pie!       ")
print(result)
```

## Dataset Tracking

Similar to models, a `weave.Dataset` object exists to help track, organize, and operate on datasets




```python
dataset = weave.Dataset(
    name="grammar-correction",
    rows=[
        {
            "user_input": "   That was so easy, it was a piece of pie!   ",
            "expected": "That was so easy, it was a piece of cake!",
        },
        {"user_input": "  I write good   ", "expected": "I write well"},
        {
            "user_input": "  GPT-4 is smartest AI model.   ",
            "expected": "GPT-4 is the smartest AI model.",
        },
    ],
)

weave.publish(dataset)
```

Notice that we saved a versioned `GrammarCorrector` object that captures the configurations you're experimenting with.

## Retrieve Published Objects & Ops

You can publish objects and then retrieve them in your code. You can even call functions from your retrieved objects!




```python
import weave

weave.init(PROJECT)

corrector = OpenAIGrammarCorrector(
    openai_model_name="gpt-4o-mini",
    system_message="You are a grammar checker, correct the following user input.",
)

ref = weave.publish(corrector)
print(ref.uri())
```




```python
import weave

weave.init(PROJECT)

# Note: this url is available from the UI after publishing the object!
ref_url = f"weave:///{ref.entity}/{PROJECT}/object/{ref.name}:{ref.digest}"
fetched_collector = weave.ref(ref_url).get()

# Notice: this object was loaded from remote location!
result = fetched_collector.predict("That was so easy, it was a piece of pie!")

print(result)
```

# Evaluation

Evaluation-driven development helps you reliably iterate on an application. The `Evaluation` class is designed to assess the performance of a `Model` on a given `Dataset` or set of examples using scoring functions.

See a preview of the API below:




```python
import weave
from weave import Evaluation


# Define any custom scoring function
@weave.op()
def exact_match(expected: str, output: dict) -> dict:
    # Here is where you'd define the logic to score the model output
    return {"match": expected == output}


# Score your examples using scoring functions
evaluation = Evaluation(
    dataset=dataset,  # can be a list of dictionaries or a weave.Dataset object
    scorers=[exact_match],  # can be a list of scoring functions
)

# Start tracking the evaluation
weave.init(PROJECT)
# Run the evaluation
summary = await evaluation.evaluate(corrector)  # can be a model or simple function
```

## What's next?

Follow the [Build an Evaluation pipeline](http://wandb.me/weave_eval_tut) tutorial to learn more about Evaluation and begin iteratively improving your applications.

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/01-intro_notebook)

<!--- Optional: Example Notebooks -->
<!--- Integrating with Weave - Production Dashboard -->

# Integrating with Weave - Production Dashboard

:::tip[This is a notebook]

Open in Colab

View in Github

:::






# Integrating with Weave: Production Dashboard

The GenAI tooling landscape is rapidly evolving - new frameworks, tools, and applications are emerging all the time. Weave aims to be a one-stop-shop for all your GenAI monitoring and evaluation needs. This also means that sometimes it is necessary to integrate with existing platforms or extend Weave to fit the specific needs of your project or organization.

In this cookbook, we'll demonstrate how to leverage Weave's powerful APIs and functions to create a custom dashboard for production monitoring as an extension to the Traces view in Weave. We'll focus on:

- Fetching traces, costs, feedback, and other metrics from Weave
- Creating aggregate views for user feedback and cost distribution
- Creating visualizations for token usage and latency over time

You can try out the dashboard with your own Weave project by installing streamlit and running [this production dashboard script](https://github.com/NiWaRe/agent-dev-collection)!





# 1. Setup

To follow along this tutorial you'll only need to install the following packages:



```python
!pip install streamlit pandas plotly weave
```

# 2. Implementation


## 2.1 Initializing Weave Client and Defining Costs

First, we'll set up a function to initialize the Weave client and add costs for each model.

- We have included the standard costs for many standard models but we also make it easy to add your own custom costs and custom models. In the following we'll show how to add custom costs for a few models and use the standard costs for the rest.
- The costs are calculate based on the tracked tokens for each call in Weave. For many LLM vendor libraries, we will automatically track the token usage, but it is also possible to return custom token counts for any call. See this cookbook on how to define the token count and cost calculation for a custom model - [custom cost cookbook](https://weave-docs.wandb.ai/reference/gen_notebooks/custom_model_cost#setting-up-a-model-with-weave).



```python
PROJECT_NAME = "wandb-smle/weave-cookboook-demo"
```


```python
import weave

MODEL_NAMES = [
    # model name, prompt cost, completion cost
    ("gpt-4o-2024-05-13", 0.03, 0.06),
    ("gpt-4o-mini-2024-07-18", 0.03, 0.06),
    ("gemini/gemini-1.5-flash", 0.00025, 0.0005),
    ("gpt-4o-mini", 0.03, 0.06),
    ("gpt-4-turbo", 0.03, 0.06),
    ("claude-3-haiku-20240307", 0.01, 0.03),
    ("gpt-4o", 0.03, 0.06),
]


def init_weave_client(project_name):
    try:
        client = weave.init(project_name)
        for model, prompt_cost, completion_cost in MODEL_NAMES:
            client.add_cost(
                llm_id=model,
                prompt_token_cost=prompt_cost,
                completion_token_cost=completion_cost,
            )
    except Exception as e:
        print(f"Failed to initialize Weave client for project '{project_name}': {e}")
        return None
    else:
        return client


client = init_weave_client(PROJECT_NAME)
```

## 2.2 Fetching Calls Data from Weave

In order to fetch call data from Weave, we have two options:

1. Fetching Data call-by-call
2. Using high-level APIs

### 2.2.1 Fetching Data call-by-call

The first option to access data from Weave is to retrieve a list of filtered calls and extract the wanted data call-by-call. For that we can use the `calls_query_stream` API to fetch the calls data from Weave:

- `calls_query_stream` API: This API allows us to fetch the calls data from Weave.
- `filter` dictionary: This dictionary contains the filter parameters to fetch the calls data - see [here](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace_server/weave.trace_server.trace_server_interface/#class-callschema) for more details.
- `expand_columns` list: This list contains the columns to expand in the calls data.
- `sort_by` list: This list contains the sorting parameters for the calls data.
- `include_costs` boolean: This boolean indicates whether to include the costs in the calls data.
- `include_feedback` boolean: This boolean indicates whether to include the feedback in the calls data.



```python
import itertools
from datetime import datetime, timedelta

import pandas as pd


def fetch_calls(client, project_id, start_time, trace_roots_only, limit):
    filter_params = {
        "project_id": project_id,
        "filter": {"started_at": start_time, "trace_roots_only": trace_roots_only},
        "expand_columns": ["inputs.example", "inputs.model"],
        "sort_by": [{"field": "started_at", "direction": "desc"}],
        "include_costs": True,
        "include_feedback": True,
    }
    try:
        calls_stream = client.server.calls_query_stream(filter_params)
        calls = list(
            itertools.islice(calls_stream, limit)
        )  # limit the number of calls to fetch if too many
        print(f"Fetched {len(calls)} calls.")
    except Exception as e:
        print(f"Error fetching calls: {e}")
        return []
    else:
        return calls


calls = fetch_calls(client, PROJECT_NAME, datetime.now() - timedelta(days=1), True, 100)
```


```python
# the raw data is a list of Call objects
pd.DataFrame([call.dict() for call in calls]).head(3)
```

Processing the calls is very easy with the return from Weave - we'll extract the relevant information and store it in a list of dictionaries. We'll then convert the list of dictionaries to a pandas DataFrame and return it.



```python
import json
from datetime import datetime

import pandas as pd


def process_calls(calls):
    records = []
    for call in calls:
        feedback = call.summary.get("weave", {}).get("feedback", [])
        thumbs_up = sum(
            1
            for item in feedback
            if isinstance(item, dict) and item.get("payload", {}).get("emoji") == "👍"
        )
        thumbs_down = sum(
            1
            for item in feedback
            if isinstance(item, dict) and item.get("payload", {}).get("emoji") == "👎"
        )
        latency = call.summary.get("weave", {}).get("latency_ms", 0)

        records.append(
            {
                "Call ID": call.id,
                "Trace ID": call.trace_id,  # this is a unique ID for the trace that can be used to retrieve it
                "Display Name": call.display_name,  # this is an optional name you can set in the UI or programatically
                "Latency (ms)": latency,
                "Thumbs Up": thumbs_up,
                "Thumbs Down": thumbs_down,
                "Started At": pd.to_datetime(getattr(call, "started_at", datetime.min)),
                "Inputs": json.dumps(call.inputs, default=str),
                "Outputs": json.dumps(call.output, default=str),
            }
        )
    return pd.DataFrame(records)
```


```python
df_calls = process_calls(calls)
df_calls.head(3)
```

### 2.2.2 Using high-level APIs

Instead of goin through every call Weave also provides high-level APIs to directly access model costs, feedback, and other metrics.
For example, for the cost, we'll use the `query_costs` API to fetch the costs of all used LLMs using in project:



```python
# Use cost API to get costs
costs = client.query_costs()
df_costs = pd.DataFrame([cost.dict() for cost in costs])
df_costs["total_cost"] = (
    df_costs["prompt_token_cost"] + df_costs["completion_token_cost"]
)

# only show the first row for every unqiue llm_id
df_costs
```

## 2.4 Gathering inputs and generating visualizations

Next, we can generate the visualizations using plotly. This is the most basic dashboard, but you can customize it as you like! For a more complex example, check out a Streamlit example [here](https://github.com/NiWaRe/knowledge-worker-weave/blob/master/prod_dashboard.py).



```python
import plotly.express as px
import plotly.graph_objects as go


def plot_feedback_pie_chart(thumbs_up, thumbs_down):
    fig = go.Figure(
        data=[
            go.Pie(
                labels=["Thumbs Up", "Thumbs Down"],
                values=[thumbs_up, thumbs_down],
                marker={"colors": ["#66b3ff", "#ff9999"]},
                hole=0.3,
            )
        ]
    )
    fig.update_traces(textinfo="percent+label", hoverinfo="label+percent")
    fig.update_layout(showlegend=False, title="Feedback Summary")
    return fig


def plot_model_cost_distribution(df):
    fig = px.bar(
        df,
        x="llm_id",
        y="total_cost",
        color="llm_id",
        title="Cost Distribution by Model",
    )
    fig.update_layout(xaxis_title="Model", yaxis_title="Cost (USD)")
    return fig


# See the source code for all the plots
```


```python
plot_feedback_pie_chart(df_calls["Thumbs Up"].sum(), df_calls["Thumbs Down"].sum())
```


```python
plot_model_cost_distribution(df_costs)
```

# Conclusion

In this cookbook, we demonstrated how to create a custom production monitoring dashboard using Weave's APIs and functions. Weave currently focuses on fast integrations for easy input of data as well as extraction of the data for custom processes.

- **Data Input:**
  - Framework-agnostic tracing with [@weave-op()](https://weave-docs.wandb.ai/quickstart#2-log-a-trace-to-a-new-project) decorator and the possibility to import calls from CSV (see related [import cookbook](https://weave-docs.wandb.ai/reference/gen_notebooks/import_from_csv))
  - Service API endpoints to log to Weave from for various programming frameworks and languages, see [here](https://weave-docs.wandb.ai/reference/service-api/call-start-call-start-post) for more details.
- **Data Output:**
  - Easy download of the data in CSV, TSV, JSONL, JSON formats - see [here](https://weave-docs.wandb.ai/guides/tracking/tracing#querying--exporting-calls) for more details.
  - Easy export using programmatic access to the data - see "Use Python" section in the export panel as described in this cookbook. See [here](https://weave-docs.wandb.ai/guides/tracking/tracing#querying--exporting-calls) for more details.

This custom dashboard extends Weave's native Traces view, allowing for tailored monitoring of LLM applications in production. If you're interested in viewing a more complex dashboard, check out a Streamlit example where you can add your own Weave project URL [in this repo](https://github.com/NiWaRe/agent-dev-collection).

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/online_monitoring)

<!--- Optional: Example Notebooks -->
<!--- Using HuggingFace Datasets in evaluations with `preprocess_model_input` -->

# Using HuggingFace Datasets in evaluations with `preprocess_model_input`

:::tip[This is a notebook]

Open in Colab

View in Github

:::



# Using HuggingFace Datasets in evaluations with `preprocess_model_input`

## Note: This is a temporary workaround
> This guide demonstrates a workaround for using HuggingFace Datasets with Weave evaluations.
We are actively working on developing more seamless integrations that will simplify this process.\
> While this approach works, expect improvements and updates in the near future that will make working with external datasets more straightforward.

## Setup and imports
First, we initialize Weave and connect to Weights & Biases for tracking experiments.


```python
!pip install datasets wandb weave
```


```python
# Initialize variables
HUGGINGFACE_DATASET = "wandb/ragbench-test-sample"
WANDB_KEY = ""
WEAVE_TEAM = ""
WEAVE_PROJECT = ""

# Init weave and required libraries
import asyncio

import nest_asyncio
import wandb
from datasets import load_dataset

import weave
from weave import Evaluation

# Login to wandb and initialize weave
wandb.login(key=WANDB_KEY)
client = weave.init(f"{WEAVE_TEAM}/{WEAVE_PROJECT}")

# Apply nest_asyncio to allow nested event loops (needed for some notebook environments)
nest_asyncio.apply()
```

## Load and prepare HuggingFace dataset

- We load a HuggingFace dataset.
- Create an index mapping to reference the dataset rows.
- This index approach allows us to maintain references to the original dataset.

> **Note:**
In the index, we encode the `hf_hub_name` along with the `hf_id` to ensure each row has a unique identifier.\
This unique digest value is used for tracking and referencing specific dataset entries during evaluations.


```python
# Load the HuggingFace dataset
ds = load_dataset(HUGGINGFACE_DATASET)
row_count = ds["train"].num_rows

# Create an index mapping for the dataset
# This creates a list of dictionaries with HF dataset indices
# Example: [{"hf_id": 0}, {"hf_id": 1}, {"hf_id": 2}, ...]
hf_index = [{"hf_id": i, "hf_hub_name": HUGGINGFACE_DATASET} for i in range(row_count)]
```

## Define processing and evaluation functions

### Processing pipeline
- `preprocess_example`: Transforms the index reference into the actual data needed for evaluation
- `hf_eval`: Defines how to score the model outputs
- `function_to_evaluate`: The actual function/model being evaluated


```python
@weave.op()
def preprocess_example(example):
    """
    Preprocesses each example before evaluation.
    Args:
        example: Dict containing hf_id
    Returns:
        Dict containing the prompt from the HF dataset
    """
    hf_row = ds["train"][example["hf_id"]]
    return {"prompt": hf_row["question"], "answer": hf_row["response"]}


@weave.op()
def hf_eval(hf_id: int, output: dict) -> dict:
    """
    Scoring function for evaluating model outputs.
    Args:
        hf_id: Index in the HF dataset
        output: The output from the model to evaluate
    Returns:
        Dict containing evaluation scores
    """
    hf_row = ds["train"][hf_id]
    return {"scorer_value": True}


@weave.op()
def function_to_evaluate(prompt: str):
    """
    The function that will be evaluated (e.g., your model or pipeline).
    Args:
        prompt: Input prompt from the dataset
    Returns:
        Dict containing model output
    """
    return {"generated_text": "testing "}
```

### Create and run evaluation

- For each index in hf_index:
  1. `preprocess_example` gets the corresponding data from the HF dataset.
  2. The preprocessed data is passed to `function_to_evaluate`.
  3. The output is scored using `hf_eval`.
  4. Results are tracked in Weave.


```python
# Create evaluation object
evaluation = Evaluation(
    dataset=hf_index,  # Use our index mapping
    scorers=[hf_eval],  # List of scoring functions
    preprocess_model_input=preprocess_example,  # Function to prepare inputs
)


# Run evaluation asynchronously
async def main():
    await evaluation.evaluate(function_to_evaluate)


asyncio.run(main())
```

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/hf_dataset_evals)

<!--- Optional: Example Notebooks -->
<!--- Log Calls from Existing CSV -->

# Log Calls from Existing CSV

:::tip[This is a notebook]

Open in Colab

View in Github

:::





# Import Traces from 3rd Party Systems

In ocassion, it is not possible to instrument your Python or Javascript code with Weave's simple integration to obtain real-time traces of your GenAI application. It is often the case that these traces are later on available to you in `csv` or `json` format.

In this cookbook we explore the lower level Weave Python API to extract data from a CSV file and import it into Weave to drive insights and rigorous evaluations.

The sample dataset assumed in this cookbook has the following structure:

```
conversation_id,turn_index,start_time,user_input,ground_truth,answer_text
1234,1,2024-09-04 13:05:39,This is the beginning, ['This was the beginning'], That was the beginning
1235,1,2024-09-04 13:02:11,This is another trace,, That was another trace
1235,2,2024-09-04 13:04:19,This is the next turn,, That was the next turn
1236,1,2024-09-04 13:02:10,This is a 3 turn conversation,, Woah thats a lot of turns
1236,2,2024-09-04 13:02:30,This is the second turn, ['That was definitely the second turn'], You are correct
1236,3,2024-09-04 13:02:53,This is the end,, Well good riddance!

```

To understand the decisions for import in this cookbook, one should know that Weave traces have parent-child relationships that are 1:Many and continuous. Meaning a single parent may have multiple children, but that parent may itself be a children of another parent.

We therefore use `conversation_id` as the parent identifier, and the `turn_index` as the child identifier to provide us complete conversation logging.


Ensure to modify the variables as needed.

# Set up the environment

We install and import all needed packages.
We set `WANDB_API_KEY` in our env so that we may easily login with `wandb.login()` (this should be given to the colab as a secret).

We set the name of the file we upload to colab in `name_of_file` and set the project in W&B we want to log this into in `name_of_wandb_project`.

**_NOTE:_** `name_of_wandb_project` may also be in the format of `{team_name}/{project_name}` to specify a team to log the traces into.

We then fetch a weave client by calling `weave.init()`


```python
%pip install wandb weave pandas datetime --quiet
```


```python
import os

import pandas as pd
import wandb
from google.colab import userdata

import weave

## Write samples file to disk
with open("/content/import_cookbook_data.csv", "w") as f:
    f.write(
        "conversation_id,turn_index,start_time,user_input,ground_truth,answer_text\n"
    )
    f.write(
        '1234,1,2024-09-04 13:05:39,This is the beginning, ["This was the beginning"], That was the beginning\n'
    )
    f.write(
        "1235,1,2024-09-04 13:02:11,This is another trace,, That was another trace\n"
    )
    f.write(
        "1235,2,2024-09-04 13:04:19,This is the next turn,, That was the next turn\n"
    )
    f.write(
        "1236,1,2024-09-04 13:02:10,This is a 3 turn conversation,, Woah thats a lot of turns\n"
    )
    f.write(
        '1236,2,2024-09-04 13:02:30,This is the second turn, ["That was definitely the second turn"], You are correct\n'
    )
    f.write("1236,3,2024-09-04 13:02:53,This is the end,, Well good riddance!\n")


os.environ["WANDB_API_KEY"] = userdata.get("WANDB_API_KEY")
name_of_file = "/content/import_cookbook_data.csv"
name_of_wandb_project = "import-weave-traces-cookbook"

wandb.login()
```


```python
weave_client = weave.init(name_of_wandb_project)
```

# Data Loading

We load the data into a Pandas dataframe, and ensure we sort it by the `conversation_id` and `turn_index` to ensure the parents and childs are correctly ordered.

This will result in a two column pandas DF with our conversation turns as an array under `conversation_data`.


```python
## Load data and shape it
df = pd.read_csv(name_of_file)

sorted_df = df.sort_values(["conversation_id", "turn_index"])


# Function to create an array of dictionaries for each conversation
def create_conversation_dict_array(group):
    return group.drop("conversation_id", axis=1).to_dict("records")


# Group the dataframe by conversation_id and apply the aggregation
result_df = (
    sorted_df.groupby("conversation_id")
    .apply(create_conversation_dict_array)
    .reset_index()
)
result_df.columns = ["conversation_id", "conversation_data"]

# Show how our aggregation looks
result_df.head()
```

# Log the Traces to Weave

We now iterate through our pandas DF:
- We create a parent call for every `conversation_id`
- We iterate through the turn array to create child calls sorted by their `turn_index`

Important concepts of the lower level python API:
- A Weave call is equivalent to a Weave trace, this call may have a parent or children associated with it
- A Weave call may have other things associated with it: Feedback, Metadata, etc. We only associate inputs and outputs to it here, but you may want to add these things in your import if the data provides it.
- A weave call is `created` and `finished` as these are meant to be tracked real time. Because this is an after-the-fact import, we create and finish once our objects are defined and tied to one another.
- The `op` value of a call is how Weave categorizes calls of the same make up. In this example, all parent calls are of `Conversation` type, and all children calls are of `Turn` type. You may modify this as you see fit.
- A call may have `inputs` and `output`. `inputs` are defined at creation an `output` is defined when the call is finished.


```python
# Log traces to weave

# Iterate through our aggregated conversations
for _, row in result_df.iterrows():
    # Define our conversation parent,
    # we are now creating a "call" with the weave_client we defined before
    parent_call = weave_client.create_call(
        # The Op value will register this as a Weave Op, which will allow us to retrieve these as a group easily in the future
        op="Conversation",
        # We set the inputs of our high level conversation as all the turns under it
        inputs={
            "conversation_data": row["conversation_data"][:-1]
            if len(row["conversation_data"]) > 1
            else row["conversation_data"]
        },
        # Our Conversation parent does not have a further parent
        parent=None,
        # The name of how this specific conversation will appear in the UI
        display_name=f"conversation-{row['conversation_id']}",
    )

    # We set the output of the parent to be the last trace in the conversation
    parent_output = row["conversation_data"][len(row["conversation_data"]) - 1]

    # We now iterate through all the conversation turns for the parent
    # and log them as children of the conversation
    for item in row["conversation_data"]:
        item_id = f"{row['conversation_id']}-{item['turn_index']}"

        # We create a call again here to be categorized under the conversation
        call = weave_client.create_call(
            # We qualify a single conversation trace as a "Turn"
            op="Turn",
            # We provide all inputs of the turn, including RAG 'ground_truth'
            inputs={
                "turn_index": item["turn_index"],
                "start_time": item["start_time"],
                "user_input": item["user_input"],
                "ground_truth": item["ground_truth"],
            },
            # We set this to be a child of the parent we defined
            parent=parent_call,
            # We provide it a name to be id'ed by in Weave
            display_name=item_id,
        )

        # We set the output of the call as the answer
        output = {
            "answer_text": item["answer_text"],
        }

        # Because these are traces that already happened, we finish the single turn call
        weave_client.finish_call(call=call, output=output)
    # Now that we have logged all its children, we also finish the parent call
    weave_client.finish_call(call=parent_call, output=parent_output)
```

# Result: Traces are Logged to Weave

Traces:




Operations:



# Bonus: Export your traces to run rigorous evaluations!

Once our traces are in Weave and we have an understanding on how the conversations are looking, we may want to later on export them to another process to run Weave Evaluations



To do this, we fetch all conversations from W&B through our simple query API and create a dataset from it.


```python
## This cell does not run by default, comment the below line to execute this script
%%script false --no-raise-error
## Get all Conversation traces for evaluation and prepare dataset for eval

# We create a query filter that brings us all our Conversation objects
# The ref shown below is specific to your project, and you can obtain it by
# going into your project's Operations in the UI, clicking on the "Conversations"
# object, then the "Use" tab in the side panel.
weave_ref_for_conversation_op = "weave:///wandb-smle/import-weave-traces-cookbook/op/Conversation:tzUhDyzVm5bqQsuqh5RT4axEXSosyLIYZn9zbRyenaw"
filter = weave.trace_server.trace_server_interface.CallsFilter(
    op_names=[weave_ref_for_conversation_op],
  )

# We execute the query
conversation_traces = weave_client.get_calls(filter=filter)

rows = []

# We go through our conversation traces and construct dataset rows from it
for single_conv in conversation_traces:
  # In this example, we may only care for conversations that utilized our RAG
  # pipeline, so we filter for such types of conversations
  is_rag = False
  for single_trace in single_conv.inputs['conversation_data']:
    if single_trace['ground_truth'] is not None:
      is_rag = True
      break
  if single_conv.output['ground_truth'] is not None:
      is_rag = True

  # Once we've identified a converation to have used RAG, we add it to our dataset
  if is_rag:
    inputs = []
    ground_truths = []
    answers = []

    # We go through every turn in the conversation
    for turn in single_conv.inputs['conversation_data']:
      inputs.append(turn.get('user_input', ''))
      ground_truths.append(turn.get('ground_truth', ''))
      answers.append(turn.get('answer_text', ''))
    ## Account for when conversations are a single turn
    if len(single_conv.inputs) != 1 or single_conv.inputs['conversation_data'][0].get('turn_index') != single_conv.output.get('turn_index'):
      inputs.append(single_conv.output.get('user_input', ''))
      ground_truths.append(single_conv.output.get('ground_truth', ''))
      answers.append(single_conv.output.get('answer_text', ''))

    data = {
        'question': inputs,
        'contexts': ground_truths,
        'answer': answers
    }

    rows.append(data)

# With our dataset rows created, we create the Dataset object and
# publish it back to Weave for later retrieval
dset = weave.Dataset(name = "conv_traces_for_eval", rows=rows)
weave.publish(dset)
```

# Result



To learn more about evaluations, check out our [Quickstart](https://weave-docs.wandb.ai/tutorial-rag) on using your newly created dataset to evaluate your RAG application!

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/import_from_csv)

<!--- Optional: Example Notebooks -->
<!--- Structured Outputs for Multi-Agent Systems -->

# Structured Outputs for Multi-Agent Systems

:::tip[This is a notebook] Open in Colab View in Github ::: # Structured Outputs for Multi-Agent Systems OpenAI relased [Structured Outputs](https://openai.com/index/introducing-structured-outputs-in-the-api/) to enable users to ensure the model will always generate responses that adhere to your supplied JSON Schema without strongly worded prompts. With Structured Outputs, we don't need to validate or retry incorrectly formatted responses. By using the new parameter `strict: true`, we are able to guarantee the response abides by a provided schema. The use of structured outputs in a multi-agent system enhances communication by ensuring consistent, easily processed data between agents. It also improves safety by allowing explicit refusals and boosts performance by eliminating the need for retries or validations. This simplifies interactions and increases overall system efficiency. This tutorial demonstrates how we can utilize structured outputs in multi-agent system and trace them with [Weave](https://weave-docs.wandb.ai/). :::tip [Source](https://cookbook.openai.com/examples/structured_outputs_multi_agent) This cookbook is based on [sample code from OpenAI's structured outputs](https://cookbook.openai.com/examples/structured_outputs_multi_agent), with some modifications added for improved visualization using Weave. ::: ## Installing the Dependencies We need the following libraries for this tutorial: - [OpenAI](https://openai.com/index/openai-api/) to create multi-agent system. - [Weave](../../introduction.md) to track our LLM workflow and evaluate our prompting strategies. ```python !pip install -qU openai weave wandb ``` ```python %%capture # Temporary workaround to fix bug in openai: # TypeError: Client.__init__() got an unexpected keyword argument 'proxies' # See https://community.openai.com/t/error-with-openai-1-56-0-client-init-got-an-unexpected-keyword-argument-proxies/1040332/15 !pip install "httpx<0.28" ``` We set `WANDB_API_KEY` in our env so that we may easily login with wandb.login() (this should be given to the colab as a secret). We set the project in W&B we want to log this into in `name_of_wandb_project`. **NOTE**: `name_of_wandb_project` may also be in the format of `{team_name}/{project_name}` to specify a team to log the traces into. We then fetch a weave client by calling weave.init() Since we'll be using [OpenAI API](https://openai.com/index/openai-api/), we will also need an OpenAI API key. You can [sign up](https://platform.openai.com/signup) on the OpenAI platform to get your own API key. (this should be given to the colab as a secret too.) ```python import base64 import json import os from io import BytesIO, StringIO import matplotlib.pyplot as plt import numpy as np import pandas as pd import wandb from google.colab import userdata from openai import OpenAI import weave ``` ```python os.environ["WANDB_API_KEY"] = userdata.get("WANDB_API_KEY") os.environ["OPENAI_API_KEY"] = userdata.get("OPENAI_API_KEY") wandb.login() name_of_wandb_project = "multi-agent-structured-output" weave.init(name_of_wandb_project) client = OpenAI() MODEL = "gpt-4o-2024-08-06" ``` ## Agents set up The use case we will tackle is a data analysis task. Let's first set up our 4-agents system: * Triaging agent: Decides which agent(s) to call * Data pre-processing Agent: Prepares data for analysis - for example by cleaning it up * Data Analysis Agent: Performs analysis on the data * Data Visualization Agent: Visualizes the output of the analysis to extract insights We will start by defining the system prompts for each of these agents. ```python triaging_system_prompt = """You are a Triaging Agent. Your role is to assess the user's query and route it to the relevant agents. The agents available are: - Data Processing Agent: Cleans, transforms, and aggregates data. - Analysis Agent: Performs statistical, correlation, and regression analysis. - Visualization Agent: Creates bar charts, line charts, and pie charts. Use the send_query_to_agents tool to forward the user's query to the relevant agents. Also, use the speak_to_user tool to get more information from the user if needed.""" processing_system_prompt = """You are a Data Processing Agent. Your role is to clean, transform, and aggregate data using the following tools: - clean_data - transform_data - aggregate_data""" analysis_system_prompt = """You are an Analysis Agent. Your role is to perform statistical, correlation, and regression analysis using the following tools: - stat_analysis - correlation_analysis - regression_analysis""" visualization_system_prompt = """You are a Visualization Agent. Your role is to create bar charts, line charts, and pie charts using the following tools: - create_bar_chart - create_line_chart - create_pie_chart""" ``` We will then define the tools for each agent. Apart from the triaging agent, each agent will be equipped with tools specific to their role: **Data pre-processing agent** : 1. Clean data, 2. Transform data, 3. Aggregate data **Data analysis agent** : 1. Statistical analysis, 2. Correlation analysis, 3. Regression Analysis **Data visualization agent** : 1. Create bar chart, 2. Create line chart, 3. Create pie chart ```python triage_tools = [ { "type": "function", "function": { "name": "send_query_to_agents", "description": "Sends the user query to relevant agents based on their capabilities.", "parameters": { "type": "object", "properties": { "agents": { "type": "array", "items": {"type": "string"}, "description": "An array of agent names to send the query to.", }, "query": { "type": "string", "description": "The user query to send.", }, }, "required": ["agents", "query"], }, }, "strict": True, } ] preprocess_tools = [ { "type": "function", "function": { "name": "clean_data", "description": "Cleans the provided data by removing duplicates and handling missing values.", "parameters": { "type": "object", "properties": { "data": { "type": "string", "description": "The dataset to clean. Should be in a suitable format such as JSON or CSV.", } }, "required": ["data"], "additionalProperties": False, }, }, "strict": True, }, { "type": "function", "function": { "name": "transform_data", "description": "Transforms data based on specified rules.", "parameters": { "type": "object", "properties": { "data": { "type": "string", "description": "The data to transform. Should be in a suitable format such as JSON or CSV.", }, "rules": { "type": "string", "description": "Transformation rules to apply, specified in a structured format.", }, }, "required": ["data", "rules"], "additionalProperties": False, }, }, "strict": True, }, { "type": "function", "function": { "name": "aggregate_data", "description": "Aggregates data by specified columns and operations.", "parameters": { "type": "object", "properties": { "data": { "type": "string", "description": "The data to aggregate. Should be in a suitable format such as JSON or CSV.", }, "group_by": { "type": "array", "items": {"type": "string"}, "description": "Columns to group by.", }, "operations": { "type": "string", "description": "Aggregation operations to perform, specified in a structured format.", }, }, "required": ["data", "group_by", "operations"], "additionalProperties": False, }, }, "strict": True, }, ] analysis_tools = [ { "type": "function", "function": { "name": "stat_analysis", "description": "Performs statistical analysis on the given dataset.", "parameters": { "type": "object", "properties": { "data": { "type": "string", "description": "The dataset to analyze. Should be in a suitable format such as JSON or CSV.", } }, "required": ["data"], "additionalProperties": False, }, }, "strict": True, }, { "type": "function", "function": { "name": "correlation_analysis", "description": "Calculates correlation coefficients between variables in the dataset.", "parameters": { "type": "object", "properties": { "data": { "type": "string", "description": "The dataset to analyze. Should be in a suitable format such as JSON or CSV.", }, "variables": { "type": "array", "items": {"type": "string"}, "description": "List of variables to calculate correlations for.", }, }, "required": ["data", "variables"], "additionalProperties": False, }, }, "strict": True, }, { "type": "function", "function": { "name": "regression_analysis", "description": "Performs regression analysis on the dataset.", "parameters": { "type": "object", "properties": { "data": { "type": "string", "description": "The dataset to analyze. Should be in a suitable format such as JSON or CSV.", }, "dependent_var": { "type": "string", "description": "The dependent variable for regression.", }, "independent_vars": { "type": "array", "items": {"type": "string"}, "description": "List of independent variables.", }, }, "required": ["data", "dependent_var", "independent_vars"], "additionalProperties": False, }, }, "strict": True, }, ] visualization_tools = [ { "type": "function", "function": { "name": "create_bar_chart", "description": "Creates a bar chart from the provided data.", "parameters": { "type": "object", "properties": { "data": { "type": "string", "description": "The data for the bar chart. Should be in a suitable format such as JSON or CSV.", }, "x": {"type": "string", "description": "Column for the x-axis."}, "y": {"type": "string", "description": "Column for the y-axis."}, }, "required": ["data", "x", "y"], "additionalProperties": False, }, }, "strict": True, }, { "type": "function", "function": { "name": "create_line_chart", "description": "Creates a line chart from the provided data.", "parameters": { "type": "object", "properties": { "data": { "type": "string", "description": "The data for the line chart. Should be in a suitable format such as JSON or CSV.", }, "x": {"type": "string", "description": "Column for the x-axis."}, "y": {"type": "string", "description": "Column for the y-axis."}, }, "required": ["data", "x", "y"], "additionalProperties": False, }, }, "strict": True, }, { "type": "function", "function": { "name": "create_pie_chart", "description": "Creates a pie chart from the provided data.", "parameters": { "type": "object", "properties": { "data": { "type": "string", "description": "The data for the pie chart. Should be in a suitable format such as JSON or CSV.", }, "labels": { "type": "string", "description": "Column for the labels.", }, "values": { "type": "string", "description": "Column for the values.", }, }, "required": ["data", "labels", "values"], "additionalProperties": False, }, }, "strict": True, }, ] ``` ## Enable tracking of multi-agent using Weave We need to write the code logic to: * handle passing the user query to the multi-agent system * handle the internal workings of the multi-agent system * execute the tool calls ```python # Example query user_query = """ Below is some data. I want you to first remove the duplicates then analyze the statistics of the data as well as plot a line chart. house_size (m3), house_price ($) 90, 100 80, 90 100, 120 90, 100 """ ``` From the user query, we can infer that the tools we would need to call are `clean_data`, `start_analysis` and `use_line_chart`. We will begin by defining the execution function responsible for running tool calls. By decorating Python functions with `@weave.op()`, we can log and debug language model inputs, outputs, and traces. When creating a multi-agent system, many functions will appear, but it's sufficient to simply add `@weave.op()` on top of them. ```python @weave.op() def clean_data(data): data_io = StringIO(data) df = pd.read_csv(data_io, sep=",") df_deduplicated = df.drop_duplicates() return df_deduplicated @weave.op() def stat_analysis(data): data_io = StringIO(data) df = pd.read_csv(data_io, sep=",") return df.describe() @weave.op() def plot_line_chart(data): data_io = StringIO(data) df = pd.read_csv(data_io, sep=",") x = df.iloc[:, 0] y = df.iloc[:, 1] coefficients = np.polyfit(x, y, 1) polynomial = np.poly1d(coefficients) y_fit = polynomial(x) plt.figure(figsize=(10, 6)) plt.plot(x, y, "o", label="Data Points") plt.plot(x, y_fit, "-", label="Best Fit Line") plt.title("Line Chart with Best Fit Line") plt.xlabel(df.columns[0]) plt.ylabel(df.columns[1]) plt.legend() plt.grid(True) # Save the plot to a BytesIO buffer before showing it buf = BytesIO() plt.savefig(buf, format="png") buf.seek(0) # Display the plot plt.show() # Encode the image in base64 for the data URL image_data = buf.getvalue() base64_encoded_data = base64.b64encode(image_data) base64_string = base64_encoded_data.decode("utf-8") data_url = f"data:image/png;base64,{base64_string}" return data_url # Define the function to execute the tools @weave.op() def execute_tool(tool_calls, messages): for tool_call in tool_calls: tool_name = tool_call.function.name tool_arguments = json.loads(tool_call.function.arguments) if tool_name == "clean_data": # Simulate data cleaning cleaned_df = clean_data(tool_arguments["data"]) cleaned_data = {"cleaned_data": cleaned_df.to_dict()} messages.append( {"role": "tool", "name": tool_name, "content": json.dumps(cleaned_data)} ) print("Cleaned data: ", cleaned_df) elif tool_name == "transform_data": # Simulate data transformation transformed_data = {"transformed_data": "sample_transformed_data"} messages.append( { "role": "tool", "name": tool_name, "content": json.dumps(transformed_data), } ) elif tool_name == "aggregate_data": # Simulate data aggregation aggregated_data = {"aggregated_data": "sample_aggregated_data"} messages.append( { "role": "tool", "name": tool_name, "content": json.dumps(aggregated_data), } ) elif tool_name == "stat_analysis": # Simulate statistical analysis stats_df = stat_analysis(tool_arguments["data"]) stats = {"stats": stats_df.to_dict()} messages.append( {"role": "tool", "name": tool_name, "content": json.dumps(stats)} ) print("Statistical Analysis: ", stats_df) elif tool_name == "correlation_analysis": # Simulate correlation analysis correlations = {"correlations": "sample_correlations"} messages.append( {"role": "tool", "name": tool_name, "content": json.dumps(correlations)} ) elif tool_name == "regression_analysis": # Simulate regression analysis regression_results = {"regression_results": "sample_regression_results"} messages.append( { "role": "tool", "name": tool_name, "content": json.dumps(regression_results), } ) elif tool_name == "create_bar_chart": # Simulate bar chart creation bar_chart = {"bar_chart": "sample_bar_chart"} messages.append( {"role": "tool", "name": tool_name, "content": json.dumps(bar_chart)} ) elif tool_name == "create_line_chart": # Simulate line chart creation line_chart = {"line_chart": plot_line_chart(tool_arguments["data"])} messages.append( {"role": "tool", "name": tool_name, "content": json.dumps(line_chart)} ) elif tool_name == "create_pie_chart": # Simulate pie chart creation pie_chart = {"pie_chart": "sample_pie_chart"} messages.append( {"role": "tool", "name": tool_name, "content": json.dumps(pie_chart)} ) return messages ``` Next, we will create the tool handlers for each of the sub-agents. These have a unique prompt and tool set passed to the model. The output is then passed to an execution function which runs the tool calls. ```python # Define the functions to handle each agent's processing @weave.op() def handle_data_processing_agent(query, conversation_messages): messages = [{"role": "system", "content": processing_system_prompt}] messages.append({"role": "user", "content": query}) response = client.chat.completions.create( model=MODEL, messages=messages, temperature=0, tools=preprocess_tools, ) conversation_messages.append( [tool_call.function for tool_call in response.choices[0].message.tool_calls] ) execute_tool(response.choices[0].message.tool_calls, conversation_messages) @weave.op() def

> Content truncated.

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/multi-agent-structured-output)

<!--- Optional: Example Notebooks -->
<!--- Ocr Pipeline -->

# Ocr Pipeline

# Trace and Evaluate a Computer Vision Pipeline

:::tip[This is a notebook]

Open in Colab

View in Github

:::

In this guide, you will learn how to use Weights & Biases (W&B) Weave to track and evaluate a computer vision pipeline that uses vision language model (VLMs) to perform optical character recognition (OCR) for a named entity recognition (NER) applications.
Specifically, OpenAI's GPT-4.1's vision capabilities are used to extract named entities from handwritten notes.

This guide demonstrates how to:

1. Track different versions of a system prompts using Weave
2. Get an image dataset from Weave
3. Create a NER pipeline
4. Set up Weave [Scorers](https://weave-docs.wandb.ai/guides/evaluation/scorers) to peform a [Weave Evaluation](https://weave-docs.wandb.ai/guides/core-types/evaluations) on the pipeline
5. Run an evaluation against our dataset of handwritten notes

##  Prerequisites

Before you begin, install and import the required libraries, get your W&B API key, and initialize your Weave project.


```python
# Install the required dependencies
!pip install openai weave -q
```


```python
import json
import os

from google.colab import userdata
from openai import OpenAI

import weave
```


```python
# Get API Keys
os.environ["OPENAI_API_KEY"] = userdata.get(
    "OPENAI_API_KEY"
)  # please set the keys as collab environment secrets from the menu on the left
os.environ["WANDB_API_KEY"] = userdata.get("WANDB_API_KEY")

# Set project name
# Replace the PROJECT value with your project name
PROJECT = "vlm-handwritten-ner"

# Initiatlize the Weave project
weave.init(PROJECT)
```

## 1. Create and iterate on prompts with Weave

Good prompt engineering is critical to guiding the model to properly extract entities. First, you'll create basic prompt that gives the model the instructions on what to extract from our image data and how to format it. Then, you'll store the promp in Weave for tracking and iteration.


```python
# Create your prompt object with Weave
prompt = """
Extract all readable text from this image. Format the extracted entities as a valid JSON.
Do not return any extra text, just the JSON. Do not include ```json```
Use the following format:
{"Patient Name": "James James","Date": "4/22/2025","Patient ID": "ZZZZZZZ123","Group Number": "3452542525"}
"""
system_prompt = weave.StringPrompt(prompt)
# Publish your prompt to Weave
weave.publish(system_prompt, name="NER-prompt")
```

Next, improve the prompt by adding more instructions and validation rules to help reduce errors in the output.


```python
better_prompt = """
You are a precision OCR assistant. Given an image of patient information, extract exactly these fields into a single JSON object—and nothing else:

- Patient Name
- Date (MM/DD/YYYY)
- Patient ID
- Group Number

Validation rules:
1. Date must match MM/DD/YY; if not, set Date to "".
2. Patient ID must be alphanumeric; if unreadable, set to "".
3. Always zero-pad months and days (e.g. "04/07/25").
4. Omit any markup, commentary, or code fences.
5. Return strictly valid JSON with only those four keys.

Do not return any extra text, just the JSON. Do not include ```json```
Example output:
{"Patient Name":"James James","Date":"04/22/25","Patient ID":"ZZZZZZZ123","Group Number":"3452542525"}
"""
# Edit the prompt
system_prompt = weave.StringPrompt(better_prompt)
# Publish the edited prompt to Weave
weave.publish(system_prompt, name="NER-prompt")
```

## 2. Get the dataset

Next, retrieve the dataset of handwritten notes to serve as input for the OCR pipeline. 

The images in the dataset are already `base64` encoded, which means the data can be used by the LLM without any pre-processing.



```python
# Retrieve the dataset from the following Weave project
dataset = weave.ref(
    "weave:///wandb-smle/vlm-handwritten-ner/object/NER-eval-dataset:G8MEkqWBtvIxPYAY23sXLvqp8JKZ37Cj0PgcG19dGjw"
).get()

# Access a specific example in the dataset
example_image = dataset.rows[3]["image_base64"]

# Display the example_image
from IPython.display import HTML, display

html = f''
display(HTML(html))
```

## 3. Build the NER pipeline

Next, build the NER pipeline. The pipeline will consist of two functions:

1. An `encode_image` function that takes a PIL image from the dataset and returns a `base64` encoded string representation of the image that can be passed to the VLM
2. An `extract_named_entities_from_image` function that takes an image and system prompt and returns the extracted entities from that image as described by the system prompt


```python
# Traceable function using GPT-4-Vision
def extract_named_entities_from_image(image_base64) -> dict:
    # init LLM Client
    client = OpenAI()

    # Setup the instruction prompt
    # You can optionally use a prompt stored in Weave withweave.ref("weave:///wandb-smle/vlm-handwritten-ner/object/NER-prompt:FmCv4xS3RFU21wmNHsIYUFal3cxjtAkegz2ylM25iB8").get().content.strip()
    prompt = better_prompt

    response = client.responses.create(
        model="gpt-4.1",
        input=[
            {
                "role": "user",
                "content": [
                    {"type": "input_text", "text": prompt},
                    {
                        "type": "input_image",
                        "image_url": image_base64,
                    },
                ],
            }
        ],
    )

    return response.output_text
```

Now, create a function called `named_entity_recognation` that:
- Passes the image data to the NER pipeline
- Returns correctly formatted JSON with the results

Use the [`@weave.op()` decorator](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace/weave.trace.op) decorator to automatically track and trace function execution in the W&B UI. 

Every `named_entity_recognation` is run, the full trace results are visible in the Weave UI. To view the traces, navigate to the **Traces** tab of your Weave project. 


```python
# NER Function for evaluations
@weave.op()
def named_entity_recognation(image_base64, id):
    result = {}
    try:
        # 1) call the vision op, get back a JSON string
        output_text = extract_named_entities_from_image(image_base64)

        # 2) parse JSON exactly once
        result = json.loads(output_text)

        print(f"Processed: {str(id)}")
    except Exception as e:
        print(f"Failed to process {str(id)}: {e}")
    return result
```

Finally, run the pipeline over the dataset, and view the results.

The following code loops over the dataset and stores the results in a local file `processing_results.json`. The results are also viewable in the Weave UI.


```python
# Output results
results = []

# loop over all images in the dataset
for row in dataset.rows:
    result = named_entity_recognation(row["image_base64"], str(row["id"]))
    result["image_id"] = str(row["id"])
    results.append(result)

# Save all results to a JSON file
output_file = "processing_results.json"
with open(output_file, "w") as f:
    json.dump(results, f, indent=2)

print(f"Results saved to: {output_file}")
```

You will see something similar to the following in the **Traces** table in the Weave UI.



## 4. Evaluate the pipeline using Weave

Now that you have created a pipeline to perform NER using a VLM, you can use Weave to systematically evaluate it and find out how well it performs. You can learn more about Evaluations in Weave in [Evaluations Overview](https://weave-docs.wandb.ai/guides/core-types/evaluations). 

A fundamental part of a Weave Evaluation are [Scorers](https://weave-docs.wandb.ai/guides/evaluation/scorers). Scorers are used to evaluate AI outputs and return evaluation metrics. They take the AI's output, analyze it, and return a dictionary of results. Scorers can use your input data as reference if needed and can also output extra information, such as explanations or reasonings from the evaluation.

In this section, you will create two Scorers to evaluate the pipeline:
1. Programatic Scorer 
2. LLM-as-a-judge Scorer



### Programatic scorer

The programmatic scorer, `check_for_missing_fields_programatically`, will take the model output (the output of the `named_entity_recognition` function), and identify which `keys` are missing or empty in the results.

This check is great for identifying samples where the model missed capturing any fields.


```python
# Add weave.op() to track execution of the scorer
@weave.op()
def check_for_missing_fields_programatically(model_output):
    # Required keys for every entry
    required_fields = {"Patient Name", "Date", "Patient ID", "Group Number"}

    for key in required_fields:
        if (
            key not in model_output
            or model_output[key] is None
            or str(model_output[key]).strip() == ""
        ):
            return False  # This entry has a missing or empty field

    return True  # All required fields are present and non-empty
```

### LLM-as-a-judge scorer

In the next step of the evaluation, both the image data and the model's output are provided to ensure the assessment reflects actual NER performance. The image content is explicitly referenced, not just the model output.

The Scorer used for this step, `check_for_missing_fields_with_llm`, use an LLM to perform scoring (specifically OpenAI's `gpt-4o`). As specified by the contents of the `eval_prompt`, `check_for_missing_fields_with_llm` outputs a `Boolean` value. If all fields match the information in the image and formatting is correct, the Scorer returns `true`. If any field is missing, empty, incorrect, or mismatched, the result is `false`, and the scorer also returns a message explaining the problem.


```python
# The system prompt for the LLM-as-a-judge

eval_prompt = """
You are an OCR validation system. Your role is to assess whether the structured text extracted from an image accurately reflects the information in that image.
Only validate the structured text and use the image as your source of truth.

Expected input text format:
{"Patient Name": "First Last", "Date": "04/23/25", "Patient ID": "131313JJH", "Group Number": "35453453"}

Evaluation criteria:
- All four fields must be present.
- No field should be empty or contain placeholder/malformed values.
- The "Date" should be in MM/DD/YY format (e.g., "04/07/25") (zero padding the date is allowed)

Scoring:
- Return: {"Correct": true, "Reason": ""} if **all fields** match the information in the image and formatting is correct.
- Return: {"Correct": false, "Reason": "EXPLANATION"} if **any** field is missing, empty, incorrect, or mismatched.

Output requirements:
- Respond with a valid JSON object only.
- "Correct" must be a JSON boolean: true or false (not a string or number).
- "Reason" must be a short, specific string indicating all the problem — e.g., "Patient Name mismatch", "Date not zero-padded", or "Missing Group Number".
- Do not return any additional explanation or formatting.

Your response must be exactly one of the following:
{"Correct": true, "Reason": null}
OR
{"Correct": false, "Reason": "EXPLANATION_HERE"}
"""


# Add weave.op() to track execution of the Scorer
@weave.op()
def check_for_missing_fields_with_llm(model_output, image_base64):
    client = OpenAI()
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "developer", "content": [{"text": eval_prompt, "type": "text"}]},
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": image_base64,
                        },
                    },
                    {"type": "text", "text": str(model_output)},
                ],
            },
        ],
        response_format={"type": "json_object"},
    )
    response = json.loads(response.choices[0].message.content)
    return response
```

## 5. Run the Evaluation

Finally, define an evaluation call that will automatically loop over the `dataset` passed and log the results together in the Weave UI.

The following code kicks off the evaluation and applies the two Scorers to every output from the NER pipeline. Results are visible in the **Evals** tab in the Weave UI.


```python
evaluation = weave.Evaluation(
    dataset=dataset,
    scorers=[
        check_for_missing_fields_with_llm,
        check_for_missing_fields_programatically,
    ],
    name="Evaluate_4.1_NER",
)

print(await evaluation.evaluate(named_entity_recognation))
```

When the above code is run, a link to the Evaluation table in the Weave UI is generated. Follow the link to view the results and compare different iterations of the pipeline across models, prompts, and datasets of your choice. The Weave UI automatically creates a visualization like the one shown below for your team.

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/ocr-pipeline)

<!--- Optional: Example Notebooks -->
<!--- Chain of Density Summarization -->

# Chain of Density Summarization

:::tip[This is a notebook]

Open in Colab

View in Github

:::





# Summarization using Chain of Density

Summarizing complex technical documents while preserving crucial details is a challenging task. The Chain of Density (CoD) summarization technique offers a solution by iteratively refining summaries to be more concise and information-dense. This guide demonstrates how to implement CoD using Weave for tracking and evaluating the application. 



## What is Chain of Density Summarization?

[](https://arxiv.org/abs/2309.04269)

Chain of Density (CoD) is an iterative summarization technique that produces increasingly concise and information-dense summaries. It works by:

1. Starting with an initial summary
2. Iteratively refining the summary, making it more concise while preserving key information
3. Increasing the density of entities and technical details with each iteration

This approach is particularly useful for summarizing scientific papers or technical documents where preserving detailed information is crucial.

## Why use Weave?

In this tutorial, we'll use Weave to implement and evaluate a Chain of Density summarization pipeline for ArXiv papers. You'll learn how to:

1. **Track your LLM pipeline**: Use Weave to automatically log inputs, outputs, and intermediate steps of your summarization process.
2. **Evaluate LLM outputs**: Create rigorous, apples-to-apples evaluations of your summaries using Weave's built-in tools.
3. **Build composable operations**: Combine and reuse Weave operations across different parts of your summarization pipeline.
4. **Integrate seamlessly**: Add Weave to your existing Python code with minimal overhead.

By the end of this tutorial, you'll have created a CoD summarization pipeline that leverages Weave's capabilities for model serving, evaluation, and result tracking.

## Set up the environment

First, let's set up our environment and import the necessary libraries:


```python
!pip install -qU anthropic weave pydantic requests PyPDF2 set-env-colab-kaggle-dotenv
```

>To get an Anthropic API key:
> 1. Sign up for an account at https://www.anthropic.com
> 2. Navigate to the API section in your account settings
> 3. Generate a new API key
> 4. Store the API key securely in your .env file


```python
import io
import os
from datetime import datetime, timezone

import anthropic
import requests
from pydantic import BaseModel
from PyPDF2 import PdfReader
from set_env import set_env

import weave

set_env("WANDB_API_KEY")
set_env("ANTHROPIC_API_KEY")

weave.init("summarization-chain-of-density-cookbook")
anthropic_client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
```

We're using Weave to track our experiment and Anthropic's Claude model for text generation. The `weave.init()` call sets up a new Weave project for our summarization task.

## Define the ArxivPaper model

We'll create a simple `ArxivPaper` class to represent our data:


```python
# Define ArxivPaper model
class ArxivPaper(BaseModel):
    entry_id: str
    updated: datetime
    published: datetime
    title: str
    authors: list[str]
    summary: str
    pdf_url: str


# Create sample ArxivPaper
arxiv_paper = ArxivPaper(
    entry_id="http://arxiv.org/abs/2406.04744v1",
    updated=datetime(2024, 6, 7, 8, 43, 7, tzinfo=timezone.utc),
    published=datetime(2024, 6, 7, 8, 43, 7, tzinfo=timezone.utc),
    title="CRAG -- Comprehensive RAG Benchmark",
    authors=["Xiao Yang", "Kai Sun", "Hao Xin"],  # Truncated for brevity
    summary="Retrieval-Augmented Generation (RAG) has recently emerged as a promising solution...",  # Truncated
    pdf_url="https://arxiv.org/pdf/2406.04744",
)
```

This class encapsulates the metadata and content of an ArXiv paper, which will be the input to our summarization pipeline.

## Load PDF content

To work with the full paper content, we'll add a function to load and extract text from PDFs:


```python
@weave.op()
def load_pdf(pdf_url: str) -> str:
    # Download the PDF
    response = requests.get(pdf_url)
    pdf_file = io.BytesIO(response.content)

    # Read the PDF
    pdf_reader = PdfReader(pdf_file)

    # Extract text from all pages
    text = ""
    for page in pdf_reader.pages:
        text += page.extract_text()

    return text
```

## Implement Chain of Density summarization

Now, let's implement the core CoD summarization logic using Weave operations:




```python
# Chain of Density Summarization
@weave.op()
def summarize_current_summary(
    document: str,
    instruction: str,
    current_summary: str = "",
    iteration: int = 1,
    model: str = "claude-3-sonnet-20240229",
):
    prompt = f"""
    Document: {document}
    Current summary: {current_summary}
    Instruction to focus on: {instruction}
    Iteration: {iteration}

    Generate an increasingly concise, entity-dense, and highly technical summary from the provided document that specifically addresses the given instruction.
    """
    response = anthropic_client.messages.create(
        model=model, max_tokens=4096, messages=[{"role": "user", "content": prompt}]
    )
    return response.content[0].text


@weave.op()
def iterative_density_summarization(
    document: str,
    instruction: str,
    current_summary: str,
    density_iterations: int,
    model: str = "claude-3-sonnet-20240229",
):
    iteration_summaries = []
    for iteration in range(1, density_iterations + 1):
        current_summary = summarize_current_summary(
            document, instruction, current_summary, iteration, model
        )
        iteration_summaries.append(current_summary)
    return current_summary, iteration_summaries


@weave.op()
def final_summary(
    instruction: str, current_summary: str, model: str = "claude-3-sonnet-20240229"
):
    prompt = f"""
    Given this summary: {current_summary}
    And this instruction to focus on: {instruction}
    Create an extremely dense, final summary that captures all key technical information in the most concise form possible, while specifically addressing the given instruction.
    """
    return (
        anthropic_client.messages.create(
            model=model, max_tokens=4096, messages=[{"role": "user", "content": prompt}]
        )
        .content[0]
        .text
    )


@weave.op()
def chain_of_density_summarization(
    document: str,
    instruction: str,
    current_summary: str = "",
    model: str = "claude-3-sonnet-20240229",
    density_iterations: int = 2,
):
    current_summary, iteration_summaries = iterative_density_summarization(
        document, instruction, current_summary, density_iterations, model
    )
    final_summary_text = final_summary(instruction, current_summary, model)
    return {
        "final_summary": final_summary_text,
        "accumulated_summary": current_summary,
        "iteration_summaries": iteration_summaries,
    }
```

Here's what each function does:

- `summarize_current_summary`: Generates a single summary iteration based on the current state.
- `iterative_density_summarization`: Applies the CoD technique by calling `summarize_current_summary` multiple times.
- `chain_of_density_summarization`: Orchestrates the entire summarization process and returns the results.

By using `@weave.op()` decorators, we ensure that Weave tracks the inputs, outputs, and execution of these functions.


## Create a Weave Model

Now, let's wrap our summarization pipeline in a Weave Model:




```python
# Weave Model
class ArxivChainOfDensityPipeline(weave.Model):
    model: str = "claude-3-sonnet-20240229"
    density_iterations: int = 3

    @weave.op()
    def predict(self, paper: ArxivPaper, instruction: str) -> dict:
        text = load_pdf(paper.pdf_url)
        result = chain_of_density_summarization(
            text,
            instruction,
            model=self.model,
            density_iterations=self.density_iterations,
        )
        return result
```

This `ArxivChainOfDensityPipeline` class encapsulates our summarization logic as a Weave Model, providing several key benefits:

1. Automatic experiment tracking: Weave captures inputs, outputs, and parameters for each run of the model.
2. Versioning: Changes to the model's attributes or code are automatically versioned, creating a clear history of how your summarization pipeline evolves over time.
3. Reproducibility: The versioning and tracking make it easy to reproduce any previous result or configuration of your summarization pipeline.
4. Hyperparameter management: Model attributes (like `model` and `density_iterations`) are clearly defined and tracked across different runs, facilitating experimentation.
5. Integration with Weave ecosystem: Using `weave.Model` allows seamless integration with other Weave tools, such as evaluations and serving capabilities.

## Implement evaluation metrics

To assess the quality of our summaries, we'll implement simple evaluation metrics:


```python
import json


@weave.op()
def evaluate_summary(
    summary: str, instruction: str, model: str = "claude-3-sonnet-20240229"
) -> dict:
    prompt = f"""
    Summary: {summary}
    Instruction: {instruction}

    Evaluate the summary based on the following criteria:
    1. Relevance (1-5): How well does the summary address the given instruction?
    2. Conciseness (1-5): How concise is the summary while retaining key information?
    3. Technical Accuracy (1-5): How accurately does the summary convey technical details?

    Your response MUST be in the following JSON format:
    {{
        "relevance": {{
            "score": ,
            "explanation": ""
        }},
        "conciseness": {{
            "score": ,
            "explanation": ""
        }},
        "technical_accuracy": {{
            "score": ,
            "explanation": ""
        }}
    }}

    Ensure that the scores are integers between 1 and 5, and that the explanations are concise.
    """
    response = anthropic_client.messages.create(
        model=model, max_tokens=1000, messages=[{"role": "user", "content": prompt}]
    )
    print(response.content[0].text)

    eval_dict = json.loads(response.content[0].text)

    return {
        "relevance": eval_dict["relevance"]["score"],
        "conciseness": eval_dict["conciseness"]["score"],
        "technical_accuracy": eval_dict["technical_accuracy"]["score"],
        "average_score": sum(eval_dict[k]["score"] for k in eval_dict) / 3,
        "evaluation_text": response.content[0].text,
    }
```

These evaluation functions use the Claude model to assess the quality of the generated summaries based on relevance, conciseness, and technical accuracy.

## Create a Weave Dataset and run evaluation

To evaluate our pipeline, we'll create a Weave Dataset and run an evaluation:




```python
# Create a Weave Dataset
dataset = weave.Dataset(
    name="arxiv_papers",
    rows=[
        {
            "paper": arxiv_paper,
            "instruction": "What was the approach to experimenting with different data mixtures?",
        },
    ],
)

weave.publish(dataset)
```

For our evaluation, we'll use an LLM-as-a-judge approach. This technique involves using a language model to assess the quality of outputs generated by another model or system. It leverages the LLM's understanding and reasoning capabilities to provide nuanced evaluations, especially for tasks where traditional metrics may fall short.

[](https://arxiv.org/abs/2306.05685)




```python
# Define the scorer function
@weave.op()
def quality_scorer(instruction: str, output: dict) -> dict:
    result = evaluate_summary(output["final_summary"], instruction)
    return result
```


```python
# Run evaluation
evaluation = weave.Evaluation(dataset=dataset, scorers=[quality_scorer])
arxiv_chain_of_density_pipeline = ArxivChainOfDensityPipeline()
results = await evaluation.evaluate(arxiv_chain_of_density_pipeline)
```

This code creates a dataset with our sample ArXiv paper, defines a quality scorer, and runs an evaluation of our summarization pipeline.

## Conclusion

In this example, we've demonstrated how to implement a Chain of Density summarization pipeline for ArXiv papers using Weave. We've shown how to:

1. Create Weave operations for each step of the summarization process
2. Wrap the pipeline in a Weave Model for easy tracking and evaluation
3. Implement custom evaluation metrics using Weave operations
4. Create a dataset and run an evaluation of the pipeline

Weave's seamless integration allows us to track inputs, outputs, and intermediate steps throughout the summarization process, making it easier to debug, optimize, and evaluate our LLM application.
You can extend this example to handle larger datasets, implement more sophisticated evaluation metrics, or integrate with other LLM workflows.

<a 
  href="https://wandb.ai/wandb_fc/arxiv-reader/reports/Building-a-bot-to-summarize-arXiv-papers-as-PDFs-using-Anthrophic-and-W-B-Weave--Vmlldzo4Nzg0ODI4"
  target="_blank"
  rel="noopener noreferrer"
  className="button button--primary button--lg"
>
  View Full Report on W&B

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/chain_of_density)

<!--- Optional: Example Notebooks -->
<!--- Log Audio With Weave -->

# Log Audio With Weave

:::tip[This is a notebook] Open in Colab View in Github ::: # How to use Weave with Audio Data: An OpenAI Example This demo uses the OpenAI chat completions API with GPT 4o Audio Preview to generate audio responses to text prompts and track these in Weave. For the advanced use case, we leverage the OpenAI Realtime API to stream audio in realtime. Click the following thumbnail to view the video demonstration, or click [here](https://www.youtube.com/watch?v=lnnd73xDElw). [](https://www.youtube.com/watch?v=lnnd73xDElw "Everything Is AWESOME") ## Setup Start by installing the OpenAI (`openai`) and Weave (`weave`) dependencies, as well as API key management dependencey `set-env`. ```python %%capture !pip install openai !pip install weave !pip install set-env-colab-kaggle-dotenv -q # for env var ``` ```python %%capture # Temporary workaround to fix bug in openai: # TypeError: Client.__init__() got an unexpected keyword argument 'proxies' # See https://community.openai.com/t/error-with-openai-1-56-0-client-init-got-an-unexpected-keyword-argument-proxies/1040332/15 !pip install "httpx<0.28" ``` Next, load the required API keys for OpenAI and Weave. Here, we use set_env which is compatible with google colab's secret keys manager, and is an alternative to colab's specific `google.colab.userdata`. See: [here](https://pypi.org/project/set-env-colab-kaggle-dotenv/) for usage instructions. ```python # Set environment variables. from set_env import set_env _ = set_env("OPENAI_API_KEY") _ = set_env("WANDB_API_KEY") ``` And finally import the required libraries. ```python import base64 import os import time import wave import numpy as np from IPython.display import display from openai import OpenAI import weave ``` ## Audio Streaming and Storage Example Now we will setup a call to OpenAI's completions endpoint with audio modality enabled. First create the OpenAI client and initiate a Weave project. ```python client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY")) weave.init("openai-audio-chat") ``` Now we will define our OpenAI completions request and add our Weave decorator (op). Here, we define the function `prompt_endpont_and_log_trace`. This function has three primary steps: 1. We make a completion object using the `GPT 4o Audio Preview` model that supports text and audio inputs and outputs. - We prompt the model to count to 13 slowly with varying accents. - We set the completion to "stream". 2. We open a new output file to which the streamed data is writen chunk by chunk. 3. We return an open file handler to the audio file so Weave logs the audio data in the trace. ```python SAMPLE_RATE = 22050 @weave.op() def prompt_endpoint_and_log_trace(system_prompt=None, user_prompt=None): if not system_prompt: system_prompt = "You're the fastest counter in the world" if not user_prompt: user_prompt = "Count to 13 super super slow, enunciate each number with a dramatic flair, changing up accents as you go along. British, French, German, Spanish, etc." # Request from the OpenAI API with audio modality completion = client.chat.completions.create( model="gpt-4o-audio-preview", modalities=["text", "audio"], audio={"voice": "fable", "format": "pcm16"}, stream=True, messages=[ {"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}, ], ) # Open a wave file for writing with wave.open("./output.wav", "wb") as wav_file: wav_file.setnchannels(1) # Mono wav_file.setsampwidth(2) # 16-bit wav_file.setframerate(SAMPLE_RATE) # Sample rate (adjust if needed) # Write chunks as they are streamed in from the API for chunk in completion: if ( hasattr(chunk, "choices") and chunk.choices is not None and len(chunk.choices) > 0 ): if ( hasattr(chunk.choices[0].delta, "audio") and chunk.choices[0].delta.audio.get("data") is not None ): # Decode the base64 audio data audio_data = base64.b64decode( chunk.choices[0].delta.audio.get("data") ) # Write the current chunk to the wave file wav_file.writeframes(audio_data) # Return the file to Weave op return wave.open("output.wav", "rb") ``` ## Testing Run the following cell. The system and user prompt will be stored in a Weave trace as well as the output audio. After running the cell, click the link next to the "🍩" emoji to view your trace. ```python from IPython.display import Audio, display # Call the function to write the audio stream prompt_endpoint_and_log_trace( system_prompt="You're the fastest counter in the world", user_prompt="Count to 13 super super slow, enunciate each number with a dramatic flair, changing up accents as you go along. British, French, German, Spanish, etc.", ) # Display the updated audio stream display(Audio("output.wav", rate=SAMPLE_RATE, autoplay=True)) ``` # Advanced Usage: Realtime Audio API with Weave (Advanced) Realtime Audio API with Weave OpenAI's realtime API is a highly functional and reliable conversational API for building realtime audio and text assistants. Please note: - Review the cells in [Microphone Configuration](#microphone-configuration) - Due to limitations of the Google Colab execution environment, **this must be run on your host machine** as a Jupyter Notebook. This cannot be ran in the browser. - On MacOS you will need to install `portaudio` via Brew (see [here](https://formulae.brew.sh/formula/portaudio)) for Pyaudio to function. - OpenAI's Python SDK does not yet provide Realtime API support. We implement the complete OAI Realtime API schema in Pydantic for greater legibility, and may deprecate once official support is released. - The `enable_audio_playback` toggle will cause playback of assistant outputted audio. Please note that **headphones are required if this is enabled**, as echo detection requires a highly complex implementation. ## Requirements Setup ```python %%capture !pip install numpy==2.0 !pip install weave !pip install pyaudio # On mac, you may need to install portaudio first with `brew install portaudio` !pip install websocket-client !pip install set-env-colab-kaggle-dotenv -q # for env var !pip install resampy ``` ```python import base64 import io import json import os import threading import time import wave from typing import Optional import numpy as np import pyaudio import resampy import websocket from set_env import set_env import weave ``` ```python # Set environment variables. # See: https://pypi.org/project/set-env-colab-kaggle-dotenv/ for usage instructions. _ = set_env("OPENAI_API_KEY") _ = set_env("WANDB_API_KEY") ``` ## Microphone Configuration Run the following cell to find all available audio devices. Then, populate the `INPUT_DEVICE_INDEX` and the `OUTPUT_DEVICE_INDEX` based on the devices listed. Your input device will have at least 1 input channels, and your output device will have at least 1 output channels. ```python # Get device list from pyaudio so we can configure the next cell p = pyaudio.PyAudio() devices_data = {i: p.get_device_info_by_index(i) for i in range(p.get_device_count())} for i, device in devices_data.items(): print( f"Found device @{i}: {device['name']} with sample rate: {device['defaultSampleRate']} and input channels: {device['maxInputChannels']} and output channels: {device['maxOutputChannels']}" ) ``` ```python INPUT_DEVICE_INDEX = 3 # @param # Choose based on device list above. Make sure device has > 0 input channels. OUTPUT_DEVICE_INDEX = 12 # @param # Chose based on device list above. Make sure device has > 0 output channels. enable_audio_playback = True # @param {type:"boolean"} # Toggle on assistant audio playback. Requires headphones. # Audio recording and streaming parameters INPUT_DEVICE_CHANNELS = devices_data[INPUT_DEVICE_INDEX][ "maxInputChannels" ] # From device list above SAMPLE_RATE = int( devices_data[INPUT_DEVICE_INDEX]["defaultSampleRate"] ) # From device list above CHUNK = int(SAMPLE_RATE / 10) # Samples per frame SAMPLE_WIDTH = p.get_sample_size(pyaudio.paInt16) # Samples per frame for the format CHUNK_DURATION = 0.3 # Seconds of audio per chunk sent to OAI API OAI_SAMPLE_RATE = ( 24000 # OAI Sample Rate is 24kHz, we need this to play or save assistant audio ) OUTPUT_DEVICE_CHANNELS = 1 # Set to 1 for mono output ``` ## OpenAI Realtime API Schema Implementation The OpenAI Python SDK does not yet provide Realtime API support. We implement the complete OAI Realtime API schema in Pydantic for greater legibility, and may deprecate once official support is released. Pydantic Schema for OpenAI Realtime API (OpenAI's SDK lacks Realtime API support) ```python from enum import Enum from typing import Any, Literal, Optional, Union from pydantic import BaseModel, Field, ValidationError class BaseEvent(BaseModel): type: Union["ClientEventTypes", "ServerEventTypes"] event_id: Optional[str] = None # Add event_id as an optional field for all events # def model_dump_json(self, *args, **kwargs): # # Only include non-None fields # return super().model_dump_json(*args, exclude_none=True, **kwargs) class ChatMessage(BaseModel): role: Literal["user", "assistant"] content: str timestamp: float """ CLIENT EVENTS """ class ClientEventTypes(str, Enum): SESSION_UPDATE = "session.update" CONVERSATION_ITEM_CREATE = "conversation.item.create" CONVERSATION_ITEM_TRUNCATE = "conversation.item.truncate" CONVERSATION_ITEM_DELETE = "conversation.item.delete" RESPONSE_CREATE = "response.create" RESPONSE_CANCEL = "response.cancel" INPUT_AUDIO_BUFFER_APPEND = "input_audio_buffer.append" INPUT_AUDIO_BUFFER_COMMIT = "input_audio_buffer.commit" INPUT_AUDIO_BUFFER_CLEAR = "input_audio_buffer.clear" ERROR = "error" #### Session Update class TurnDetection(BaseModel): type: Literal["server_vad"] threshold: float = Field(..., ge=0.0, le=1.0) prefix_padding_ms: int silence_duration_ms: int class InputAudioTranscription(BaseModel): model: Optional[str] = None class ToolParameterProperty(BaseModel): type: str class ToolParameter(BaseModel): type: str properties: dict[str, ToolParameterProperty] required: list[str] class Tool(BaseModel): type: Literal["function", "code_interpreter", "file_search"] name: Optional[str] = None description: Optional[str] = None parameters: Optional[ToolParameter] = None class Session(BaseModel): modalities: Optional[list[str]] = None instructions: Optional[str] = None voice: Optional[str] = None input_audio_format: Optional[str] = None output_audio_format: Optional[str] = None input_audio_transcription: Optional[InputAudioTranscription] = None turn_detection: Optional[TurnDetection] = None tools: Optional[list[Tool]] = None tool_choice: Optional[str] = None temperature: Optional[float] = None max_output_tokens: Optional[int] = None class SessionUpdate(BaseEvent): type: Literal[ClientEventTypes.SESSION_UPDATE] = ClientEventTypes.SESSION_UPDATE session: Session #### Audio Buffers class InputAudioBufferAppend(BaseEvent): type: Literal[ClientEventTypes.INPUT_AUDIO_BUFFER_APPEND] = ( ClientEventTypes.INPUT_AUDIO_BUFFER_APPEND ) audio: str class InputAudioBufferCommit(BaseEvent): type: Literal[ClientEventTypes.INPUT_AUDIO_BUFFER_COMMIT] = ( ClientEventTypes.INPUT_AUDIO_BUFFER_COMMIT ) class InputAudioBufferClear(BaseEvent): type: Literal[ClientEventTypes.INPUT_AUDIO_BUFFER_CLEAR] = ( ClientEventTypes.INPUT_AUDIO_BUFFER_CLEAR ) #### Messages class MessageContent(BaseModel): type: Literal["input_audio"] audio: str class ConversationItemContent(BaseModel): type: Literal["input_text", "input_audio", "text", "audio"] text: Optional[str] = None audio: Optional[str] = None transcript: Optional[str] = None class FunctionCallContent(BaseModel): call_id: str name: str arguments: str class FunctionCallOutputContent(BaseModel): output: str class ConversationItem(BaseModel): id: Optional[str] = None type: Literal["message", "function_call", "function_call_output"] status: Optional[Literal["completed", "in_progress", "incomplete"]] = None role: Literal["user", "assistant", "system"] content: list[ Union[ConversationItemContent, FunctionCallContent, FunctionCallOutputContent] ] call_id: Optional[str] = None name: Optional[str] = None arguments: Optional[str] = None output: Optional[str] = None class ConversationItemCreate(BaseEvent): type: Literal[ClientEventTypes.CONVERSATION_ITEM_CREATE] = ( ClientEventTypes.CONVERSATION_ITEM_CREATE ) item: ConversationItem class ConversationItemTruncate(BaseEvent): type: Literal[ClientEventTypes.CONVERSATION_ITEM_TRUNCATE] = ( ClientEventTypes.CONVERSATION_ITEM_TRUNCATE ) item_id: str content_index: int audio_end_ms: int class ConversationItemDelete(BaseEvent): type: Literal[ClientEventTypes.CONVERSATION_ITEM_DELETE] = ( ClientEventTypes.CONVERSATION_ITEM_DELETE ) item_id: str #### Responses class ResponseCreate(BaseEvent): type: Literal[ClientEventTypes.RESPONSE_CREATE] = ClientEventTypes.RESPONSE_CREATE class ResponseCancel(BaseEvent): type: Literal[ClientEventTypes.RESPONSE_CANCEL] = ClientEventTypes.RESPONSE_CANCEL # Update the Event union to include all event types ClientEvent = Union[ SessionUpdate, InputAudioBufferAppend, InputAudioBufferCommit, InputAudioBufferClear, ConversationItemCreate, ConversationItemTruncate, ConversationItemDelete, ResponseCreate, ResponseCancel, ] """ SERVER EVENTS """ class ServerEventTypes(str, Enum): ERROR = "error" RESPONSE_AUDIO_TRANSCRIPT_DONE = "response.audio_transcript.done" RESPONSE_AUDIO_TRANSCRIPT_DELTA = "response.audio_transcript.delta" RESPONSE_AUDIO_DELTA = "response.audio.delta" SESSION_CREATED = "session.created" SESSION_UPDATED = "session.updated" CONVERSATION_CREATED = "conversation.created" INPUT_AUDIO_BUFFER_COMMITTED = "input_audio_buffer.committed" INPUT_AUDIO_BUFFER_CLEARED = "input_audio_buffer.cleared" INPUT_AUDIO_BUFFER_SPEECH_STARTED = "input_audio_buffer.speech_started" INPUT_AUDIO_BUFFER_SPEECH_STOPPED = "input_audio_buffer.speech_stopped" CONVERSATION_ITEM_CREATED = "conversation.item.created" CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_COMPLETED = ( "conversation.item.input_audio_transcription.completed" ) CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_FAILED = ( "conversation.item.input_audio_transcription.failed" ) CONVERSATION_ITEM_TRUNCATED = "conversation.item.truncated" CONVERSATION_ITEM_DELETED = "conversation.item.deleted" RESPONSE_CREATED = "response.created" RESPONSE_DONE = "response.done" RESPONSE_OUTPUT_ITEM_ADDED = "response.output_item.added" RESPONSE_OUTPUT_ITEM_DONE = "response.output_item.done" RESPONSE_CONTENT_PART_ADDED = "response.content_part.added" RESPONSE_CONTENT_PART_DONE = "response.content_part.done" RESPONSE_TEXT_DELTA = "response.text.delta" RESPONSE_TEXT_DONE = "response.text.done" RESPONSE_AUDIO_DONE = "response.audio.done" RESPONSE_FUNCTION_CALL_ARGUMENTS_DELTA = "response.function_call_arguments.delta" RESPONSE_FUNCTION_CALL_ARGUMENTS_DONE = "response.function_call_arguments.done" RATE_LIMITS_UPDATED = "rate_limits.updated" #### Errors class ErrorDetails(BaseModel): type: Optional[str] = None code: Optional[str] = None message: Optional[str] = None param: Optional[str] = None class ErrorEvent(BaseEvent): type: Literal[ServerEventTypes.ERROR] = ServerEventTypes.ERROR error: ErrorDetails #### Session class SessionCreated(BaseEvent): type: Literal[ServerEventTypes.SESSION_CREATED] = ServerEventTypes.SESSION_CREATED session: Session class SessionUpdated(BaseEvent): type: Literal[ServerEventTypes.SESSION_UPDATED] = ServerEventTypes.SESSION_UPDATED session: Session #### Conversation class Conversation(BaseModel): id: str object: Literal["realtime.conversation"] class ConversationCreated(BaseEvent): type: Literal[ServerEventTypes.CONVERSATION_CREATED] = ( ServerEventTypes.CONVERSATION_CREATED ) conversation: Conversation class ConversationItemCreated(BaseEvent): type: Literal[ServerEventTypes.CONVERSATION_ITEM_CREATED] = ( ServerEventTypes.CONVERSATION_ITEM_CREATED ) previous_item_id: Optional[str] = None item: ConversationItem class ConversationItemInputAudioTranscriptionCompleted(BaseEvent): type: Literal[ ServerEventTypes.CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_COMPLETED ] = ServerEventTypes.CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_COMPLETED item_id: str content_index: int transcript: str class ConversationItemInputAudioTranscriptionFailed(BaseEvent): type: Literal[ ServerEventTypes.CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_FAILED ] = ServerEventTypes.CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_FAILED item_id: str content_index: int error: dict[str, Any] class ConversationItemTruncated(BaseEvent): type: Literal[ServerEventTypes.CONVERSATION_ITEM_TRUNCATED] = ( ServerEventTypes.CONVERSATION_ITEM_TRUNCATED ) item_id: str content_index: int audio_end_ms: int class ConversationItemDeleted(BaseEvent): type: Literal[ServerEventTypes.CONVERSATION_ITEM_DELETED] = ( ServerEventTypes.CONVERSATION_ITEM_DELETED ) item_id: str #### Response class ResponseUsage(BaseModel): total_tokens: int input_tokens: int output_tokens: int input_token_details: Optional[dict[str, int]] = None output_token_details: Optional[dict[str, int]] = None class ResponseOutput(BaseModel): id: str object: Literal["realtime.item"] type: str status: str role: str content: list[dict[str, Any]] class ResponseContentPart(BaseModel): type: str text: Optional[str] = None class ResponseOutputItemContent(BaseModel): type: str text: Optional[str] = None class ResponseStatusDetails(BaseModel): type: str reason: str class ResponseOutputItem(BaseModel): id: str object: Literal["realtime.item"] type: str status: str role: str content: list[ResponseOutputItemContent] class Response(BaseModel): id: str object: Literal["realtime.response"] status: str status_details: Optional[ResponseStatusDetails] = None output: list[ResponseOutput] usage: Optional[ResponseUsage] class ResponseCreated(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_CREATED] = ServerEventTypes.RESPONSE_CREATED response: Response class ResponseDone(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_DONE] = ServerEventTypes.RESPONSE_DONE response: Response class ResponseOutputItemAdded(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_OUTPUT_ITEM_ADDED] = ( ServerEventTypes.RESPONSE_OUTPUT_ITEM_ADDED ) response_id: str output_index: int item: ResponseOutputItem class ResponseOutputItemDone(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_OUTPUT_ITEM_DONE] = ( ServerEventTypes.RESPONSE_OUTPUT_ITEM_DONE ) response_id: str output_index: int item: ResponseOutputItem class ResponseContentPartAdded(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_CONTENT_PART_ADDED] = ( ServerEventTypes.RESPONSE_CONTENT_PART_ADDED ) response_id: str item_id: str output_index: int content_index: int part: ResponseContentPart class ResponseContentPartDone(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_CONTENT_PART_DONE] = ( ServerEventTypes.RESPONSE_CONTENT_PART_DONE ) response_id: str item_id: str output_index: int content_index: int part: ResponseContentPart #### Response Text class ResponseTextDelta(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_TEXT_DELTA] = ( ServerEventTypes.RESPONSE_TEXT_DELTA ) response_id: str item_id: str output_index: int content_index: int delta: str class ResponseTextDone(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_TEXT_DONE] = ( ServerEventTypes.RESPONSE_TEXT_DONE ) response_id: str item_id: str output_index: int content_index: int text: str #### Response Audio class ResponseAudioTranscriptDone(BaseEvent): type:

> Content truncated.

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/audio_with_weave)

<!--- Optional: Example Notebooks -->
<!--- Leaderboard Quickstart -->

# Leaderboard Quickstart

:::tip[This is a notebook]

Open in Colab

View in Github

:::





# Leaderboard Quickstart

In this notebook we will learn to use Weave's Leaderboard to compare model performance across different datasets and scoring functions. Specifically, we will:

1. Generate a dataset of fake zip code data
2. Author some scoring functions and evaluate a baseline model.
3. Use these techniques to evaluate a matrix of models vs evaluations.
4. Review the leaderboard in the Weave UI.

## Step 1: Generate a dataset of fake zip code data

First we will create a function `generate_dataset_rows` that generates a list of fake zip code data.


```python
import json

from openai import OpenAI
from pydantic import BaseModel


class Row(BaseModel):
    zip_code: str
    city: str
    state: str
    avg_temp_f: float
    population: int
    median_income: int
    known_for: str


class Rows(BaseModel):
    rows: list[Row]


def generate_dataset_rows(
    location: str = "United States", count: int = 5, year: int = 2022
):
    client = OpenAI()

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {
                "role": "user",
                "content": f"Please generate {count} rows of data for random zip codes in {location} for the year {year}.",
            },
        ],
        response_format={
            "type": "json_schema",
            "json_schema": {
                "name": "response_format",
                "schema": Rows.model_json_schema(),
            },
        },
    )

    return json.loads(completion.choices[0].message.content)["rows"]
```


```python
import weave

weave.init("leaderboard-demo")
```

## Step 2: Author scoring functions

Next we will author 3 scoring functions:

1. `check_concrete_fields`: Checks if the model output matches the expected city and state.
2. `check_value_fields`: Checks if the model output is within 10% of the expected population and median income.
3. `check_subjective_fields`: Uses a LLM to check if the model output matches the expected "known for" field.



```python
@weave.op
def check_concrete_fields(city: str, state: str, output: dict):
    return {
        "city_match": city == output["city"],
        "state_match": state == output["state"],
    }


@weave.op
def check_value_fields(
    avg_temp_f: float, population: int, median_income: int, output: dict
):
    return {
        "avg_temp_f_err": abs(avg_temp_f - output["avg_temp_f"]) / avg_temp_f,
        "population_err": abs(population - output["population"]) / population,
        "median_income_err": abs(median_income - output["median_income"])
        / median_income,
    }


@weave.op
def check_subjective_fields(zip_code: str, known_for: str, output: dict):
    client = OpenAI()

    class Response(BaseModel):
        correct_known_for: bool

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {
                "role": "user",
                "content": f"My student was asked what the zip code {zip_code} is best known best for. The right answer is '{known_for}', and they said '{output['known_for']}'. Is their answer correct?",
            },
        ],
        response_format={
            "type": "json_schema",
            "json_schema": {
                "name": "response_format",
                "schema": Response.model_json_schema(),
            },
        },
    )

    return json.loads(completion.choices[0].message.content)
```

## Step 3: Create a simple Evaluation

Next we define a simple evaliation using our fake data and scoring functions.



```python
rows = generate_dataset_rows()
evaluation = weave.Evaluation(
    name="United States - 2022",
    dataset=rows,
    scorers=[
        check_concrete_fields,
        check_value_fields,
        check_subjective_fields,
    ],
)
```

## Step 4: Evaluate a baseline model

Now we will evaluate a baseline model which returns a static response.



```python
@weave.op
def baseline_model(zip_code: str):
    return {
        "city": "New York",
        "state": "NY",
        "avg_temp_f": 50.0,
        "population": 1000000,
        "median_income": 100000,
        "known_for": "The Big Apple",
    }


await evaluation.evaluate(baseline_model)
```

## Step 5: Create more Models

Now we will create 2 more models to compare against the baseline.


```python
@weave.op
def gpt_4o_mini_no_context(zip_code: str):
    client = OpenAI()

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": f"""Zip code {zip_code}"""}],
        response_format={
            "type": "json_schema",
            "json_schema": {
                "name": "response_format",
                "schema": Row.model_json_schema(),
            },
        },
    )

    return json.loads(completion.choices[0].message.content)


await evaluation.evaluate(gpt_4o_mini_no_context)
```


```python
@weave.op
def gpt_4o_mini_with_context(zip_code: str):
    client = OpenAI()

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "user",
                "content": f"""Please answer the following questions about the zip code {zip_code}:
                   1. What is the city?
                   2. What is the state?
                   3. What is the average temperature in Fahrenheit?
                   4. What is the population?
                   5. What is the median income?
                   6. What is the most well known thing about this zip code?
                   """,
            }
        ],
        response_format={
            "type": "json_schema",
            "json_schema": {
                "name": "response_format",
                "schema": Row.model_json_schema(),
            },
        },
    )

    return json.loads(completion.choices[0].message.content)


await evaluation.evaluate(gpt_4o_mini_with_context)
```

## Step 6: Create more Evaluations

Now we will evaluate a matrix of models vs evaluations.



```python
scorers = [
    check_concrete_fields,
    check_value_fields,
    check_subjective_fields,
]
evaluations = [
    weave.Evaluation(
        name="United States - 2022",
        dataset=weave.Dataset(
            name="United States - 2022",
            rows=generate_dataset_rows("United States", 5, 2022),
        ),
        scorers=scorers,
    ),
    weave.Evaluation(
        name="California - 2022",
        dataset=weave.Dataset(
            name="California - 2022", rows=generate_dataset_rows("California", 5, 2022)
        ),
        scorers=scorers,
    ),
    weave.Evaluation(
        name="United States - 2000",
        dataset=weave.Dataset(
            name="United States - 2000",
            rows=generate_dataset_rows("United States", 5, 2000),
        ),
        scorers=scorers,
    ),
]
models = [
    baseline_model,
    gpt_4o_mini_no_context,
    gpt_4o_mini_with_context,
]

for evaluation in evaluations:
    for model in models:
        await evaluation.evaluate(
            model, __weave={"display_name": evaluation.name + ":" + model.__name__}
        )
```

## Step 7: Review the Leaderboard

You can create a new leaderboard by navigating to the leaderboard tab in the UI and clicking "Create Leaderboard".

We can also generate a leaderboard directly from Python:


```python
from weave.flow import leaderboard
from weave.trace.ref_util import get_ref

spec = leaderboard.Leaderboard(
    name="Zip Code World Knowledge",
    description="""
This leaderboard compares the performance of models in terms of world knowledge about zip codes.

### Columns

1. **State Match against `United States - 2022`**: The fraction of zip codes that the model correctly identified the state for.
2. **Avg Temp F Error against `California - 2022`**: The mean absolute error of the model's average temperature prediction.
3. **Correct Known For against `United States - 2000`**: The fraction of zip codes that the model correctly identified the most well known thing about the zip code.
""",
    columns=[
        leaderboard.LeaderboardColumn(
            evaluation_object_ref=get_ref(evaluations[0]).uri(),
            scorer_name="check_concrete_fields",
            summary_metric_path="state_match.true_fraction",
        ),
        leaderboard.LeaderboardColumn(
            evaluation_object_ref=get_ref(evaluations[1]).uri(),
            scorer_name="check_value_fields",
            should_minimize=True,
            summary_metric_path="avg_temp_f_err.mean",
        ),
        leaderboard.LeaderboardColumn(
            evaluation_object_ref=get_ref(evaluations[2]).uri(),
            scorer_name="check_subjective_fields",
            summary_metric_path="correct_known_for.true_fraction",
        ),
    ],
)

ref = weave.publish(spec)
```

[Source](https://weave-docs.wandb.ai/reference/gen_notebooks/leaderboard_quickstart)

