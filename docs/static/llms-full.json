[
  {
    "title": "Tutorial Eval",
    "url": "https://weave-docs.wandb.ai/tutorial-eval",
    "section": "Docs",
    "category": "Tutorials",
    "content": "# Tutorial: Build an Evaluation pipeline\n\nTo iterate on an application, we need a way to evaluate if it's improving. To do so, a common practice is to test it against the same set of examples when there is a change. Weave has a first-class way to track evaluations with `Model` & `Evaluation` classes. We have built the APIs to make minimal assumptions to allow for the flexibility to support a wide array of use-cases.\n\n\n\n## 1. Build a `Model`\n\n\n  \n\n`Model`s store and version information about your system, such as prompts, temperatures, and more.\nWeave automatically captures when they are used and updates the version when there are changes.\n\n`Model`s are declared by subclassing `Model` and implementing a `predict` function definition, which takes one example and returns the response.\n\n> \ud83d\udea8 **Important**: **Known Issue**: If you are using Google Colab, remove `async` from the following examples.\n\n\n    ```python\n    import json\n    import openai\n    import weave\n    class ExtractFruitsModel(weave.Model):\n        model_name: str\n        prompt_template: str\n        @weave.op()\n        async def predict(self, sentence: str) -> dict:\n            client = openai.AsyncClient()\n\n            response = await client.chat.completions.create(\n                model=self.model_name,\n                messages=[\n                    {\"role\": \"user\", \"content\": self.prompt_template.format(sentence=sentence)}\n                ],\n            )\n            result = response.choices[0].message.content\n            if result is None:\n                raise ValueError(\"No response from model\")\n            parsed = json.loads(result)\n            return parsed\n    ```\n\n    You can instantiate `Model` objects as normal like this:\n\n    ```python\n    import asyncio\n    import weave\n\n    weave.init('intro-example')\n\n    model = ExtractFruitsModel(model_name='gpt-3.5-turbo-1106',\n                            prompt_template='Extract fields (\"fruit\": , \"color\": , \"flavor\": ) from the following text, as json: {sentence}')\n    sentence = \"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.\"\n    print(asyncio.run(model.predict(sentence)))\n    # if you're in a Jupyter Notebook, run:\n    # await model.predict(sentence)\n    ```\n\n> \ud83d\udca1 **Note**: Checkout the [Models](/guides/core-types/models) guide to learn more.\n\n  \n  \n\n    `weave.Model` is not supported in TypeScript yet.  Instead, you can just wrap your model-like function with `weave.op`\n\n    ```typescript\n    // highlight-next-line\n    const model = weave.op(async function myModel({datasetRow}) {\n      const prompt = `Extract fields (\"fruit\": , \"color\": , \"flavor\") from the following text, as json: ${datasetRow.sentence}`;\n      const response = await openaiClient.chat.completions.create({\n        model: 'gpt-3.5-turbo',\n        messages: [{role: 'user', content: prompt}],\n        response_format: {type: 'json_object'},\n      });\n      const result = response?.choices?.[0]?.message?.content;\n      if (result == null) {\n        throw new Error('No response from model');\n      }\n      return JSON.parse(result);\n    });\n    ```\n\n  \n\n\n## 2. Collect some examples\n\n\n  \n\n    ```python\n    sentences = [\n        \"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.\",\n        \"Pounits are a bright green color and are more savory than sweet.\",\n        \"Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\"\n    ]\n    labels = [\n        {'fruit': 'neoskizzles', 'color': 'purple', 'flavor': 'candy'},\n        {'fruit': 'pounits', 'color': 'bright green', 'flavor': 'savory'},\n        {'fruit': 'glowls', 'color': 'pale orange', 'flavor': 'sour and bitter'}\n    ]\n    examples = [\n        {'id': '0', 'sentence': sentences[0], 'target': labels[0]},\n        {'id': '1', 'sentence': sentences[1], 'target': labels[1]},\n        {'id': '2', 'sentence': sentences[2], 'target': labels[2]}\n    ]\n    ```\n\n  \n  \n  \n    ```typescript\n    const sentences = [\n      'There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.',\n      'Pounits are a bright green color and are more savory than sweet.',\n      'Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.',\n    ];\n    const labels = [\n      {fruit: 'neoskizzles', color: 'purple', flavor: 'candy'},\n      {fruit: 'pounits', color: 'bright green', flavor: 'savory'},\n      {fruit: 'glowls', color: 'pale orange', flavor: 'sour and bitter'},\n    ];\n    const examples = [\n      {id: '0', sentence: sentences[0], target: labels[0]},\n      {id: '1', sentence: sentences[1], target: labels[1]},\n      {id: '2', sentence: sentences[2], target: labels[2]},\n    ];\n    const dataset = new weave.Dataset({\n      id: 'Fruit Dataset',\n      rows: examples,\n    });\n    ```\n  \n\n\n## 3. Evaluate a `Model`\n\n\n  \n\n`Evaluation`s assess a `Model`s performance on a set of examples using a list of specified scoring functions or `weave.scorer.Scorer` classes.\n\nHere, we'll use a default scoring class `MultiTaskBinaryClassificationF1` and we'll also define our own `fruit_name_score` scoring function.\n\nHere `sentence` is passed to the model's predict function, and `target` is used in the scoring function, these are inferred based on the argument names of the `predict` and scoring functions. The `fruit` key needs to be outputted by the model's predict function and must also be existing as a column in the dataset (or outputted by the `preprocess_model_input` function if defined).\n\n    ```python\n    import weave\n    from weave.scorers import MultiTaskBinaryClassificationF1\n\n    weave.init('intro-example')\n\n    @weave.op()\n    def fruit_name_score(target: dict, output: dict) -> dict:\n        return {'correct': target['fruit'] == output['fruit']}\n    evaluation = weave.Evaluation(\n        dataset=examples,\n        scorers=[\n            MultiTaskBinaryClassificationF1(class_names=[\"fruit\", \"color\", \"flavor\"]),\n            fruit_name_score\n        ],\n    )\n    print(asyncio.run(evaluation.evaluate(model)))\n    # if you're in a Jupyter Notebook, run:\n    # await evaluation.evaluate(model)\n    ```\n\n  \n  \n`Evaluation`s assess a model's performance on a set of examples using a list of specified scoring functions.\n\nFor this example, we'll define a few simple scoring functions.\n\nHere, `sentence` is passed to the model and `...` is used in the scoring function. These are defined...\n\n    ```typescript\n        \n    const client = await weave.init('intro-example');\n    const openaiClient = weave.wrapOpenAI(new OpenAI());\n\n    const fruitNameScorer = weave.op(\n      ({modelOutput, datasetRow}) => datasetRow.target.fruit == modelOutput.fruit,\n      {name: 'fruitNameScore'}\n    );\n\n    const evaluation = new weave.Evaluation({\n      dataset: ds,\n      scorers: [fruitNameScorer],\n    });\n\n    const results = await evaluation.evaluate(model);\n    console.log(JSON.stringify(results, null, 2));\n    ```\n\n  \n\n\nIn some applications we want to create custom `Scorer` classes - where for example a standardized `LLMJudge` class should be created with specific parameters (e.g. chat model, prompt), specific scoring of each row, and specific calculation of an aggregate score. See the tutorial on defining a `Scorer` class in the next chapter on [Model-Based Evaluation of RAG applications](/tutorial-rag#optional-defining-a-scorer-class) for more information.\n\n## 4. Pulling it all together\n\n\n  \n  \n    ```python\n    import json\n    import asyncio\n    import weave\n    from weave.scorers import MultiTaskBinaryClassificationF1\n    import openai\n\n    # We create a model class with one predict function.\n    # All inputs, predictions and parameters are automatically captured for easy inspection.\n    class ExtractFruitsModel(weave.Model):\n        model_name: str\n        prompt_template: str\n        @weave.op()\n        async def predict(self, sentence: str) -> dict:\n            client = openai.AsyncClient()\n\n            response = await client.chat.completions.create(\n                model=self.model_name,\n                messages=[\n                    {\"role\": \"user\", \"content\": self.prompt_template.format(sentence=sentence)}\n                ],\n                response_format={ \"type\": \"json_object\" }\n            )\n            result = response.choices[0].message.content\n            if result is None:\n                raise ValueError(\"No response from model\")\n            parsed = json.loads(result)\n            return parsed\n\n    # We call init to begin capturing data in the project, intro-example.\n    weave.init('intro-example')\n\n    # We create our model with our system prompt.\n    model = ExtractFruitsModel(name='gpt4',\n                            model_name='gpt-4-0125-preview',\n                            prompt_template='Extract fields (\"fruit\": , \"color\": , \"flavor\") from the following text, as json: {sentence}')\n    sentences = [\"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.\",\n    \"Pounits are a bright green color and are more savory than sweet.\",\n    \"Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\"]\n    labels = [\n        {'fruit': 'neoskizzles', 'color': 'purple', 'flavor': 'candy'},\n        {'fruit': 'pounits', 'color': 'bright green', 'flavor': 'savory'},\n        {'fruit': 'glowls', 'color': 'pale orange', 'flavor': 'sour and bitter'}\n    ]\n    examples = [\n        {'id': '0', 'sentence': sentences[0], 'target': labels[0]},\n        {'id': '1', 'sentence': sentences[1], 'target': labels[1]},\n        {'id': '2', 'sentence': sentences[2], 'target': labels[2]}\n    ]\n    # If you have already published the Dataset, you can run:\n    # dataset = weave.ref('example_labels').get()\n\n    # We define a scoring function to compare our model predictions with a ground truth label.\n    @weave.op()\n    def fruit_name_score(target: dict, output: dict) -> dict:\n        return {'correct': target['fruit'] == output['fruit']}\n\n    # Finally, we run an evaluation of this model.\n    # This will generate a prediction for each input example, and then score it with each scoring function.\n    evaluation = weave.Evaluation(\n        name='fruit_eval',\n        dataset=examples, scorers=[MultiTaskBinaryClassificationF1(class_names=[\"fruit\", \"color\", \"flavor\"]), fruit_name_score],\n    )\n    print(asyncio.run(evaluation.evaluate(model)))\n    # if you're in a Jupyter Notebook, run:\n    # await evaluation.evaluate(model)\n    ```\n\n  \n  \n\n    ```typescript\n        import 'source-map-support/register';\n    \n    const sentences = [\n      'There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.',\n      'Pounits are a bright green color and are more savory than sweet.',\n      'Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.',\n      'There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.',\n    ];\n    const labels = [\n      {fruit: 'neoskizzles', color: 'purple', flavor: 'candy'},\n      {fruit: 'pounits', color: 'bright green', flavor: 'savory'},\n      {fruit: 'glowls', color: 'pale orange', flavor: 'sour and bitter'},\n    ];\n    const examples = [\n      {id: '0', sentence: sentences[0], target: labels[0]},\n      {id: '1', sentence: sentences[1], target: labels[1]},\n      {id: '2', sentence: sentences[2], target: labels[2]},\n    ];\n    const dataset = new weave.Dataset({\n      id: 'Fruit Dataset',\n      rows: examples,\n    });\n\n    const openaiClient = weave.wrapOpenAI(new OpenAI());\n\n    const model = weave.op(async function myModel({datasetRow}) {\n      const prompt = `Extract fields (\"fruit\": , \"color\": , \"flavor\") from the following text, as json: ${datasetRow.sentence}`;\n      const response = await openaiClient.chat.completions.create({\n        model: 'gpt-3.5-turbo',\n        messages: [{role: 'user', content: prompt}],\n        response_format: {type: 'json_object'},\n      });\n      const result = response?.choices?.[0]?.message?.content;\n      if (result == null) {\n        throw new Error('No response from model');\n      }\n      return JSON.parse(result);\n    });\n\n    const fruitNameScorer = weave.op(\n      ({modelOutput, datasetRow}) => datasetRow.target.fruit == modelOutput.fruit,\n      {name: 'fruitNameScore'}\n    );\n\n    async function main() {\n      await weave.init('examples');\n      const evaluation = new weave.Evaluation({\n        dataset,\n        scorers: [fruitNameScorer],\n      });\n\n      const results = await evaluation.evaluate({model});\n      console.log(JSON.stringify(results, null, 2));\n    }\n\n    main();\n\n    ```\n\n  \n\n\n## What's next?\n\n- Follow the [Model-Based Evaluation of RAG applications](/tutorial-rag) to evaluate a RAG app using an LLM judge."
  },
  {
    "title": "Tutorial Rag",
    "url": "https://weave-docs.wandb.ai/tutorial-rag",
    "section": "Docs",
    "category": "Tutorials",
    "content": "# Tutorial: Model-Based Evaluation of RAG applications\n\nRetrieval Augmented Generation (RAG) is a common way of building Generative AI applications that have access to custom knowledge bases.\n\nIn this example, we'll show an example that has a retrieval step to get documents. By tracking this, you can debug your app and see what documents were pulled into the LLM context.\nWe'll also show how to evaluate it using an LLM judge.\n\n\n\nCheck out the [RAG++ course](https://www.wandb.courses/courses/rag-in-production?utm_source=wandb_docs&utm_medium=code&utm_campaign=weave_docs) for a more advanced dive into practical RAG techniques for engineers, where you'll learn production-ready solutions from Weights & Biases, Cohere and Weaviate to optimize performance, cut costs, and enhance the accuracy and relevance of your applications.\n\n## 1. Build a knowledge base\n\nFirst, we compute the embeddings for our articles. You would typically do this once with your articles and put the embeddings & metadata in a database, but here we're doing it every time we run our script for simplicity.\n\n\n  \n    ```python\n    from openai import OpenAI\n    import weave\n    from weave import Model\n    import numpy as np\n    import json\n    import asyncio\n\n    articles = [\n        \"Novo Nordisk and Eli Lilly rival soars 32 percent after promising weight loss drug results Shares of Denmarks Zealand Pharma shot 32 percent higher in morning trade, after results showed success in its liver disease treatment survodutide, which is also on trial as a drug to treat obesity. The trial \u201ctells us that the 6mg dose is safe, which is the top dose used in the ongoing [Phase 3] obesity trial too,\u201d one analyst said in a note. The results come amid feverish investor interest in drugs that can be used for weight loss.\",\n        \"Berkshire shares jump after big profit gain as Buffetts conglomerate nears $1 trillion valuation Berkshire Hathaway shares rose on Monday after Warren Buffetts conglomerate posted strong earnings for the fourth quarter over the weekend. Berkshires Class A and B shares jumped more than 1.5%, each. Class A shares are higher by more than 17% this year, while Class B has gained more than 18%. Berkshire was last valued at $930.1 billion, up from $905.5 billion where it closed on Friday, according to FactSet. Berkshire on Saturday posted fourth-quarter operating earnings of $8.481 billion, about 28 percent higher than the $6.625 billion from the year-ago period, driven by big gains in its insurance business. Operating earnings refers to profits from businesses across insurance, railroads and utilities. Meanwhile, Berkshires cash levels also swelled to record levels. The conglomerate held $167.6 billion in cash in the fourth quarter, surpassing the $157.2 billion record the conglomerate held in the prior quarter.\",\n        \"Highmark Health says its combining tech from Google and Epic to give doctors easier access to information Highmark Health announced it is integrating technology from Google Cloud and the health-care software company Epic Systems. The integration aims to make it easier for both payers and providers to access key information they need, even if its stored across multiple points and formats, the company said. Highmark is the parent company of a health plan with 7 million members, a provider network of 14 hospitals and other entities\",\n        \"Rivian and Lucid shares plunge after weak EV earnings reports Shares of electric vehicle makers Rivian and Lucid fell Thursday after the companies reported stagnant production in their fourth-quarter earnings after the bell Wednesday. Rivian shares sank about 25 percent, and Lucids stock dropped around 17 percent. Rivian forecast it will make 57,000 vehicles in 2024, slightly less than the 57,232 vehicles it produced in 2023. Lucid said it expects to make 9,000 vehicles in 2024, more than the 8,428 vehicles it made in 2023.\",\n        \"Mauritius blocks Norwegian cruise ship over fears of a potential cholera outbreak Local authorities on Sunday denied permission for the Norwegian Dawn ship, which has 2,184 passengers and 1,026 crew on board, to access the Mauritius capital of Port Louis, citing \u201cpotential health risks.\u201d The Mauritius Ports Authority said Sunday that samples were taken from at least 15 passengers on board the cruise ship. A spokesperson for the U.S.-headquartered Norwegian Cruise Line Holdings said Sunday that 'a small number of guests experienced mild symptoms of a stomach-related illness' during Norwegian Dawns South Africa voyage.\",\n        \"Intuitive Machines lands on the moon in historic first for a U.S. company Intuitive Machines Nova-C cargo lander, named Odysseus after the mythological Greek hero, is the first U.S. spacecraft to soft land on the lunar surface since 1972. Intuitive Machines is the first company to pull off a moon landing \u2014 government agencies have carried out all previously successful missions. The company's stock surged in extended trading Thursday, after falling 11 percent in regular trading.\",\n        \"Lunar landing photos: Intuitive Machines Odysseus sends back first images from the moon Intuitive Machines cargo moon lander Odysseus returned its first images from the surface. Company executives believe the lander caught its landing gear sideways on the moon's surface while touching down and tipped over. Despite resting on its side, the company's historic IM-1 mission is still operating on the moon.\",\n    ]\n\n    def docs_to_embeddings(docs: list) -> list:\n        openai = OpenAI()\n        document_embeddings = []\n        for doc in docs:\n            response = (\n                openai.embeddings.create(input=doc, model=\"text-embedding-3-small\")\n                .data[0]\n                .embedding\n            )\n            document_embeddings.append(response)\n        return document_embeddings\n\n    article_embeddings = docs_to_embeddings(articles) # Note: you would typically do this once with your articles and put the embeddings & metadata in a database\n    ```\n\n  \n  \n    ```typescript\n    require('dotenv').config();\n        \n    interface Article {\n        text: string;\n        embedding?: number[];\n    }\n\n    const articles: Article[] = [\n        { \n            text: `Novo Nordisk and Eli Lilly rival soars 32 percent...` // truncated for brevity\n        },\n        // ... other articles\n    ];\n\n    function cosineSimilarity(a: number[], b: number[]): number {\n        const dotProduct = a.reduce((sum, val, i) => sum + val * b[i], 0);\n        const magnitudeA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));\n        const magnitudeB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));\n        return dotProduct / (magnitudeA * magnitudeB);\n    }\n\n    const docsToEmbeddings = weave.op(async function(docs: Article[]): Promise {\n        const openai = new OpenAI();\n        const enrichedDocs = await Promise.all(docs.map(async (doc) => {\n            const response = await openai.embeddings.create({\n                input: doc.text,\n                model: \"text-embedding-3-small\"\n            });\n            return {\n                ...doc,\n                embedding: response.data[0].embedding\n            };\n        }));\n        return enrichedDocs;\n    });\n    ```\n  \n\n\n## 2. Create a RAG app\n\nNext, we wrap our retrieval function `get_most_relevant_document` with a `weave.op()` decorator and we create our `Model` class. We call `weave.init('rag-qa')` to begin tracking all the inputs and outputs of our functions for later inspection.\n\n\n  \n    ```python\n    from openai import OpenAI\n    import weave\n    from weave import Model\n    import numpy as np\n    import asyncio\n    @weave.op()\n    def get_most_relevant_document(query):\n        openai = OpenAI()\n        query_embedding = (\n            openai.embeddings.create(input=query, model=\"text-embedding-3-small\")\n            .data[0]\n            .embedding\n        )\n        similarities = [\n            np.dot(query_embedding, doc_emb)\n            / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb))\n            for doc_emb in article_embeddings\n        ]\n        # Get the index of the most similar document\n        most_relevant_doc_index = np.argmax(similarities)\n        return articles[most_relevant_doc_index]\n    class RAGModel(Model):\n        system_message: str\n        model_name: str = \"gpt-3.5-turbo-1106\"\n        @weave.op()\n        def predict(self, question: str) -> dict: # note: `question` will be used later to select data from our evaluation rows\n            from openai import OpenAI\n            context = get_most_relevant_document(question)\n            client = OpenAI()\n            query = f\"\"\"Use the following information to answer the subsequent question. If the answer cannot be found, write \"I don't know.\"\n            Context:\n            \\\"\\\"\\\"\n            {context}\n            \\\"\\\"\\\"\n            Question: {question}\"\"\"\n            response = client.chat.completions.create(\n                model=self.model_name,\n                messages=[\n                    {\"role\": \"system\", \"content\": self.system_message},\n                    {\"role\": \"user\", \"content\": query},\n                ],\n                temperature=0.0,\n                response_format={\"type\": \"text\"},\n            )\n            answer = response.choices[0].message.content\n            return {'answer': answer, 'context': context}\n    weave.init('rag-qa')\n    model = RAGModel(\n        system_message=\"You are an expert in finance and answer questions related to finance, financial services, and financial markets. When responding based on provided information, be sure to cite the source.\"\n    )\n    model.predict(\"What significant result was reported about Zealand Pharma's obesity trial?\")\n    ```\n\n  \n  \n    ```typescript\n    class RAGModel {\n        private openai: OpenAI;\n        private systemMessage: string;\n        private modelName: string;\n        private articleEmbeddings: Article[];\n\n        constructor(config: {\n            systemMessage: string;\n            modelName?: string;\n            articleEmbeddings: Article[];\n        }) {\n            this.openai = weave.wrapOpenAI(new OpenAI());\n            this.systemMessage = config.systemMessage;\n            this.modelName = config.modelName || \"gpt-3.5-turbo-1106\";\n            this.articleEmbeddings = config.articleEmbeddings;\n            this.predict = weave.op(this, this.predict);\n        }\n\n        async predict(question: string): Promise<{\n            answer: string;\n            context: string;\n        }> {\n            const context = await this.getMostRelevantDocument(question);\n            \n            const response = await this.openai.chat.completions.create({\n                model: this.modelName,\n                messages: [\n                    { role: \"system\", content: this.systemMessage },\n                    { role: \"user\", content: `Use the following information...` }\n                ],\n                temperature: 0\n            });\n\n            return {\n                answer: response.choices[0].message.content || \"\",\n                context\n            };\n        }\n    }\n    ```\n  \n\n\n## 3. Evaluating with an LLM Judge\n\nWhen there aren't simple ways to evaluate your application, one approach is to use an LLM to evaluate aspects of it. Here is an example of using an LLM judge to try to measure the context precision by prompting it to verify if the context was useful in arriving at the given answer. This prompt was augmented from the popular [RAGAS framework](https://docs.ragas.io/).\n\n### Defining a scoring function\n\nAs we did in the [Build an Evaluation pipeline tutorial](/tutorial-eval), we'll define a set of example rows to test our app against and a scoring function. Our scoring function will take one row and evaluate it. The input arguments should match with the corresponding keys in our row, so `question` here will be taken from the row dictionary. `output` is the output of the model. The input to the model will be taken from the example based on its input argument, so `question` here too. We're using `async` functions so they run fast in parallel. If you need a quick introduction to async, you can find one [here](https://docs.python.org/3/library/asyncio.html).\n\n\n  \n    ```python\n    from openai import OpenAI\n    import weave\n    import asyncio\n    @weave.op()\n    async def context_precision_score(question, output):\n        context_precision_prompt = \"\"\"Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.\n        Output in only valid JSON format.\n\n        question: {question}\n        context: {context}\n        answer: {answer}\n        verdict: \"\"\"\n        client = OpenAI()\n\n        prompt = context_precision_prompt.format(\n            question=question,\n            context=output['context'],\n            answer=output['answer'],\n        )\n\n        response = client.chat.completions.create(\n            model=\"gpt-4-turbo-preview\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            response_format={ \"type\": \"json_object\" }\n        )\n        response_message = response.choices[0].message\n        response = json.loads(response_message.content)\n        return {\n            \"verdict\": int(response[\"verdict\"]) == 1,\n        }\n\n    questions = [\n        {\"question\": \"What significant result was reported about Zealand Pharma's obesity trial?\"},\n        {\"question\": \"How much did Berkshire Hathaway's cash levels increase in the fourth quarter?\"},\n        {\"question\": \"What is the goal of Highmark Health's integration of Google Cloud and Epic Systems technology?\"},\n        {\"question\": \"What were Rivian and Lucid's vehicle production forecasts for 2024?\"},\n        {\"question\": \"Why was the Norwegian Dawn cruise ship denied access to Mauritius?\"},\n        {\"question\": \"Which company achieved the first U.S. moon landing since 1972?\"},\n        {\"question\": \"What issue did Intuitive Machines' lunar lander encounter upon landing on the moon?\"}\n    ]\n    evaluation = weave.Evaluation(dataset=questions, scorers=[context_precision_score])\n    asyncio.run(evaluation.evaluate(model)) # note: you'll need to define a model to evaluate\n    ```\n\n  \n  \n    ```typescript\n    const contextPrecisionScore = weave.op(async function(args: {\n        datasetRow: QuestionRow;\n        modelOutput: { answer: string; context: string; }\n    }): Promise {\n        const openai = new OpenAI();\n        \n        const prompt = `Given question, answer and context verify if the context was useful...`;\n\n        const response = await openai.chat.completions.create({\n            model: \"gpt-4-turbo-preview\",\n            messages: [{ role: \"user\", content: prompt }],\n            response_format: { type: \"json_object\" }\n        });\n\n        const result = JSON.parse(response.choices[0].message.content || \"{}\");\n        return {\n            verdict: parseInt(result.verdict) === 1\n        };\n    });\n\n    const evaluation = new weave.Evaluation({\n        dataset: createQuestionDataset(),\n        scorers: [contextPrecisionScore]\n    });\n\n    await evaluation.evaluate({\n        model: weave.op((args: { datasetRow: QuestionRow }) => \n            model.predict(args.datasetRow.question)\n        )\n    });\n    ```\n  \n\n\n### Optional: Defining a `Scorer` class\n\nIn some applications we want to create custom evaluation classes - where for example a standardized `LLMJudge` class should be created with specific parameters (e.g. chat model, prompt), specific scoring of each row, and specific calculation of an aggregate score. In order to do that Weave defines a list of ready-to-use `Scorer` classes and also makes it easy to create a custom `Scorer` - in the following we'll see how to create a custom `class CorrectnessLLMJudge(Scorer)`.\n\nOn a high-level the steps to create custom Scorer are quite simple:\n\n1. Define a custom class that inherits from `weave.flow.scorer.Scorer`\n2. Overwrite the `score` function and add a `@weave.op()` if you want to track each call of the function\n   - this function has to define an `output` argument where the prediction of the model will be passed to. We define it as type `Optional[dict]` in case the mode might return \"None\".\n   - the rest of the arguments can either be a general `Any` or `dict` or can select specific columns from the dataset that is used to evaluate the model using the `weave.Evaluate` class - they have to have the exact same names as the column names or keys of a single row after being passed to `preprocess_model_input` if that is used.\n3. _Optional:_ Overwrite the `summarize` function to customize the calculation of the aggregate score. By default Weave uses the `weave.flow.scorer.auto_summarize` function if you don't define a custom function.\n   - this function has to have a `@weave.op()` decorator.\n\n\n  \n    ```python\n    from weave import Scorer\n    from weave import WeaveList\n\n    class CorrectnessLLMJudge(Scorer):\n        prompt: str\n        model_name: str\n        device: str\n\n        @weave.op()\n        async def score(self, output: Optional[dict], query: str, answer: str) -> Any:\n            \"\"\"Score the correctness of the predictions by comparing the pred, query, target.\n            Args:\n                - output: the dict that will be provided by the model that is evaluated\n                - query: the question asked - as defined in the dataset\n                - answer: the target answer - as defined in the dataset\n            Returns:\n                - single dict {metric name: single evaluation value}\"\"\"\n\n            # get_model is defined as general model getter based on provided params (OpenAI,HF...)\n            eval_model = get_model(\n                model_name = self.model_name,\n                prompt = self.prompt\n                device = self.device,\n            )\n            # async evaluation to speed up evaluation - this doesn't have to be async\n            grade = await eval_model.async_predict(\n                {\n                    \"query\": query,\n                    \"answer\": answer,\n                    \"result\": output.get(\"result\"),\n                }\n            )\n            # output parsing - could be done more reobustly with pydantic\n            evaluation = \"incorrect\" not in grade[\"text\"].strip().lower()\n\n            # the column name displayed in Weave\n            return {\"correct\": evaluation}\n\n        @weave.op()\n        def summarize(self, score_rows: WeaveList) -> Optional[dict]:\n            \"\"\"Aggregate all the scores that are calculated for each row by the scoring function.\n            Args:\n                - score_rows: a WeaveList object, nested dict of metrics and scores\n            Returns:\n                - nested dict with the same structure as the input\"\"\"\n\n            # if nothing is provided the weave.flow.scorer.auto_summarize function is used\n            # return auto_summarize(score_rows)\n\n            valid_data = [x.get(\"correct\") for x in score_rows if x.get(\"correct\") is not None]\n            count_true = list(valid_data).count(True)\n            int_data = [int(x) for x in valid_data]\n\n            sample_mean = np.mean(int_data) if int_data else 0\n            sample_variance = np.var(int_data) if int_data else 0\n            sample_error = np.sqrt(sample_variance / len(int_data)) if int_data else 0\n\n            # the extra \"correct\" layer is not necessary but adds structure in the UI\n            return {\n                \"correct\": {\n                    \"true_count\": count_true,\n                    \"true_fraction\": sample_mean,\n                    \"stderr\": sample_error,\n                }\n            }\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\nTo use this as a scorer, you would initialize it and pass it to `scorers` argument in your `Evaluation like this:\n\n\n  \n    ```python\n    evaluation = weave.Evaluation(dataset=questions, scorers=[CorrectnessLLMJudge()])\n    ```\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n## 4. Pulling it all together\n\nTo get the same result for your RAG apps:\n\n- Wrap LLM calls & retrieval step functions with `weave.op()`\n- (optional) Create a `Model` subclass with `predict` function and app details\n- Collect examples to evaluate\n- Create scoring functions that score one example\n- Use `Evaluation` class to run evaluations on your examples\n\n**NOTE:** Sometimes the async execution of Evaluations will trigger a rate limit on the models of OpenAI, Anthropic, etc. To prevent that you can set an environment variable to limit the amount of parallel workers e.g. `WEAVE_PARALLELISM=3`.\n\nHere, we show the code in it's entirety.\n\n\n  \n    ```python\n    from openai import OpenAI\n    import weave\n    from weave import Model\n    import numpy as np\n    import json\n    import asyncio\n\n    # Examples we've gathered that we want to use for evaluations\n    articles = [\n        \"Novo Nordisk and Eli Lilly rival soars 32 percent after promising weight loss drug results Shares of Denmarks Zealand Pharma shot 32 percent higher in morning trade, after results showed success in its liver disease treatment survodutide, which is also on trial as a drug to treat obesity. The trial \u201ctells us that the 6mg dose is safe, which is the top dose used in the ongoing [Phase 3] obesity trial too,\u201d one analyst said in a note. The results come amid feverish investor interest in drugs that can be used for weight loss.\",\n        \"Berkshire shares jump after big profit gain as Buffetts conglomerate nears $1 trillion valuation Berkshire Hathaway shares rose on Monday after Warren Buffetts conglomerate posted strong earnings for the fourth quarter over the weekend. Berkshires Class A and B shares jumped more than 1.5%, each. Class A shares are higher by more than 17% this year, while Class B has gained more than 18%. Berkshire was last valued at $930.1 billion, up from $905.5 billion where it closed on Friday, according to FactSet. Berkshire on Saturday posted fourth-quarter operating earnings of $8.481 billion, about 28 percent higher than the $6.625 billion from the year-ago period, driven by big gains in its insurance business. Operating earnings refers to profits from businesses across insurance, railroads and utilities. Meanwhile, Berkshires cash levels also swelled to record levels. The conglomerate held $167.6 billion in cash in the fourth quarter, surpassing the $157.2 billion record the conglomerate held in the prior quarter.\",\n        \"Highmark Health says its combining tech from Google and Epic to give doctors easier access to information Highmark Health announced it is integrating technology from Google Cloud and the health-care software company Epic Systems. The integration aims to make it easier for both payers and providers to access key information they need, even if it's stored across multiple points and formats, the company said. Highmark is the parent company of a health plan with 7 million members, a provider network of 14 hospitals and other entities\",\n        \"Rivian and Lucid shares plunge after weak EV earnings reports Shares of electric vehicle makers Rivian and Lucid fell Thursday after the companies reported stagnant production in their fourth-quarter earnings after the bell Wednesday. Rivian shares sank about 25 percent, and Lucids stock dropped around 17 percent. Rivian forecast it will make 57,000 vehicles in 2024, slightly less than the 57,232 vehicles it produced in 2023. Lucid said it expects to make 9,000 vehicles in 2024, more than the 8,428 vehicles it made in 2023.\",\n        \"Mauritius blocks Norwegian cruise ship over fears of a potential cholera outbreak Local authorities on Sunday denied permission for the Norwegian Dawn ship, which has 2,184 passengers and 1,026 crew on board, to access the Mauritius capital of Port Louis, citing \u201cpotential health risks.\u201d The Mauritius Ports Authority said Sunday that samples were taken from at least 15 passengers on board the cruise ship. A spokesperson for the U.S.-headquartered Norwegian Cruise Line Holdings said Sunday that 'a small number of guests experienced mild symptoms of a stomach-related illness' during Norwegian Dawns South Africa voyage.\",\n        \"Intuitive Machines lands on the moon in historic first for a U.S. company Intuitive Machines Nova-C cargo lander, named Odysseus after the mythological Greek hero, is the first U.S. spacecraft to soft land on the lunar surface since 1972. Intuitive Machines is the first company to pull off a moon landing \u2014 government agencies have carried out all previously successful missions. The company's stock surged in extended trading Thursday, after falling 11 percent in regular trading.\",\n        \"Lunar landing photos: Intuitive Machines Odysseus sends back first images from the moon Intuitive Machines cargo moon lander Odysseus returned its first images from the surface. Company executives believe the lander caught its landing gear sideways on the surface of the moon while touching down and tipped over. Despite resting on its side, the company's historic IM-1 mission is still operating on the moon.\",\n    ]\n\n    def docs_to_embeddings(docs: list) -> list:\n        openai = OpenAI()\n        document_embeddings = []\n        for doc in docs:\n            response = (\n                openai.embeddings.create(input=doc, model=\"text-embedding-3-small\")\n                .data[0]\n                .embedding\n            )\n            document_embeddings.append(response)\n        return document_embeddings\n\n    article_embeddings = docs_to_embeddings(articles) # Note: you would typically do this once with your articles and put the embeddings & metadata in a database\n\n    # We've added a decorator to our retrieval step\n    @weave.op()\n    def get_most_relevant_document(query):\n        openai = OpenAI()\n        query_embedding = (\n            openai.embeddings.create(input=query, model=\"text-embedding-3-small\")\n            .data[0]\n            .embedding\n        )\n        similarities = [\n            np.dot(query_embedding, doc_emb)\n            / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb))\n            for doc_emb in article_embeddings\n        ]\n        # Get the index of the most similar document\n        most_relevant_doc_index = np.argmax(similarities)\n        return articles[most_relevant_doc_index]\n\n    # We create a Model subclass with some details about our app, along with a predict function that produces a response\n    class RAGModel(Model):\n        system_message: str\n        model_name: str = \"gpt-3.5-turbo-1106\"\n        @weave.op()\n        def predict(self, question: str) -> dict: # note: `question` will be used later to select data from our evaluation rows\n            from openai import OpenAI\n            context = get_most_relevant_document(question)\n            client = OpenAI()\n            query = f\"\"\"Use the following information to answer the subsequent question. If the answer cannot be found, write \"I don't know.\"\n            Context:\n            \\\"\\\"\\\"\n            {context}\n            \\\"\\\"\\\"\n            Question: {question}\"\"\"\n            response = client.chat.completions.create(\n                model=self.model_name,\n                messages=[\n                    {\"role\": \"system\", \"content\": self.system_message},\n                    {\"role\": \"user\", \"content\": query},\n                ],\n                temperature=0.0,\n                response_format={\"type\": \"text\"},\n            )\n            answer = response.choices[0].message.content\n            return {'answer': answer, 'context': context}\n    weave.init('rag-qa')\n    model = RAGModel(\n        system_message=\"You are an expert in finance and answer questions related to finance, financial services, and financial markets. When responding based on provided information, be sure to cite the source.\"\n    )\n\n    # Here is our scoring function uses our question and output to product a score\n    @weave.op()\n    async def context_precision_score(question, output):\n        context_precision_prompt = \"\"\"Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.\n        Output in only valid JSON format.\n\n        question: {question}\n        context: {context}\n        answer: {answer}\n        verdict: \"\"\"\n        client = OpenAI()\n\n        prompt = context_precision_prompt.format(\n            question=question,\n            context=output['context'],\n            answer=output['answer'],\n        )\n\n        response = client.chat.completions.create(\n            model=\"gpt-4-turbo-preview\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            response_format={ \"type\": \"json_object\" }\n        )\n        response_message = response.choices[0].message\n        response = json.loads(response_message.content)\n        return {\n            \"verdict\": int(response[\"verdict\"]) == 1,\n        }\n\n    questions = [\n        {\"question\": \"What significant result was reported about Zealand Pharma's obesity trial?\"},\n        {\"question\": \"How much did Berkshire Hathaway's cash levels increase in the fourth quarter?\"},\n        {\"question\": \"What is the goal of Highmark Health's integration of Google Cloud and Epic Systems technology?\"},\n        {\"question\": \"What were Rivian and Lucid's vehicle production forecasts for 2024?\"},\n        {\"question\": \"Why was the Norwegian Dawn cruise ship denied access to Mauritius?\"},\n        {\"question\": \"Which company achieved the first U.S. moon landing since 1972?\"},\n        {\"question\": \"What issue did Intuitive Machines' lunar lander encounter upon landing on the moon?\"}\n    ]\n\n    # We define an Evaluation object and pass our example questions along with scoring functions\n    evaluation = weave.Evaluation(dataset=questions, scorers=[context_precision_score])\n    asyncio.run(evaluation.evaluate(model))\n    ```\n\n  \n  \n    ```typescript\n    require('dotenv').config();\n        \n    interface Article {\n        text: string;\n        embedding?: number[];\n    }\n\n    const articles: Article[] = [\n        { \n            text: `Novo Nordisk and Eli Lilly rival soars 32 percent after promising weight loss drug results Shares of Denmarks Zealand Pharma shot 32 percent higher in morning trade, after results showed success in its liver disease treatment survodutide, which is also on trial as a drug to treat obesity. The trial tells us that the 6mg dose is safe, which is the top dose used in the ongoing [Phase 3] obesity trial too, one analyst said in a note. The results come amid feverish investor interest in drugs that can be used for weight loss.`\n        },\n        { \n            text: `Berkshire shares jump after big profit gain as Buffetts conglomerate nears $1 trillion valuation Berkshire Hathaway shares rose on Monday after Warren Buffetts conglomerate posted strong earnings for the fourth quarter over the weekend. Berkshires Class A and B shares jumped more than 1.5%, each. Class A shares are higher by more than 17% this year, while Class B has gained more than 18%. Berkshire was last valued at $930.1 billion, up from $905.5 billion where it closed on Friday, according to FactSet. Berkshire on Saturday posted fourth-quarter operating earnings of $8.481 billion, about 28 percent higher than the $6.625 billion from the year-ago period, driven by big gains in its insurance business. Operating earnings refers to profits from businesses across insurance, railroads and utilities. Meanwhile, Berkshires cash levels also swelled to record levels. The conglomerate held $167.6 billion in cash in the fourth quarter, surpassing the $157.2 billion record the conglomerate held in the prior quarter.`\n        },\n        { \n            text: `Highmark Health says its combining tech from Google and Epic to give doctors easier access to information Highmark Health announced it is integrating technology from Google Cloud and the health-care software company Epic Systems. The integration aims to make it easier for both payers and providers to access key information they need, even if its stored across multiple points and formats, the company said. Highmark is the parent company of a health plan with 7 million members, a provider network of 14 hospitals and other entities`\n        }\n    ];\n\n    function cosineSimilarity(a: number[], b: number[]): number {\n        const dotProduct = a.reduce((sum, val, i) => sum + val * b[i], 0);\n        const magnitudeA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));\n        const magnitudeB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));\n        return dotProduct / (magnitudeA * magnitudeB);\n    }\n\n    const docsToEmbeddings = weave.op(async function(docs: Article[]): Promise {\n        const openai = new OpenAI();\n        const enrichedDocs = await Promise.all(docs.map(async (doc) => {\n            const response = await openai.embeddings.create({\n                input: doc.text,\n                model: \"text-embedding-3-small\"\n            });\n            return {\n                ...doc,\n                embedding: response.data[0].embedding\n            };\n        }));\n        return enrichedDocs;\n    });\n\n    class RAGModel {\n        private openai: OpenAI;\n        private systemMessage: string;\n        private modelName: string;\n        private articleEmbeddings: Article[];\n\n        constructor(config: {\n            systemMessage: string;\n            modelName?: string;\n            articleEmbeddings: Article[];\n        }) {\n            this.openai = weave.wrapOpenAI(new OpenAI());\n            this.systemMessage = config.systemMessage;\n            this.modelName = config.modelName || \"gpt-3.5-turbo-1106\";\n            this.articleEmbeddings = config.articleEmbeddings;\n            this.predict = weave.op(this, this.predict);\n        }\n\n        private async getMostRelevantDocument(query: string): Promise {\n            const queryEmbedding = await this.openai.embeddings.create({\n                input: query,\n                model: \"text-embedding-3-small\"\n            });\n\n            const similarities = this.articleEmbeddings.map(doc => {\n                if (!doc.embedding) return 0;\n                return cosineSimilarity(queryEmbedding.data[0].embedding, doc.embedding);\n            });\n\n            const mostRelevantIndex = similarities.indexOf(Math.max(...similarities));\n            return this.articleEmbeddings[mostRelevantIndex].text;\n        }\n\n        async predict(question: string): Promise<{\n            answer: string;\n            context: string;\n        }> {\n            const context = await this.getMostRelevantDocument(question);\n            \n            const response = await this.openai.chat.completions.create({\n                model: this.modelName,\n                messages: [\n                    { role: \"system\", content: this.systemMessage },\n                    { \n                        role: \"user\", \n                        content: `Use the following information to answer the subsequent question. If the answer cannot be found, write \"I don't know.\"\n                        Context:\n                        \"\"\"\n                        ${context}\n                        \"\"\"\n                        Question: ${question}`\n                    }\n                ],\n                temperature: 0\n            });\n\n            return {\n                answer: response.choices[0].message.content || \"\",\n                context\n            };\n        }\n    }\n\n    interface ScorerResult {\n        verdict: boolean;\n    }\n\n    interface QuestionRow {\n        question: string;\n    }\n\n    function createQuestionDataset(): weave.Dataset {\n        return new weave.Dataset({\n            id: 'rag-questions',\n            rows: [\n                { question: \"What significant result was reported about Zealand Pharma's obesity trial?\" },\n                { question: \"How much did Berkshire Hathaway's cash levels increase in the fourth quarter?\" },\n                { question: \"What is the goal of Highmark Health's integration of Google Cloud and Epic Systems technology?\" }\n            ]\n        });\n    }\n\n    const contextPrecisionScore = weave.op(async function(args: {\n        datasetRow: QuestionRow;\n        modelOutput: { answer: string; context: string; }\n    }): Promise {\n        const openai = new OpenAI();\n        \n        const prompt = `Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.\n        Output in only valid JSON format.\n\n        question: ${args.datasetRow.question}\n        context: ${args.modelOutput.context}\n        answer: ${args.modelOutput.answer}\n        verdict: `;\n\n        const response = await openai.chat.completions.create({\n            model: \"gpt-4-turbo-preview\",\n            messages: [{ role: \"user\", content: prompt }],\n            response_format: { type: \"json_object\" }\n        });\n\n        const result = JSON.parse(response.choices[0].message.content || \"{}\");\n        return {\n            verdict: parseInt(result.verdict) === 1\n        };\n    });\n\n    async function main() {\n        await weave.init('rag-qa-ts');\n        \n        const articleEmbeddings = await docsToEmbeddings(articles);\n        \n        const model = new RAGModel({\n            systemMessage: \"You are an expert in finance and answer questions related to finance, financial services, and financial markets. When responding based on provided information, be sure to cite the source.\",\n            articleEmbeddings\n        });\n\n        const evaluation = new weave.Evaluation({\n            dataset: createQuestionDataset(),\n            scorers: [contextPrecisionScore]\n        });\n\n        const results = await evaluation.evaluate({\n            model: weave.op((args: { datasetRow: QuestionRow }) => \n                model.predict(args.datasetRow.question)\n            )\n        });\n        \n        console.log('Evaluation results:', results);\n    }\n\n    if (require.main === module) {\n        main().catch(console.error);\n    }\n    ```\n  \n\n\n## Conclusion\n\nWe've learned how to build observability into different steps of our applications, like the retrieval step in this example.\nWe've also learned how to build more complex scoring functions, like an LLM judge, for doing automatic evaluation of application responses."
  },
  {
    "title": "Quickstart",
    "url": "https://weave-docs.wandb.ai/quickstart",
    "section": "Docs",
    "category": "Quickstart",
    "content": "# Track LLM inputs & outputs\n\n\n\nFollow these steps to track your first call or \n\n## 1. Install Weave and create an API Key\n\n**Install weave**\n\nFirst install the weave library:\n\n\n  \n    ```bash\n    pip install weave\n    ```\n  \n  \n    ```bash\n    pnpm install weave\n    ```\n  \n\n\n**Get your API key**\n\nThen, create a Weights & Biases (W&B) account at https://wandb.ai and copy your API key from https://wandb.ai/authorize\n\n## 2. Log a trace to a new project\n\nTo get started with tracking your first project with Weave:\n\n- Import the `weave` library\n- Call `weave.init('project-name')` to start tracking\n  - You will be prompted to log in with your API key if you are not yet logged in on your machine.\n  - To log to a specific W&B Team name, replace `project-name` with `team-name/project-name`\n  - **NOTE:** In automated environments, you can define the environment variable `WANDB_API_KEY` with your API key to login without prompting.\n- Add the `@weave.op()` decorator to the python functions you want to track\n\n_In this example, we're using openai so you will need to add an OpenAI [API key](https://platform.openai.com/docs/quickstart/step-2-setup-your-api-key)._\n\n\n  \n    ```python\n    import weave\n    from openai import OpenAI\n\n    client = OpenAI()\n\n    # Weave will track the inputs, outputs and code of this function\n    @weave.op()\n    def extract_dinos(sentence: str) -> dict:\n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": \"\"\"In JSON format extract a list of `dinosaurs`, with their `name`,\n    their `common_name`, and whether its `diet` is a herbivore or carnivore\"\"\"\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": sentence\n                }\n                ],\n                response_format={ \"type\": \"json_object\" }\n            )\n        return response.choices[0].message.content\n\n\n    # Initialise the weave project\n    weave.init('jurassic-park')\n\n    sentence = \"\"\"I watched as a Tyrannosaurus rex (T. rex) chased after a Triceratops (Trike), \\\n    both carnivore and herbivore locked in an ancient dance. Meanwhile, a gentle giant \\\n    Brachiosaurus (Brachi) calmly munched on treetops, blissfully unaware of the chaos below.\"\"\"\n\n    result = extract_dinos(sentence)\n    print(result)\n    ```\n    When you call the `extract_dinos` function Weave will output a link to view your trace.\n\n  \n  \n    ```typescript\n        // highlight-next-line\n    \n    // highlight-next-line\n    const openai = weave.wrapOpenAI(new OpenAI());\n\n    async function extractDinos(input: string) {\n      const response = await openai.chat.completions.create({\n        model: 'gpt-4o',\n        messages: [\n          {\n            role: 'user',\n            content: `In JSON format extract a list of 'dinosaurs', with their 'name', their 'common_name', and whether its 'diet' is a herbivore or carnivore: ${input}`,\n          },\n        ],\n      });\n      return response.choices[0].message.content;\n    }\n    // highlight-next-line\n    const extractDinosOp = weave.op(extractDinos);\n\n    async function main() {\n      // highlight-next-line\n      await weave.init('examples');\n      const result = await extractDinosOp(\n        'I watched as a Tyrannosaurus rex (T. rex) chased after a Triceratops (Trike), both carnivore and herbivore locked in an ancient dance. Meanwhile, a gentle giant Brachiosaurus (Brachi) calmly munched on treetops, blissfully unaware of the chaos below.'\n      );\n      console.log(result);\n    }\n\n    main();\n\n    ```\n    When you call the `extractDinos` function Weave will output a link to view your trace.\n\n  \n\n\n## 3. Automated LLM library logging\n\nCalls made to OpenAI, Anthropic and [many more LLM libraries](./guides/integrations/index.md) are automatically tracked with Weave, with **LLM metadata**, **token usage** and **cost** being logged automatically. If your LLM library isn't currently one of our integrations you can track calls to other LLMs libraries or frameworks easily by wrapping them with `@weave.op()`.\n\n## 4. See traces of your application in your project\n\n\ud83c\udf89 Congrats! Now, every time you call this function, weave will automatically capture the input & output data and log any changes made to the code.\n\n\n\n## What's next?\n\n- Follow the [Tracking flows and app metadata](/tutorial-tracing_2) to start tracking and the data flowing through your app."
  },
  {
    "title": "Introduction",
    "url": "https://weave-docs.wandb.ai/introduction",
    "section": "Docs",
    "category": "Introduction",
    "content": "# W&B Weave\n\nWeights & Biases (W&B) Weave is a framework for tracking, experimenting with, evaluating, deploying, and improving LLM-based applications. Designed for flexibility and scalability, Weave supports every stage of your LLM application development workflow:\n\n- **Tracing & Monitoring**: [Track LLM calls and application logic](./guides/tracking/) to debug and analyze production systems.\n- **Systematic Iteration**: Refine and iterate on [prompts](./guides/core-types/prompts.md), [datasets](./guides/core-types/datasets.md), and [models](./guides/core-types/models.md).\n- **Experimentation**: Experiment with different models and prompts in the [LLM Playground](./guides/tools/playground.md). \n- **Evaluation**: Use custom or [pre-built scorers](./guides/evaluation/scorers#predefined-scorers) alongside our [comparison tools](./guides/tools/comparison.md) to systematically assess and enhance application performance.\n- **Guardrails**: Protect your application with [pre- and post-safeguards](./guides/evaluation/guardrails_and_monitors.md) for content moderation, prompt safety, and more.\n\nIntegrate Weave with your existing development stack via the:\n- [Python SDK](./reference/python-sdk/weave/index.md)\n- [TypeScript SDK](./reference/typescript-sdk/weave/README.md)\n- [Service API](./reference/service-api/call-start-call-start-post)\n\nWeave supports [numerous LLM providers, local models, frameworks, protocols, and third-party services](./guides/integrations/index.md).\n\n## Get started\n\nAre you new to Weave? Set up and start using Weave with the [Python quickstart](/quickstart) or [TypeScript quickstart](./reference/generated_typescript_docs/intro-notebook.md).\n\n## Advanced guides\n\nLearn more about advanced topics:\n\n- [Integrations](./guides/integrations/index.md): Use Weave with popular LLM providers, local models, frameworks, and third-party services.\n- [Cookbooks](./reference/gen_notebooks/01-intro_notebook.md): Build with Weave using Python and TypeScript. Tutorials are available as interactive notebooks.\n- [W&B AI Academy](https://www.wandb.courses/pages/w-b-courses): Build advanced RAG systems, improve LLM prompting, fine-tune LLMs, and more."
  },
  {
    "title": "Tutorial Weave Models",
    "url": "https://weave-docs.wandb.ai/tutorial-weave_models",
    "section": "Docs",
    "category": "Tutorials",
    "content": "# Tutorial: App versioning\n\nTracking the [inputs, outputs, metadata](/quickstart) as well as [data flowing through your app](/tutorial-tracing_2) is critical to understanding the performance of your system. However **versioning your app over time** is also critical to understand how modifications to your code or application parameters change your outputs. Weave's `Model` class is how these changes can be tracked in Weave.\n\nIn this tutorial you'll learn:\n\n- How to use Weave `Model` to track and version your application and its parameters.\n- How to export, modify and re-use a Weave `Model` already logged.\n\n## Using `weave.Model`\n\n> \ud83d\udea8 **Important**: The `weave.Model` class is currently only supported in Python.\n\n\nUsing Weave `Model`s means that parameters such as model vendor ids, prompts, temperature, and more are stored and versioned when they change.\n\nTo create a `Model` in Weave, you need the following:\n\n- a class that inherits from `weave.Model`\n- type definitions on all class fields\n- a typed `invoke` function with the `@weave.op()` decorator\n\nWhen you change the class fields or the code that defines your model, **these changes will be logged and the version will be updated**. This ensures that you can compare the generations across different versions of your app.\n\nIn the example below, the **model name, temperature and system prompt will be tracked and versioned**:\n\n\n  \n    ```python\n    import json\n    from openai import OpenAI\n\n    import weave\n\n    @weave.op()\n    def extract_dinos(wmodel: weave.Model, sentence: str) -> dict:\n        response = wmodel.client.chat.completions.create(\n            model=wmodel.model_name,\n            temperature=wmodel.temperature,\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": wmodel.system_prompt\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": sentence\n                }\n                ],\n                response_format={ \"type\": \"json_object\" }\n            )\n        return response.choices[0].message.content\n\n    # Sub-class with a weave.Model\n    class ExtractDinos(weave.Model):\n        client: OpenAI = None\n        model_name: str\n        temperature: float\n        system_prompt: str\n\n        # Ensure your function is called `invoke` or `predict`\n        @weave.op()\n        def invoke(self, sentence: str) -> dict:\n            dino_data  = extract_dinos(self, sentence)\n            return json.loads(dino_data)\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\nNow you can instantiate and call the model with `invoke`:\n\n\n  \n    ```python\n    weave.init('jurassic-park')\n    client = OpenAI()\n\n    system_prompt = \"\"\"Extract any dinosaur `name`, their `common_name`, \\\n    names and whether its `diet` is a herbivore or carnivore, in JSON format.\"\"\"\n    dinos = ExtractDinos(\n        client=client,\n        model_name='gpt-4o',\n        temperature=0.4,\n        system_prompt=system_prompt\n    )\n\n    sentence = \"\"\"I watched as a Tyrannosaurus rex (T. rex) chased after a Triceratops (Trike), \\\n    both carnivore and herbivore locked in an ancient dance. Meanwhile, a gentle giant \\\n    Brachiosaurus (Brachi) calmly munched on treetops, blissfully unaware of the chaos below.\"\"\"\n    result = dinos.invoke(sentence)\n    print(result)\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\nNow after calling `.invoke` you can see the trace in Weave **now tracks the model parameters as well as the code** for the model functions that have been decorated with `weave.op()`. You can see the model is also versioned, \"v21\" in this case, and if you click on the model **you can see all of the calls** that have used that version of the model\n\n\n\n**A note on using `weave.Model`:**\n\n- You can use `predict` instead of `invoke` for the name of the function in your Weave `Model` if you prefer.\n- If you want other class methods to be tracked by weave they need to be wrapped in `weave.op()`\n- Parameters starting with an underscore are ignored by weave and won't be logged\n\n## Exporting and re-using a logged `weave.Model`\n\nBecause Weave stores and versions Models that have been invoked, it is possible to export and re-use these models.\n\n**Get the Model ref**\nIn the Weave UI you can get the Model ref for a particular version\n\n**Using the Model**\nOnce you have the URI of the Model object, you can export and re-use it. Note that the exported model is already initialised and ready to use:\n\n\n  \n    ```python\n    # the exported weave model is already initialised and ready to be called\n    new_dinos = weave.ref(\"weave:///morgan/jurassic-park/object/ExtractDinos:ey4udBU2MU23heQFJenkVxLBX4bmDsFk7vsGcOWPjY4\").get()\n\n    # set the client to the openai client again\n    new_dinos.client = client\n\n    new_sentence = \"\"\"I also saw an Ankylosaurus grazing on giant ferns\"\"\"\n    new_result = new_dinos.invoke(new_sentence)\n    print(new_result)\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\nHere you can now see the name Model version (v21) was used with the new input:\n\n\n\n## What's next?\n\n- Follow the [Build an Evaluation pipeline tutorial](/tutorial-eval) to start iteratively improving your applications."
  },
  {
    "title": "Tutorial Tracing 2",
    "url": "https://weave-docs.wandb.ai/tutorial-tracing_2",
    "section": "Docs",
    "category": "Tutorials",
    "content": "# Tutorial: Track Application Logic\n\nIn the [Track LLM inputs & outputs](/quickstart) tutorial, the basics of tracking the inputs and outputs of your LLMs was covered.\n\nIn this tutorial you will learn how to:\n\n- **Track data** as it flows through your application\n- **Track metadata** at call time\n\n## Tracking nested function calls\n\nLLM-powered applications can contain multiple LLMs calls and additional data processing and validation logic that is important to monitor. Even deep nested call structures common in many apps, Weave will keep track of the parent-child relationships in nested functions as long as `weave.op()` is added to every function you'd like to track.\n\nBuilding on our [basic tracing example](/quickstart), we will now add additional logic to count the returned items from our LLM and wrap them all in a higher level function. We'll then add `weave.op()` to trace every function, its call order and its parent-child relationship:\n\n\n  \n\n    ```python\n    import weave\n    import json\n    from openai import OpenAI\n\n    client = OpenAI()\n    @weave.op()\n    def extract_dinos(sentence: str) -> dict:\n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": \"\"\"Extract any dinosaur `name`, their `common_name`, \\\n    names and whether its `diet` is a herbivore or carnivore, in JSON format.\"\"\"\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": sentence\n                }\n                ],\n                response_format={ \"type\": \"json_object\" }\n            )\n        return response.choices[0].message.content\n    @weave.op()\n    def count_dinos(dino_data: dict) -> int:\n        # count the number of items in the returned list\n        k = list(dino_data.keys())[0]\n        return len(dino_data[k])\n    @weave.op()\n    def dino_tracker(sentence: str) -> dict:\n        # extract dinosaurs using a LLM\n        dino_data = extract_dinos(sentence)\n\n        # count the number of dinosaurs returned\n        dino_data = json.loads(dino_data)\n        n_dinos = count_dinos(dino_data)\n        return {\"n_dinosaurs\": n_dinos, \"dinosaurs\": dino_data}\n    weave.init('jurassic-park')\n\n    sentence = \"\"\"I watched as a Tyrannosaurus rex (T. rex) chased after a Triceratops (Trike), \\\n    both carnivore and herbivore locked in an ancient dance. Meanwhile, a gentle giant \\\n    Brachiosaurus (Brachi) calmly munched on treetops, blissfully unaware of the chaos below.\"\"\"\n\n    result = dino_tracker(sentence)\n    print(result)\n    ```\n    **Nested functions**\n\n    When you run the above code you will see the the inputs and outputs from the two nested functions (`extract_dinos` and `count_dinos`), as well as the automatically-logged OpenAI trace.\n\n    \n\n  \n  \n\n    ```typescript\n        \n    const openai = weave.wrapOpenAI(new OpenAI());\n\n    const extractDinos = weave.op(async (sentence: string) => {\n      const response = await openai.chat.completions.create({\n        model: 'gpt-4o',\n        messages: [\n          {\n            role: 'system',\n            content:\n              'Extract any dinosaur `name`, their `common_name`, names and whether its `diet` is a herbivore or carnivore, in JSON format.',\n          },\n          {role: 'user', content: sentence},\n        ],\n        response_format: {type: 'json_object'},\n      });\n      return response.choices[0].message.content;\n    });\n\n    const countDinos = weave.op(async (dinoData: string) => {\n      const parsed = JSON.parse(dinoData);\n      return Object.keys(parsed).length;\n    });\n\n    const dinoTracker = weave.op(async (sentence: string) => {\n      const dinoData = await extractDinos(sentence);\n      const nDinos = await countDinos(dinoData);\n      return {nDinos, dinoData};\n    });\n\n    async function main() {\n      await weave.init('jurassic-park');\n\n      const sentence = `I watched as a Tyrannosaurus rex (T. rex) chased after a Triceratops (Trike),\n            both carnivore and herbivore locked in an ancient dance. Meanwhile, a gentle giant\n            Brachiosaurus (Brachi) calmly munched on treetops, blissfully unaware of the chaos below.`;\n\n      const result = await dinoTracker(sentence);\n      console.log(result);\n    }\n\n    main();\n\n    ```\n\n    **Nested functions**\n\n    When you run the above code you will see the the inputs and outputs from the two nested functions (`extractDinos` and `countDinos`), as well as the automatically-logged OpenAI trace.\n\n    \n    \n\n  \n\n\n## Tracking metadata\n\nTracking metadata can be done easily by using the `weave.attributes` context manager and passing it a dictionary of the metadata to track at call time.\n\nContinuing our example from above:\n\n\n  \n    ```python\n    import weave\n\n    weave.init('jurassic-park')\n\n    sentence = \"\"\"I watched as a Tyrannosaurus rex (T. rex) chased after a Triceratops (Trike), \\\n    both carnivore and herbivore locked in an ancient dance. Meanwhile, a gentle giant \\\n    Brachiosaurus (Brachi) calmly munched on treetops, blissfully unaware of the chaos below.\"\"\"\n\n    # track metadata alongside our previously defined function\n    with weave.attributes({'user_id': 'lukas', 'env': 'production'}):\n        result = dino_tracker(sentence)\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n> \ud83d\udca1 **Note**: It's recommended to use metadata tracking to track metadata at run time, e.g. user ids or whether or not the call is part of the development process or is in production etc.\n\nTo track system settings, such as a System Prompt, we recommend using [weave Models](guides/core-types/models)\n\n## What's next?\n\n- Follow the [App Versioning tutorial](/tutorial-weave_models) to capture, version and organize ad-hoc prompt, model, and application changes."
  },
  {
    "title": "Troubleshooting",
    "url": "https://weave-docs.wandb.ai/guides/troubleshooting",
    "section": "Docs",
    "category": "Other",
    "content": "# Troubleshooting\n\nThis page provides solutions and guidance for common issues you may encounter. As we continue to expand this guide, more troubleshooting topics will be added to address a broader range of scenarios.\n\n> \ud83c\udf1f **Tip**: Do you have Weave troubleshooting advice to share with the community? Click **Edit this page** at the bottom of this guide to contribute directly by submitting a pull request.\n\n## Trace pages load slowly\n\nIf trace pages are loading slowly, reduce the number of rows displayed to improve load time. The default value is `50`. You can either reduce the number of rows via the UI, or using query parameters.\n\n### Adjust via the UI (recommended)\n\nUse the **Per page** control at the bottom-right of the Traces page to adjust the number of rows displayed. In addition to the default of `50`, you can also set to `10`, `25`, or `100`.\n\n### Use query parameters\n\nIf you prefer a manual approach, you can modify the `pageSize` query parameter in your query URL to a value less than the maximum of `100`.\n\n## Server response caching\n\nWeave provides server response caching to improve performance when making repeated queries or working with limited network bandwidth. While currently disabled by default, this feature is expected to become the default behavior in a future release.\n\n### When to use caching\n\nServer response caching is particularly beneficial when:\n\n- You frequently run the same queries\n- You have limited network bandwidth\n- You're working in an environment with high latency\n- You're developing offline and want to cache responses for later use\n\nThis feature is especially useful when running repeated evaluations on a dataset, as it allows caching the dataset between runs.\n\n### How to enable caching\n\nTo enable caching, you can set the following environment variables:\n\n```bash\n# Enable server response caching\nexport WEAVE_USE_SERVER_CACHE=true\n\n# Set cache size limit (default is 1GB)\nexport WEAVE_SERVER_CACHE_SIZE_LIMIT=1000000000\n\n# Set cache directory (optional, defaults to temporary directory)\nexport WEAVE_SERVER_CACHE_DIR=/path/to/cache\n```\n\n### Caching behavior\n\nTechnically, this feature will cache idempotent requests against the server. Specifically, we cache:\n\n- `obj_read`\n- `table_query`\n- `table_query_stats`\n- `refs_read_batch`\n- `file_content_read`\n\n### Cache size and storage details\n\nThe cache size is controlled by `WEAVE_SERVER_CACHE_SIZE_LIMIT` (in bytes). The actual disk space used consists of three components:\n\n1. A constant 32KB checksum file\n2. A Write-Ahead Log (WAL) file up to ~4MB per running client (automatically removed when the program exits)\n3. The main database file, which is at least 32KB and at most `WEAVE_SERVER_CACHE_SIZE_LIMIT`\n\nTotal disk space used:\n\n- While running >= 32KB + ~4MB + cache size\n- After exit >= 32KB + cache size\n\nFor example, with the a 5MB cache limit:\n\n- While running: ~9MB maximum\n- After exit: ~5MB maximum\n\n## Trace data is truncated\n\nSometimes, large trace data is partially cut off in the Weave UI. This problem occurs because default trace output is a raw, custom Python object that Weave doesn\u2019t know how to serialize.\n\nTo ensure that large trace data isn't cut off, define a dictionary of strings to return all trace data. \n\n```python\nimport weave\n\nclass MyObj:\n    def __init__(self, x: int):\n        self.x = x\n\n    def __repr__(self):\n        return f\"MyObj(x={self.x})\"\n\n    def to_dict(self):\n        return {\"x\": self.x}\n\n@weave.op()\ndef make_my_obj():\n    x = \"s\" * 10_000\n    return MyObj(x)\n```\n\n## Long eval clean up times\n\nThe following two methods should be used together in order to improve performance when running evaluations with large datasets.\n\n### Flushing\n\nWhen running evaluations with large datasets, you may experience a long period of time before program execution, while the dataset is being uploaded in background threads. This generally occurs when main thread execution finished before background cleanup is complete. Calling `client.flush()` will force all background tasks to be processed in the main thread, ensuring parallel processing during main thread execution. This can improve performance when user code completes before data has been uploaded to the server.\n\nExample:\n\n```python\nclient = weave.init(\"fast-upload\")\n\n# ... evaluation setup\nresult = evaluation.Evaluate(dataset_id=\"my_dataset_id\")\n\nclient.flush()\n```\n\n### Increasing client parallelism\n\nClient parallelism is automatically determined based on the environment, but can be set manually using the following environment variable:\n\n- `WEAVE_CLIENT_PARALLELISM`: The number of threads available for parallel processing. Increasing this number will increase the number of threads available for parallel processing, potentially improving the performance of background tasks like dataset uploads.\n\nThis can also be set programmatically using the `settings` argument to `weave.init()`:\n\n```python\nclient = weave.init(\"fast-upload\", settings={\"client_parallelism\": 100})\n```\n\n## OS errors\n\n### `[Errno 24]: Too many open files`\n\nThis error occurs when the number of open files exceeds the limit set by your operating system. In Weave, this may happen because you're working with large image datasets. Weave uses `PIL` for image processing, which keeps file descriptors open for the duration of the program.\n\nTo resolve this issue, increase the system limit for open files to `65,536` using `ulimit`:\n\n```bash\nulimit -n 65536\n```"
  },
  {
    "title": "Intro Notebook",
    "url": "https://weave-docs.wandb.ai/reference/generated_typescript_docs/intro-notebook",
    "section": "Docs",
    "category": "Other",
    "content": "# Weave with TypeScript Quickstart Guide\n\nYou can use W&B Weave with Typescript to:\n\n- Log and debug language model inputs, outputs, and traces\n- Build rigorous, apples-to-apples evaluations for language model use cases\n- Organize all the information generated across the LLM workflow, from experimentation to evaluations to production\n\nFor more information, see the [Weave documentation](/). \n\n## Function tracking\n\nTo use Weave in your Typescript code, initialize a new Weave project and add the `weave.op` wrapper to the functions you want to track.\n\nAfter adding `weave.op` and calling the function, visit the W&B dashboard to see it tracked within your project.\n\nWe automatically track your code - check the code tab in the UI!\n\n```typescript\nasync function initializeWeaveProject() {\n    const PROJECT = 'weave-examples';\n    await weave.init(PROJECT);\n}\n```\n\n```typescript\nconst stripUserInput = weave.op(function stripUserInput(userInput: string): string {\n    return userInput.trim();\n});\n```\n\nThe following example shows how basic function tracking works.\n\n```typescript\nasync function demonstrateBasicTracking() {\n    const result = await stripUserInput(\"    hello    \");\n    console.log('Basic tracking result:', result);\n}\n```\n\n## OpenAI integration\n\nWeave automatically tracks all OpenAI calls, including:\n\n- Token usage\n- API costs\n- Request/response pairs\n- Model configurations\n\n> \ud83d\udca1 **Note**: In addition to OpenAI, Weave supports automatic logging of other LLM providers, such as Anthropic and Mistral. For the full list, see [LLM Providers in the Integrations documentation](../../guides/integrations/index.md#llm-providers).\n\n```typescript\nfunction initializeOpenAIClient() {\n    return weave.wrapOpenAI(new OpenAI({\n        apiKey: process.env.OPENAI_API_KEY\n    }));\n}\n```\n\n```typescript\nasync function demonstrateOpenAITracking() {\n    const client = initializeOpenAIClient();\n    const result = await client.chat.completions.create({\n        model: \"gpt-4-turbo\",\n        messages: [{ role: \"user\", content: \"Hello, how are you?\" }],\n    });\n    console.log('OpenAI tracking result:', result);\n}\n```\n\n## Nested function tracking\n\nWeave allows you to track complex workflows by combining multiple tracked functions\nand LLM calls while preserving the entire execution trace. The benefits of this include:\n\n- Full visibility into your application's logic flow\n- Easy debugging of complex chains of operations\n- Performance optimization opportunities\n\n```typescript\nasync function demonstrateNestedTracking() {\n    const client = initializeOpenAIClient();\n    \n    const correctGrammar = weave.op(async function correctGrammar(userInput: string): Promise {\n        const stripped = await stripUserInput(userInput);\n        const response = await client.chat.completions.create({\n            model: \"gpt-4-turbo\",\n            messages: [\n                {\n                    role: \"system\",\n                    content: \"You are a grammar checker, correct the following user input.\"\n                },\n                { role: \"user\", content: stripped }\n            ],\n            temperature: 0,\n        });\n        return response.choices[0].message.content ?? '';\n    });\n\n    const grammarResult = await correctGrammar(\"That was so easy, it was a piece of pie!\");\n    console.log('Nested tracking result:', grammarResult);\n}\n```\n\n## Dataset management\n\nYou can create and manage datasets with Weave using the [`weave.Dataset`](../../guides/core-types/datasets.md) class. Similar to [Weave `Models`](../../guides/core-types/models.md), `weave.Dataset` helps:\n\n- Track and version your data\n- Organize test cases\n- Share datasets between team members\n- Power systematic evaluations\n\n```typescript\ninterface GrammarExample {\n    userInput: string;\n    expected: string;\n}\n```\n\n```typescript\nfunction createGrammarDataset(): weave.Dataset {\n    return new weave.Dataset({\n        id: 'grammar-correction',\n        rows: [\n            {\n                userInput: \"That was so easy, it was a piece of pie!\",\n                expected: \"That was so easy, it was a piece of cake!\"\n            },\n            {\n                userInput: \"I write good\",\n                expected: \"I write well\"\n            },\n            {\n                userInput: \"LLM's are best\",\n                expected: \"LLM's are the best\"\n            }\n        ]\n    });\n}\n```\n\n## Evaluation framework\n\nWeave supports evaluation-driven development with the [`Evaluation` class](../../guides/core-types/evaluations.md). Evaluations help you reliably iterate on your GenAI application. The `Evaluation` class does the following:\n\n- Assesses `Model` performance on a `Dataset`\n- Applies custom scoring functions\n- Generates detailed performance reports\n- Enables comparison between model versions\n\nYou can find a complete evaluation tutorial at [http://wandb.me/weave_eval_tut](http://wandb.me/weave_eval_tut)\n\n```typescript\nclass OpenAIGrammarCorrector {\n    private oaiClient: ReturnType;\n    \n    constructor() {\n        this.oaiClient = weave.wrapOpenAI(new OpenAI({\n            apiKey: process.env.OPENAI_API_KEY\n        }));\n        this.predict = weave.op(this, this.predict);\n    }\n\n    async predict(userInput: string): Promise {\n        const response = await this.oaiClient.chat.completions.create({\n            model: 'gpt-4-turbo',\n            messages: [\n                { \n                    role: \"system\", \n                    content: \"You are a grammar checker, correct the following user input.\" \n                },\n                { role: \"user\", content: userInput }\n            ],\n            temperature: 0\n        });\n        return response.choices[0].message.content ?? '';\n    }\n}\n```\n\n```typescript\nasync function runEvaluation() {\n    const corrector = new OpenAIGrammarCorrector();\n    const dataset = createGrammarDataset();\n    \n    const exactMatch = weave.op(\n        function exactMatch({ modelOutput, datasetRow }: { \n            modelOutput: string; \n            datasetRow: GrammarExample \n        }): { match: boolean } {\n            return { match: datasetRow.expected === modelOutput };\n        },\n        { name: 'exactMatch' }\n    );\n\n    const evaluation = new weave.Evaluation({\n        dataset,\n        scorers: [exactMatch],\n    });\n\n    const summary = await evaluation.evaluate({\n        model: weave.op((args: { datasetRow: GrammarExample }) => \n            corrector.predict(args.datasetRow.userInput)\n        )\n    });\n    console.log('Evaluation summary:', summary);\n}\n```\n\nThe following `main` function runs all demonstrations:\n\n```typescript\nasync function main() {\n    try {\n        await initializeWeaveProject();\n        await demonstrateBasicTracking();\n        await demonstrateOpenAITracking();\n        await demonstrateNestedTracking();\n        await runEvaluation();\n    } catch (error) {\n        console.error('Error running demonstrations:', error);\n    }\n}\n```"
  },
  {
    "title": "\"Refs Read Batch\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/refs-read-batch-refs-read-batch-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Refs Read Batch\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/refs/read_batch\"}\n>\n  \n\n\n\n\nRefs Read Batch\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"refs\"}\n          required={true}\n          schemaName={\"string[]\"}\n          qualifierMessage={undefined}\n          schema={{\"items\":{\"type\":\"string\"},\"type\":\"array\",\"title\":\"Refs\"}}\n        >\n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"vals\"}\n                        required={true}\n                        schemaName={\"undefined[]\"}\n                        qualifierMessage={undefined}\n                        schema={{\"items\":{},\"type\":\"array\",\"title\":\"Vals\"}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"vals\\\": [\\n    null\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Objs Query\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/objs-query-objs-query-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Objs Query\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/objs/query\"}\n>\n  \n\n\n\n\nObjs Query\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\",\"description\":\"The ID of the project to query\",\"examples\":[\"user/project\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                filter\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Filter criteria for the query. See `ObjectVersionFilter`\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"ObjectVersionFilter\"}\n                  value={\"0-item-properties\"}\n                >\n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          base_object_classes\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        <div\n                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                        >\n                          \n                          \n                          Filter objects by their base classes\n                          \n                          \n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          object_ids\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        <div\n                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                        >\n                          \n                          \n                          Filter objects by their IDs\n                          \n                          \n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          is_op\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        <div\n                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                        >\n                          \n                          \n                          Filter objects based on whether they are weave.ops or not. `True` will only return ops, `False` will return non-ops, and `None` will return all objects\n                          \n                          \n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              boolean\n                              \n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          latest_only\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        <div\n                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                        >\n                          \n                          \n                          If True, return only the latest version of each object. `False` and `None` will return all versions\n                          \n                          \n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              boolean\n                              \n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                limit\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Maximum number of results to return\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    integer\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                offset\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Number of results to skip before returning\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    integer\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                sort_by\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Sorting criteria for the query results. Currently only supports 'object_id' and 'created_at'.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                    >\n                      Array [\n                    \n                  <SchemaItem\n                    collapsible={false}\n                    name={\"field\"}\n                    required={true}\n                    schemaName={\"Field (string)\"}\n                    qualifierMessage={undefined}\n                    schema={{\"type\":\"string\",\"title\":\"Field\"}}\n                  >\n                    \n                  <SchemaItem\n                    collapsible={false}\n                    name={\"direction\"}\n                    required={true}\n                    schemaName={\"Direction (string)\"}\n                    qualifierMessage={\"**Possible values:** [`asc`, `desc`]\"}\n                    schema={{\"type\":\"string\",\"enum\":[\"asc\",\"desc\"],\"title\":\"Direction\"}}\n                  >\n                    \n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                    >\n                      ]\n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                metadata_only\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                If true, the `val` column is not read from the database and is empty.All other fields are returned.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    boolean\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                include_storage_size\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                If true, the `size_bytes` column is returned.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    boolean\n                    \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                objs\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              <span\n                                className={\"openapi-schema__divider\"}\n                              >\n                                \n                              <span\n                                className={\"openapi-schema__required\"}\n                              >\n                                required\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"project_id\"}\n                              required={true}\n                              schemaName={\"Project Id (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"object_id\"}\n                              required={true}\n                              schemaName={\"Object Id (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Object Id\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"created_at\"}\n                              required={true}\n                              schemaName={\"date-time\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"format\":\"date-time\",\"title\":\"Created At\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    deleted_at\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        string\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"digest\"}\n                              required={true}\n                              schemaName={\"Digest (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Digest\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"version_index\"}\n                              required={true}\n                              schemaName={\"Version Index (integer)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"integer\",\"title\":\"Version Index\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"is_latest\"}\n                              required={true}\n                              schemaName={\"Is Latest (integer)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"integer\",\"title\":\"Is Latest\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"kind\"}\n                              required={true}\n                              schemaName={\"Kind (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Kind\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    base_object_class\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  <strong\n                                    style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"color\":\"var(--openapi-required)\"}}\n                                  >\n                                     required\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        string\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"val\"}\n                              required={true}\n                              schemaName={\"Val\"}\n                              qualifierMessage={undefined}\n                              schema={{\"title\":\"Val\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    wb_user_id\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  <div\n                                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                  >\n                                    \n                                    \n                                    Do not set directly. Server will automatically populate this field.\n                                    \n                                    \n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        string\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    size_bytes\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        integer\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"objs\\\": [\\n    {\\n      \\\"project_id\\\": \\\"string\\\",\\n      \\\"object_id\\\": \\\"string\\\",\\n      \\\"created_at\\\": \\\"2025-04-30T23:50:38.691Z\\\",\\n      \\\"deleted_at\\\": \\\"2025-04-30T23:50:38.691Z\\\",\\n      \\\"digest\\\": \\\"string\\\",\\n      \\\"version_index\\\": 0,\\n      \\\"is_latest\\\": 0,\\n      \\\"kind\\\": \\\"string\\\",\\n      \\\"base_object_class\\\": \\\"string\\\",\\n      \\\"wb_user_id\\\": \\\"string\\\",\\n      \\\"size_bytes\\\": 0\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Call Start\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/call-start-call-start-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Call Start\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/call/start\"}\n>\n  \n\n\n\n\nCall Start\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              <span\n                className={\"openapi-schema__container\"}\n              >\n                <strong\n                  className={\"openapi-schema__property\"}\n                >\n                  start\n                <span\n                  className={\"openapi-schema__name\"}\n                >\n                   object\n                <span\n                  className={\"openapi-schema__divider\"}\n                >\n                  \n                <span\n                  className={\"openapi-schema__required\"}\n                >\n                  required\n                \n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <SchemaItem\n                collapsible={false}\n                name={\"project_id\"}\n                required={true}\n                schemaName={\"Project Id (string)\"}\n                qualifierMessage={undefined}\n                schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n              >\n                \n              <SchemaItem\n                collapsible={true}\n                className={\"schemaItem\"}\n              >\n                <details\n                  style={{}}\n                  className={\"openapi-markdown__details\"}\n                >\n                  <summary\n                    style={{}}\n                  >\n                    \n                      id\n                    <span\n                      style={{\"opacity\":\"0.6\"}}\n                    >\n                       object\n                    \n                  <div\n                    style={{\"marginLeft\":\"1rem\"}}\n                  >\n                    \n                  \n                    <span\n                      className={\"badge badge--info\"}\n                    >\n                      anyOf\n                    \n                      <TabItem\n                        label={\"MOD1\"}\n                        value={\"0-item-properties\"}\n                      >\n                        <div\n                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                        >\n                          \n                          \n                          string\n                          \n                          \n                        \n                      \n                    \n                  \n                \n              <SchemaItem\n                collapsible={false}\n                name={\"op_name\"}\n                required={true}\n                schemaName={\"Op Name (string)\"}\n                qualifierMessage={undefined}\n                schema={{\"type\":\"string\",\"title\":\"Op Name\"}}\n              >\n                \n              <SchemaItem\n                collapsible={true}\n                className={\"schemaItem\"}\n              >\n                <details\n                  style={{}}\n                  className={\"openapi-markdown__details\"}\n                >\n                  <summary\n                    style={{}}\n                  >\n                    \n                      display_name\n                    <span\n                      style={{\"opacity\":\"0.6\"}}\n                    >\n                       object\n                    \n                  <div\n                    style={{\"marginLeft\":\"1rem\"}}\n                  >\n                    \n                  \n                    <span\n                      className={\"badge badge--info\"}\n                    >\n                      anyOf\n                    \n                      <TabItem\n                        label={\"MOD1\"}\n                        value={\"0-item-properties\"}\n                      >\n                        <div\n                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                        >\n                          \n                          \n                          string\n                          \n                          \n                        \n                      \n                    \n                  \n                \n              <SchemaItem\n                collapsible={true}\n                className={\"schemaItem\"}\n              >\n                <details\n                  style={{}}\n                  className={\"openapi-markdown__details\"}\n                >\n                  <summary\n                    style={{}}\n                  >\n                    \n                      trace_id\n                    <span\n                      style={{\"opacity\":\"0.6\"}}\n                    >\n                       object\n                    \n                  <div\n                    style={{\"marginLeft\":\"1rem\"}}\n                  >\n                    \n                  \n                    <span\n                      className={\"badge badge--info\"}\n                    >\n                      anyOf\n                    \n                      <TabItem\n                        label={\"MOD1\"}\n                        value={\"0-item-properties\"}\n                      >\n                        <div\n                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                        >\n                          \n                          \n                          string\n                          \n                          \n                        \n                      \n                    \n                  \n                \n              <SchemaItem\n                collapsible={true}\n                className={\"schemaItem\"}\n              >\n                <details\n                  style={{}}\n                  className={\"openapi-markdown__details\"}\n                >\n                  <summary\n                    style={{}}\n                  >\n                    \n                      parent_id\n                    <span\n                      style={{\"opacity\":\"0.6\"}}\n                    >\n                       object\n                    \n                  <div\n                    style={{\"marginLeft\":\"1rem\"}}\n                  >\n                    \n                  \n                    <span\n                      className={\"badge badge--info\"}\n                    >\n                      anyOf\n                    \n                      <TabItem\n                        label={\"MOD1\"}\n                        value={\"0-item-properties\"}\n                      >\n                        <div\n                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                        >\n                          \n                          \n                          string\n                          \n                          \n                        \n                      \n                    \n                  \n                \n              <SchemaItem\n                collapsible={false}\n                name={\"started_at\"}\n                required={true}\n                schemaName={\"date-time\"}\n                qualifierMessage={undefined}\n                schema={{\"type\":\"string\",\"format\":\"date-time\",\"title\":\"Started At\"}}\n              >\n                \n              <SchemaItem\n                collapsible={false}\n                name={\"attributes\"}\n                required={true}\n                schemaName={\"object\"}\n                qualifierMessage={undefined}\n                schema={{\"type\":\"object\",\"title\":\"Attributes\"}}\n              >\n                \n              <SchemaItem\n                collapsible={false}\n                name={\"inputs\"}\n                required={true}\n                schemaName={\"object\"}\n                qualifierMessage={undefined}\n                schema={{\"type\":\"object\",\"title\":\"Inputs\"}}\n              >\n                \n              <SchemaItem\n                collapsible={true}\n                className={\"schemaItem\"}\n              >\n                <details\n                  style={{}}\n                  className={\"openapi-markdown__details\"}\n                >\n                  <summary\n                    style={{}}\n                  >\n                    \n                      wb_user_id\n                    <span\n                      style={{\"opacity\":\"0.6\"}}\n                    >\n                       object\n                    \n                  <div\n                    style={{\"marginLeft\":\"1rem\"}}\n                  >\n                    <div\n                      style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                    >\n                      \n                      \n                      Do not set directly. Server will automatically populate this field.\n                      \n                      \n                    \n                  \n                    <span\n                      className={\"badge badge--info\"}\n                    >\n                      anyOf\n                    \n                      <TabItem\n                        label={\"MOD1\"}\n                        value={\"0-item-properties\"}\n                      >\n                        <div\n                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                        >\n                          \n                          \n                          string\n                          \n                          \n                        \n                      \n                    \n                  \n                \n              <SchemaItem\n                collapsible={true}\n                className={\"schemaItem\"}\n              >\n                <details\n                  style={{}}\n                  className={\"openapi-markdown__details\"}\n                >\n                  <summary\n                    style={{}}\n                  >\n                    \n                      wb_run_id\n                    <span\n                      style={{\"opacity\":\"0.6\"}}\n                    >\n                       object\n                    \n                  <div\n                    style={{\"marginLeft\":\"1rem\"}}\n                  >\n                    \n                  \n                    <span\n                      className={\"badge badge--info\"}\n                    >\n                      anyOf\n                    \n                      <TabItem\n                        label={\"MOD1\"}\n                        value={\"0-item-properties\"}\n                      >\n                        <div\n                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                        >\n                          \n                          \n                          string\n                          \n                          \n                        \n                      \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"id\"}\n                        required={true}\n                        schemaName={\"Id (string)\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"string\",\"title\":\"Id\"}}\n                      >\n                        \n                      <SchemaItem\n                        collapsible={false}\n                        name={\"trace_id\"}\n                        required={true}\n                        schemaName={\"Trace Id (string)\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"string\",\"title\":\"Trace Id\"}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"id\\\": \\\"string\\\",\\n  \\\"trace_id\\\": \\\"string\\\"\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Table Update\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/table-update-table-update-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Table Update\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/table/update\"}\n>\n  \n\n\n\n\nTable Update\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n        >\n          \n        <SchemaItem\n          collapsible={false}\n          name={\"base_digest\"}\n          required={true}\n          schemaName={\"Base Digest (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Base Digest\"}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              <span\n                className={\"openapi-schema__container\"}\n              >\n                <strong\n                  className={\"openapi-schema__property\"}\n                >\n                  updates\n                <span\n                  className={\"openapi-schema__name\"}\n                >\n                   object[]\n                <span\n                  className={\"openapi-schema__divider\"}\n                >\n                  \n                <span\n                  className={\"openapi-schema__required\"}\n                >\n                  required\n                \n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n                <div\n                  style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                >\n                  Array [\n                \n              \n                <span\n                  className={\"badge badge--info\"}\n                >\n                  anyOf\n                \n                  <TabItem\n                    label={\"TableAppendSpec\"}\n                    value={\"0-item-properties\"}\n                  >\n                    <SchemaItem\n                      collapsible={true}\n                      className={\"schemaItem\"}\n                    >\n                      <details\n                        style={{}}\n                        className={\"openapi-markdown__details\"}\n                      >\n                        <summary\n                          style={{}}\n                        >\n                          <span\n                            className={\"openapi-schema__container\"}\n                          >\n                            <strong\n                              className={\"openapi-schema__property\"}\n                            >\n                              append\n                            <span\n                              className={\"openapi-schema__name\"}\n                            >\n                               object\n                            <span\n                              className={\"openapi-schema__divider\"}\n                            >\n                              \n                            <span\n                              className={\"openapi-schema__required\"}\n                            >\n                              required\n                            \n                          \n                        <div\n                          style={{\"marginLeft\":\"1rem\"}}\n                        >\n                          <SchemaItem\n                            collapsible={false}\n                            name={\"row\"}\n                            required={true}\n                            schemaName={\"object\"}\n                            qualifierMessage={undefined}\n                            schema={{\"type\":\"object\",\"title\":\"Row\"}}\n                          >\n                            \n                          \n                        \n                      \n                    \n                  <TabItem\n                    label={\"TablePopSpec\"}\n                    value={\"1-item-properties\"}\n                  >\n                    <SchemaItem\n                      collapsible={true}\n                      className={\"schemaItem\"}\n                    >\n                      <details\n                        style={{}}\n                        className={\"openapi-markdown__details\"}\n                      >\n                        <summary\n                          style={{}}\n                        >\n                          <span\n                            className={\"openapi-schema__container\"}\n                          >\n                            <strong\n                              className={\"openapi-schema__property\"}\n                            >\n                              pop\n                            <span\n                              className={\"openapi-schema__name\"}\n                            >\n                               object\n                            <span\n                              className={\"openapi-schema__divider\"}\n                            >\n                              \n                            <span\n                              className={\"openapi-schema__required\"}\n                            >\n                              required\n                            \n                          \n                        <div\n                          style={{\"marginLeft\":\"1rem\"}}\n                        >\n                          <SchemaItem\n                            collapsible={false}\n                            name={\"index\"}\n                            required={true}\n                            schemaName={\"Index (integer)\"}\n                            qualifierMessage={undefined}\n                            schema={{\"type\":\"integer\",\"title\":\"Index\"}}\n                          >\n                            \n                          \n                        \n                      \n                    \n                  <TabItem\n                    label={\"TableInsertSpec\"}\n                    value={\"2-item-properties\"}\n                  >\n                    <SchemaItem\n                      collapsible={true}\n                      className={\"schemaItem\"}\n                    >\n                      <details\n                        style={{}}\n                        className={\"openapi-markdown__details\"}\n                      >\n                        <summary\n                          style={{}}\n                        >\n                          <span\n                            className={\"openapi-schema__container\"}\n                          >\n                            <strong\n                              className={\"openapi-schema__property\"}\n                            >\n                              insert\n                            <span\n                              className={\"openapi-schema__name\"}\n                            >\n                               object\n                            <span\n                              className={\"openapi-schema__divider\"}\n                            >\n                              \n                            <span\n                              className={\"openapi-schema__required\"}\n                            >\n                              required\n                            \n                          \n                        <div\n                          style={{\"marginLeft\":\"1rem\"}}\n                        >\n                          <SchemaItem\n                            collapsible={false}\n                            name={\"index\"}\n                            required={true}\n                            schemaName={\"Index (integer)\"}\n                            qualifierMessage={undefined}\n                            schema={{\"type\":\"integer\",\"title\":\"Index\"}}\n                          >\n                            \n                          <SchemaItem\n                            collapsible={false}\n                            name={\"row\"}\n                            required={true}\n                            schemaName={\"object\"}\n                            qualifierMessage={undefined}\n                            schema={{\"type\":\"object\",\"title\":\"Row\"}}\n                          >\n                            \n                          \n                        \n                      \n                    \n                  \n                \n              \n                <div\n                  style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                >\n                  ]\n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"digest\"}\n                        required={true}\n                        schemaName={\"Digest (string)\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"string\",\"title\":\"Digest\"}}\n                      >\n                        \n                      <SchemaItem\n                        collapsible={false}\n                        name={\"updated_row_digests\"}\n                        required={false}\n                        schemaName={\"string[]\"}\n                        qualifierMessage={undefined}\n                        schema={{\"items\":{\"type\":\"string\"},\"type\":\"array\",\"title\":\"Updated Row Digests\",\"description\":\"The digests of the rows that were updated\"}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"digest\\\": \\\"string\\\",\\n  \\\"updated_row_digests\\\": [\\n    \\\"string\\\"\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Table Query Stats Batch\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/table-query-stats-batch-table-query-stats-batch-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Table Query Stats Batch\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/table/query_stats_batch\"}\n>\n  \n\n\n\n\nTable Query Stats Batch\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\",\"description\":\"The ID of the project\",\"examples\":[\"my_entity/my_project\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                digests\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                The digests of the tables to query\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                    >\n                      Array [\n                    \n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                    >\n                      ]\n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                include_storage_size\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                If true, the `storage_size_bytes` column is returned.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    boolean\n                    \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                tables\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              <span\n                                className={\"openapi-schema__divider\"}\n                              >\n                                \n                              <span\n                                className={\"openapi-schema__required\"}\n                              >\n                                required\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"count\"}\n                              required={true}\n                              schemaName={\"Count (integer)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"integer\",\"title\":\"Count\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"digest\"}\n                              required={true}\n                              schemaName={\"Digest (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Digest\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    storage_size_bytes\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        integer\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"tables\\\": [\\n    {\\n      \\\"count\\\": 0,\\n      \\\"digest\\\": \\\"string\\\",\\n      \\\"storage_size_bytes\\\": 0\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Feedback Purge\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/feedback-purge-feedback-purge-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Feedback Purge\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/feedback/purge\"}\n>\n  \n\n\n\n\nPermanently delete feedback.\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\",\"examples\":[\"entity/project\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              <span\n                className={\"openapi-schema__container\"}\n              >\n                <strong\n                  className={\"openapi-schema__property\"}\n                >\n                  query\n                <span\n                  className={\"openapi-schema__name\"}\n                >\n                   object\n                <span\n                  className={\"openapi-schema__divider\"}\n                >\n                  \n                <span\n                  className={\"openapi-schema__required\"}\n                >\n                  required\n                \n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <SchemaItem\n                collapsible={false}\n                name={\"$expr\"}\n                required={true}\n                schemaName={\"object\"}\n                qualifierMessage={undefined}\n                schema={{\"title\":\"$Expr\",\"type\":\"object\"}}\n              >\n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"\"}\n                        required={false}\n                        schemaName={\"object\"}\n                        qualifierMessage={undefined}\n                        schema={{}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Table Query\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/table-query-table-query-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Table Query\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/table/query\"}\n>\n  \n\n\n\n\nTable Query\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\",\"description\":\"The ID of the project\",\"examples\":[\"my_entity/my_project\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={false}\n          name={\"digest\"}\n          required={true}\n          schemaName={\"Digest (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Digest\",\"description\":\"The digest of the table to query\",\"examples\":[\"aonareimsvtl13apimtalpa4435rpmgnaemrpgmarltarstaorsnte134avrims\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                filter\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Optional filter to apply to the query. See `TableRowFilter` for more details.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"TableRowFilter\"}\n                  value={\"0-item-properties\"}\n                >\n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          row_digests\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        <div\n                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                        >\n                          \n                          \n                          List of row digests to filter by\n                          \n                          \n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                limit\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Maximum number of rows to return\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    integer\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                offset\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Number of rows to skip before starting to return rows\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    integer\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                sort_by\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                List of fields to sort by. Fields can be dot-separated to access dictionary values. No sorting uses the default table order (insertion order).\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                    >\n                      Array [\n                    \n                  <SchemaItem\n                    collapsible={false}\n                    name={\"field\"}\n                    required={true}\n                    schemaName={\"Field (string)\"}\n                    qualifierMessage={undefined}\n                    schema={{\"type\":\"string\",\"title\":\"Field\"}}\n                  >\n                    \n                  <SchemaItem\n                    collapsible={false}\n                    name={\"direction\"}\n                    required={true}\n                    schemaName={\"Direction (string)\"}\n                    qualifierMessage={\"**Possible values:** [`asc`, `desc`]\"}\n                    schema={{\"type\":\"string\",\"enum\":[\"asc\",\"desc\"],\"title\":\"Direction\"}}\n                  >\n                    \n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                    >\n                      ]\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                rows\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              <span\n                                className={\"openapi-schema__divider\"}\n                              >\n                                \n                              <span\n                                className={\"openapi-schema__required\"}\n                              >\n                                required\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"digest\"}\n                              required={true}\n                              schemaName={\"Digest (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Digest\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"val\"}\n                              required={true}\n                              schemaName={\"Val\"}\n                              qualifierMessage={undefined}\n                              schema={{\"title\":\"Val\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    original_index\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        integer\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"rows\\\": [\\n    {\\n      \\\"digest\\\": \\\"string\\\",\\n      \\\"original_index\\\": 0\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Calls Query Stream\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/calls-query-stream-calls-stream-query-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Calls Query Stream\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/calls/stream_query\"}\n>\n  \n\n\n\n\nCalls Query Stream\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<details\n  style={{\"marginBottom\":\"1rem\"}}\n  className={\"openapi-markdown__details\"}\n  data-collapsed={false}\n  open={true}\n>\n  <summary\n    style={{}}\n  >\n    <h3\n      className={\"openapi-markdown__details-summary-header-params\"}\n    >\n      Header Parameters\n    \n  \n    \n      <ParamsItem\n        className={\"paramsItem\"}\n        param={{\"name\":\"accept\",\"in\":\"header\",\"required\":false,\"schema\":{\"type\":\"string\",\"default\":\"application/jsonl\",\"title\":\"Accept\"}}}\n      >\n        \n      \n    \n  \n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                filter\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"CallsFilter\"}\n                  value={\"0-item-properties\"}\n                >\n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          op_names\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          input_refs\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          output_refs\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          parent_ids\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          trace_ids\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          call_ids\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          trace_roots_only\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              boolean\n                              \n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          wb_user_ids\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          wb_run_ids\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                limit\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    integer\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                offset\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    integer\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                sort_by\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                    >\n                      Array [\n                    \n                  <SchemaItem\n                    collapsible={false}\n                    name={\"field\"}\n                    required={true}\n                    schemaName={\"Field (string)\"}\n                    qualifierMessage={undefined}\n                    schema={{\"type\":\"string\",\"title\":\"Field\"}}\n                  >\n                    \n                  <SchemaItem\n                    collapsible={false}\n                    name={\"direction\"}\n                    required={true}\n                    schemaName={\"Direction (string)\"}\n                    qualifierMessage={\"**Possible values:** [`asc`, `desc`]\"}\n                    schema={{\"type\":\"string\",\"enum\":[\"asc\",\"desc\"],\"title\":\"Direction\"}}\n                  >\n                    \n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                    >\n                      ]\n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                query\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"Query\"}\n                  value={\"0-item-properties\"}\n                >\n                  <SchemaItem\n                    collapsible={false}\n                    name={\"$expr\"}\n                    required={true}\n                    schemaName={\"object\"}\n                    qualifierMessage={undefined}\n                    schema={{\"title\":\"$Expr\",\"type\":\"object\"}}\n                  >\n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                include_costs\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Beta, subject to change. If true, the response will include any model costs for each call.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    boolean\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                include_feedback\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Beta, subject to change. If true, the response will include feedback for each call.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    boolean\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                include_storage_size\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Beta, subject to change. If true, the response will include the storage size for a call.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    boolean\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                include_total_storage_size\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Beta, subject to change. If true, the response will include the total storage size for a trace.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    boolean\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                columns\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                    >\n                      Array [\n                    \n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                    >\n                      ]\n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                expand_columns\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Columns to expand, i.e. refs to other objects\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                    >\n                      Array [\n                    \n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                    >\n                      ]\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      any\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Cost Create\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/cost-create-cost-create-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Cost Create\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/cost/create\"}\n>\n  \n\n\n\n\nCost Create\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\",\"examples\":[\"entity/project\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              <span\n                className={\"openapi-schema__container\"}\n              >\n                <strong\n                  className={\"openapi-schema__property\"}\n                >\n                  costs\n                <span\n                  className={\"openapi-schema__name\"}\n                >\n                   object\n                <span\n                  className={\"openapi-schema__divider\"}\n                >\n                  \n                <span\n                  className={\"openapi-schema__required\"}\n                >\n                  required\n                \n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <SchemaItem\n                collapsible={true}\n                className={\"schemaItem\"}\n              >\n                <details\n                  style={{}}\n                  className={\"openapi-markdown__details\"}\n                >\n                  <summary\n                    style={{}}\n                  >\n                    <span\n                      className={\"openapi-schema__container\"}\n                    >\n                      <strong\n                        className={\"openapi-schema__property\"}\n                      >\n                        property name*\n                      <span\n                        className={\"openapi-schema__name\"}\n                      >\n                         CostCreateInput\n                      \n                    \n                  <div\n                    style={{\"marginLeft\":\"1rem\"}}\n                  >\n                    <SchemaItem\n                      collapsible={false}\n                      name={\"prompt_token_cost\"}\n                      required={true}\n                      schemaName={\"Prompt Token Cost (number)\"}\n                      qualifierMessage={undefined}\n                      schema={{\"type\":\"number\",\"title\":\"Prompt Token Cost\"}}\n                    >\n                      \n                    <SchemaItem\n                      collapsible={false}\n                      name={\"completion_token_cost\"}\n                      required={true}\n                      schemaName={\"Completion Token Cost (number)\"}\n                      qualifierMessage={undefined}\n                      schema={{\"type\":\"number\",\"title\":\"Completion Token Cost\"}}\n                    >\n                      \n                    <SchemaItem\n                      collapsible={true}\n                      className={\"schemaItem\"}\n                    >\n                      <details\n                        style={{}}\n                        className={\"openapi-markdown__details\"}\n                      >\n                        <summary\n                          style={{}}\n                        >\n                          \n                            prompt_token_cost_unit\n                          <span\n                            style={{\"opacity\":\"0.6\"}}\n                          >\n                             object\n                          \n                        <div\n                          style={{\"marginLeft\":\"1rem\"}}\n                        >\n                          <div\n                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                          >\n                            \n                            \n                            The unit of the cost for the prompt tokens\n                            \n                            \n                          \n                        \n                          <span\n                            className={\"badge badge--info\"}\n                          >\n                            anyOf\n                          \n                            <TabItem\n                              label={\"MOD1\"}\n                              value={\"0-item-properties\"}\n                            >\n                              <div\n                                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                              >\n                                \n                                \n                                string\n                                \n                                \n                              \n                            \n                          \n                        \n                      \n                    <SchemaItem\n                      collapsible={true}\n                      className={\"schemaItem\"}\n                    >\n                      <details\n                        style={{}}\n                        className={\"openapi-markdown__details\"}\n                      >\n                        <summary\n                          style={{}}\n                        >\n                          \n                            completion_token_cost_unit\n                          <span\n                            style={{\"opacity\":\"0.6\"}}\n                          >\n                             object\n                          \n                        <div\n                          style={{\"marginLeft\":\"1rem\"}}\n                        >\n                          <div\n                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                          >\n                            \n                            \n                            The unit of the cost for the completion tokens\n                            \n                            \n                          \n                        \n                          <span\n                            className={\"badge badge--info\"}\n                          >\n                            anyOf\n                          \n                            <TabItem\n                              label={\"MOD1\"}\n                              value={\"0-item-properties\"}\n                            >\n                              <div\n                                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                              >\n                                \n                                \n                                string\n                                \n                                \n                              \n                            \n                          \n                        \n                      \n                    <SchemaItem\n                      collapsible={true}\n                      className={\"schemaItem\"}\n                    >\n                      <details\n                        style={{}}\n                        className={\"openapi-markdown__details\"}\n                      >\n                        <summary\n                          style={{}}\n                        >\n                          \n                            effective_date\n                          <span\n                            style={{\"opacity\":\"0.6\"}}\n                          >\n                             object\n                          \n                        <div\n                          style={{\"marginLeft\":\"1rem\"}}\n                        >\n                          <div\n                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                          >\n                            \n                            \n                            The date after which the cost is effective for, will default to the current date if not provided\n                            \n                            \n                          \n                        \n                          <span\n                            className={\"badge badge--info\"}\n                          >\n                            anyOf\n                          \n                            <TabItem\n                              label={\"MOD1\"}\n                              value={\"0-item-properties\"}\n                            >\n                              <div\n                                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                              >\n                                \n                                \n                                string\n                                \n                                \n                              \n                            \n                          \n                        \n                      \n                    <SchemaItem\n                      collapsible={true}\n                      className={\"schemaItem\"}\n                    >\n                      <details\n                        style={{}}\n                        className={\"openapi-markdown__details\"}\n                      >\n                        <summary\n                          style={{}}\n                        >\n                          \n                            provider_id\n                          <span\n                            style={{\"opacity\":\"0.6\"}}\n                          >\n                             object\n                          \n                        <div\n                          style={{\"marginLeft\":\"1rem\"}}\n                        >\n                          <div\n                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                          >\n                            \n                            \n                            The provider of the LLM, e.g. 'openai' or 'mistral'. If not provided, the provider_id will be set to 'default'\n                            \n                            \n                          \n                        \n                          <span\n                            className={\"badge badge--info\"}\n                          >\n                            anyOf\n                          \n                            <TabItem\n                              label={\"MOD1\"}\n                              value={\"0-item-properties\"}\n                            >\n                              <div\n                                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                              >\n                                \n                                \n                                string\n                                \n                                \n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                wb_user_id\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Do not set directly. Server will automatically populate this field.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"ids\"}\n                        required={true}\n                        schemaName={\"array[]\"}\n                        qualifierMessage={\"**Possible values:** `>= 2`, `<= 2`\"}\n                        schema={{\"items\":{\"prefixItems\":[{\"type\":\"string\"},{\"type\":\"string\"}],\"type\":\"array\",\"maxItems\":2,\"minItems\":2},\"type\":\"array\",\"title\":\"Ids\"}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"ids\\\": [\\n    [\\n      null\\n    ]\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Read Root\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/read-root-health-get.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Read Root\"}\n>\n\n\n<MethodEndpoint\n  method={\"get\"}\n  path={\"/health\"}\n>\n  \n\n\n\n\nRead Root\n\n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      any"
  },
  {
    "title": "\"Calls Delete\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/calls-delete-calls-delete-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Calls Delete\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/calls/delete\"}\n>\n  \n\n\n\n\nCalls Delete\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n        >\n          \n        <SchemaItem\n          collapsible={false}\n          name={\"call_ids\"}\n          required={true}\n          schemaName={\"string[]\"}\n          qualifierMessage={undefined}\n          schema={{\"items\":{\"type\":\"string\"},\"type\":\"array\",\"title\":\"Call Ids\"}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                wb_user_id\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Do not set directly. Server will automatically populate this field.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"\"}\n                        required={false}\n                        schemaName={\"object\"}\n                        qualifierMessage={undefined}\n                        schema={{}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Call Update\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/call-update-call-update-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Call Update\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/call/update\"}\n>\n  \n\n\n\n\nCall Update\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n        >\n          \n        <SchemaItem\n          collapsible={false}\n          name={\"call_id\"}\n          required={true}\n          schemaName={\"Call Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Call Id\"}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                display_name\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                wb_user_id\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Do not set directly. Server will automatically populate this field.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"\"}\n                        required={false}\n                        schemaName={\"object\"}\n                        qualifierMessage={undefined}\n                        schema={{}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Read Version\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/read-version-version-get.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Read Version\"}\n>\n\n\n<MethodEndpoint\n  method={\"get\"}\n  path={\"/version\"}\n>\n  \n\n\n\n\nRead Version\n\n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      any"
  },
  {
    "title": "\"Table Query Stats\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/table-query-stats-table-query-stats-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Table Query Stats\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/table/query_stats\"}\n>\n  \n\n\n\n\nTable Query Stats\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\",\"description\":\"The ID of the project\",\"examples\":[\"my_entity/my_project\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={false}\n          name={\"digest\"}\n          required={true}\n          schemaName={\"Digest (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Digest\",\"description\":\"The digest of the table to query\"}}\n        >\n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"count\"}\n                        required={true}\n                        schemaName={\"Count (integer)\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"integer\",\"title\":\"Count\"}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"count\\\": 0\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"FastAPI\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/fastapi.info",
    "section": "Docs",
    "category": "Service API",
    "content": "<span\n  className={\"theme-doc-version-badge badge badge--secondary\"}\n  children={\"Version: 0.1.0\"}\n>\n\n\n<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"FastAPI\"}\n>\n\n\n\n\n\n\n<div\n  style={{\"marginBottom\":\"2rem\"}}\n>\n  <Heading\n    id={\"authentication\"}\n    as={\"h2\"}\n    className={\"openapi-tabs__heading\"}\n    children={\"Authentication\"}\n  >\n  <SchemaTabs\n    className={\"openapi-tabs__security-schemes\"}\n  >\n    <TabItem\n      label={\"HTTP: Basic Auth\"}\n      value={\"HTTPBasic\"}\n    >\n      \n      \n      \n      \n      \n        \n          \n            \n              \n                Security Scheme Type:\n              \n                http\n              \n            \n              \n                HTTP Authorization Scheme:\n              \n                basic"
  },
  {
    "title": "\"Obj Read\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/obj-read-obj-read-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Obj Read\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/obj/read\"}\n>\n  \n\n\n\n\nObj Read\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n        >\n          \n        <SchemaItem\n          collapsible={false}\n          name={\"object_id\"}\n          required={true}\n          schemaName={\"Object Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Object Id\"}}\n        >\n          \n        <SchemaItem\n          collapsible={false}\n          name={\"digest\"}\n          required={true}\n          schemaName={\"Digest (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Digest\"}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                metadata_only\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                If true, the `val` column is not read from the database and is empty.All other fields are returned.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    boolean\n                    \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                obj\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object\n                              <span\n                                className={\"openapi-schema__divider\"}\n                              >\n                                \n                              <span\n                                className={\"openapi-schema__required\"}\n                              >\n                                required\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            <SchemaItem\n                              collapsible={false}\n                              name={\"project_id\"}\n                              required={true}\n                              schemaName={\"Project Id (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"object_id\"}\n                              required={true}\n                              schemaName={\"Object Id (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Object Id\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"created_at\"}\n                              required={true}\n                              schemaName={\"date-time\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"format\":\"date-time\",\"title\":\"Created At\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    deleted_at\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        string\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"digest\"}\n                              required={true}\n                              schemaName={\"Digest (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Digest\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"version_index\"}\n                              required={true}\n                              schemaName={\"Version Index (integer)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"integer\",\"title\":\"Version Index\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"is_latest\"}\n                              required={true}\n                              schemaName={\"Is Latest (integer)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"integer\",\"title\":\"Is Latest\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"kind\"}\n                              required={true}\n                              schemaName={\"Kind (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Kind\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    base_object_class\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  <strong\n                                    style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"color\":\"var(--openapi-required)\"}}\n                                  >\n                                     required\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        string\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"val\"}\n                              required={true}\n                              schemaName={\"Val\"}\n                              qualifierMessage={undefined}\n                              schema={{\"title\":\"Val\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    wb_user_id\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  <div\n                                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                  >\n                                    \n                                    \n                                    Do not set directly. Server will automatically populate this field.\n                                    \n                                    \n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        string\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    size_bytes\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        integer\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"obj\\\": {\\n    \\\"project_id\\\": \\\"string\\\",\\n    \\\"object_id\\\": \\\"string\\\",\\n    \\\"created_at\\\": \\\"2025-04-30T23:50:38.689Z\\\",\\n    \\\"deleted_at\\\": \\\"2025-04-30T23:50:38.689Z\\\",\\n    \\\"digest\\\": \\\"string\\\",\\n    \\\"version_index\\\": 0,\\n    \\\"is_latest\\\": 0,\\n    \\\"kind\\\": \\\"string\\\",\\n    \\\"base_object_class\\\": \\\"string\\\",\\n    \\\"wb_user_id\\\": \\\"string\\\",\\n    \\\"size_bytes\\\": 0\\n  }\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Table Create\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/table-create-table-create-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Table Create\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/table/create\"}\n>\n  \n\n\n\n\nTable Create\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              <span\n                className={\"openapi-schema__container\"}\n              >\n                <strong\n                  className={\"openapi-schema__property\"}\n                >\n                  table\n                <span\n                  className={\"openapi-schema__name\"}\n                >\n                   object\n                <span\n                  className={\"openapi-schema__divider\"}\n                >\n                  \n                <span\n                  className={\"openapi-schema__required\"}\n                >\n                  required\n                \n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <SchemaItem\n                collapsible={false}\n                name={\"project_id\"}\n                required={true}\n                schemaName={\"Project Id (string)\"}\n                qualifierMessage={undefined}\n                schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n              >\n                \n              <SchemaItem\n                collapsible={false}\n                name={\"rows\"}\n                required={true}\n                schemaName={\"object[]\"}\n                qualifierMessage={undefined}\n                schema={{\"items\":{\"type\":\"object\"},\"type\":\"array\",\"title\":\"Rows\"}}\n              >\n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"digest\"}\n                        required={true}\n                        schemaName={\"Digest (string)\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"string\",\"title\":\"Digest\"}}\n                      >\n                        \n                      <SchemaItem\n                        collapsible={false}\n                        name={\"row_digests\"}\n                        required={false}\n                        schemaName={\"string[]\"}\n                        qualifierMessage={undefined}\n                        schema={{\"items\":{\"type\":\"string\"},\"type\":\"array\",\"title\":\"Row Digests\",\"description\":\"The digests of the rows that were created\"}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"digest\\\": \\\"string\\\",\\n  \\\"row_digests\\\": [\\n    \\\"string\\\"\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Server Info\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/server-info-server-info-get.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Server Info\"}\n>\n\n\n<MethodEndpoint\n  method={\"get\"}\n  path={\"/server_info\"}\n>\n  \n\n\n\n\nServer Info\n\n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"min_required_weave_python_version\"}\n                        required={true}\n                        schemaName={\"Min Required Weave Python Version (string)\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"string\",\"title\":\"Min Required Weave Python Version\"}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"min_required_weave_python_version\\\": \\\"string\\\"\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Obj Create\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/obj-create-obj-create-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Obj Create\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/obj/create\"}\n>\n  \n\n\n\n\nObj Create\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              <span\n                className={\"openapi-schema__container\"}\n              >\n                <strong\n                  className={\"openapi-schema__property\"}\n                >\n                  obj\n                <span\n                  className={\"openapi-schema__name\"}\n                >\n                   object\n                <span\n                  className={\"openapi-schema__divider\"}\n                >\n                  \n                <span\n                  className={\"openapi-schema__required\"}\n                >\n                  required\n                \n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <SchemaItem\n                collapsible={false}\n                name={\"project_id\"}\n                required={true}\n                schemaName={\"Project Id (string)\"}\n                qualifierMessage={undefined}\n                schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n              >\n                \n              <SchemaItem\n                collapsible={false}\n                name={\"object_id\"}\n                required={true}\n                schemaName={\"Object Id (string)\"}\n                qualifierMessage={undefined}\n                schema={{\"type\":\"string\",\"title\":\"Object Id\"}}\n              >\n                \n              <SchemaItem\n                collapsible={false}\n                name={\"val\"}\n                required={true}\n                schemaName={\"Val\"}\n                qualifierMessage={undefined}\n                schema={{\"title\":\"Val\"}}\n              >\n                \n              <SchemaItem\n                collapsible={true}\n                className={\"schemaItem\"}\n              >\n                <details\n                  style={{}}\n                  className={\"openapi-markdown__details\"}\n                >\n                  <summary\n                    style={{}}\n                  >\n                    \n                      builtin_object_class\n                    <span\n                      style={{\"opacity\":\"0.6\"}}\n                    >\n                       object\n                    \n                  <div\n                    style={{\"marginLeft\":\"1rem\"}}\n                  >\n                    \n                  \n                    <span\n                      className={\"badge badge--info\"}\n                    >\n                      anyOf\n                    \n                      <TabItem\n                        label={\"MOD1\"}\n                        value={\"0-item-properties\"}\n                      >\n                        <div\n                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                        >\n                          \n                          \n                          string\n                          \n                          \n                        \n                      \n                    \n                  \n                \n              <SchemaItem\n                collapsible={true}\n                className={\"schemaItem\"}\n              >\n                <details\n                  style={{}}\n                  className={\"openapi-markdown__details\"}\n                >\n                  <summary\n                    style={{}}\n                  >\n                    \n                      set_base_object_class\n                    <span\n                      style={{\"opacity\":\"0.6\"}}\n                    >\n                       object\n                    \n                  <div\n                    style={{\"marginLeft\":\"1rem\"}}\n                  >\n                    \n                  \n                    <span\n                      className={\"badge badge--info\"}\n                    >\n                      anyOf\n                    \n                      <TabItem\n                        label={\"MOD1\"}\n                        value={\"0-item-properties\"}\n                      >\n                        <div\n                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                        >\n                          \n                          \n                          string\n                          \n                          \n                        \n                      \n                    \n                  \n                \n              <SchemaItem\n                collapsible={true}\n                className={\"schemaItem\"}\n              >\n                <details\n                  style={{}}\n                  className={\"openapi-markdown__details\"}\n                >\n                  <summary\n                    style={{}}\n                  >\n                    \n                      wb_user_id\n                    <span\n                      style={{\"opacity\":\"0.6\"}}\n                    >\n                       object\n                    \n                  <div\n                    style={{\"marginLeft\":\"1rem\"}}\n                  >\n                    <div\n                      style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                    >\n                      \n                      \n                      Do not set directly. Server will automatically populate this field.\n                      \n                      \n                    \n                  \n                    <span\n                      className={\"badge badge--info\"}\n                    >\n                      anyOf\n                    \n                      <TabItem\n                        label={\"MOD1\"}\n                        value={\"0-item-properties\"}\n                      >\n                        <div\n                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                        >\n                          \n                          \n                          string\n                          \n                          \n                        \n                      \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"digest\"}\n                        required={true}\n                        schemaName={\"Digest (string)\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"string\",\"title\":\"Digest\"}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"digest\\\": \\\"string\\\"\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Feedback Create\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/feedback-create-feedback-create-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Feedback Create\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/feedback/create\"}\n>\n  \n\n\n\n\nAdd feedback to a call or object.\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\",\"examples\":[\"entity/project\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={false}\n          name={\"weave_ref\"}\n          required={true}\n          schemaName={\"Weave Ref (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Weave Ref\",\"examples\":[\"weave:///entity/project/object/name:digest\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                creator\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={false}\n          name={\"feedback_type\"}\n          required={true}\n          schemaName={\"Feedback Type (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Feedback Type\",\"examples\":[\"custom\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={false}\n          name={\"payload\"}\n          required={true}\n          schemaName={\"object\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"object\",\"title\":\"Payload\",\"examples\":[{\"key\":\"value\"}]}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                annotation_ref\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                runnable_ref\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                call_ref\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                trigger_ref\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                wb_user_id\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Do not set directly. Server will automatically populate this field.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"id\"}\n                        required={true}\n                        schemaName={\"Id (string)\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"string\",\"title\":\"Id\"}}\n                      >\n                        \n                      <SchemaItem\n                        collapsible={false}\n                        name={\"created_at\"}\n                        required={true}\n                        schemaName={\"date-time\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"string\",\"format\":\"date-time\",\"title\":\"Created At\"}}\n                      >\n                        \n                      <SchemaItem\n                        collapsible={false}\n                        name={\"wb_user_id\"}\n                        required={true}\n                        schemaName={\"Wb User Id (string)\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"string\",\"title\":\"Wb User Id\"}}\n                      >\n                        \n                      <SchemaItem\n                        collapsible={false}\n                        name={\"payload\"}\n                        required={true}\n                        schemaName={\"object\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"object\",\"title\":\"Payload\"}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"id\\\": \\\"string\\\",\\n  \\\"created_at\\\": \\\"2025-04-30T23:50:38.708Z\\\",\\n  \\\"wb_user_id\\\": \\\"string\\\",\\n  \\\"payload\\\": {}\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Call End\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/call-end-call-end-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Call End\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/call/end\"}\n>\n  \n\n\n\n\nCall End\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              <span\n                className={\"openapi-schema__container\"}\n              >\n                <strong\n                  className={\"openapi-schema__property\"}\n                >\n                  end\n                <span\n                  className={\"openapi-schema__name\"}\n                >\n                   object\n                <span\n                  className={\"openapi-schema__divider\"}\n                >\n                  \n                <span\n                  className={\"openapi-schema__required\"}\n                >\n                  required\n                \n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <SchemaItem\n                collapsible={false}\n                name={\"project_id\"}\n                required={true}\n                schemaName={\"Project Id (string)\"}\n                qualifierMessage={undefined}\n                schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n              >\n                \n              <SchemaItem\n                collapsible={false}\n                name={\"id\"}\n                required={true}\n                schemaName={\"Id (string)\"}\n                qualifierMessage={undefined}\n                schema={{\"type\":\"string\",\"title\":\"Id\"}}\n              >\n                \n              <SchemaItem\n                collapsible={false}\n                name={\"ended_at\"}\n                required={true}\n                schemaName={\"date-time\"}\n                qualifierMessage={undefined}\n                schema={{\"type\":\"string\",\"format\":\"date-time\",\"title\":\"Ended At\"}}\n              >\n                \n              <SchemaItem\n                collapsible={true}\n                className={\"schemaItem\"}\n              >\n                <details\n                  style={{}}\n                  className={\"openapi-markdown__details\"}\n                >\n                  <summary\n                    style={{}}\n                  >\n                    \n                      exception\n                    <span\n                      style={{\"opacity\":\"0.6\"}}\n                    >\n                       object\n                    \n                  <div\n                    style={{\"marginLeft\":\"1rem\"}}\n                  >\n                    \n                  \n                    <span\n                      className={\"badge badge--info\"}\n                    >\n                      anyOf\n                    \n                      <TabItem\n                        label={\"MOD1\"}\n                        value={\"0-item-properties\"}\n                      >\n                        <div\n                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                        >\n                          \n                          \n                          string\n                          \n                          \n                        \n                      \n                    \n                  \n                \n              <SchemaItem\n                collapsible={false}\n                name={\"output\"}\n                required={false}\n                schemaName={\"object\"}\n                qualifierMessage={undefined}\n                schema={{\"title\":\"Output\",\"type\":\"object\"}}\n              >\n                \n              <SchemaItem\n                collapsible={true}\n                className={\"schemaItem\"}\n              >\n                <details\n                  style={{}}\n                  className={\"openapi-markdown__details\"}\n                >\n                  <summary\n                    style={{}}\n                  >\n                    <span\n                      className={\"openapi-schema__container\"}\n                    >\n                      <strong\n                        className={\"openapi-schema__property\"}\n                      >\n                        summary\n                      <span\n                        className={\"openapi-schema__name\"}\n                      >\n                         object\n                      <span\n                        className={\"openapi-schema__divider\"}\n                      >\n                        \n                      <span\n                        className={\"openapi-schema__required\"}\n                      >\n                        required\n                      \n                    \n                  <div\n                    style={{\"marginLeft\":\"1rem\"}}\n                  >\n                    <SchemaItem\n                      collapsible={true}\n                      className={\"schemaItem\"}\n                    >\n                      <details\n                        style={{}}\n                        className={\"openapi-markdown__details\"}\n                      >\n                        <summary\n                          style={{}}\n                        >\n                          <span\n                            className={\"openapi-schema__container\"}\n                          >\n                            <strong\n                              className={\"openapi-schema__property\"}\n                            >\n                              usage\n                            <span\n                              className={\"openapi-schema__name\"}\n                            >\n                               object\n                            \n                          \n                        <div\n                          style={{\"marginLeft\":\"1rem\"}}\n                        >\n                          <SchemaItem\n                            collapsible={true}\n                            className={\"schemaItem\"}\n                          >\n                            <details\n                              style={{}}\n                              className={\"openapi-markdown__details\"}\n                            >\n                              <summary\n                                style={{}}\n                              >\n                                <span\n                                  className={\"openapi-schema__container\"}\n                                >\n                                  <strong\n                                    className={\"openapi-schema__property\"}\n                                  >\n                                    property name*\n                                  <span\n                                    className={\"openapi-schema__name\"}\n                                  >\n                                     LLMUsageSchema\n                                  \n                                \n                              <div\n                                style={{\"marginLeft\":\"1rem\"}}\n                              >\n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        prompt_tokens\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            integer\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        input_tokens\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            integer\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        completion_tokens\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            integer\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        output_tokens\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            integer\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        requests\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            integer\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        total_tokens\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            integer\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            \n                          \n                        \n                      \n                    <SchemaItem\n                      name={\"property name*\"}\n                      required={false}\n                      schemaName={\"any\"}\n                      qualifierMessage={undefined}\n                      schema={{\"properties\":{\"usage\":{\"additionalProperties\":{\"properties\":{\"prompt_tokens\":{\"anyOf\":[{\"type\":\"integer\"},{\"type\":\"null\"}],\"title\":\"Prompt Tokens\"},\"input_tokens\":{\"anyOf\":[{\"type\":\"integer\"},{\"type\":\"null\"}],\"title\":\"Input Tokens\"},\"completion_tokens\":{\"anyOf\":[{\"type\":\"integer\"},{\"type\":\"null\"}],\"title\":\"Completion Tokens\"},\"output_tokens\":{\"anyOf\":[{\"type\":\"integer\"},{\"type\":\"null\"}],\"title\":\"Output Tokens\"},\"requests\":{\"anyOf\":[{\"type\":\"integer\"},{\"type\":\"null\"}],\"title\":\"Requests\"},\"total_tokens\":{\"anyOf\":[{\"type\":\"integer\"},{\"type\":\"null\"}],\"title\":\"Total Tokens\"}},\"type\":\"object\",\"title\":\"LLMUsageSchema\"},\"type\":\"object\",\"title\":\"Usage\"}},\"additionalProperties\":true,\"type\":\"object\",\"title\":\"SummaryInsertMap\"}}\n                      collapsible={false}\n                      discriminator={false}\n                    >\n                      \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"\"}\n                        required={false}\n                        schemaName={\"object\"}\n                        qualifierMessage={undefined}\n                        schema={{}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"File Content\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/file-content-file-content-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"File Content\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/file/content\"}\n>\n  \n\n\n\n\nFile Content\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n        >\n          \n        <SchemaItem\n          collapsible={false}\n          name={\"digest\"}\n          required={true}\n          schemaName={\"Digest (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Digest\"}}\n        >\n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      any\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Cost Purge\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/cost-purge-cost-purge-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Cost Purge\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/cost/purge\"}\n>\n  \n\n\n\n\nCost Purge\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\",\"examples\":[\"entity/project\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              <span\n                className={\"openapi-schema__container\"}\n              >\n                <strong\n                  className={\"openapi-schema__property\"}\n                >\n                  query\n                <span\n                  className={\"openapi-schema__name\"}\n                >\n                   object\n                <span\n                  className={\"openapi-schema__divider\"}\n                >\n                  \n                <span\n                  className={\"openapi-schema__required\"}\n                >\n                  required\n                \n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <SchemaItem\n                collapsible={false}\n                name={\"$expr\"}\n                required={true}\n                schemaName={\"object\"}\n                qualifierMessage={undefined}\n                schema={{\"title\":\"$Expr\",\"type\":\"object\"}}\n              >\n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"\"}\n                        required={false}\n                        schemaName={\"object\"}\n                        qualifierMessage={undefined}\n                        schema={{}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Export Trace\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/export-trace-otel-v-1-traces-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Export Trace\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/otel/v1/traces\"}\n>\n  \n\n\n\n\nExport Trace\n\n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      any\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Feedback Query\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/feedback-query-feedback-query-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Feedback Query\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/feedback/query\"}\n>\n  \n\n\n\n\nQuery for feedback.\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\",\"examples\":[\"entity/project\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                fields\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                    >\n                      Array [\n                    \n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                    >\n                      ]\n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                query\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"Query\"}\n                  value={\"0-item-properties\"}\n                >\n                  <SchemaItem\n                    collapsible={false}\n                    name={\"$expr\"}\n                    required={true}\n                    schemaName={\"object\"}\n                    qualifierMessage={undefined}\n                    schema={{\"title\":\"$Expr\",\"type\":\"object\"}}\n                  >\n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                sort_by\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                    >\n                      Array [\n                    \n                  <SchemaItem\n                    collapsible={false}\n                    name={\"field\"}\n                    required={true}\n                    schemaName={\"Field (string)\"}\n                    qualifierMessage={undefined}\n                    schema={{\"type\":\"string\",\"title\":\"Field\"}}\n                  >\n                    \n                  <SchemaItem\n                    collapsible={false}\n                    name={\"direction\"}\n                    required={true}\n                    schemaName={\"Direction (string)\"}\n                    qualifierMessage={\"**Possible values:** [`asc`, `desc`]\"}\n                    schema={{\"type\":\"string\",\"enum\":[\"asc\",\"desc\"],\"title\":\"Direction\"}}\n                  >\n                    \n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                    >\n                      ]\n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                limit\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    integer\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                offset\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    integer\n                    \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"result\"}\n                        required={true}\n                        schemaName={\"object[]\"}\n                        qualifierMessage={undefined}\n                        schema={{\"items\":{\"type\":\"object\"},\"type\":\"array\",\"title\":\"Result\"}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"result\\\": [\\n    {}\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Call Read\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/call-read-call-read-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Call Read\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/call/read\"}\n>\n  \n\n\n\n\nCall Read\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n        >\n          \n        <SchemaItem\n          collapsible={false}\n          name={\"id\"}\n          required={true}\n          schemaName={\"Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Id\"}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                include_costs\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    boolean\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                include_storage_size\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    boolean\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                include_total_storage_size\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    boolean\n                    \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            \n                              call\n                            <span\n                              style={{\"opacity\":\"0.6\"}}\n                            >\n                               object\n                            <strong\n                              style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"color\":\"var(--openapi-required)\"}}\n                            >\n                               required\n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                          \n                            <span\n                              className={\"badge badge--info\"}\n                            >\n                              anyOf\n                            \n                              <TabItem\n                                label={\"CallSchema\"}\n                                value={\"0-item-properties\"}\n                              >\n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"id\"}\n                                  required={true}\n                                  schemaName={\"Id (string)\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"string\",\"title\":\"Id\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"project_id\"}\n                                  required={true}\n                                  schemaName={\"Project Id (string)\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"op_name\"}\n                                  required={true}\n                                  schemaName={\"Op Name (string)\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"string\",\"title\":\"Op Name\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        display_name\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            string\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"trace_id\"}\n                                  required={true}\n                                  schemaName={\"Trace Id (string)\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"string\",\"title\":\"Trace Id\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        parent_id\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            string\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"started_at\"}\n                                  required={true}\n                                  schemaName={\"date-time\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"string\",\"format\":\"date-time\",\"title\":\"Started At\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"attributes\"}\n                                  required={true}\n                                  schemaName={\"object\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"object\",\"title\":\"Attributes\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"inputs\"}\n                                  required={true}\n                                  schemaName={\"object\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"object\",\"title\":\"Inputs\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        ended_at\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            string\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        exception\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            string\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"output\"}\n                                  required={false}\n                                  schemaName={\"object\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"title\":\"Output\",\"type\":\"object\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"summary\"}\n                                  required={false}\n                                  schemaName={\"object\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"object\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        wb_user_id\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            string\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        wb_run_id\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            string\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        deleted_at\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            string\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        storage_size_bytes\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            integer\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        total_storage_size_bytes\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            integer\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"call\\\": {}\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Calls Query Stats\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/calls-query-stats-calls-query-stats-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Calls Query Stats\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/calls/query_stats\"}\n>\n  \n\n\n\n\nCalls Query Stats\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                filter\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"CallsFilter\"}\n                  value={\"0-item-properties\"}\n                >\n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          op_names\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          input_refs\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          output_refs\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          parent_ids\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          trace_ids\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          call_ids\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          trace_roots_only\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              boolean\n                              \n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          wb_user_ids\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  <SchemaItem\n                    collapsible={true}\n                    className={\"schemaItem\"}\n                  >\n                    <details\n                      style={{}}\n                      className={\"openapi-markdown__details\"}\n                    >\n                      <summary\n                        style={{}}\n                      >\n                        \n                          wb_run_ids\n                        <span\n                          style={{\"opacity\":\"0.6\"}}\n                        >\n                           object\n                        \n                      <div\n                        style={{\"marginLeft\":\"1rem\"}}\n                      >\n                        \n                      \n                        <span\n                          className={\"badge badge--info\"}\n                        >\n                          anyOf\n                        \n                          <TabItem\n                            label={\"MOD1\"}\n                            value={\"0-item-properties\"}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <div\n                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                            >\n                              \n                              \n                              string\n                              \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                query\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"Query\"}\n                  value={\"0-item-properties\"}\n                >\n                  <SchemaItem\n                    collapsible={false}\n                    name={\"$expr\"}\n                    required={true}\n                    schemaName={\"object\"}\n                    qualifierMessage={undefined}\n                    schema={{\"title\":\"$Expr\",\"type\":\"object\"}}\n                  >\n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                limit\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    integer\n                    \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"count\"}\n                        required={true}\n                        schemaName={\"Count (integer)\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"integer\",\"title\":\"Count\"}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"count\\\": 0\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"File Create\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/file-create-file-create-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"File Create\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/file/create\"}\n>\n  \n\n\n\n\nFile Create\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"multipart/form-data\"}\n    value={\"multipart/form-data-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n        >\n          \n        <SchemaItem\n          collapsible={false}\n          name={\"file\"}\n          required={true}\n          schemaName={\"binary\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"format\":\"binary\",\"title\":\"File\"}}\n        >\n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"digest\"}\n                        required={true}\n                        schemaName={\"Digest (string)\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"string\",\"title\":\"Digest\"}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"digest\\\": \\\"string\\\"\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Cost Query\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/cost-query-cost-query-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Cost Query\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/cost/query\"}\n>\n  \n\n\n\n\nCost Query\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\",\"examples\":[\"entity/project\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                fields\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                    >\n                      Array [\n                    \n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                    >\n                      ]\n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                query\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"Query\"}\n                  value={\"0-item-properties\"}\n                >\n                  <SchemaItem\n                    collapsible={false}\n                    name={\"$expr\"}\n                    required={true}\n                    schemaName={\"object\"}\n                    qualifierMessage={undefined}\n                    schema={{\"title\":\"$Expr\",\"type\":\"object\"}}\n                  >\n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                sort_by\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                    >\n                      Array [\n                    \n                  <SchemaItem\n                    collapsible={false}\n                    name={\"field\"}\n                    required={true}\n                    schemaName={\"Field (string)\"}\n                    qualifierMessage={undefined}\n                    schema={{\"type\":\"string\",\"title\":\"Field\"}}\n                  >\n                    \n                  <SchemaItem\n                    collapsible={false}\n                    name={\"direction\"}\n                    required={true}\n                    schemaName={\"Direction (string)\"}\n                    qualifierMessage={\"**Possible values:** [`asc`, `desc`]\"}\n                    schema={{\"type\":\"string\",\"enum\":[\"asc\",\"desc\"],\"title\":\"Direction\"}}\n                  >\n                    \n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                    >\n                      ]\n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                limit\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    integer\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                offset\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    integer\n                    \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                results\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              <span\n                                className={\"openapi-schema__divider\"}\n                              >\n                                \n                              <span\n                                className={\"openapi-schema__required\"}\n                              >\n                                required\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    id\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        string\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    llm_id\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        string\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    prompt_token_cost\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        number\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    completion_token_cost\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        number\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    prompt_token_cost_unit\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        string\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    completion_token_cost_unit\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        string\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    effective_date\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        string\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  \n                                    provider_id\n                                  <span\n                                    style={{\"opacity\":\"0.6\"}}\n                                  >\n                                     object\n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                \n                                  <span\n                                    className={\"badge badge--info\"}\n                                  >\n                                    anyOf\n                                  \n                                    <TabItem\n                                      label={\"MOD1\"}\n                                      value={\"0-item-properties\"}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        string\n                                        \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"results\\\": [\\n    {\\n      \\\"id\\\": \\\"string\\\",\\n      \\\"llm_id\\\": \\\"string\\\",\\n      \\\"prompt_token_cost\\\": 0,\\n      \\\"completion_token_cost\\\": 0,\\n      \\\"prompt_token_cost_unit\\\": \\\"string\\\",\\n      \\\"completion_token_cost_unit\\\": \\\"string\\\",\\n      \\\"effective_date\\\": \\\"2025-04-30T23:50:38.705Z\\\",\\n      \\\"provider_id\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Call Start Batch\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/call-start-batch-call-upsert-batch-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Call Start Batch\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/call/upsert_batch\"}\n>\n  \n\n\n\n\nCall Start Batch\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              <span\n                className={\"openapi-schema__container\"}\n              >\n                <strong\n                  className={\"openapi-schema__property\"}\n                >\n                  batch\n                <span\n                  className={\"openapi-schema__name\"}\n                >\n                   object[]\n                <span\n                  className={\"openapi-schema__divider\"}\n                >\n                  \n                <span\n                  className={\"openapi-schema__required\"}\n                >\n                  required\n                \n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n                <div\n                  style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                >\n                  Array [\n                \n              \n                <span\n                  className={\"badge badge--info\"}\n                >\n                  anyOf\n                \n                  <TabItem\n                    label={\"CallBatchStartMode\"}\n                    value={\"0-item-properties\"}\n                  >\n                    <SchemaItem\n                      collapsible={false}\n                      name={\"mode\"}\n                      required={false}\n                      schemaName={\"Mode (string)\"}\n                      qualifierMessage={undefined}\n                      schema={{\"type\":\"string\",\"title\":\"Mode\",\"default\":\"start\"}}\n                    >\n                      \n                    <SchemaItem\n                      collapsible={true}\n                      className={\"schemaItem\"}\n                    >\n                      <details\n                        style={{}}\n                        className={\"openapi-markdown__details\"}\n                      >\n                        <summary\n                          style={{}}\n                        >\n                          <span\n                            className={\"openapi-schema__container\"}\n                          >\n                            <strong\n                              className={\"openapi-schema__property\"}\n                            >\n                              req\n                            <span\n                              className={\"openapi-schema__name\"}\n                            >\n                               object\n                            <span\n                              className={\"openapi-schema__divider\"}\n                            >\n                              \n                            <span\n                              className={\"openapi-schema__required\"}\n                            >\n                              required\n                            \n                          \n                        <div\n                          style={{\"marginLeft\":\"1rem\"}}\n                        >\n                          <SchemaItem\n                            collapsible={true}\n                            className={\"schemaItem\"}\n                          >\n                            <details\n                              style={{}}\n                              className={\"openapi-markdown__details\"}\n                            >\n                              <summary\n                                style={{}}\n                              >\n                                <span\n                                  className={\"openapi-schema__container\"}\n                                >\n                                  <strong\n                                    className={\"openapi-schema__property\"}\n                                  >\n                                    start\n                                  <span\n                                    className={\"openapi-schema__name\"}\n                                  >\n                                     object\n                                  <span\n                                    className={\"openapi-schema__divider\"}\n                                  >\n                                    \n                                  <span\n                                    className={\"openapi-schema__required\"}\n                                  >\n                                    required\n                                  \n                                \n                              <div\n                                style={{\"marginLeft\":\"1rem\"}}\n                              >\n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"project_id\"}\n                                  required={true}\n                                  schemaName={\"Project Id (string)\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        id\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            string\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"op_name\"}\n                                  required={true}\n                                  schemaName={\"Op Name (string)\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"string\",\"title\":\"Op Name\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        display_name\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            string\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        trace_id\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            string\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        parent_id\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            string\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"started_at\"}\n                                  required={true}\n                                  schemaName={\"date-time\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"string\",\"format\":\"date-time\",\"title\":\"Started At\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"attributes\"}\n                                  required={true}\n                                  schemaName={\"object\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"object\",\"title\":\"Attributes\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"inputs\"}\n                                  required={true}\n                                  schemaName={\"object\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"object\",\"title\":\"Inputs\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        wb_user_id\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      <div\n                                        style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                      >\n                                        \n                                        \n                                        Do not set directly. Server will automatically populate this field.\n                                        \n                                        \n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            string\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        wb_run_id\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            string\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            \n                          \n                        \n                      \n                    \n                  <TabItem\n                    label={\"CallBatchEndMode\"}\n                    value={\"1-item-properties\"}\n                  >\n                    <SchemaItem\n                      collapsible={false}\n                      name={\"mode\"}\n                      required={false}\n                      schemaName={\"Mode (string)\"}\n                      qualifierMessage={undefined}\n                      schema={{\"type\":\"string\",\"title\":\"Mode\",\"default\":\"end\"}}\n                    >\n                      \n                    <SchemaItem\n                      collapsible={true}\n                      className={\"schemaItem\"}\n                    >\n                      <details\n                        style={{}}\n                        className={\"openapi-markdown__details\"}\n                      >\n                        <summary\n                          style={{}}\n                        >\n                          <span\n                            className={\"openapi-schema__container\"}\n                          >\n                            <strong\n                              className={\"openapi-schema__property\"}\n                            >\n                              req\n                            <span\n                              className={\"openapi-schema__name\"}\n                            >\n                               object\n                            <span\n                              className={\"openapi-schema__divider\"}\n                            >\n                              \n                            <span\n                              className={\"openapi-schema__required\"}\n                            >\n                              required\n                            \n                          \n                        <div\n                          style={{\"marginLeft\":\"1rem\"}}\n                        >\n                          <SchemaItem\n                            collapsible={true}\n                            className={\"schemaItem\"}\n                          >\n                            <details\n                              style={{}}\n                              className={\"openapi-markdown__details\"}\n                            >\n                              <summary\n                                style={{}}\n                              >\n                                <span\n                                  className={\"openapi-schema__container\"}\n                                >\n                                  <strong\n                                    className={\"openapi-schema__property\"}\n                                  >\n                                    end\n                                  <span\n                                    className={\"openapi-schema__name\"}\n                                  >\n                                     object\n                                  <span\n                                    className={\"openapi-schema__divider\"}\n                                  >\n                                    \n                                  <span\n                                    className={\"openapi-schema__required\"}\n                                  >\n                                    required\n                                  \n                                \n                              <div\n                                style={{\"marginLeft\":\"1rem\"}}\n                              >\n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"project_id\"}\n                                  required={true}\n                                  schemaName={\"Project Id (string)\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"id\"}\n                                  required={true}\n                                  schemaName={\"Id (string)\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"string\",\"title\":\"Id\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"ended_at\"}\n                                  required={true}\n                                  schemaName={\"date-time\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"type\":\"string\",\"format\":\"date-time\",\"title\":\"Ended At\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      \n                                        exception\n                                      <span\n                                        style={{\"opacity\":\"0.6\"}}\n                                      >\n                                         object\n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      \n                                    \n                                      <span\n                                        className={\"badge badge--info\"}\n                                      >\n                                        anyOf\n                                      \n                                        <TabItem\n                                          label={\"MOD1\"}\n                                          value={\"0-item-properties\"}\n                                        >\n                                          <div\n                                            style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                          >\n                                            \n                                            \n                                            string\n                                            \n                                            \n                                          \n                                        \n                                      \n                                    \n                                  \n                                <SchemaItem\n                                  collapsible={false}\n                                  name={\"output\"}\n                                  required={false}\n                                  schemaName={\"object\"}\n                                  qualifierMessage={undefined}\n                                  schema={{\"title\":\"Output\",\"type\":\"object\"}}\n                                >\n                                  \n                                <SchemaItem\n                                  collapsible={true}\n                                  className={\"schemaItem\"}\n                                >\n                                  <details\n                                    style={{}}\n                                    className={\"openapi-markdown__details\"}\n                                  >\n                                    <summary\n                                      style={{}}\n                                    >\n                                      <span\n                                        className={\"openapi-schema__container\"}\n                                      >\n                                        <strong\n                                          className={\"openapi-schema__property\"}\n                                        >\n                                          summary\n                                        <span\n                                          className={\"openapi-schema__name\"}\n                                        >\n                                           object\n                                        <span\n                                          className={\"openapi-schema__divider\"}\n                                        >\n                                          \n                                        <span\n                                          className={\"openapi-schema__required\"}\n                                        >\n                                          required\n                                        \n                                      \n                                    <div\n                                      style={{\"marginLeft\":\"1rem\"}}\n                                    >\n                                      <SchemaItem\n                                        collapsible={true}\n                                        className={\"schemaItem\"}\n                                      >\n                                        <details\n                                          style={{}}\n                                          className={\"openapi-markdown__details\"}\n                                        >\n                                          <summary\n                                            style={{}}\n                                          >\n                                            <span\n                                              className={\"openapi-schema__container\"}\n                                            >\n                                              <strong\n                                                className={\"openapi-schema__property\"}\n                                              >\n                                                usage\n                                              <span\n                                                className={\"openapi-schema__name\"}\n                                              >\n                                                 object\n                                              \n                                            \n                                          <div\n                                            style={{\"marginLeft\":\"1rem\"}}\n                                          >\n                                            <SchemaItem\n                                              collapsible={true}\n                                              className={\"schemaItem\"}\n                                            >\n                                              <details\n                                                style={{}}\n                                                className={\"openapi-markdown__details\"}\n                                              >\n                                                <summary\n                                                  style={{}}\n                                                >\n                                                  <span\n                                                    className={\"openapi-schema__container\"}\n                                                  >\n                                                    <strong\n                                                      className={\"openapi-schema__property\"}\n                                                    >\n                                                      property name*\n                                                    <span\n                                                      className={\"openapi-schema__name\"}\n                                                    >\n                                                       LLMUsageSchema\n                                                    \n                                                  \n                                                <div\n                                                  style={{\"marginLeft\":\"1rem\"}}\n                                                >\n                                                  <SchemaItem\n                                                    collapsible={true}\n                                                    className={\"schemaItem\"}\n                                                  >\n                                                    <details\n                                                      style={{}}\n                                                      className={\"openapi-markdown__details\"}\n                                                    >\n                                                      <summary\n                                                        style={{}}\n                                                      >\n                                                        \n                                                          prompt_tokens\n                                                        <span\n                                                          style={{\"opacity\":\"0.6\"}}\n                                                        >\n                                                           object\n                                                        \n                                                      <div\n                                                        style={{\"marginLeft\":\"1rem\"}}\n                                                      >\n                                                        \n                                                      \n                                                        <span\n                                                          className={\"badge badge--info\"}\n                                                        >\n                                                          anyOf\n                                                        \n                                                          <TabItem\n                                                            label={\"MOD1\"}\n                                                            value={\"0-item-properties\"}\n                                                          >\n                                                            <div\n                                                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                                            >\n                                                              \n                                                              \n                                                              integer\n                                                              \n                                                              \n                                                            \n                                                          \n                                                        \n                                                      \n                                                    \n                                                  <SchemaItem\n                                                    collapsible={true}\n                                                    className={\"schemaItem\"}\n                                                  >\n                                                    <details\n                                                      style={{}}\n                                                      className={\"openapi-markdown__details\"}\n                                                    >\n                                                      <summary\n                                                        style={{}}\n                                                      >\n                                                        \n                                                          input_tokens\n                                                        <span\n                                                          style={{\"opacity\":\"0.6\"}}\n                                                        >\n                                                           object\n                                                        \n                                                      <div\n                                                        style={{\"marginLeft\":\"1rem\"}}\n                                                      >\n                                                        \n                                                      \n                                                        <span\n                                                          className={\"badge badge--info\"}\n                                                        >\n                                                          anyOf\n                                                        \n                                                          <TabItem\n                                                            label={\"MOD1\"}\n                                                            value={\"0-item-properties\"}\n                                                          >\n                                                            <div\n                                                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                                            >\n                                                              \n                                                              \n                                                              integer\n                                                              \n                                                              \n                                                            \n                                                          \n                                                        \n                                                      \n                                                    \n                                                  <SchemaItem\n                                                    collapsible={true}\n                                                    className={\"schemaItem\"}\n                                                  >\n                                                    <details\n                                                      style={{}}\n                                                      className={\"openapi-markdown__details\"}\n                                                    >\n                                                      <summary\n                                                        style={{}}\n                                                      >\n                                                        \n                                                          completion_tokens\n                                                        <span\n                                                          style={{\"opacity\":\"0.6\"}}\n                                                        >\n                                                           object\n                                                        \n                                                      <div\n                                                        style={{\"marginLeft\":\"1rem\"}}\n                                                      >\n                                                        \n                                                      \n                                                        <span\n                                                          className={\"badge badge--info\"}\n                                                        >\n                                                          anyOf\n                                                        \n                                                          <TabItem\n                                                            label={\"MOD1\"}\n                                                            value={\"0-item-properties\"}\n                                                          >\n                                                            <div\n                                                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                                            >\n                                                              \n                                                              \n                                                              integer\n                                                              \n                                                              \n                                                            \n                                                          \n                                                        \n                                                      \n                                                    \n                                                  <SchemaItem\n                                                    collapsible={true}\n                                                    className={\"schemaItem\"}\n                                                  >\n                                                    <details\n                                                      style={{}}\n                                                      className={\"openapi-markdown__details\"}\n                                                    >\n                                                      <summary\n                                                        style={{}}\n                                                      >\n                                                        \n                                                          output_tokens\n                                                        <span\n                                                          style={{\"opacity\":\"0.6\"}}\n                                                        >\n                                                           object\n                                                        \n                                                      <div\n                                                        style={{\"marginLeft\":\"1rem\"}}\n                                                      >\n                                                        \n                                                      \n                                                        <span\n                                                          className={\"badge badge--info\"}\n                                                        >\n                                                          anyOf\n                                                        \n                                                          <TabItem\n                                                            label={\"MOD1\"}\n                                                            value={\"0-item-properties\"}\n                                                          >\n                                                            <div\n                                                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                                            >\n                                                              \n                                                              \n                                                              integer\n                                                              \n                                                              \n                                                            \n                                                          \n                                                        \n                                                      \n                                                    \n                                                  <SchemaItem\n                                                    collapsible={true}\n                                                    className={\"schemaItem\"}\n                                                  >\n                                                    <details\n                                                      style={{}}\n                                                      className={\"openapi-markdown__details\"}\n                                                    >\n                                                      <summary\n                                                        style={{}}\n                                                      >\n                                                        \n                                                          requests\n                                                        <span\n                                                          style={{\"opacity\":\"0.6\"}}\n                                                        >\n                                                           object\n                                                        \n                                                      <div\n                                                        style={{\"marginLeft\":\"1rem\"}}\n                                                      >\n                                                        \n                                                      \n                                                        <span\n                                                          className={\"badge badge--info\"}\n                                                        >\n                                                          anyOf\n                                                        \n                                                          <TabItem\n                                                            label={\"MOD1\"}\n                                                            value={\"0-item-properties\"}\n                                                          >\n                                                            <div\n                                                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                                            >\n                                                              \n                                                              \n                                                              integer\n                                                              \n                                                              \n                                                            \n                                                          \n                                                        \n                                                      \n                                                    \n                                                  <SchemaItem\n                                                    collapsible={true}\n                                                    className={\"schemaItem\"}\n                                                  >\n                                                    <details\n                                                      style={{}}\n                                                      className={\"openapi-markdown__details\"}\n                                                    >\n                                                      <summary\n                                                        style={{}}\n                                                      >\n                                                        \n                                                          total_tokens\n                                                        <span\n                                                          style={{\"opacity\":\"0.6\"}}\n                                                        >\n                                                           object\n                                                        \n                                                      <div\n                                                        style={{\"marginLeft\":\"1rem\"}}\n                                                      >\n                                                        \n                                                      \n                                                        <span\n                                                          className={\"badge badge--info\"}\n                                                        >\n                                                          anyOf\n                                                        \n                                                          <TabItem\n                                                            label={\"MOD1\"}\n                                                            value={\"0-item-properties\"}\n                                                          >\n                                                            <div\n                                                              style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                                            >\n                                                              \n                                                              \n                                                              integer\n                                                              \n                                                              \n                                                            \n                                                          \n                                                        \n                                                      \n                                                    \n                                                  \n                                                \n                                              \n                                            \n                                          \n                                        \n                                      <SchemaItem\n                                        name={\"property name*\"}\n                                        required={false}\n                                        schemaName={\"any\"}\n                                        qualifierMessage={undefined}\n                                        schema={{\"properties\":{\"usage\":{\"additionalProperties\":{\"properties\":{\"prompt_tokens\":{\"anyOf\":[{\"type\":\"integer\"},{\"type\":\"null\"}],\"title\":\"Prompt Tokens\"},\"input_tokens\":{\"anyOf\":[{\"type\":\"integer\"},{\"type\":\"null\"}],\"title\":\"Input Tokens\"},\"completion_tokens\":{\"anyOf\":[{\"type\":\"integer\"},{\"type\":\"null\"}],\"title\":\"Completion Tokens\"},\"output_tokens\":{\"anyOf\":[{\"type\":\"integer\"},{\"type\":\"null\"}],\"title\":\"Output Tokens\"},\"requests\":{\"anyOf\":[{\"type\":\"integer\"},{\"type\":\"null\"}],\"title\":\"Requests\"},\"total_tokens\":{\"anyOf\":[{\"type\":\"integer\"},{\"type\":\"null\"}],\"title\":\"Total Tokens\"}},\"type\":\"object\",\"title\":\"LLMUsageSchema\"},\"type\":\"object\",\"title\":\"Usage\"}},\"additionalProperties\":true,\"type\":\"object\",\"title\":\"SummaryInsertMap\"}}\n                                        collapsible={false}\n                                        discriminator={false}\n                                      >\n                                        \n                                      \n                                    \n                                  \n                                \n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                \n              \n                <div\n                  style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                >\n                  ]\n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                res\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              <span\n                                className={\"openapi-schema__divider\"}\n                              >\n                                \n                              <span\n                                className={\"openapi-schema__required\"}\n                              >\n                                required\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            \n                              <span\n                                className={\"badge badge--info\"}\n                              >\n                                anyOf\n                              \n                                <TabItem\n                                  label={\"CallStartRes\"}\n                                  value={\"0-item-properties\"}\n                                >\n                                  <SchemaItem\n                                    collapsible={false}\n                                    name={\"id\"}\n                                    required={true}\n                                    schemaName={\"Id (string)\"}\n                                    qualifierMessage={undefined}\n                                    schema={{\"type\":\"string\",\"title\":\"Id\"}}\n                                  >\n                                    \n                                  <SchemaItem\n                                    collapsible={false}\n                                    name={\"trace_id\"}\n                                    required={true}\n                                    schemaName={\"Trace Id (string)\"}\n                                    qualifierMessage={undefined}\n                                    schema={{\"type\":\"string\",\"title\":\"Trace Id\"}}\n                                  >\n                                    \n                                  \n                                <TabItem\n                                  label={\"CallEndRes\"}\n                                  value={\"1-item-properties\"}\n                                >\n                                  <SchemaItem\n                                    collapsible={false}\n                                    name={\"\"}\n                                    required={false}\n                                    schemaName={\"object\"}\n                                    qualifierMessage={undefined}\n                                    schema={{}}\n                                  >\n                                    \n                                  \n                                \n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"res\\\": [\\n    {},\\n    {}\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Feedback Replace\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/feedback-replace-feedback-replace-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Feedback Replace\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/feedback/replace\"}\n>\n  \n\n\n\n\nFeedback Replace\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\",\"examples\":[\"entity/project\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={false}\n          name={\"weave_ref\"}\n          required={true}\n          schemaName={\"Weave Ref (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Weave Ref\",\"examples\":[\"weave:///entity/project/object/name:digest\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                creator\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={false}\n          name={\"feedback_type\"}\n          required={true}\n          schemaName={\"Feedback Type (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Feedback Type\",\"examples\":[\"custom\"]}}\n        >\n          \n        <SchemaItem\n          collapsible={false}\n          name={\"payload\"}\n          required={true}\n          schemaName={\"object\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"object\",\"title\":\"Payload\",\"examples\":[{\"key\":\"value\"}]}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                annotation_ref\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                runnable_ref\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                call_ref\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                trigger_ref\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                wb_user_id\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                Do not set directly. Server will automatically populate this field.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                \n              \n            \n          \n        <SchemaItem\n          collapsible={false}\n          name={\"feedback_id\"}\n          required={true}\n          schemaName={\"Feedback Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Feedback Id\"}}\n        >\n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"id\"}\n                        required={true}\n                        schemaName={\"Id (string)\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"string\",\"title\":\"Id\"}}\n                      >\n                        \n                      <SchemaItem\n                        collapsible={false}\n                        name={\"created_at\"}\n                        required={true}\n                        schemaName={\"date-time\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"string\",\"format\":\"date-time\",\"title\":\"Created At\"}}\n                      >\n                        \n                      <SchemaItem\n                        collapsible={false}\n                        name={\"wb_user_id\"}\n                        required={true}\n                        schemaName={\"Wb User Id (string)\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"string\",\"title\":\"Wb User Id\"}}\n                      >\n                        \n                      <SchemaItem\n                        collapsible={false}\n                        name={\"payload\"}\n                        required={true}\n                        schemaName={\"object\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"object\",\"title\":\"Payload\"}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"id\\\": \\\"string\\\",\\n  \\\"created_at\\\": \\\"2025-04-30T23:50:38.711Z\\\",\\n  \\\"wb_user_id\\\": \\\"string\\\",\\n  \\\"payload\\\": {}\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "\"Obj Delete\"",
    "url": "https://weave-docs.wandb.ai/reference/service-api/obj-delete-obj-delete-post.api",
    "section": "Docs",
    "category": "Service API",
    "content": "<Heading\n  as={\"h1\"}\n  className={\"openapi__heading\"}\n  children={\"Obj Delete\"}\n>\n\n\n<MethodEndpoint\n  method={\"post\"}\n  path={\"/obj/delete\"}\n>\n  \n\n\n\n\nObj Delete\n\n<Heading\n  id={\"request\"}\n  as={\"h2\"}\n  className={\"openapi-tabs__heading\"}\n  children={\"Request\"}\n>\n\n\n<MimeTabs\n  className={\"openapi-tabs__mime\"}\n>\n  <TabItem\n    label={\"application/json\"}\n    value={\"application/json-schema\"}\n  >\n    <details\n      style={{}}\n      className={\"openapi-markdown__details mime\"}\n      data-collapsed={false}\n      open={true}\n    >\n      <summary\n        style={{}}\n        className={\"openapi-markdown__details-summary-mime\"}\n      >\n        <h3\n          className={\"openapi-markdown__details-summary-header-body\"}\n        >\n          Body\n        <strong\n          className={\"openapi-schema__required\"}\n        >\n          required\n        \n      <div\n        style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n      >\n        \n      <ul\n        style={{\"marginLeft\":\"1rem\"}}\n      >\n        <SchemaItem\n          collapsible={false}\n          name={\"project_id\"}\n          required={true}\n          schemaName={\"Project Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Project Id\"}}\n        >\n          \n        <SchemaItem\n          collapsible={false}\n          name={\"object_id\"}\n          required={true}\n          schemaName={\"Object Id (string)\"}\n          qualifierMessage={undefined}\n          schema={{\"type\":\"string\",\"title\":\"Object Id\"}}\n        >\n          \n        <SchemaItem\n          collapsible={true}\n          className={\"schemaItem\"}\n        >\n          <details\n            style={{}}\n            className={\"openapi-markdown__details\"}\n          >\n            <summary\n              style={{}}\n            >\n              \n                digests\n              <span\n                style={{\"opacity\":\"0.6\"}}\n              >\n                 object\n              \n            <div\n              style={{\"marginLeft\":\"1rem\"}}\n            >\n              <div\n                style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n              >\n                \n                \n                List of digests to delete. If not provided, all digests for the object will be deleted.\n                \n                \n              \n            \n              <span\n                className={\"badge badge--info\"}\n              >\n                anyOf\n              \n                <TabItem\n                  label={\"MOD1\"}\n                  value={\"0-item-properties\"}\n                >\n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                    >\n                      Array [\n                    \n                  <div\n                    style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                  >\n                    \n                    \n                    string\n                    \n                    \n                  \n                    <div\n                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                    >\n                      ]\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n  \n\n  \n    <ApiTabs\n      label={undefined}\n      id={undefined}\n    >\n      <TabItem\n        label={\"200\"}\n        value={\"200\"}\n      >\n        \n          \n          \n          Successful Response\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={false}\n                        name={\"num_deleted\"}\n                        required={true}\n                        schemaName={\"Num Deleted (integer)\"}\n                        qualifierMessage={undefined}\n                        schema={{\"type\":\"integer\",\"title\":\"Num Deleted\"}}\n                      >\n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"num_deleted\\\": 0\\n}\"}\n                    language={\"json\"}\n                  >\n                    \n                  \n                \n              \n            \n          \n        \n      <TabItem\n        label={\"422\"}\n        value={\"422\"}\n      >\n        \n          \n          \n          Validation Error\n          \n          \n        \n          <MimeTabs\n            className={\"openapi-tabs__mime\"}\n            schemaType={\"response\"}\n          >\n            <TabItem\n              label={\"application/json\"}\n              value={\"application/json\"}\n            >\n              <SchemaTabs\n                className={\"openapi-tabs__schema\"}\n              >\n                <TabItem\n                  label={\"Schema\"}\n                  value={\"Schema\"}\n                >\n                  <details\n                    style={{}}\n                    className={\"openapi-markdown__details response\"}\n                    data-collapsed={false}\n                    open={true}\n                  >\n                    <summary\n                      style={{}}\n                      className={\"openapi-markdown__details-summary-response\"}\n                    >\n                      \n                        Schema\n                      \n                    <div\n                      style={{\"textAlign\":\"left\",\"marginLeft\":\"1rem\"}}\n                    >\n                      \n                    <ul\n                      style={{\"marginLeft\":\"1rem\"}}\n                    >\n                      <SchemaItem\n                        collapsible={true}\n                        className={\"schemaItem\"}\n                      >\n                        <details\n                          style={{}}\n                          className={\"openapi-markdown__details\"}\n                        >\n                          <summary\n                            style={{}}\n                          >\n                            <span\n                              className={\"openapi-schema__container\"}\n                            >\n                              <strong\n                                className={\"openapi-schema__property\"}\n                              >\n                                detail\n                              <span\n                                className={\"openapi-schema__name\"}\n                              >\n                                 object[]\n                              \n                            \n                          <div\n                            style={{\"marginLeft\":\"1rem\"}}\n                          >\n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                              >\n                                Array [\n                              \n                            <SchemaItem\n                              collapsible={true}\n                              className={\"schemaItem\"}\n                            >\n                              <details\n                                style={{}}\n                                className={\"openapi-markdown__details\"}\n                              >\n                                <summary\n                                  style={{}}\n                                >\n                                  <span\n                                    className={\"openapi-schema__container\"}\n                                  >\n                                    <strong\n                                      className={\"openapi-schema__property\"}\n                                    >\n                                      loc\n                                    <span\n                                      className={\"openapi-schema__name\"}\n                                    >\n                                       object[]\n                                    <span\n                                      className={\"openapi-schema__divider\"}\n                                    >\n                                      \n                                    <span\n                                      className={\"openapi-schema__required\"}\n                                    >\n                                      required\n                                    \n                                  \n                                <div\n                                  style={{\"marginLeft\":\"1rem\"}}\n                                >\n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\",\"paddingBottom\":\".5rem\"}}\n                                    >\n                                      Array [\n                                    \n                                  \n                                    <span\n                                      className={\"badge badge--info\"}\n                                    >\n                                      anyOf\n                                    \n                                      <TabItem\n                                        label={\"MOD1\"}\n                                        value={\"0-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          string\n                                          \n                                          \n                                        \n                                      <TabItem\n                                        label={\"MOD2\"}\n                                        value={\"1-item-properties\"}\n                                      >\n                                        <div\n                                          style={{\"marginTop\":\".5rem\",\"marginBottom\":\".5rem\"}}\n                                        >\n                                          \n                                          \n                                          integer\n                                          \n                                          \n                                        \n                                      \n                                    \n                                  \n                                    <div\n                                      style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                                    >\n                                      ]\n                                    \n                                  \n                                \n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"msg\"}\n                              required={true}\n                              schemaName={\"Message (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Message\"}}\n                            >\n                              \n                            <SchemaItem\n                              collapsible={false}\n                              name={\"type\"}\n                              required={true}\n                              schemaName={\"Error Type (string)\"}\n                              qualifierMessage={undefined}\n                              schema={{\"type\":\"string\",\"title\":\"Error Type\"}}\n                            >\n                              \n                            \n                              <div\n                                style={{\"fontSize\":\"var(--ifm-code-font-size)\",\"opacity\":\"0.6\",\"marginLeft\":\"-.5rem\"}}\n                              >\n                                ]\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                <TabItem\n                  label={\"Example (from schema)\"}\n                  value={\"Example (from schema)\"}\n                >\n                  <ResponseSamples\n                    responseExample={\"{\\n  \\\"detail\\\": [\\n    {\\n      \\\"loc\\\": [\\n        \\\"string\\\",\\n        0\\n      ],\\n      \\\"msg\\\": \\\"string\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  ]\\n}\"}\n                    language={\"json\"}\n                  >"
  },
  {
    "title": "Scorers as Guardrails",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/scorers_as_guardrails",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n\n\n\n# Scorers as Guardrails\n\nWeave Scorers are special classes with a `score` method that can evaluate the performance of a call. They can range from quite simple rules to complex LLMs as judges. \n\nIn this notebook, we will explore how to use Scorers as guardrails to prevent your LLM from generating harmful or inappropriate content.\n\n\n\n```python\n%pip install weave --quiet\n```\n\n\n```python\n\"\"\"\nExample demonstrating how to implement guardrails in Weave.\nThis example shows a simple content safety checker that prevents\npotentially harmful or negative responses.\n\"\"\"\n\nimport weave\n\n# Initialize Weave with a descriptive project name\nweave.init(\"content-safety-guardrails\")\n\n\nclass ContentSafetyScorer(weave.Scorer):\n    \"\"\"A scorer that evaluates content safety based on presence of specified phrases.\"\"\"\n\n    unsafe_phrases: list[str]\n    case_sensitive: bool = False\n\n    @weave.op\n    def score(self, output: str) -> bool:\n        \"\"\"\n        Evaluate output safety based on presence of unsafe phrases.\n\n        Args:\n            output: The text output to evaluate\n\n        Returns:\n            bool: True if output is safe, False if unsafe\n        \"\"\"\n        normalized_output = output if self.case_sensitive else output.lower()\n\n        for phrase in self.unsafe_phrases:\n            normalized_phrase = phrase if self.case_sensitive else phrase.lower()\n            if normalized_phrase in normalized_output:\n                return False\n        return True\n\n\n@weave.op\ndef generate_response(prompt: str) -> str:\n    \"\"\"Simulate an LLM response generation.\"\"\"\n    if \"test\" in prompt.lower():\n        return \"I'm sorry, I cannot process that request.\"\n    elif \"help\" in prompt.lower():\n        return \"I'd be happy to help you with that!\"\n    else:\n        return \"Here's what you requested: \" + prompt\n\n\nasync def process_with_guardrail(prompt: str) -> str:\n    \"\"\"\n    Process user input with content safety guardrail.\n    Returns the response if safe, or a fallback message if unsafe.\n    \"\"\"\n    # Initialize safety scorer\n    safety_scorer = ContentSafetyScorer(\n        name=\"Content Safety Checker\",\n        unsafe_phrases=[\"sorry\", \"cannot\", \"unable\", \"won't\", \"will not\"],\n    )\n\n    # Generate response and get Call object\n    response, call = generate_response.call(prompt)\n\n    # Apply safety scoring\n    evaluation = await call.apply_scorer(safety_scorer)\n\n    # Return response or fallback based on safety check\n    if evaluation.result:\n        return response\n    else:\n        return \"I cannot provide that response.\"\n```\n\n\n```python\n\"\"\"Example usage of the guardrail system.\"\"\"\ntest_prompts = [\n    \"Please help me with my homework\",\n    \"Can you run a test for me?\",\n    \"Tell me a joke\",\n]\n\nprint(\"Testing content safety guardrails:\\n\")\n\nfor prompt in test_prompts:\n    print(f\"Input: '{prompt}'\")\n    response = await process_with_guardrail(prompt)\n    print(f\"Response: {response}\\n\")\n```"
  },
  {
    "title": "Intro To Weave Hello Eval",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/Intro_to_Weave_Hello_Eval",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n# Introduction to Evaluations\n\n\n\nWeave is a toolkit for developing AI-powered applications.\n\nYou can use Weave to:\n- Log and debug language model inputs, outputs, and traces.\n- Build rigorous, apples-to-apples evaluations for language model use cases.\n- Organize all the information generated across the LLM workflow, from experimentation to evaluations to production.\n\nThis notebook demonstrates how to evaluate a model or function using Weave\u2019s Evaluation API. Evaluation is a core concept in Weave that helps you measure and iterate on your application by running it against a dataset of examples and scoring the outputs using custom-defined functions. You'll define a simple model, create a labeled dataset, track scoring functions with `@weave.op`, and run an evaluation that automatically tracks results in the Weave UI. This forms the foundation for more advanced workflows like LLM fine-tuning, regression testing, or model comparison.\n\nTo get started, complete the prerequisites. Then, define a Weave `Model` with a `predict` method, create a labeled dataset and scoring function, and run an evaluation using `weave.Evaluation.evaluate()`.\n\n## \ud83d\udd11 Prerequisites\n\nBefore you can run a Weave evaluation, complete the following prerequisites.\n\n1. Install the W&B Weave SDK and log in with your [API key](https://wandb.ai/settings#api).\n2. Install the OpenAI SDK and log in with your [API key](https://platform.openai.com/api-keys).\n3. Initialize your W&B project.\n\n\n```python\n# Install dependancies and imports\n!pip install wandb weave openai -q\n\nimport os\nfrom getpass import getpass\n\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nimport weave\n\n# \ud83d\udd11 Setup your API keys\n# Running this cell will prompt you for your API key with `getpass` and will not echo to the terminal.\n#####\nprint(\"---\")\nprint(\n    \"You can find your Weights and Biases API key here: https://wandb.ai/settings#api\"\n)\nos.environ[\"WANDB_API_KEY\"] = getpass(\"Enter your Weights and Biases API key: \")\nprint(\"---\")\nprint(\"You can generate your OpenAI API key here: https://platform.openai.com/api-keys\")\nos.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\nprint(\"---\")\n#####\n\n# \ud83c\udfe0 Enter your W&B project name\nweave_client = weave.init(\"MY_PROJECT_NAME\")  # \ud83d\udc1d Your W&B project name\n```\n\n## \ud83d\udc1d Run your first evaluation\n\nThe following code sample shows how to evaluate an LLM using Weave\u2019s `Model` and `Evaluation` APIs. First, define a Weave model by subclassing `weave.Model`, specifying the model name and prompt format, and tracking a `predict` method with `@weave.op`. The `predict` method sends a prompt to OpenAI and parses the response into a structured output using a Pydantic schema (`FruitExtract`). Then, create a small evaluation dataset consisting of input sentences and expected targets. Next, define a custom scoring function (also tracked using `@weave.op`) that compares the model\u2019s output to the target label. Finally,  wrap everything in a `weave.Evaluation`, specifying your dataset and scorers, and call `evaluate()` to run the evaluation pipeline asynchronously.\n\n\n```python\n# 1. Construct a Weave model\nclass FruitExtract(BaseModel):\n    fruit: str\n    color: str\n    flavor: str\n\n\nclass ExtractFruitsModel(weave.Model):\n    model_name: str\n    prompt_template: str\n\n    @weave.op()\n    def predict(self, sentence: str) -> dict:\n        client = OpenAI()\n\n        response = client.beta.chat.completions.parse(\n            model=self.model_name,\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": self.prompt_template.format(sentence=sentence),\n                }\n            ],\n            response_format=FruitExtract,\n        )\n        result = response.choices[0].message.parsed\n        return result\n\n\nmodel = ExtractFruitsModel(\n    name=\"gpt4o\",\n    model_name=\"gpt-4o\",\n    prompt_template='Extract fields (\"fruit\": , \"color\": , \"flavor\": ) as json, from the following text : {sentence}',\n)\n\n# 2. Collect some samples\nsentences = [\n    \"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.\",\n    \"Pounits are a bright green color and are more savory than sweet.\",\n    \"Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\",\n]\nlabels = [\n    {\"fruit\": \"neoskizzles\", \"color\": \"purple\", \"flavor\": \"candy\"},\n    {\"fruit\": \"pounits\", \"color\": \"green\", \"flavor\": \"savory\"},\n    {\"fruit\": \"glowls\", \"color\": \"orange\", \"flavor\": \"sour, bitter\"},\n]\nexamples = [\n    {\"id\": \"0\", \"sentence\": sentences[0], \"target\": labels[0]},\n    {\"id\": \"1\", \"sentence\": sentences[1], \"target\": labels[1]},\n    {\"id\": \"2\", \"sentence\": sentences[2], \"target\": labels[2]},\n]\n\n\n# 3. Define a scoring function for your evaluation\n@weave.op()\ndef fruit_name_score(target: dict, output: FruitExtract) -> dict:\n    target_flavors = [f.strip().lower() for f in target[\"flavor\"].split(\",\")]\n    output_flavors = [f.strip().lower() for f in output.flavor.split(\",\")]\n    # Check if any target flavor is present in the output flavors\n    matches = any(tf in of for tf in target_flavors for of in output_flavors)\n    return {\"correct\": matches}\n\n\n# 4. Run your evaluation\nevaluation = weave.Evaluation(\n    name=\"fruit_eval\",\n    dataset=examples,\n    scorers=[fruit_name_score],\n)\nawait evaluation.evaluate(model)\n```\n\n## \ud83d\ude80 Looking for more examples?\n\n- Learn how to build an [evlauation pipeline end-to-end](https://weave-docs.wandb.ai/tutorial-eval). \n- Learn how to evaluate a [RAG application by building](https://weave-docs.wandb.ai/tutorial-rag)."
  },
  {
    "title": "Service API",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/weave_via_service_api",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n\n\n\n# Use the Service API to Log and Query Traces\n\nIn the following guide, you will learn how to use the Weave Service API to log traces. Specifically, you will use the Service API to:\n\n1. [Create a mock of a simple LLM call and response, and log it to Weave.](#simple-trace)\n2. [Create a mock of a more complex LLM call and response, and log it to Weave.](#complex-trace)\n3. [Run a sample lookup query on the logged traces.](#run-a-lookup-query)\n\n> **View logged traces**\n>\n> You can view all of the Weave traces created when you run the code in this guide by going to the **Traces** tab in your Weave project (specified by `team_id\\project_id`), and selecting the name of the trace.\n\nBefore beginning, complete the [prerequisites](#prerequisites-set-variables-and-endpoints)\n\n## Prerequisites: Set variables and endpoints\n\nThe following code sets the URL endpoints that will be used to access the Service API:\n\n- [`https://trace.wandb.ai/call/start`](https://weave-docs.wandb.ai/reference/service-api/call-start-call-start-post)\n- [`https://trace.wandb.ai/call/end`](https://weave-docs.wandb.ai/reference/service-api/call-end-call-end-post)\n- [`https://trace.wandb.ai/calls/stream_query`](https://weave-docs.wandb.ai/reference/service-api/calls-query-stream-calls-stream-query-post)\n\nAdditionally, you must set the following variables:\n\n- `project_id`: The name of the W&B project that you want to log your traces to.\n- `team_id`: Your W&B team name.\n- `wandb_token`: Your [W&B authorization token](https://wandb.ai/authorize).\n\n\n```python\nimport datetime\nimport json\n\nimport requests\n\n# Headers and URLs\nheaders = {\"Content-Type\": \"application/json\"}\nurl_start = \"https://trace.wandb.ai/call/start\"\nurl_end = \"https://trace.wandb.ai/call/end\"\nurl_stream_query = \"https://trace.wandb.ai/calls/stream_query\"\n\n# W&B variables\nteam_id = \"\"\nproject_id = \"\"\nwandb_token = \"\"\n```\n\n## Simple trace\nThe following sections walk you through creating a simple trace.\n\n1. [Start a simple trace](#start-a-simple-trace)\n2. [End a simple trace](#end-a-simple-trace)\n\n### Start a simple trace \n\nThe following code creates a sample LLM call `payload_start` and logs it to Weave using the `url_start` endpoint. The `payload_start` object mimics a call to OpenAI's `gpt-4o` with the query `Why is the sky blue?`.\n\nOn success, this code will output a message indicating that the trace was started:\n\n```\nCall started. ID: 01939cdc-38d2-7d61-940d-dcca0a56c575, Trace ID: 01939cdc-38d2-7d61-940d-dcd0e76c5f34\n```\n\n\n```python\n## ------------\n## Start trace\n## ------------\npayload_start = {\n    \"start\": {\n        \"project_id\": f\"{team_id}/{project_id}\",\n        \"op_name\": \"simple_trace\",\n        \"started_at\": datetime.datetime.now().isoformat(),\n        \"inputs\": {\n            # Use this \"messages\" style to generate the chat UI in the expanded trace.\n            \"messages\": [{\"role\": \"user\", \"content\": \"Why is the sky blue?\"}],\n            \"model\": \"gpt-4o\",\n        },\n        \"attributes\": {},\n    }\n}\nresponse = requests.post(\n    url_start, headers=headers, json=payload_start, auth=(\"api\", wandb_token)\n)\nif response.status_code == 200:\n    data = response.json()\n    call_id = data.get(\"id\")\n    trace_id = data.get(\"trace_id\")\n    print(f\"Call started. ID: {call_id}, Trace ID: {trace_id}\")\nelse:\n    print(\"Start request failed with status:\", response.status_code)\n    print(response.text)\n    exit()\n```\n\n### End a simple trace\n\nTo complete the simple trace, the following code creates a sample LLM call `payload_end` and logs it to Weave using the `url_end` endpoint. The `payload_end` object mimics the response from OpenAI's `gpt-4o` given the query `Why is the sky blue?`. The object is formatted so that pricing summary information and the chat completion are generated in trace view in the Weave Dashboard.\n\nOn success, this code will output a message indicating that the trace completed:\n\n```\nCall ended.\n```\n\n\n```python\n## ------------\n## End trace\n## ------------\npayload_end = {\n    \"end\": {\n        \"project_id\": f\"{team_id}/{project_id}\",\n        \"id\": call_id,\n        \"ended_at\": datetime.datetime.now().isoformat(),\n        \"output\": {\n            # Use this \"choices\" style to add the completion to the chat UI in the expanded trace.\n            \"choices\": [\n                {\n                    \"message\": {\n                        \"content\": \"It\u2019s due to Rayleigh scattering, where shorter blue wavelengths of sunlight scatter in all directions.\"\n                    }\n                },\n            ]\n        },\n        # Format the summary like this to generate the pricing summary information in the traces table.\n        \"summary\": {\n            \"usage\": {\n                \"gpt-4o\": {\n                    \"prompt_tokens\": 10,\n                    \"completion_tokens\": 20,\n                    \"total_tokens\": 30,\n                    \"requests\": 1,\n                }\n            }\n        },\n    }\n}\nresponse = requests.post(\n    url_end, headers=headers, json=payload_end, auth=(\"api\", wandb_token)\n)\nif response.status_code == 200:\n    print(\"Call ended.\")\nelse:\n    print(\"End request failed with status:\", response.status_code)\n    print(response.text)\n```\n\n## Complex trace\nThe following sections walk you through creating a more complex trace with child spans, similar to a mult-operation RAG lookup.\n\n1. [Start a complex trace](#complex-trace)\n2. [Add a child span: RAG document lookup](#add-a-child-span-to-a-complex-trace-rag-document-lookup)\n3. [Add a child span: LLM completion call](#add-a-child-span-to-a-complex-trace-llm-completion-call)\n4. [End a complex trace](#end-a-complex-trace)\n\n### Start a complex trace \n\nThe following code demonstrates how to create a more complex trace with multiple spans. An example of this would be a Retrieval-Augmented Generation (RAG) lookup followed by an LLM call. The first part initializes a parent trace(`payload_parent_start`) that represents the overall operation. In this case, the operation is  processing the user query `Can you summarize the key points of this document?`.\n\nThe `payload_parent_start` object mimics the initial step in a multi-step workflow, logging the the operation in Weave using the `url_start` endpoint.\n\nOn success, this code will output a message indicating that the parent call was logged:\n\n```\nParent call started. ID: 01939d26-0844-7c43-94bb-cdc471b6d65f, Trace ID: 01939d26-0844-7c43-94bb-cdd97dc296c8\n```\n\n\n```python\n## ------------\n## Start trace (parent)\n## ------------\n\n# Parent call: Start\npayload_parent_start = {\n    \"start\": {\n        \"project_id\": f\"{team_id}/{project_id}\",\n        \"op_name\": \"complex_trace\",\n        \"started_at\": datetime.datetime.now().isoformat(),\n        \"inputs\": {\"question\": \"Can you summarize the key points of this document?\"},\n        \"attributes\": {},\n    }\n}\nresponse = requests.post(\n    url_start, headers=headers, json=payload_parent_start, auth=(\"api\", wandb_token)\n)\nif response.status_code == 200:\n    data = response.json()\n    parent_call_id = data.get(\"id\")\n    trace_id = data.get(\"trace_id\")\n    print(f\"Parent call started. ID: {parent_call_id}, Trace ID: {trace_id}\")\nelse:\n    print(\"Parent start request failed with status:\", response.status_code)\n    print(response.text)\n    exit()\n```\n\n### Add a child span to a complex trace: RAG document lookup\n\nThe following code demonstrates how to add a child span to the parent trace started in the previous step. This step models a the RAG document lookup sub-operation in the overarching workflow.\n\nThe child trace is initiated with the `payload_child_start` object, which includes:\n- `trace_id`: Links this child span to the parent trace.\n- `parent_id`: Associates the child span with the parent operation.\n- `inputs`: Logs the search query, e.g., \n  `\"This is a search query of the documents I'm looking for.\"`\n\nOn a successful call to the `url_start` endpoint, the code outputs a message indicating that the child call was started and completed:\n\n```\nChild call started. ID: 01939d32-23d6-75f2-9128-36a4a806f179\nChild call ended.\n```\n\n\n```python\n## ------------\n## Child span:\n## Ex. RAG Document lookup\n## ------------\n\n# Child call: Start\npayload_child_start = {\n    \"start\": {\n        \"project_id\": f\"{team_id}/{project_id}\",\n        \"op_name\": \"rag_document_lookup\",\n        \"trace_id\": trace_id,\n        \"parent_id\": parent_call_id,\n        \"started_at\": datetime.datetime.now().isoformat(),\n        \"inputs\": {\n            \"document_search\": \"This is a search query of the documents I'm looking for.\"\n        },\n        \"attributes\": {},\n    }\n}\nresponse = requests.post(\n    url_start, headers=headers, json=payload_child_start, auth=(\"api\", wandb_token)\n)\nif response.status_code == 200:\n    data = response.json()\n    child_call_id = data.get(\"id\")\n    print(f\"Child call started. ID: {child_call_id}\")\nelse:\n    print(\"Child start request failed with status:\", response.status_code)\n    print(response.text)\n    exit()\n\n# Child call: End\npayload_child_end = {\n    \"end\": {\n        \"project_id\": f\"{team_id}/{project_id}\",\n        \"id\": child_call_id,\n        \"ended_at\": datetime.datetime.now().isoformat(),\n        \"output\": {\n            \"document_results\": \"This will be the RAG'd document text which will be returned from the search query.\"\n        },\n        \"summary\": {},\n    }\n}\nresponse = requests.post(\n    url_end, headers=headers, json=payload_child_end, auth=(\"api\", wandb_token)\n)\nif response.status_code == 200:\n    print(\"Child call ended.\")\nelse:\n    print(\"Child end request failed with status:\", response.status_code)\n    print(response.text)\n```\n\n### Add a child span to a complex trace: LLM completion call\n\nThe following code demonstrates how to add another child span to the parent trace, representing an LLM completion call. This step models the AI's response generation based on document context retrieved in the previous RAG operation.\n\nThe LLM completion trace is initiated with the `payload_child_start` object, which includes:\n- `trace_id`: Links this child span to the parent trace.\n- `parent_id`: Associates the child span with the overarching workflow.\n- `inputs`: Logs the input messages for the LLM, including the user query and the appended document context.\n- `model`: Specifies the model used for the operation (`gpt-4o`).\n\nOn success, the code outputs a message indicating the LLM child span trace has started and ended:\n\n```\nChild call started. ID: 0245acdf-83a9-4c90-90df-dcb2b89f234a\n```\n\nOnce the operation completes, the `payload_child_end` object ends the trace by logging the LLM-generated response in the `output` field. Usage summary information is also logged.\n\nOn success, the code outputs a message indicating the LLM child span trace has started and ended:\n\n```\nChild call started. ID: 0245acdf-83a9-4c90-90df-dcb2b89f234a\nChild call ended.\n```\n\n\n```python\n## ------------\n## Child span:\n## Create an LLM completion call\n## ------------\n\n# Child call: Start\npayload_child_start = {\n    \"start\": {\n        \"project_id\": f\"{team_id}/{project_id}\",\n        \"op_name\": \"llm_completion\",\n        \"trace_id\": trace_id,\n        \"parent_id\": parent_call_id,\n        \"started_at\": datetime.datetime.now().isoformat(),\n        \"inputs\": {\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": \"With the following document context, could you help me answer:\\n Can you summarize the key points of this document?\\n [+ appended document context]\",\n                }\n            ],\n            \"model\": \"gpt-4o\",\n        },\n        \"attributes\": {},\n    }\n}\nresponse = requests.post(\n    url_start, headers=headers, json=payload_child_start, auth=(\"api\", wandb_token)\n)\nif response.status_code == 200:\n    data = response.json()\n    child_call_id = data.get(\"id\")\n    print(f\"Child call started. ID: {child_call_id}\")\nelse:\n    print(\"Child start request failed with status:\", response.status_code)\n    print(response.text)\n    exit()\n\n# Child call: End\npayload_child_end = {\n    \"end\": {\n        \"project_id\": f\"{team_id}/{project_id}\",\n        \"id\": child_call_id,\n        \"ended_at\": datetime.datetime.now().isoformat(),\n        \"output\": {\n            \"choices\": [\n                {\"message\": {\"content\": \"This is the response generated by the LLM.\"}},\n            ]\n        },\n        \"summary\": {\n            \"usage\": {\n                \"gpt-4o\": {\n                    \"prompt_tokens\": 10,\n                    \"completion_tokens\": 20,\n                    \"total_tokens\": 30,\n                    \"requests\": 1,\n                }\n            }\n        },\n    }\n}\nresponse = requests.post(\n    url_end, headers=headers, json=payload_child_end, auth=(\"api\", wandb_token)\n)\nif response.status_code == 200:\n    print(\"Child call ended.\")\nelse:\n    print(\"Child end request failed with status:\", response.status_code)\n    print(response.text)\n```\n\n### End a complex trace\n\nThe following code demonstrates how to finalize the parent trace, marking the completion of the entire workflow. This step aggregates the results of all child spans (e.g., RAG lookup and LLM completion) and logs the final output and metadata.\n\nThe trace is finalized using the `payload_parent_end` object, which includes:\n- `id`: The `parent_call_id` from the initial parent trace start.\n- `output`: Represents the final output of the entire workflow. \n- `summary`: Consolidates usage data for the entire workflow.\n- `prompt_tokens`: Total tokens used for all prompts.\n- `completion_tokens`: Total tokens generated in all responses.\n- `total_tokens`: Combined token count for the workflow.\n- `requests`: Total number of requests made (in this case, `1`).\n\nOn success, the code outputs:\n\n```\nParent call ended.\n```\n\n\n```python\n## ------------\n## End trace\n## ------------\n\n# Parent call: End\npayload_parent_end = {\n    \"end\": {\n        \"project_id\": f\"{team_id}/{project_id}\",\n        \"id\": parent_call_id,\n        \"ended_at\": datetime.datetime.now().isoformat(),\n        \"output\": {\n            \"choices\": [\n                {\"message\": {\"content\": \"This is the response generated by the LLM.\"}},\n            ]\n        },\n        \"summary\": {\n            \"usage\": {\n                \"gpt-4o\": {\n                    \"prompt_tokens\": 10,\n                    \"completion_tokens\": 20,\n                    \"total_tokens\": 30,\n                    \"requests\": 1,\n                }\n            }\n        },\n    }\n}\nresponse = requests.post(\n    url_end, headers=headers, json=payload_parent_end, auth=(\"api\", wandb_token)\n)\nif response.status_code == 200:\n    print(\"Parent call ended.\")\nelse:\n    print(\"Parent end request failed with status:\", response.status_code)\n    print(response.text)\n```\n\n## Run a lookup query\nThe following code demonstrates how to query the traces created in previous examples, filtering only for traces where the `inputs.model` field is equal to `gpt-4o`.\n\nThe `query_payload` object includes:\n- `project_id`: Identifies the team and project to query.\n- `filter`: Ensures the query returns only **trace roots** (top-level traces).\n- `query`: Defines the filter logic using the `$expr` operator:\n  - `$getField`: Retrieves the `inputs.model` field.\n  - `$literal`: Matches traces where `inputs.model` equals `\"gpt-4o\"`.\n- `limit`: Limits the query to 10,000 results.\n- `offset`: Starts the query at the first result.\n- `sort_by`: Orders results by the `started_at` timestamp in descending order.\n- `include_feedback`: Excludes feedback data from the results.\n\nOn a successful query, the response will include trace data matching the query parameters:\n\n```\n{'id': '01939cf3-541f-76d3-ade3-50cfae068b39', 'project_id': 'cool-new-team/uncategorized', 'op_name': 'simple_trace', 'display_name': None, 'trace_id': '01939cf3-541f-76d3-ade3-50d5cfabe2db', 'parent_id': None, 'started_at': '2024-12-06T17:10:12.590000Z', 'attributes': {}, 'inputs': {'messages': [{'role': 'user', 'content': 'Why is the sky blue?'}], 'model': 'gpt-4o'}, 'ended_at': '2024-12-06T17:47:08.553000Z', 'exception': None, 'output': {'choices': [{'message': {'content': 'It\u2019s due to Rayleigh scattering, where shorter blue wavelengths of sunlight scatter in all directions.'}}]}, 'summary': {'usage': {'gpt-4o': {'prompt_tokens': 10, 'completion_tokens': 20, 'requests': 1, 'total_tokens': 30}}, 'weave': {'status': 'success', 'trace_name': 'simple_trace', 'latency_ms': 2215963}}, 'wb_user_id': 'VXNlcjoyMDk5Njc0', 'wb_run_id': None, 'deleted_at': None}\n```\n\n\n\n\n\n```python\nquery_payload = {\n    \"project_id\": f\"{team_id}/{project_id}\",\n    \"filter\": {\"trace_roots_only\": True},\n    \"query\": {\n        \"$expr\": {\"$eq\": [{\"$getField\": \"inputs.model\"}, {\"$literal\": \"gpt-4o\"}]}\n    },\n    \"limit\": 10000,\n    \"offset\": 0,\n    \"sort_by\": [{\"field\": \"started_at\", \"direction\": \"desc\"}],\n    \"include_feedback\": False,\n}\nresponse = requests.post(\n    url_stream_query, headers=headers, json=query_payload, auth=(\"api\", wandb_token)\n)\nif response.status_code == 200:\n    print(\"Query successful!\")\n    try:\n        data = response.json()\n        print(data)\n    except json.JSONDecodeError as e:\n        # Alternate decode\n        json_objects = response.text.strip().split(\"\\n\")\n        parsed_data = [json.loads(obj) for obj in json_objects]\n        print(parsed_data)\nelse:\n    print(f\"Query failed with status code: {response.status_code}\")\n    print(response.text)\n```"
  },
  {
    "title": "Custom Model Cost",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/custom_model_cost",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n\n\n\n# Setting up a custom cost model\n\nWeave calculates costs based on the number of tokens used and the model used.\nWeave grabs this usage and model from the output and associates them with the call.\n\nLet's set up a simple custom model, that calculates its own token usage, and stores that in weave.\n\n## Set up the environment\n\nWe install and import all needed packages.\nWe set `WANDB_API_KEY` in our env so that we may easily login with `wandb.login()` (this should be given to the colab as a secret).\n\nWe set the project in W&B we want to log this into in `name_of_wandb_project`.\n\n**_NOTE:_** `name_of_wandb_project` may also be in the format of `{team_name}/{project_name}` to specify a team to log the traces into.\n\nWe then fetch a weave client by calling `weave.init()`\n\n\n```python\n%pip install wandb weave datetime --quiet\n```\n\n\n```python\nimport os\n\nimport wandb\nfrom google.colab import userdata\n\nimport weave\n\nos.environ[\"WANDB_API_KEY\"] = userdata.get(\"WANDB_API_KEY\")\nname_of_wandb_project = \"custom-cost-model\"\n\nwandb.login()\n```\n\n\n```python\nweave_client = weave.init(name_of_wandb_project)\n```\n\n## Setting up a model with weave\n\n\n\n```python\nfrom weave import Model\n\n\nclass YourModel(Model):\n    attribute1: str\n    attribute2: int\n\n    def simple_token_count(self, text: str) -> int:\n        return len(text) // 3\n\n    # This is a custom op that we are defining\n    # It takes in a string, and outputs a dict with the usage counts, model name, and the output\n    @weave.op()\n    def custom_model_generate(self, input_data: str) -> dict:\n        # Model logic goes here\n        # Here is where you would have a custom generate function\n        prediction = self.attribute1 + \" \" + input_data\n\n        # Usage counts\n        prompt_tokens = self.simple_token_count(input_data)\n        completion_tokens = self.simple_token_count(prediction)\n\n        # We return a dictionary with the usage counts, model name, and the output\n        # Weave will automatically associate this with the trace\n        # This object {usage, model, output} matches the output of a OpenAI Call\n        return {\n            \"usage\": {\n                \"input_tokens\": prompt_tokens,\n                \"output_tokens\": completion_tokens,\n                \"total_tokens\": prompt_tokens + completion_tokens,\n            },\n            \"model\": \"your_model_name\",\n            \"output\": prediction,\n        }\n\n    # In our predict function we call our custom generate function, and return the output.\n    @weave.op()\n    def predict(self, input_data: str) -> dict:\n        # Here is where you would do any post processing of the data\n        outputs = self.custom_model_generate(input_data)\n        return outputs[\"output\"]\n```\n\n## Add a custom cost\n\nHere we add a custom cost, and now that we have a custom cost, and our calls have usage, we can fetch the calls with `include_cost` and our calls with have costs under `summary.weave.costs`.\n\n\n```python\nmodel = YourModel(attribute1=\"Hello\", attribute2=1)\nmodel.predict(\"world\")\n\n# We then add a custom cost to our project\nweave_client.add_cost(\n    llm_id=\"your_model_name\", prompt_token_cost=0.1, completion_token_cost=0.2\n)\n\n# We can then query for the calls, and with include_costs=True\n# we receive the costs back attached to the calls\ncalls = weave_client.get_calls(filter={\"trace_roots_only\": True}, include_costs=True)\n\nlist(calls)\n```"
  },
  {
    "title": "Log Feedback from Production",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/feedback_prod",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n\n\n\n\nIt is often hard to automatically evaluate a generated LLM response so, depending on your risk tolerance, you can gather direct user feedback to find areas to improve.\n\nIn this tutorial, we'll use a custom chatbot as an example app from which to collect user feedback.\nWe'll use Streamlit to build the interface and we'll capture the LLM interactions and feedback in Weave.\n\n## Setup\n\n\n```python\n!pip install weave openai streamlit wandb\n!pip install set-env-colab-kaggle-dotenv -q # for env var\n```\n\n\n```python\n# Add a .env file with your OpenAI and WandB API keys\nfrom set_env import set_env\n\n_ = set_env(\"OPENAI_API_KEY\")\n_ = set_env(\"WANDB_API_KEY\")\n```\n\nNext, create a file called `chatbot.py` with the following contents:\n\n\n```python\n# chatbot.py\n\nimport openai\nimport streamlit as st\nimport wandb\nfrom set_env import set_env\n\nimport weave\n\n_ = set_env(\"OPENAI_API_KEY\")\n_ = set_env(\"WANDB_API_KEY\")\nwandb.login()\nweave_client = weave.init(\"feedback-example\")\noai_client = openai.OpenAI()\n\n\ndef init_states():\n    \"\"\"Set up session_state keys if they don't exist yet.\"\"\"\n    if \"messages\" not in st.session_state:\n        st.session_state[\"messages\"] = []\n    if \"calls\" not in st.session_state:\n        st.session_state[\"calls\"] = []\n    if \"session_id\" not in st.session_state:\n        st.session_state[\"session_id\"] = \"123abc\"\n@weave.op\ndef chat_response(full_history):\n    \"\"\"\n    Calls the OpenAI API in streaming mode given the entire conversation history so far.\n    full_history is a list of dicts: [{\"role\":\"user\"|\"assistant\",\"content\":...}, ...]\n    \"\"\"\n    stream = oai_client.chat.completions.create(\n        model=\"gpt-4\", messages=full_history, stream=True\n    )\n    response_text = st.write_stream(stream)\n    return {\"response\": response_text}\n\n\ndef render_feedback_buttons(call_idx):\n    \"\"\"Renders thumbs up/down and text feedback for the call.\"\"\"\n    col1, col2, col3 = st.columns([1, 1, 4])\n\n    # Thumbs up button\n    with col1:\n        if st.button(\"\ud83d\udc4d\", key=f\"thumbs_up_{call_idx}\"):\n            st.session_state.calls[call_idx].feedback.add_reaction(\"\ud83d\udc4d\")\n            st.success(\"Thanks for the feedback!\")\n\n    # Thumbs down button\n    with col2:\n        if st.button(\"\ud83d\udc4e\", key=f\"thumbs_down_{call_idx}\"):\n            st.session_state.calls[call_idx].feedback.add_reaction(\"\ud83d\udc4e\")\n            st.success(\"Thanks for the feedback!\")\n\n    # Text feedback\n    with col3:\n        feedback_text = st.text_input(\"Feedback\", key=f\"feedback_input_{call_idx}\")\n        if st.button(\"Submit Feedback\", key=f\"submit_feedback_{call_idx}\"):\n            if feedback_text:\n                st.session_state.calls[call_idx].feedback.add_note(feedback_text)\n                st.success(\"Feedback submitted!\")\n\n\ndef display_old_messages():\n    \"\"\"Displays the conversation stored in st.session_state.messages with feedback buttons\"\"\"\n    for idx, message in enumerate(st.session_state.messages):\n        with st.chat_message(message[\"role\"]):\n            st.markdown(message[\"content\"])\n\n            # If it's an assistant message, show feedback form\n            if message[\"role\"] == \"assistant\":\n                # Figure out index of this assistant message in st.session_state.calls\n                assistant_idx = (\n                    len(\n                        [\n                            m\n                            for m in st.session_state.messages[: idx + 1]\n                            if m[\"role\"] == \"assistant\"\n                        ]\n                    )\n                    - 1\n                )\n                # Render thumbs up/down & text feedback\n                if assistant_idx < len(st.session_state.calls):\n                    render_feedback_buttons(assistant_idx)\n\n\ndef display_chat_prompt():\n    \"\"\"Displays the chat prompt input box.\"\"\"\n    if prompt := st.chat_input(\"Ask me anything!\"):\n        # Immediately render new user message\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n\n        # Save user message in session\n        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n\n        # Prepare chat history for the API\n        full_history = [\n            {\"role\": msg[\"role\"], \"content\": msg[\"content\"]}\n            for msg in st.session_state.messages\n        ]\n\n        with st.chat_message(\"assistant\"):\n            # Attach Weave attributes for tracking of conversation instances\n            with weave.attributes(\n                {\"session\": st.session_state[\"session_id\"], \"env\": \"prod\"}\n            ):\n                # Call the OpenAI API (stream)\n                result, call = chat_response.call(full_history)\n\n                # Store the assistant message\n                st.session_state.messages.append(\n                    {\"role\": \"assistant\", \"content\": result[\"response\"]}\n                )\n\n                # Store the weave call object to link feedback to the specific response\n                st.session_state.calls.append(call)\n\n                # Render feedback buttons for the new message\n                new_assistant_idx = (\n                    len(\n                        [\n                            m\n                            for m in st.session_state.messages\n                            if m[\"role\"] == \"assistant\"\n                        ]\n                    )\n                    - 1\n                )\n\n                # Render feedback buttons\n                if new_assistant_idx < len(st.session_state.calls):\n                    render_feedback_buttons(new_assistant_idx)\n\n\ndef main():\n    st.title(\"Chatbot with immediate feedback forms\")\n    init_states()\n    display_old_messages()\n    display_chat_prompt()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\nYou can run this with `streamlit run chatbot.py`.\n\nNow, you can interact with this application and click the feedback buttons after each response. \nVisit the Weave UI to see the attached feedback.\n\n## Explanation\n\nIf we consider our decorated prediction function as:\n\n\n```python\nimport weave\n\nweave.init(\"feedback-example\")\n@weave.op\ndef predict(input_data):\n    # Your prediction logic here\n    some_result = \"hello world\"\n    return some_result\n```\n\nWe can use it as usual to deliver some model response to the user:\n\n\n```python\nwith weave.attributes(\n    {\"session\": \"123abc\", \"env\": \"prod\"}\n):  # attach arbitrary attributes to the call alongside inputs & outputs\n    result = predict(input_data=\"your data here\")  # user question through the App UI\n```\n\nTo attach feedback, you need the `call` object, which is obtained by using the `.call()` method *instead of calling the function as normal*:\n\n\n```python\nresult, call = predict.call(input_data=\"your data here\")\n```\n\nThis call object is needed for attaching feedback to the specific response.\nAfter making the call, the output of the operation is available using `result` above.\n\n\n```python\ncall.feedback.add_reaction(\"\ud83d\udc4d\")  # user reaction through the App UI\n```\n\n## Conclusion\n\nIn this tutorial, we built a chat UI with Streamlit which had inputs & outputs captured in Weave, alongside \ud83d\udc4d\ud83d\udc4e buttons to capture user feedback."
  },
  {
    "title": "Intro To Weave Hello Trace",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/Intro_to_Weave_Hello_Trace",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n# Introduction to Traces\n\n\n\nWeave is a toolkit for developing AI-powered applications.\n\nYou can use Weave to:\n- Log and debug language model inputs, outputs, and traces.\n- Build rigorous, apples-to-apples evaluations for language model use cases.\n- Organize all the information generated across the LLM workflow, from experimentation to evaluations to production.\n\nWeave traces let you automatically capture the inputs, outputs, and internal structure of your Python functions\u2014especially useful when working with LLMs. By decorating a function with `@weave.op`, Weave records a rich trace of how your function runs, including any nested operations or external API calls. This makes it easy to debug, understand, and visualize how your code is interacting with language models, all from within your notebook.\n\nTo get started, complete the prerequisites. Then, define a function with the `@weave.op` decorator to track LLM calls, run it on an example input, and Weave will automatically capture and visualize the trace.\n\n## \ud83d\udd11 Prerequisites\n\nBefore you can begin tracing in Weave, complete the following prerequisites.\n\n1. Install the W&B Weave SDK and log in with your [API key](https://wandb.ai/settings#api).\n2. Install the OpenAI SDK and log in with your [API key](https://platform.openai.com/api-keys).\n3. Initialize your W&B project.\n\n\n\n```python\n# Install dependancies and imports\n!pip install wandb weave openai -q\n\nimport json\nimport os\nfrom getpass import getpass\n\nfrom openai import OpenAI\n\nimport weave\n\n# \ud83d\udd11 Setup your API keys\n# Running this cell will prompt you for your API key with `getpass` and will not echo to the terminal.\n#####\nprint(\"---\")\nprint(\n    \"You can find your Weights and Biases API key here: https://wandb.ai/settings#api\"\n)\nos.environ[\"WANDB_API_KEY\"] = getpass(\"Enter your Weights and Biases API key: \")\nprint(\"---\")\nprint(\"You can generate your OpenAI API key here: https://platform.openai.com/api-keys\")\nos.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\nprint(\"---\")\n#####\n\n# \ud83c\udfe0 Enter your W&B project name\nweave_client = weave.init(\"MY_PROJECT_NAME\")  # \ud83d\udc1d Your W&B project name\n```\n\n## \ud83d\udc1d Run your first trace\n\nThe following code sample shows how to capture and visualize a trace in Weave using the `@weave.op` decorator. It defines a function called `extract_fruit` that sends a prompt to OpenAI's GPT-4o to extract structured data (fruit, color, and flavor) from a sentence. By decorating the function with `@weave.op`, Weave automatically tracks the function execution, including inputs, outputs, and intermediate steps. When the function is called with a sample sentence, the full trace is saved and viewable in the Weave UI.\n\n\n```python\n@weave.op()  # \ud83d\udc1d Decorator to track requests\ndef extract_fruit(sentence: str) -> dict:\n    client = OpenAI()\n    system_prompt = (\n        \"Parse sentences into a JSON dict with keys: fruit, color and flavor.\"\n    )\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": sentence},\n        ],\n        temperature=0.7,\n        response_format={\"type\": \"json_object\"},\n    )\n    extracted = response.choices[0].message.content\n    return json.loads(extracted)\n\n\nsentence = \"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.\"\nextract_fruit(sentence)\n```\n\n## \ud83d\ude80 Looking for more examples?\n- Check out the [Quickstart guide](https://weave-docs.wandb.ai/quickstart).\n- Learn more about [advanced tracing topics](https://weave-docs.wandb.ai/tutorial-tracing_2).\n- Learn more about [tracing in Weave](https://weave-docs.wandb.ai/guides/tracking/tracing)"
  },
  {
    "title": "NotDiamond Custom Routing",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/notdiamond_custom_routing",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n\n\n\n\n# Custom Routing for LLM Prompts with Not Diamond\n\nThis notebook demonstrates how to use Weave with [Not Diamond's custom routing](https://docs.notdiamond.ai/docs/router-training-quickstart) to route LLM prompts to the most appropriate model based on evaluation results.\n\n## Routing prompts\n\nWhen building complex LLM workflows users may need to prompt different models according to accuracy, cost, or call latency.\nUsers can use [Not Diamond](https://www.notdiamond.ai/) to route prompts in these workflows to the right model for their needs, helping maximize accuracy while saving on model costs.\n\nFor any given distribution of data, rarely will one single model outperform every other model on every single query. By combining together multiple models into a \"meta-model\" that learns when to call each LLM, you can beat every individual model's performance and even drive down costs and latency in the process.\n\n## Custom routing\n\nYou need three things to train a custom router for your prompts:\n\n1. A set of LLM prompts: Prompts must be strings and should be representative of the prompts used in our application.\n1. LLM responses: The responses from candidate LLMs for each input. Candidate LLMs can include both our supported LLMs and your own custom models.\n1. Evaluation scores for responses to the inputs from candidate LLMs: Scores are numbers, and can be any metric that fit your needs.\n\nBy submitting these to the Not Diamond API you can then train a custom router tuned to each of your workflows.\n\n\n## Setting up the training data\n\nIn practice, you will use your own Evaluations to train a custom router. For this example notebook, however, you will use LLM responses\nfor [the HumanEval dataset](https://github.com/openai/human-eval) to train a custom router for coding tasks.\n\nWe start by downloading the dataset we have prepared for this example, then parsing LLM responses into EvaluationResults for each model.\n\n\n\n```python\n!curl -L \"https://drive.google.com/uc?export=download&id=1q1zNZHioy9B7M-WRjsJPkfvFosfaHX38\" -o humaneval.csv\n```\n\n\n```python\nimport random\n\nimport weave\nfrom weave.flow.dataset import Dataset\nfrom weave.flow.eval import EvaluationResults\nfrom weave.integrations.notdiamond.util import get_model_evals\n\npct_train = 0.8\npct_test = 1 - pct_train\n\n# In practice, you will build an Evaluation on your dataset and call\n# `evaluation.get_eval_results(model)`\nmodel_evals = get_model_evals(\"./humaneval.csv\")\nmodel_train = {}\nmodel_test = {}\nfor model, evaluation_results in model_evals.items():\n    n_results = len(evaluation_results.rows)\n    all_idxs = list(range(n_results))\n    train_idxs = random.sample(all_idxs, k=int(n_results * pct_train))\n    test_idxs = [idx for idx in all_idxs if idx not in train_idxs]\n\n    model_train[model] = EvaluationResults(\n        rows=weave.Table([evaluation_results.rows[idx] for idx in train_idxs])\n    )\n    model_test[model] = Dataset(\n        rows=weave.Table([evaluation_results.rows[idx] for idx in test_idxs])\n    )\n    print(\n        f\"Found {len(train_idxs)} train rows and {len(test_idxs)} test rows for {model}.\"\n    )\n```\n\n## Training a custom router\n\nNow that you have EvaluationResults, you can train a custom router. Make sure you have [created an account](https://app.notdiamond.ai/keys) and\n[generated an API key](https://app.notdiamond.ai/keys), then insert your API key below.\n\n\n\n\n\n```python\nimport os\n\nfrom weave.integrations.notdiamond.custom_router import train_router\n\napi_key = os.getenv(\"NOTDIAMOND_API_KEY\", \"\")\n\npreference_id = train_router(\n    model_evals=model_train,\n    prompt_column=\"prompt\",\n    response_column=\"actual\",\n    language=\"en\",\n    maximize=True,\n    api_key=api_key,\n    # Leave this commented out to train your first custom router\n    # Uncomment this to retrain your custom router in place\n    # preference_id=preference_id,\n)\n```\n\nYou can then follow the training process for your custom router via the Not Diamond app.\n\n\n\n\nOnce your custom router has finished training, you can use it to route your prompts.\n\n\n\n```python\nfrom notdiamond import NotDiamond\n\nimport weave\n\nweave.init(\"notdiamond-quickstart\")\n\nllm_configs = [\n    \"anthropic/claude-3-5-sonnet-20240620\",\n    \"openai/gpt-4o-2024-05-13\",\n    \"google/gemini-1.5-pro-latest\",\n    \"openai/gpt-4-turbo-2024-04-09\",\n    \"anthropic/claude-3-opus-20240229\",\n]\nclient = NotDiamond(api_key=api_key, llm_configs=llm_configs)\n\nnew_prompt = (\n    \"\"\"\nYou are a helpful coding assistant. Using the provided function signature, write the implementation for the function\nin Python. Write only the function. Do not include any other text.\n\nfrom typing import List\n\n\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\n    \"\"\"\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n    given threshold.\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n    False\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n    True\n    \"\"\"\n    \"\"\"\n\"\"\"\n)\nsession_id, routing_target_model = client.model_select(\n    messages=[{\"role\": \"user\", \"content\": new_prompt}],\n    preference_id=preference_id,\n)\n\nprint(f\"Session ID: {session_id}\")\nprint(f\"Target Model: {routing_target_model}\")\n```\n\nThis example also used Not Diamond's compatibility with Weave auto-tracing. You can see the results in the Weave UI.\n\n\n\n\n## Evaluating your custom router\n\nOnce you have trained your custom router, you can evaluate either its\n\n- in-sample performance by submitting the training prompts, or\n- out-of-sample performance by submitting new or held-out prompts\n\nBelow, we submit the test set to the custom router to evaluate its performance.\n\n\n\n```python\nfrom weave.integrations.notdiamond.custom_router import evaluate_router\n\neval_prompt_column = \"prompt\"\neval_response_column = \"actual\"\n\nbest_provider_model, nd_model = evaluate_router(\n    model_datasets=model_test,\n    prompt_column=eval_prompt_column,\n    response_column=eval_response_column,\n    api_key=api_key,\n    preference_id=preference_id,\n)\n```\n\n\n```python\n@weave.op()\ndef is_correct(score: int, output: dict) -> dict:\n    # We hack score, since we already have model responses\n    return {\"correct\": score}\n\n\nbest_provider_eval = weave.Evaluation(\n    dataset=best_provider_model.model_results.to_dict(orient=\"records\"),\n    scorers=[is_correct],\n)\nawait best_provider_eval.evaluate(best_provider_model)\n\nnd_eval = weave.Evaluation(\n    dataset=nd_model.model_results.to_dict(orient=\"records\"), scorers=[is_correct]\n)\nawait nd_eval.evaluate(nd_model)\n```\n\nIn this instance, the Not Diamond \"meta-model\" routes prompts across several different models.\n\nTraining the custom router via Weave will also run evaluations and upload results to the Weave UI. Once the custom router process is completed, you can review the results in the Weave UI.\n\nIn the UI we see that the Not Diamond \"meta-model\" outperforms the best-performing model by routing prompts to other models with higher likelihood of answering the prompt accurately."
  },
  {
    "title": "Handling and Redacting PII",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/pii",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook] Open in Colab View in Github ::: # How to use Weave with PII data In this guide, you'll learn how to use W&B Weave while ensuring your Personally Identifiable Information (PII) data remains private. The guide demonstrates the following methods to identify, redact and anonymize PII data: 1. __Regular expressions__ to identify PII data and redact it. 2. __Microsoft's [Presidio](https://microsoft.github.io/presidio/)__, a python-based data protection SDK. This tool provides redaction and replacement functionalities. 3. __[Faker](https://faker.readthedocs.io/en/master/)__, a Python library to generate fake data, combined with Presidio to anonymize PII data. Additionally, you'll learn how to use _`weave.op` input/output logging customization_ and _`autopatch_settings`_ to integrate PII redaction and anonymization into the workflow. For more information, see [Customize logged inputs and outputs](https://weave-docs.wandb.ai/guides/tracking/ops/#customize-logged-inputs-and-outputs). To get started, do the following: 1. Review the [Overview](#overview) section. 2. Complete the [prerequisites](#prerequisites). 3. Review the [available methods](#redaction-methods-overview) for identifying, redacting and anonymizing PII data. 4. [Apply the methods to Weave calls](#apply-the-methods-to-weave-calls). ## Overview The following section provides an overview of input and output logging using `weave.op`, as well as best practices for working with PII data in Weave. ### Customize input and output logging using `weave.op` Weave Ops allow you to define input and output postprocessing functions. Using these functions, you can modify the data that is passed to your LLM call or logged to Weave. In the following example, two postprocessing functions are defined and passed as arguments to `weave.op()`. ```python from dataclasses import dataclass from typing import Any import weave # Inputs Wrapper Class @dataclass class CustomObject: x: int secret_password: str # First we define functions for input and output postprocessing: def postprocess_inputs(inputs: dict[str, Any]) -> dict[str, Any]: return {k:v for k,v in inputs.items() if k != \"hide_me\"} def postprocess_output(output: CustomObject) -> CustomObject: return CustomObject(x=output.x, secret_password=\"REDACTED\") # Then, when we use the `@weave.op` decorator, we pass these processing functions as arguments to the decorator: @weave.op( postprocess_inputs=postprocess_inputs, postprocess_output=postprocess_output, ) def some_llm_call(a: int, hide_me: str) -> CustomObject: return CustomObject(x=a, secret_password=hide_me) ``` ### Best practices for using Weave with PII data Before using Weave with PII data, review the best practices for using Weave with PII data. #### During testing - Log anonymized data to check PII detection - Track PII handling processes with Weave Traces - Measure anonymization performance without exposing real PII #### In production - Never log raw PII - Encrypt sensitive fields before logging #### Encryption tips - Use reversible encryption for data you need to decrypt later - Apply one-way hashing for unique IDs you don't need to reverse - Consider specialized encryption for data you need to analyze while encrypted ## Prerequisites 1. First, install the required packages. ```python %%capture # @title required python packages: !pip install cryptography !pip install presidio_analyzer !pip install presidio_anonymizer !python -m spacy download en_core_web_lg # Presidio uses spacy NLP engine !pip install Faker # we'll use Faker to replace PII data with fake data !pip install weave # To leverage Traces !pip install set-env-colab-kaggle-dotenv -q # for env var !pip install anthropic # to use sonnet !pip install cryptography # to encrypt our data ``` 2. Set up your API keys. You can find your API keys at the following links. - [W&B](https://wandb.ai/authorize) - [Anthropic](https://console.anthropic.com/settings/keys). ```python %%capture # @title Make sure to set up set up your API keys correctly # See: https://pypi.org/project/set-env-colab-kaggle-dotenv/ for usage instructions. from set_env import set_env _ = set_env(\"ANTHROPIC_API_KEY\") _ = set_env(\"WANDB_API_KEY\") ``` 3. Initialize your Weave project. ```python import weave # Start a new Weave project WEAVE_PROJECT = \"pii_cookbook\" weave.init(WEAVE_PROJECT) ``` 4. Load the demo PII dataset, which contains 10 text blocks. ```python import requests url = \"https://raw.githubusercontent.com/wandb/weave/master/docs/notebooks/10_pii_data.json\" response = requests.get(url) pii_data = response.json() print('PII data first sample: \"' + pii_data[0][\"text\"] + '\"') ``` ## Redaction methods overview Once you've completed the [setup](#setup), you can To detect and protect our PII data, we'll identify and redact PII data and optionally anonymize it using the following methods: 1. __Regular expressions__ to identify PII data and redact it. 2. __Microsoft [Presidio](https://microsoft.github.io/presidio/)__, a Python-based data protection SDK that provides redaction and replacement functionality. 3. __[Faker](https://faker.readthedocs.io/en/master/)__, a Python library for generating fake data. ### Method 1: Filter using regular expressions [Regular expressions (regex)](https://docs.python.org/3/library/re.html) are the simplest method to identify and redact PII data. Regex allows you to define patterns that can match various formats of sensitive information like phone numbers, email addresses, and social security numbers. Using regex, you can scan through large volumes of text and replace or redact information without the need for more complex NLP techniques. ```python import re # Define a function to clean PII data using regex def redact_with_regex(text): # Phone number pattern # \\b : Word boundary # \\d{3} : Exactly 3 digits # [-.]? : Optional hyphen or dot # \\d{3} : Another 3 digits # [-.]? : Optional hyphen or dot # \\d{4} : Exactly 4 digits # \\b : Word boundary text = re.sub(r\"\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b\", \"\", text) # Email pattern # \\b : Word boundary # [A-Za-z0-9._%+-]+ : One or more characters that can be in an email username # @ : Literal @ symbol # [A-Za-z0-9.-]+ : One or more characters that can be in a domain name # \\. : Literal dot # [A-Z|a-z]{2,} : Two or more uppercase or lowercase letters (TLD) # \\b : Word boundary text = re.sub( r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\", \"\", text ) # SSN pattern # \\b : Word boundary # \\d{3} : Exactly 3 digits # - : Literal hyphen # \\d{2} : Exactly 2 digits # - : Literal hyphen # \\d{4} : Exactly 4 digits # \\b : Word boundary text = re.sub(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\", \"\", text) # Simple name pattern (this is not comprehensive) # \\b : Word boundary # [A-Z] : One uppercase letter # [a-z]+ : One or more lowercase letters # \\s : One whitespace character # [A-Z] : One uppercase letter # [a-z]+ : One or more lowercase letters # \\b : Word boundary text = re.sub(r\"\\b[A-Z][a-z]+ [A-Z][a-z]+\\b\", \"\", text) return text ``` Let's test the function with a sample text: ```python # Test the function test_text = \"My name is John Doe, my email is john.doe@example.com, my phone is 123-456-7890, and my SSN is 123-45-6789.\" cleaned_text = redact_with_regex(test_text) print(f\"Raw text:\\n\\t{test_text}\") print(f\"Redacted text:\\n\\t{cleaned_text}\") ``` ### Method 2: Redact using Microsoft Presidio The next method involves complete removal of PII data using [Microsoft Presidio](https://microsoft.github.io/presidio/). Presidio redacts PII and replaces it with a placeholder representing the PII type. For example, Presidio replaces `Alex` in `\"My name is Alex\"` with ``. Presidio comes with a built-in support for [common entities](https://microsoft.github.io/presidio/supported_entities/). In the below example, we redact all entities that are a `PHONE_NUMBER`, `PERSON`, `LOCATION`, `EMAIL_ADDRESS` or `US_SSN`. The Presidio process is encapsulated in a function. ```python from presidio_analyzer import AnalyzerEngine from presidio_anonymizer import AnonymizerEngine # Set up the Analyzer, which loads an NLP module (spaCy model by default) and other PII recognizers. analyzer = AnalyzerEngine() # Set up the Anonymizer, which will use the analyzer results to anonymize the text. anonymizer = AnonymizerEngine() # Encapsulate the Presidio redaction process into a function def redact_with_presidio(text): # Analyze the text to identify PII data results = analyzer.analyze( text=text, entities=[\"PHONE_NUMBER\", \"PERSON\", \"LOCATION\", \"EMAIL_ADDRESS\", \"US_SSN\"], language=\"en\", ) # Anonymize the identified PII data anonymized_text = anonymizer.anonymize(text=text, analyzer_results=results) return anonymized_text.text ``` Let's test the function with a sample text: ```python text = \"My phone number is 212-555-5555 and my name is alex\" # Test the function anonymized_text = redact_with_presidio(text) print(f\"Raw text:\\n\\t{text}\") print(f\"Redacted text:\\n\\t{anonymized_text}\") ``` ### Method 3: Anonymize with replacement using Faker and Presidio Instead of redacting text, you can anonymize it by using MS Presidio to swap PII like names and phone numbers with fake data generated using the [Faker](https://faker.readthedocs.io/en/master/) Python library. For example, suppose you have the following data: `\"My name is Raphael and I like to fish. My phone number is 212-555-5555\"` Once the data has been processed using Presidio and Faker, it might look like: `\"My name is Katherine Dixon and I like to fish. My phone number is 667.431.7379\"` To effectively use Presidio and Faker together, we must supply references to our custom operators. These operators will direct Presidio to the Faker functions responsible for swapping PII with fake data. ```python from faker import Faker from presidio_anonymizer import AnonymizerEngine from presidio_anonymizer.entities import OperatorConfig fake = Faker() # Create faker functions (note that it has to receive a value) def fake_name(x): return fake.name() def fake_number(x): return fake.phone_number() # Create custom operator for the PERSON and PHONE_NUMBER\" entities operators = { \"PERSON\": OperatorConfig(\"custom\", {\"lambda\": fake_name}), \"PHONE_NUMBER\": OperatorConfig(\"custom\", {\"lambda\": fake_number}), } text_to_anonymize = ( \"My name is Raphael and I like to fish. My phone number is 212-555-5555\" ) # Analyzer output analyzer_results = analyzer.analyze( text=text_to_anonymize, entities=[\"PHONE_NUMBER\", \"PERSON\"], language=\"en\" ) anonymizer = AnonymizerEngine() # do not forget to pass the operators from above to the anonymizer anonymized_results = anonymizer.anonymize( text=text_to_anonymize, analyzer_results=analyzer_results, operators=operators ) print(f\"Raw text:\\n\\t{text_to_anonymize}\") print(f\"Anonymized text:\\n\\t{anonymized_results.text}\") ``` Let's consolidate our code into a single class and expand the list of entities to include the additional ones identified earlier. ```python from faker import Faker from presidio_anonymizer import AnonymizerEngine from presidio_anonymizer.entities import OperatorConfig # A custom class for generating fake data that extends Faker class my_faker(Faker): # Create faker functions (note that it has to receive a value) def fake_address(x): return fake.address() def fake_ssn(x): return fake.ssn() def fake_name(x): return fake.name() def fake_number(x): return fake.phone_number() def fake_email(x): return fake.email() # Create custom operators for the entities operators = { \"PERSON\": OperatorConfig(\"custom\", {\"lambda\": fake_name}), \"PHONE_NUMBER\": OperatorConfig(\"custom\", {\"lambda\": fake_number}), \"EMAIL_ADDRESS\": OperatorConfig(\"custom\", {\"lambda\": fake_email}), \"LOCATION\": OperatorConfig(\"custom\", {\"lambda\": fake_address}), \"US_SSN\": OperatorConfig(\"custom\", {\"lambda\": fake_ssn}), } def redact_and_anonymize_with_faker(self, text): anonymizer = AnonymizerEngine() analyzer_results = analyzer.analyze( text=text, entities=[\"PHONE_NUMBER\", \"PERSON\", \"LOCATION\", \"EMAIL_ADDRESS\", \"US_SSN\"], language=\"en\", ) anonymized_results = anonymizer.anonymize( text=text, analyzer_results=analyzer_results, operators=self.operators ) return anonymized_results.text ``` Let's test the function with a sample text: ```python faker = my_faker() text_to_anonymize = ( \"My name is Raphael and I like to fish. My phone number is 212-555-5555\" ) anonymized_text = faker.redact_and_anonymize_with_faker(text_to_anonymize) print(f\"Raw text:\\n\\t{text_to_anonymize}\") print(f\"Anonymized text:\\n\\t{anonymized_text}\") ``` ### Method 4: Use `autopatch_settings` You can use `autopatch_settings` to configure PII handling directly during initialization for one or more of the supported LLM integrations. The advantages of this method are: 1. PII handling logic is centralized and scoped at initialization, reducing the need for scattered custom logic. 2. PII processing workflows can be customized or disabled entirely for specific intergations. To use `autopatch_settings` to configure PII handling, define `postprocess_inputs` and/or `postprocess_output` in `op_settings` for any one of the supported LLM integrations. ```python def postprocess(inputs: dict) -> dict: if \"SENSITIVE_KEY\" in inputs: inputs[\"SENSITIVE_KEY\"] = \"REDACTED\" return inputs client = weave.init( ..., autopatch_settings={ \"openai\": { \"op_settings\": { \"postprocess_inputs\": postprocess, \"postprocess_output\": ..., } }, \"anthropic\": { \"op_settings\": { \"postprocess_inputs\": ..., \"postprocess_output\": ..., } } }, ) ``` ## Apply the methods to Weave calls In the following examples, we will integrate our PII redaction and anonymization methods into Weave Models and preview the results in Weave Traces. First, we'll create a [Weave Model](https://wandb.github.io/weave/guides/core-types/models). A Weave Model is a combination of information like configuration settings, model weights, and code that defines how the model operates. In our model, we will include our predict function where the Anthropic API will be called. Anthropic's Claude Sonnet is used to perform sentiment analysis while tracing LLM calls using [Traces](https://wandb.github.io/weave/quickstart). Claude Sonnet will receive a block of text and output one of the following sentiment classifications: _positive_, _negative_, or _neutral_. Additionally, we will include our postprocessing functions to ensure that our PII data is redacted or anonymized before it is sent to the LLM. Once you run this code, you will receive a links to the Weave project page, as well as the specific trace (LLM calls) you ran. ### Regex method In the simplest case, we can use regex to identify and redact PII data from the original text. ```python import json from typing import Any import anthropic import weave # Define an input postprocessing function that applies our regex redaction for the model prediction Weave Op def postprocess_inputs_regex(inputs: dict[str, Any]) -> dict: inputs[\"text_block\"] = redact_with_regex(inputs[\"text_block\"]) return inputs # Weave model / predict function class sentiment_analysis_regex_pii_model(weave.Model): model_name: str system_prompt: str temperature: int @weave.op(\n\n> Content truncated."
  },
  {
    "title": "Prompt Optimization",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/dspy_prompt_optimization",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n\n\n\n# Optimizing LLM Workflows Using DSPy and Weave\n\nThe [BIG-bench (Beyond the Imitation Game Benchmark)](https://github.com/google/BIG-bench) is a collaborative benchmark intended to probe large language models and extrapolate their future capabilities consisting of more than 200 tasks. The [BIG-Bench Hard (BBH)](https://github.com/suzgunmirac/BIG-Bench-Hard) is a suite of 23 most challenging BIG-Bench tasks that can be quite difficult to be solved using the current generation of language models.\n\nThis tutorial demonstrates how we can improve the performance of our LLM workflow implemented  on the **causal judgement task** from the BIG-bench Hard benchmark and evaluate our prompting strategies. We will use [DSPy](https://dspy-docs.vercel.app/) for implementing our LLM workflow and optimizing our prompting strategy. We will also use [Weave](../../introduction.md) to track our LLM workflow and evaluate our prompting strategies.\n\n## Installing the Dependencies\n\nWe need the following libraries for this tutorial:\n\n- [DSPy](https://dspy-docs.vercel.app/) for building the LLM workflow and optimizing it.\n- [Weave](../../introduction.md) to track our LLM workflow and evaluate our prompting strategies.\n- [datasets](https://huggingface.co/docs/datasets/index) to access the Big-Bench Hard dataset from HuggingFace Hub.\n\n\n```python\n!pip install -qU dspy-ai weave datasets\n```\n\nSince we'll be using [OpenAI API](https://openai.com/index/openai-api/) as the LLM Vendor, we will also need an OpenAI API key. You can [sign up](https://platform.openai.com/signup) on the OpenAI platform to get your own API key.\n\n\n```python\nimport os\nfrom getpass import getpass\n\napi_key = getpass(\"Enter you OpenAI API key: \")\nos.environ[\"OPENAI_API_KEY\"] = api_key\n```\n\n## Enable Tracking using Weave\n\nWeave is currently integrated with DSPy, and including [`weave.init`](../../reference/python-sdk/weave/index.md) at the start of our code lets us automatically trace our DSPy functions which can be explored in the Weave UI. Check out the [Weave integration docs for DSPy](../../guides/integrations/dspy.md) to learn more.\n\n\n\n```python\nimport weave\n\nweave.init(project_name=\"dspy-bigbench-hard\")\n```\n\nIn this tutorial, we use a metadata class inherited from [`weave.Object`](../../guides/tracking/objects.md) to manage our metadata.\n\n\n```python\nclass Metadata(weave.Object):\n    dataset_address: str = \"maveriq/bigbenchhard\"\n    big_bench_hard_task: str = \"causal_judgement\"\n    num_train_examples: int = 50\n    openai_model: str = \"gpt-3.5-turbo\"\n    openai_max_tokens: int = 2048\n    max_bootstrapped_demos: int = 8\n    max_labeled_demos: int = 8\n\n\nmetadata = Metadata()\n```\n\n:::tip Object Versioning\nThe `Metadata` objects are automatically versioned and traced when functions consuming them are traced\n:::\n\n## Load the BIG-Bench Hard Dataset\n\nWe will load this dataset from HuggingFace Hub, split into training and validation sets, and [publish](../../guides/core-types/datasets.md) them on Weave, this will let us version the datasets, and also use [`weave.Evaluation`](../../guides/core-types/evaluations.md) to evaluate our prompting strategy.\n\n\n```python\nimport dspy\nfrom datasets import load_dataset\n\n\n@weave.op()\ndef get_dataset(metadata: Metadata):\n    # load the BIG-Bench Hard dataset corresponding to the task from Huggingface Hug\n    dataset = load_dataset(metadata.dataset_address, metadata.big_bench_hard_task)[\n        \"train\"\n    ]\n\n    # create the training and validation datasets\n    rows = [{\"question\": data[\"input\"], \"answer\": data[\"target\"]} for data in dataset]\n    train_rows = rows[0 : metadata.num_train_examples]\n    val_rows = rows[metadata.num_train_examples :]\n\n    # create the training and validation examples consisting of `dspy.Example` objects\n    dspy_train_examples = [\n        dspy.Example(row).with_inputs(\"question\") for row in train_rows\n    ]\n    dspy_val_examples = [dspy.Example(row).with_inputs(\"question\") for row in val_rows]\n\n    # publish the datasets to the Weave, this would let us version the data and use for evaluation\n    weave.publish(\n        weave.Dataset(\n            name=f\"bigbenchhard_{metadata.big_bench_hard_task}_train\", rows=train_rows\n        )\n    )\n    weave.publish(\n        weave.Dataset(\n            name=f\"bigbenchhard_{metadata.big_bench_hard_task}_val\", rows=val_rows\n        )\n    )\n\n    return dspy_train_examples, dspy_val_examples\n\n\ndspy_train_examples, dspy_val_examples = get_dataset(metadata)\n```\n\n\n\n## The DSPy Program\n\n[DSPy](https://dspy-docs.vercel.app) is a framework that pushes building new LM pipelines away from manipulating free-form strings and closer to programming (composing modular operators to build text transformation graphs) where a compiler automatically generates optimized LM invocation strategies and prompts from a program.\n\nWe will use the [`dspy.OpenAI`](https://dspy-docs.vercel.app/api/language_model_clients/OpenAI) abstraction to make LLM calls to [GPT3.5 Turbo](https://platform.openai.com/docs/models/gpt-3-5-turbo).\n\n\n```python\nsystem_prompt = \"\"\"\nYou are an expert in the field of causal reasoning. You are to analyze the a given question carefully and answer in `Yes` or `No`.\nYou should also provide a detailed explanation justifying your answer.\n\"\"\"\n\nllm = dspy.OpenAI(model=\"gpt-3.5-turbo\", system_prompt=system_prompt)\ndspy.settings.configure(lm=llm)\n```\n\n### Writing the Causal Reasoning Signature\n\nA [signature](https://dspy-docs.vercel.app/docs/building-blocks/signatures) is a declarative specification of input/output behavior of a [DSPy module](https://dspy-docs.vercel.app/docs/building-blocks/modules) which are task-adaptive components\u2014akin to neural network layers\u2014that abstract any particular text transformation.\n\n\n```python\nfrom pydantic import BaseModel, Field\n\n\nclass Input(BaseModel):\n    query: str = Field(description=\"The question to be answered\")\n\n\nclass Output(BaseModel):\n    answer: str = Field(description=\"The answer for the question\")\n    confidence: float = Field(\n        ge=0, le=1, description=\"The confidence score for the answer\"\n    )\n    explanation: str = Field(description=\"The explanation for the answer\")\n\n\nclass QuestionAnswerSignature(dspy.Signature):\n    input: Input = dspy.InputField()\n    output: Output = dspy.OutputField()\n\n\nclass CausalReasoningModule(dspy.Module):\n    def __init__(self):\n        self.prog = dspy.TypedPredictor(QuestionAnswerSignature)\n\n    @weave.op()\n    def forward(self, question) -> dict:\n        return self.prog(input=Input(query=question)).output.dict()\n```\n\nLet's test our LLM workflow, i.e., the `CausalReasoningModule` on an example from the causal reasoning subset of Big-Bench Hard.\n\n\n```python\nimport rich\n\nbaseline_module = CausalReasoningModule()\n\nprediction = baseline_module(dspy_train_examples[0][\"question\"])\nrich.print(prediction)\n```\n\n\n\n## Evaluating our DSPy Program\n\nNow that we have a baseline prompting strategy, let's evaluate it on our validation set using [`weave.Evaluation`](../../guides/core-types/evaluations.md) on a simple metric that matches the predicted answer with the ground truth. Weave will take each example, pass it through your application and score the output on multiple custom scoring functions. By doing this, you'll have a view of the performance of your application, and a rich UI to drill into individual outputs and scores.\n\nFirst, we need to create a simple weave evaluation scoring function that tells whether the answer from the baseline module's output is the same as the ground truth answer or not. Scoring functions need to have a `model_output` keyword argument, but the other arguments are user defined and are taken from the dataset examples. It will only take the necessary keys by using a dictionary key based on the argument name.\n\n\n```python\n@weave.op()\ndef weave_evaluation_scorer(answer: str, output: Output) -> dict:\n    return {\"match\": int(answer.lower() == output[\"answer\"].lower())}\n```\n\nNext, we can simply define the evaluation and run it.\n\n\n```python\nvalidation_dataset = weave.ref(\n    f\"bigbenchhard_{metadata.big_bench_hard_task}_val:v0\"\n).get()\n\nevaluation = weave.Evaluation(\n    name=\"baseline_causal_reasoning_module\",\n    dataset=validation_dataset,\n    scorers=[weave_evaluation_scorer],\n)\n\nawait evaluation.evaluate(baseline_module.forward)\n```\n\n\n\n> \ud83d\udca1 **Note**: If you're running from a python script, you can use the following code to run the evaluation:\n\n```python\nimport asyncio\nasyncio.run(evaluation.evaluate(baseline_module.forward))\n```\n\n:::warning\nRunning the evaluation causal reasoning dataset will cost approximately $0.24 in OpenAI credits.\n:::\n\n## Optimizing our DSPy Program\n\nNow, that we have a baseline DSPy program, let us try to improve its performance for causal reasoning using a [DSPy teleprompter](https://dspy-docs.vercel.app/docs/building-blocks/optimizers) that can tune the parameters of a DSPy program to maximize the specified metrics. In this tutorial, we use the [BootstrapFewShot](https://dspy-docs.vercel.app/api/category/optimizers) teleprompter.\n\n\n```python\nfrom dspy.teleprompt import BootstrapFewShot\n\n\n@weave.op()\ndef get_optimized_program(model: dspy.Module, metadata: Metadata) -> dspy.Module:\n    @weave.op()\n    def dspy_evaluation_metric(true, prediction, trace=None):\n        return prediction[\"answer\"].lower() == true.answer.lower()\n\n    teleprompter = BootstrapFewShot(\n        metric=dspy_evaluation_metric,\n        max_bootstrapped_demos=metadata.max_bootstrapped_demos,\n        max_labeled_demos=metadata.max_labeled_demos,\n    )\n    return teleprompter.compile(model, trainset=dspy_train_examples)\n\n\noptimized_module = get_optimized_program(baseline_module, metadata)\n```\n\n\n\n:::warning\nRunning the evaluation causal reasoning dataset will cost approximately $0.04 in OpenAI credits.\n:::\n\nNow that we have our optimized program (the optimized prompting strategy), let's evaluate it once again on our validation set and compare it with our baseline DSPy program.\n\n\n```python\nevaluation = weave.Evaluation(\n    name=\"optimized_causal_reasoning_module\",\n    dataset=validation_dataset,\n    scorers=[weave_evaluation_scorer],\n)\n\nawait evaluation.evaluate(optimized_module.forward)\n```\n\n\n\nWhen coomparing the evalution of the baseline program with the optimized one shows that the optimized program answers the causal reasoning questions with siginificantly more accuracy.\n\n## Conclusion\n\nIn this tutorial, we learned how to use DSPy for prompt optimization alongside using Weave for tracking and evaluation to compare the original and optimized programs."
  },
  {
    "title": "Code Generation",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/codegen",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n\n# Code Generation using Weave and OpenAI\n\nGenerating high-quality code with proper structure, documentation, and tests is a challenging task. This guide demonstrates how to implement a code generation pipeline. You'll learn to create a code generation pipeline that produces high-quality Python functions against the humaneval test suite.\n\nWe'll use Weave for evaluation comparison and tracking, and OpenAI's GPT models for code generation using structured outputs.\n\n\n\n## Video Demonstration\n\nFor a visual demonstration of the code generation pipeline using Weave, Groq, and E2B check out this video:\n\n\n\nThis video provides a step-by-step walkthrough of the process, showcasing how Weave integrates with Groq to create a powerful code generation tool and then running the code in E2B, to validate the code. We use OpenAI in the following example, but you can use any LLM provider with Weave.\n\n## Why use Weave?\n\nIn this tutorial, we'll use Weave to implement and evaluate a code generation pipeline. You'll learn how to:\n\n1. **Track your LLM pipeline**: Log inputs, outputs, and intermediate steps of your code generation process.\n2. **Evaluate LLM outputs**: Create and compare evaluations of your generated code with rich debugging tools and visualizations.\n\n## Set up the environment\n\nFirst, let's set up our environment and import the necessary libraries:\n\n\n```python\n!pip install -qU autopep8 autoflake weave isort openai set-env-colab-kaggle-dotenv datasets\n```\n\n\n```python\n%%capture\n# Temporary workaround to fix bug in openai:\n# TypeError: Client.__init__() got an unexpected keyword argument 'proxies'\n# See https://community.openai.com/t/error-with-openai-1-56-0-client-init-got-an-unexpected-keyword-argument-proxies/1040332/15\n!pip install \"httpx<0.28\"\n```\n\n\n```python\nimport ast\nimport os\nimport re\nimport subprocess\nimport tempfile\nimport traceback\n\nimport autopep8\nimport isort\nfrom autoflake import fix_code\nfrom datasets import load_dataset\nfrom openai import OpenAI\nfrom pydantic import BaseModel\nfrom set_env import set_env\n\nimport weave\nfrom weave import Dataset, Evaluation\n\nset_env(\"WANDB_API_KEY\")\nset_env(\"OPENAI_API_KEY\")\n```\n\n\n```python\nWEAVE_PROJECT = \"codegen-cookbook-example\"\nweave.init(WEAVE_PROJECT)\n```\n\n\n```python\nclient = OpenAI()\n```\n\n\n```python\nhuman_eval = load_dataset(\"openai_humaneval\")\nselected_examples = human_eval[\"test\"][:3]\n```\n\n> \ud83d\udca1 **Note**: Weave automatically tracks OpenAI API calls, including inputs, outputs, and metadata. This means you don't need to add any additional logging code for your OpenAI interactions \u2013 Weave handles it seamlessly in the background.\n\n## Leveraging Structured Outputs and Pydantic Models\n\nIn this code generation pipeline, we utilize OpenAI's [structured outputs mode](https://platform.openai.com/docs/guides/structured-outputs) and Pydantic models to ensure consistent and well-formatted responses from the language model. This approach offers several advantages:\n\n\n1. **Type Safety**: By defining Pydantic models for our expected outputs, we enforce a strict structure for the generated code, program runners, and unit tests.\n2. **Easier Parsing**: The structured output mode allows us to directly parse the model's response into our predefined Pydantic models, reducing the need for complex post-processing.\n3. **Improved Reliability**: By specifying the exact format we expect, we reduce the likelihood of unexpected or malformed outputs from the language model.\n\nHere's an example of how we define our Pydantic models and use them with OpenAI's structured outputs:\n\n\n```python\nclass GeneratedCode(BaseModel):\n    function_signature: str\n    function_args_with_docstring_within_triple_quotes: str\n    code_logic: str\n\n\nclass FormattedGeneratedCode(BaseModel):\n    full_code: str\n```\n\n## Implementing a Code Formatter\n\nTo ensure consistent and clean code output, we implement a `CodeFormatter` class using Weave operations. This formatter applies various linting and styling rules to the generated code, program runner, and unit tests.\n\n\n```python\nclass CodeFormatter(BaseModel):\n    @weave.op()\n    def lint_code(self, code: str) -> str:\n        # Replace escaped newlines with actual newlines\n        code = code.replace(\"\\\\n\", \"\\n\")\n\n        # Remove unused imports and variables\n        code = fix_code(\n            code, remove_all_unused_imports=True, remove_unused_variables=True\n        )\n\n        # Sort imports\n        code = isort.code(code)\n\n        # Apply PEP 8 formatting\n        code = autopep8.fix_code(code, options={\"aggressive\": 2})\n\n        return code\n\n    @weave.op()\n    def add_imports(self, code: str) -> str:\n        tree = ast.parse(code)\n        from_imports = {}\n        global_names = set()\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Name):\n                if node.id not in dir(__builtins__):\n                    global_names.add(node.id)\n\n        # Only add typing imports that are actually used\n        typing_imports = global_names.intersection(\n            {\"List\", \"Dict\", \"Tuple\", \"Set\", \"Optional\", \"Union\"}\n        )\n        if typing_imports:\n            from_imports[\"typing\"] = typing_imports\n\n        # Remove names that are defined within the function\n        function_def = next(\n            node for node in tree.body if isinstance(node, ast.FunctionDef)\n        )\n        local_names = {arg.arg for arg in function_def.args.args}\n        local_names.update(\n            node.id\n            for node in ast.walk(function_def)\n            if isinstance(node, ast.Name) and isinstance(node.ctx, ast.Store)\n        )\n\n        global_names -= local_names\n        global_names -= {\"sorted\"}  # Remove built-in functions\n\n        # Construct the import statements\n        import_statements = []\n        for module, names in from_imports.items():\n            names_str = \", \".join(sorted(names))\n            import_statements.append(f\"from {module} import {names_str}\")\n\n        return (\n            \"\\n\".join(import_statements) + (\"\\n\\n\" if import_statements else \"\") + code\n        )\n\n    @weave.op()\n    def format_generated_code(\n        self, generated_code: GeneratedCode\n    ) -> FormattedGeneratedCode:\n        # Combine the code parts\n        full_code = f\"{generated_code.function_signature}\\n{generated_code.function_args_with_docstring_within_triple_quotes}\\n{generated_code.code_logic}\"\n\n        # Ensure proper indentation\n        lines = full_code.split(\"\\n\")\n        indented_lines = []\n        for i, line in enumerate(lines):\n            if i == 0:  # Function signature\n                indented_lines.append(line)\n            elif i == 1:  # Function arguments (docstring)\n                indented_lines.append(\"    \" + line)\n            else:  # Function body\n                indented_lines.append(\"    \" + line)\n        full_code = \"\\n\".join(indented_lines)\n\n        # Lint the code\n        full_code = self.lint_code(full_code)\n\n        # Add imports\n        cleaned_code = self.add_imports(full_code)\n\n        return FormattedGeneratedCode(full_code=cleaned_code)\n```\n\nThis `CodeFormatter` class provides several Weave operations to clean and format the generated code:\n   - Replacing escaped newlines with actual newlines\n   - Removing unused imports and variables\n   - Sorting imports\n   - Applying PEP 8 formatting\n   - Adding missing imports\n\n## Define the CodeGenerationPipeline\n\n\n\nNow, let's implement the core code generation logic:\n\nWe're using a `weave.Model` so that it's automatically versioned when it changes. We're also keeping the `model_name` as an attribute so that we can experiment with it and easily diff & compare it in Weave. We're tracking our function calls with `@weave.op` so the inputs & outputs are logged to help with error tracking and debugging. \n\n\n```python\nclass CodeGenerationPipeline(weave.Model):\n    model_name: str\n    formatter: CodeFormatter\n\n    def __init__(\n        self, model_name: str = \"gpt-4o\", formatter: CodeFormatter = CodeFormatter()\n    ):\n        super().__init__(model_name=model_name, formatter=formatter)\n        self.model_name = model_name\n        self.formatter = formatter\n\n    @weave.op()\n    async def predict(self, prompt: str):\n        generated_code = self.generate_code(prompt)\n        formatted_generated_code = self.formatter.format_generated_code(generated_code)\n\n        return formatted_generated_code.full_code\n\n    @weave.op()\n    def generate_code(self, prompt: str) -> GeneratedCode:\n        completion = client.beta.chat.completions.parse(\n            model=self.model_name,\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": \"You are an expert Python code generator.\",\n                },\n                {\"role\": \"user\", \"content\": prompt},\n            ],\n            response_format=GeneratedCode,\n        )\n        message = completion.choices[0].message\n        if message.parsed:\n            return message.parsed\n        else:\n            raise ValueError(message.refusal)\n```\n\nThis `CodeGenerationPipeline` class encapsulates our code generation logic as a Weave Model, providing several key benefits:\n\n1. Automatic experiment tracking: Weave captures inputs, outputs, and parameters for each run of the model.\n2. Versioning: Changes to the model's attributes or code are automatically versioned, creating a clear history of how your code generation pipeline evolves over time.\n3. Reproducibility: The versioning and tracking make it easy to reproduce any previous result or configuration of your code generation pipeline.\n4. Hyperparameter management: Model attributes (like `model_name`) are clearly defined and tracked across different runs, facilitating experimentation.\n5. Integration with Weave ecosystem: Using `weave.Model` allows seamless integration with other Weave tools, such as evaluations and serving capabilities.\n\n## Implement evaluation metrics\n\nTo assess the quality of our generated code, we'll implement simple evaluation metrics using a `weave.Scorer` subclass. This will run `score` on every `model_output` from our dataset. `model_output` comes from the output of the `predict` function in our `weave.Model`. `prompt` is taken from our dataset `human-eval`.\n\n\n```python\nCODE_TEMPLATE = \"\"\"\n{model_output}\n\n{test}\n\nif __name__ == \"__main__\":\n    check({entry_point})\n\"\"\"\n```\n\n\n```python\n@weave.op()\nasync def score_humaneval_test(test: str, entry_point: str, output: str):\n    generated_code = output\n\n    # Extract test cases from the test string\n    test_cases = re.findall(r\"assert.*\", test)\n    test_cases_str = \"\\n            \".join(test_cases)\n\n    # Generate the full source code\n    full_code = CODE_TEMPLATE.format(\n        model_output=generated_code,\n        test=test,\n        test_cases=test_cases_str,\n        entry_point=entry_point,\n    )\n\n    # Create a temporary file to store the code\n    with tempfile.NamedTemporaryFile(delete=False, suffix=\".py\") as tmp_file:\n        # Write the generated code to the temporary file\n        tmp_file.write(full_code.encode())\n        tmp_file_path = tmp_file.name\n\n    try:\n        # Run the temporary Python file as a subprocess with a timeout\n        result = subprocess.run(\n            [\"python\", tmp_file_path],\n            capture_output=True,\n            text=True,\n            timeout=10,  # Timeout of 10 seconds\n        )\n\n        print(result)\n\n        if result.returncode == 0:\n            return {\"correct\": True}\n        else:\n            return {\"correct\": False, \"error\": result.stderr, \"output\": result.stdout}\n    except subprocess.TimeoutExpired:\n        return {\"correct\": False, \"error\": \"TimeoutExpired\"}\n    except Exception as e:\n        return {\"correct\": False, \"error\": traceback.format_exc()}\n    finally:\n        # Ensure the temporary file is removed after execution\n        os.remove(tmp_file_path)\n```\n\nThese evaluation functions run the generated code and return a boolean value indicating whether the code passed the test provided from the dataset.\n\n\n\n## Create a Weave Dataset and run evaluation\n\nTo evaluate our pipeline, we'll create a Weave Dataset and run an evaluation:\n\n\n```python\nformatted_selected_examples = [\n    {\n        \"task_id\": task_id,\n        \"prompt\": prompt,\n        \"canonical_solution\": solution,\n        \"test\": test,\n        \"entry_point\": entry_point,\n    }\n    for task_id, prompt, solution, test, entry_point in zip(\n        selected_examples[\"task_id\"],\n        selected_examples[\"prompt\"],\n        selected_examples[\"canonical_solution\"],\n        selected_examples[\"test\"],\n        selected_examples[\"entry_point\"],\n    )\n]\n```\n\n\n```python\nprompt_dataset = Dataset(\n    name=\"humaneval_code_gen_example\",\n    rows=[\n        {\n            \"prompt\": example[\"prompt\"],\n            \"test\": example[\"test\"],\n            \"entry_point\": example[\"entry_point\"],\n        }\n        for example in formatted_selected_examples\n    ],\n)\nweave.publish(prompt_dataset)\n```\n\n\n```python\nEVAL_RUN = True\n```\n\n\n```python\nfor model_name in [\"gpt-4o-2024-08-06\"]:\n    pipeline = CodeGenerationPipeline(model_name=model_name)\n    if not EVAL_RUN:\n        dataset = prompt_dataset.rows[2]\n        result = await pipeline.predict(dataset[\"prompt\"])\n        score_result = await score_humaneval_test(\n            dataset[\"test\"], dataset[\"entry_point\"], result[\"generated_code\"].full_code\n        )\n    else:\n        evaluation = Evaluation(\n            name=\"minimal_code_gen_evaluation\",\n            dataset=prompt_dataset,\n            scorers=[score_humaneval_test],\n        )\n        results = await evaluation.evaluate(pipeline)\n```\n\nThis code creates a dataset with our sample prompts, defines our humaneval test scorer, and runs an evaluation of our code generation pipeline.\n\n\n\n## Conclusion\n\nIn this example, we've demonstrated how to implement a code generation pipeline using Weave and OpenAI's language models. We've shown how to:\n\n1. Create Weave operations for each step of the code generation process\n2. Wrap the pipeline in a Weave Model for easy tracking and evaluation\n3. Implement custom evaluation metrics using Weave operations\n4. Create a dataset and run an evaluation of the pipeline\n\nWeave's seamless integration allows us to track inputs, outputs, and intermediate steps throughout the code generation process, making it easier to debug, optimize, and evaluate our LLM application.\n\nFor more information on Weave and its capabilities, check out the [Weave documentation](https://docs.wandb.ai/weave). You can extend this example to handle larger datasets, implement more sophisticated evaluation metrics, or integrate with other LLM workflows."
  },
  {
    "title": "Models And Weave Integration Demo",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/Models_and_Weave_Integration_Demo",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n# Use Weave with W&B Models\n\nThis notebook demonstrates how to use W&B Weave with [W&B Models](https://docs.wandb.ai/guides/) using the scenario of two different teams working on an end-to-end implementation of a Retrieval-Augmented Generation (RAG) application, from fine-tuning the model to building an app around the model. Specifically, the Model Team fine-tunes a new Chat Model (Llama 3.2),and saves it to the [W&B Models Registry](https://docs.wandb.ai/guides/registry/). Then, the App Team retrieves the fine-tuned Chat Model from the Registry, and uses Weave to create and evaluate a RAG chatbot application\n\nThe guide walks you through the following steps, which are the same steps that the teams in the described scenario would follow:\n\n1. Downloading a fine-tuned Llama 3.2 model registered in [W&B Models Registry](https://docs.wandb.ai/guides/registry/)\n2. Implementing a RAG application using the fine-tuned Llama 3.2 model \n3. Tracking and evaluating the RAG application using Weave\n4. Registering the improved RAG app to Registry\n\nFind the public workspace for both W&B Models and W&B Weave [here](https://wandb.ai/wandb-smle/weave-cookboook-demo/weave/evaluations).\n\n\n\n\n\n\n\n\n## Prerequisites\n\nFirst, install the necessary libraries, set up API keys, log in to W&B, and create a new W&B project.\n\n1. Install `weave`, `pandas`, `unsloth`, `wandb`, `litellm`, `pydantic`, `torch`, and `faiss-gpu` using `pip`.\n\n\n```python\n%%capture\n!pip install weave wandb pandas pydantic litellm faiss-gpu\n```\n\n\n```python\n%%capture\n!pip install unsloth\n# Also get the latest nightly Unsloth!\n!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n```\n\n2. Add the necessary API keys from your environment.\n\n\n```python\nimport os\n\nfrom google.colab import userdata\n\nos.environ[\"WANDB_API_KEY\"] = userdata.get(\"WANDB_API_KEY\")  # W&B Models and Weave\nos.environ[\"OPENAI_API_KEY\"] = userdata.get(\n    \"OPENAI_API_KEY\"\n)  # OpenAI - for retrieval embeddings\nos.environ[\"GEMINI_API_KEY\"] = userdata.get(\n    \"GEMINI_API_KEY\"\n)  # Gemini - for the base chat model\n```\n\n3. Log in to W&B, and create a new project.\n\n\n```python\nimport pandas as pd\nimport wandb\n\nimport weave\n\nwandb.login()\n\nPROJECT = \"weave-cookboook-demo\"\nENTITY = \"wandb-smle\"\n\nweave.init(ENTITY + \"/\" + PROJECT)\n```\n\n##  Download `ChatModel` from Models Registry and implement `UnslothLoRAChatModel`\n\nIn our scenario, the Llama-3.2 model has already been fine-tuned by the Model Team using the `unsloth` library for performance optimization, and is [available in the W&B Models Registry](https://wandb.ai/wandb-smle/weave-cookboook-demo/weave/object-versions?filter=%7B%22objectName%22%3A%22RagModel%22%7D&peekPath=%2Fwandb-smle%2Fweave-rag-experiments%2Fobjects%2FChatModelRag%2Fversions%2F2mhdPb667uoFlXStXtZ0MuYoxPaiAXj3KyLS1kYRi84%3F%26). In this step, we'll retrieve the fine-tuned [`ChatModel`](https://wandb.ai/wandb-smle/weave-cookboook-demo/weave/object-versions?filter=%7B%22objectName%22%3A%22RagModel%22%7D&peekPath=%2Fwandb-smle%2Fweave-rag-experiments%2Fobjects%2FChatModelRag%2Fversions%2F2mhdPb667uoFlXStXtZ0MuYoxPaiAXj3KyLS1kYRi84%3F%26) from the Registry and convert it into a `weave.Model` to make it compatible with the [`RagModel`](https://wandb.ai/wandb-smle/weave-cookboook-demo/weave/object-versions?filter=%7B%22objectName%22%3A%22RagModel%22%7D&peekPath=%2Fwandb-smle%2Fweave-cookboook-demo%2Fobjects%2FRagModel%2Fversions%2FcqRaGKcxutBWXyM0fCGTR1Yk2mISLsNari4wlGTwERo%3F%26). \n\n> \ud83d\udea8 **Important**: The `RagModel` referenced below is a top-level `weave.Model` that can be considered a complete RAG Application. It contains a `ChatModel`, vector database, and a prompt. The `ChatModel` is also a `weave.Model`, which contains code to download an artifact from the W&B Registry. `ChatModel` can be changed modularly to support any kind of other LLM chat model as part of the `RagModel`. For more information, [view the model in Weave](https://wandb.ai/wandb-smle/weave-cookboook-demo/weave/evaluations?peekPath=%2Fwandb-smle%2Fweave-cookboook-demo%2Fobjects%2FRagModel%2Fversions%2Fx7MzcgHDrGXYHHDQ9BA8N89qDwcGkdSdpxH30ubm8ZM%3F%26).\n\nTo load the `ChatModel`, `unsloth.FastLanguageModel` or `peft.AutoPeftModelForCausalLM` with adapters are used, enabling efficient integration into the app. After downloading the model from the Registry, you can set up the initialization and prediction logic by using the `model_post_init` method. The required code for this step is available in the **Use** tab of the Registry and can be copied directly into your implementation\n\nThe code below defines the `UnslothLoRAChatModel` class to manage, initialize, and use the fine-tuned Llama-3.2 model retrieved from the W&B Models Registry. `UnslothLoRAChatModel` uses `unsloth.FastLanguageModel` for optimized inference. The `model_post_init` method handles downloading and setting up the model, while the `predict` method processes user queries and generates responses. To adapt the code for your use case, update the `MODEL_REG_URL` with the correct Registry path for your fine-tuned model and adjust parameters like `max_seq_length` or `dtype` based on your hardware or requirements.\n\n\n\n```python\nfrom typing import Any\n\nfrom pydantic import PrivateAttr\nfrom unsloth import FastLanguageModel\n\nimport weave\n\n\nclass UnslothLoRAChatModel(weave.Model):\n    \"\"\"\n    We define an extra ChatModel class to be able store and version more parameters than just the model name.\n    Especially, relevant if we consider fine-tuning (locally or aaS) because of specific parameters.\n    \"\"\"\n\n    chat_model: str\n    cm_temperature: float\n    cm_max_new_tokens: int\n    cm_quantize: bool\n    inference_batch_size: int\n    dtype: Any\n    device: str\n    _model: Any = PrivateAttr()\n    _tokenizer: Any = PrivateAttr()\n\n    def model_post_init(self, __context):\n        # we can simply paste this from the \"Use\" tab from the registry\n        run = wandb.init(project=PROJECT, job_type=\"model_download\")\n        artifact = run.use_artifact(f\"{self.chat_model}\")\n        model_path = artifact.download()\n\n        # unsloth version (enable native 2x faster inference)\n        self._model, self._tokenizer = FastLanguageModel.from_pretrained(\n            model_name=model_path,\n            max_seq_length=self.cm_max_new_tokens,\n            dtype=self.dtype,\n            load_in_4bit=self.cm_quantize,\n        )\n        FastLanguageModel.for_inference(self._model)\n\n    @weave.op()\n    async def predict(self, query: list[str]) -> dict:\n        # add_generation_prompt = true - Must add for generation\n        input_ids = self._tokenizer.apply_chat_template(\n            query,\n            tokenize=True,\n            add_generation_prompt=True,\n            return_tensors=\"pt\",\n        ).to(\"cuda\")\n\n        output_ids = self._model.generate(\n            input_ids=input_ids,\n            max_new_tokens=64,\n            use_cache=True,\n            temperature=1.5,\n            min_p=0.1,\n        )\n\n        decoded_outputs = self._tokenizer.batch_decode(\n            output_ids[0][input_ids.shape[1] :], skip_special_tokens=True\n        )\n\n        return \"\".join(decoded_outputs).strip()\n```\n\n\n```python\nMODEL_REG_URL = \"wandb32/wandb-registry-RAG Chat Models/Finetuned Llama-3.2:v3\"\n\nmax_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!\ndtype = (\n    None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n)\nload_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.\n\nnew_chat_model = UnslothLoRAChatModel(\n    name=\"UnslothLoRAChatModelRag\",\n    chat_model=MODEL_REG_URL,\n    cm_temperature=1.0,\n    cm_max_new_tokens=max_seq_length,\n    cm_quantize=load_in_4bit,\n    inference_batch_size=max_seq_length,\n    dtype=dtype,\n    device=\"auto\",\n)\n```\n\n\n```python\nawait new_chat_model.predict(\n    [{\"role\": \"user\", \"content\": \"What is the capital of Germany?\"}]\n)\n```\n\n## Integrate the new `ChatModel` version into `RagModel`\n\nBuilding a RAG application from a fine-tuned chat model improves conversational AI by using tailored components without having to rebuild the entire pipeline. In this step, we retrieve the existing `RagModel` from our Weave project and update its `ChatModel` to use the newly fine-tuned model. This seamless swap means that other components like the vector database (VDB) and prompts remain untouched, preserving the application's overall structure while improving performance.\n\nThe code below retrieves the `RagModel` object using a reference from the Weave project. The `chat_model` attribute of the `RagModel` is then updated to use the new `UnslothLoRAChatModel` instance created in the previous step. After this, the updated `RagModel` is published to create a new version. Finally, the updated `RagModel` is used to run a sample prediction query, verifying that the new chat model is being used. \n\n\n\n```python\nRagModel = weave.ref(\n    \"weave:///wandb-smle/weave-cookboook-demo/object/RagModel:cqRaGKcxutBWXyM0fCGTR1Yk2mISLsNari4wlGTwERo\"\n).get()\n```\n\n\n```python\nRagModel.chat_model.chat_model\n```\n\n\n```python\nawait RagModel.predict(\"When was the first conference on climate change?\")\n```\n\n\n```python\n# MAGIC: exchange chat_model and publish new version (no need to worry about other RAG components)\nRagModel.chat_model = new_chat_model\n```\n\n\n```python\nRagModel.chat_model.chat_model\n```\n\n\n```python\n# first publish new version so that in prediction we reference new version\nPUB_REFERENCE = weave.publish(RagModel, \"RagModel\")\n```\n\n\n```python\nawait RagModel.predict(\"When was the first conference on climate change?\")\n```\n\n## Run a `weave.Evaluation` \n\nIn the next step, we evaluate the performance of our updated `RagModel` using an existing `weave.Evaluation`. This process ensures that the new fine-tuned chat model is performing as expected within the RAG application. To streamline integration and enable collaboration between the Models and Apps teams, we log evaluation results for both the model's W&B run and as part of the Weave workspace.\n\nIn Models:\n- The evaluation summary is logged to the W&B run used to download the fine-tuned chat model. This includes summary metrics and graphs displayed in a [workspace view](https://wandb.ai/wandb-smle/weave-cookboook-demo/workspace?nw=eglm8z7o9) for analysis.\n- The evaluation trace ID is added to the run's configuration, linking directly to the Weave page for easier traceability by the Model Team.\n\nIn Weave:\n- The artifact or registry link for the `ChatModel` is stored as an input to the `RagModel`.\n- The W&B run ID is saved as an extra column in the evaluation traces for better context.\n\nThe code below demonstrates how to retrieve an evaluation object, execute the evaluation using the updated `RagModel`, and log the results to both W&B and Weave. Ensure that the evaluation reference (`WEAVE_EVAL`) matches your project setup. \n\n\n\n```python\n# MAGIC: we can simply get an evaluation with a eval dataset and scorers and use them\nWEAVE_EVAL = \"weave:///wandb-smle/weave-cookboook-demo/object/climate_rag_eval:ntRX6qn3Tx6w3UEVZXdhIh1BWGh7uXcQpOQnIuvnSgo\"\nclimate_rag_eval = weave.ref(WEAVE_EVAL).get()\n```\n\n\n```python\nwith weave.attributes({\"wandb-run-id\": wandb.run.id}):\n    # use .call attribute to retrieve both the result and the call in order to save eval trace to Models\n    summary, call = await climate_rag_eval.evaluate.call(climate_rag_eval, RagModel)\n```\n\n\n```python\n# log to models\nwandb.run.log(pd.json_normalize(summary, sep=\"/\").to_dict(orient=\"records\")[0])\nwandb.run.config.update(\n    {\"weave_url\": f\"https://wandb.ai/wandb-smle/weave-cookboook-demo/r/call/{call.id}\"}\n)\nwandb.run.finish()\n```\n\n## Save the new RAG Model to the Registry\n\nTo make the updated `RagModel` available for future use by both the Models and Apps teams, we push it to the W&B Models Registry as a reference artifact.\n\nThe code below retrieves the `weave` object version and name for the updated `RagModel` and uses them to create reference links. A new artifact is then created in W&B with metadata containing the model's Weave URL. This artifact is logged to the W&B Registry and linked to a designated registry path.\n\nBefore running the code, ensure the `ENTITY` and `PROJECT` variables match your W&B setup, and the target registry path is correctly specified. This process finalizes the workflow by publishing the new `RagModel` to the W&B ecosystem for easy collaboration and reuse.\n\n\n\n```python\nMODELS_OBJECT_VERSION = PUB_REFERENCE.digest  # weave object version\nMODELS_OBJECT_NAME = PUB_REFERENCE.name  # weave object name\n```\n\n\n```python\nmodels_url = f\"https://wandb.ai/{ENTITY}/{PROJECT}/weave/objects/{MODELS_OBJECT_NAME}/versions/{MODELS_OBJECT_VERSION}\"\nmodels_link = (\n    f\"weave:///{ENTITY}/{PROJECT}/object/{MODELS_OBJECT_NAME}:{MODELS_OBJECT_VERSION}\"\n)\n\nwith wandb.init(project=PROJECT, entity=ENTITY) as run:\n    # create new Artifact\n    artifact_model = wandb.Artifact(\n        name=\"RagModel\",\n        type=\"model\",\n        description=\"Models Link from RagModel in Weave\",\n        metadata={\"url\": models_url},\n    )\n    artifact_model.add_reference(models_link, name=\"model\", checksum=False)\n\n    # log new artifact\n    run.log_artifact(artifact_model, aliases=[MODELS_OBJECT_VERSION])\n\n    # link to registry\n    run.link_artifact(\n        artifact_model, target_path=\"wandb32/wandb-registry-RAG Models/RAG Model\"\n    )\n```"
  },
  {
    "title": "Introduction Notebook",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/01-intro_notebook",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n\n\n\n# \ud83c\udfc3\u200d\u2640\ufe0f Quickstart\n\nGet started using Weave to:\n- Log and debug language model inputs, outputs, and traces\n- Build rigorous, apples-to-apples evaluations for language model use cases\n- Organize all the information generated across the LLM workflow, from experimentation to evaluations to production\n\nSee the full Weave documentation [here](https://wandb.me/weave).\n\n\n## \ud83e\ude84 Install `weave` library and login\n\n\nStart by installing the library and logging in to your account.\n\nIn this example, we're using openai so you should [add an openai API key](https://platform.openai.com/docs/quickstart/step-2-setup-your-api-key).\n\n\n\n```python\n%%capture\n!pip install weave openai set-env-colab-kaggle-dotenv\n```\n\n\n```python\n# Set your OpenAI API key\nfrom set_env import set_env\n\n# Put your OPENAI_API_KEY in the secrets panel to the left \ud83d\udddd\ufe0f\n_ = set_env(\"OPENAI_API_KEY\")\n# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\" # alternatively, put your key here\n\nPROJECT = \"weave-intro-notebook\"\n```\n\n# Track inputs & outputs of functions\n\nWeave allows users to track function calls: the code, inputs, outputs, and even LLM tokens & costs! In the following sections we will cover:\n\n* Custom Functions\n* Vendor Integrations\n* Nested Function Calling\n* Error Tracking\n\nNote: in all cases, we will:\n\n```python\nimport weave                    # import the weave library\nweave.init('project-name')      # initialize tracking for a specific W&B project\n```\n\n## Track custom functions\n\nAdd the @weave.op decorator to the functions you want to track\n\n\n\n\n```python\nfrom openai import OpenAI\n\nimport weave\n\nweave.init(PROJECT)\n\nclient = OpenAI()\nresponse = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a grammar checker, correct the following user input.\",\n        },\n        {\"role\": \"user\", \"content\": \"That was so easy, it was a piece of pie!\"},\n    ],\n    temperature=0,\n)\ngeneration = response.choices[0].message.content\nprint(generation)\n```\n\nYou can find your interactive dashboard by clicking any of the  \ud83d\udc46 wandb links above.\n\n## Vendor Integrations (OpenAI, Anthropic, Mistral, etc...)\n\nHere, we're automatically tracking all calls to `openai`. We automatically track a lot of LLM libraries, but it's really easy to add support for whatever LLM you're using, as you'll see below. \n\n\n\n\n```python\nimport weave\n\nweave.init(PROJECT)\n\n\n@weave.op()\ndef strip_user_input(user_input):\n    return user_input.strip()\n\n\nresult = strip_user_input(\"    hello    \")\nprint(result)\n```\n\nAfter adding `weave.op` and calling the function, visit the link and see it tracked within your project.\n\n\ud83d\udca1 We automatically track your code, have a look at the code tab!\n\n## Track nested functions\n\nNow that you've seen the basics, let's combine all of the above and track some deeply nested functions alongside LLM calls.\n\n\n\n\n\n\n```python\nfrom openai import OpenAI\n\nimport weave\n\nweave.init(PROJECT)\n\n\n@weave.op()\ndef strip_user_input(user_input):\n    return user_input.strip()\n\n\n@weave.op()\ndef correct_grammar(user_input):\n    client = OpenAI()\n\n    stripped = strip_user_input(user_input)\n    response = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a grammar checker, correct the following user input.\",\n            },\n            {\"role\": \"user\", \"content\": stripped},\n        ],\n        temperature=0,\n    )\n    return response.choices[0].message.content\n\n\nresult = correct_grammar(\"   That was so easy, it was a piece of pie!    \")\nprint(result)\n```\n\n## Track Errors\n\nWhenever your code crashes, weave will highlight what caused the issue. This is especially useful for finding things like JSON parsing issues that can occasionally happen when parsing data from LLM responses.\n\n\n\n\n```python\nimport json\n\nfrom openai import OpenAI\n\nimport weave\n\nweave.init(PROJECT)\n\n\n@weave.op()\ndef strip_user_input(user_input):\n    return user_input.strip()\n\n\n@weave.op()\ndef correct_grammar(user_input):\n    client = OpenAI()\n\n    stripped = strip_user_input(user_input)\n    response = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a grammar checker, correct the following user input.\",\n            },\n            {\"role\": \"user\", \"content\": stripped},\n        ],\n        temperature=0,\n        response_format={\"type\": \"json_object\"},\n    )\n    return json.loads(response.choices[0].message.content)\n\n\nresult = correct_grammar(\"   That was so easy, it was a piece of pie!    \")\nprint(result)\n```\n\n# Tracking Objects\n\nOrganizing experimentation is difficult when there are many moving pieces. You can capture and organize the experimental details of your app like your system prompt or the model you're using within `weave.Objects`. This helps organize and compare different iterations of your app. In this section, we will cover:\n\n* General Object Tracking\n* Tracking Models\n* Tracking Datasets\n\n## General Object Tracking\n\nMany times, it is useful to track & version data, just like you track and version code. For example, here we define a `SystemPrompt(weave.Object)` object that can be shared between teammates\n\n\n\n\n```python\nimport weave\n\nweave.init(PROJECT)\n\n\nclass SystemPrompt(weave.Object):\n    prompt: str\n\n\nsystem_prompt = SystemPrompt(\n    prompt=\"You are a grammar checker, correct the following user input.\"\n)\nweave.publish(system_prompt)\n```\n\n## Model Tracking\n\nModels are so common of an object type, that we have a special class to represent them: `weave.Model`. The only requirement is that we define a `predict` method.\n\n\n\n\n```python\nfrom openai import OpenAI\n\nimport weave\n\nweave.init(PROJECT)\n\n\nclass OpenAIGrammarCorrector(weave.Model):\n    # Properties are entirely user-defined\n    openai_model_name: str\n    system_message: str\n\n    @weave.op()\n    def predict(self, user_input):\n        client = OpenAI()\n        response = client.chat.completions.create(\n            model=self.openai_model_name,\n            messages=[\n                {\"role\": \"system\", \"content\": self.system_message},\n                {\"role\": \"user\", \"content\": user_input},\n            ],\n            temperature=0,\n        )\n        return response.choices[0].message.content\n\n\ncorrector = OpenAIGrammarCorrector(\n    openai_model_name=\"gpt-4o-mini\",\n    system_message=\"You are a grammar checker, correct the following user input.\",\n)\n\nresult = corrector.predict(\"     That was so easy, it was a piece of pie!       \")\nprint(result)\n```\n\n## Dataset Tracking\n\nSimilar to models, a `weave.Dataset` object exists to help track, organize, and operate on datasets\n\n\n\n\n```python\ndataset = weave.Dataset(\n    name=\"grammar-correction\",\n    rows=[\n        {\n            \"user_input\": \"   That was so easy, it was a piece of pie!   \",\n            \"expected\": \"That was so easy, it was a piece of cake!\",\n        },\n        {\"user_input\": \"  I write good   \", \"expected\": \"I write well\"},\n        {\n            \"user_input\": \"  GPT-4 is smartest AI model.   \",\n            \"expected\": \"GPT-4 is the smartest AI model.\",\n        },\n    ],\n)\n\nweave.publish(dataset)\n```\n\nNotice that we saved a versioned `GrammarCorrector` object that captures the configurations you're experimenting with.\n\n## Retrieve Published Objects & Ops\n\nYou can publish objects and then retrieve them in your code. You can even call functions from your retrieved objects!\n\n\n\n\n```python\nimport weave\n\nweave.init(PROJECT)\n\ncorrector = OpenAIGrammarCorrector(\n    openai_model_name=\"gpt-4o-mini\",\n    system_message=\"You are a grammar checker, correct the following user input.\",\n)\n\nref = weave.publish(corrector)\nprint(ref.uri())\n```\n\n\n\n\n```python\nimport weave\n\nweave.init(PROJECT)\n\n# Note: this url is available from the UI after publishing the object!\nref_url = f\"weave:///{ref.entity}/{PROJECT}/object/{ref.name}:{ref.digest}\"\nfetched_collector = weave.ref(ref_url).get()\n\n# Notice: this object was loaded from remote location!\nresult = fetched_collector.predict(\"That was so easy, it was a piece of pie!\")\n\nprint(result)\n```\n\n# Evaluation\n\nEvaluation-driven development helps you reliably iterate on an application. The `Evaluation` class is designed to assess the performance of a `Model` on a given `Dataset` or set of examples using scoring functions.\n\nSee a preview of the API below:\n\n\n\n\n```python\nimport weave\nfrom weave import Evaluation\n\n\n# Define any custom scoring function\n@weave.op()\ndef exact_match(expected: str, output: dict) -> dict:\n    # Here is where you'd define the logic to score the model output\n    return {\"match\": expected == output}\n\n\n# Score your examples using scoring functions\nevaluation = Evaluation(\n    dataset=dataset,  # can be a list of dictionaries or a weave.Dataset object\n    scorers=[exact_match],  # can be a list of scoring functions\n)\n\n# Start tracking the evaluation\nweave.init(PROJECT)\n# Run the evaluation\nsummary = await evaluation.evaluate(corrector)  # can be a model or simple function\n```\n\n## What's next?\n\nFollow the [Build an Evaluation pipeline](http://wandb.me/weave_eval_tut) tutorial to learn more about Evaluation and begin iteratively improving your applications."
  },
  {
    "title": "Integrating with Weave - Production Dashboard",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/online_monitoring",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n\n\n\n\n# Integrating with Weave: Production Dashboard\n\nThe GenAI tooling landscape is rapidly evolving - new frameworks, tools, and applications are emerging all the time. Weave aims to be a one-stop-shop for all your GenAI monitoring and evaluation needs. This also means that sometimes it is necessary to integrate with existing platforms or extend Weave to fit the specific needs of your project or organization.\n\nIn this cookbook, we'll demonstrate how to leverage Weave's powerful APIs and functions to create a custom dashboard for production monitoring as an extension to the Traces view in Weave. We'll focus on:\n\n- Fetching traces, costs, feedback, and other metrics from Weave\n- Creating aggregate views for user feedback and cost distribution\n- Creating visualizations for token usage and latency over time\n\nYou can try out the dashboard with your own Weave project by installing streamlit and running [this production dashboard script](https://github.com/NiWaRe/agent-dev-collection)!\n\n\n\n\n\n# 1. Setup\n\nTo follow along this tutorial you'll only need to install the following packages:\n\n\n\n```python\n!pip install streamlit pandas plotly weave\n```\n\n# 2. Implementation\n\n\n## 2.1 Initializing Weave Client and Defining Costs\n\nFirst, we'll set up a function to initialize the Weave client and add costs for each model.\n\n- We have included the standard costs for many standard models but we also make it easy to add your own custom costs and custom models. In the following we'll show how to add custom costs for a few models and use the standard costs for the rest.\n- The costs are calculate based on the tracked tokens for each call in Weave. For many LLM vendor libraries, we will automatically track the token usage, but it is also possible to return custom token counts for any call. See this cookbook on how to define the token count and cost calculation for a custom model - [custom cost cookbook](https://weave-docs.wandb.ai/reference/gen_notebooks/custom_model_cost#setting-up-a-model-with-weave).\n\n\n\n```python\nPROJECT_NAME = \"wandb-smle/weave-cookboook-demo\"\n```\n\n\n```python\nimport weave\n\nMODEL_NAMES = [\n    # model name, prompt cost, completion cost\n    (\"gpt-4o-2024-05-13\", 0.03, 0.06),\n    (\"gpt-4o-mini-2024-07-18\", 0.03, 0.06),\n    (\"gemini/gemini-1.5-flash\", 0.00025, 0.0005),\n    (\"gpt-4o-mini\", 0.03, 0.06),\n    (\"gpt-4-turbo\", 0.03, 0.06),\n    (\"claude-3-haiku-20240307\", 0.01, 0.03),\n    (\"gpt-4o\", 0.03, 0.06),\n]\n\n\ndef init_weave_client(project_name):\n    try:\n        client = weave.init(project_name)\n        for model, prompt_cost, completion_cost in MODEL_NAMES:\n            client.add_cost(\n                llm_id=model,\n                prompt_token_cost=prompt_cost,\n                completion_token_cost=completion_cost,\n            )\n    except Exception as e:\n        print(f\"Failed to initialize Weave client for project '{project_name}': {e}\")\n        return None\n    else:\n        return client\n\n\nclient = init_weave_client(PROJECT_NAME)\n```\n\n## 2.2 Fetching Calls Data from Weave\n\nIn order to fetch call data from Weave, we have two options:\n\n1. Fetching Data call-by-call\n2. Using high-level APIs\n\n### 2.2.1 Fetching Data call-by-call\n\nThe first option to access data from Weave is to retrieve a list of filtered calls and extract the wanted data call-by-call. For that we can use the `calls_query_stream` API to fetch the calls data from Weave:\n\n- `calls_query_stream` API: This API allows us to fetch the calls data from Weave.\n- `filter` dictionary: This dictionary contains the filter parameters to fetch the calls data - see [here](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace_server/weave.trace_server.trace_server_interface/#class-callschema) for more details.\n- `expand_columns` list: This list contains the columns to expand in the calls data.\n- `sort_by` list: This list contains the sorting parameters for the calls data.\n- `include_costs` boolean: This boolean indicates whether to include the costs in the calls data.\n- `include_feedback` boolean: This boolean indicates whether to include the feedback in the calls data.\n\n\n\n```python\nimport itertools\nfrom datetime import datetime, timedelta\n\nimport pandas as pd\n\n\ndef fetch_calls(client, project_id, start_time, trace_roots_only, limit):\n    filter_params = {\n        \"project_id\": project_id,\n        \"filter\": {\"started_at\": start_time, \"trace_roots_only\": trace_roots_only},\n        \"expand_columns\": [\"inputs.example\", \"inputs.model\"],\n        \"sort_by\": [{\"field\": \"started_at\", \"direction\": \"desc\"}],\n        \"include_costs\": True,\n        \"include_feedback\": True,\n    }\n    try:\n        calls_stream = client.server.calls_query_stream(filter_params)\n        calls = list(\n            itertools.islice(calls_stream, limit)\n        )  # limit the number of calls to fetch if too many\n        print(f\"Fetched {len(calls)} calls.\")\n    except Exception as e:\n        print(f\"Error fetching calls: {e}\")\n        return []\n    else:\n        return calls\n\n\ncalls = fetch_calls(client, PROJECT_NAME, datetime.now() - timedelta(days=1), True, 100)\n```\n\n\n```python\n# the raw data is a list of Call objects\npd.DataFrame([call.dict() for call in calls]).head(3)\n```\n\nProcessing the calls is very easy with the return from Weave - we'll extract the relevant information and store it in a list of dictionaries. We'll then convert the list of dictionaries to a pandas DataFrame and return it.\n\n\n\n```python\nimport json\nfrom datetime import datetime\n\nimport pandas as pd\n\n\ndef process_calls(calls):\n    records = []\n    for call in calls:\n        feedback = call.summary.get(\"weave\", {}).get(\"feedback\", [])\n        thumbs_up = sum(\n            1\n            for item in feedback\n            if isinstance(item, dict) and item.get(\"payload\", {}).get(\"emoji\") == \"\ud83d\udc4d\"\n        )\n        thumbs_down = sum(\n            1\n            for item in feedback\n            if isinstance(item, dict) and item.get(\"payload\", {}).get(\"emoji\") == \"\ud83d\udc4e\"\n        )\n        latency = call.summary.get(\"weave\", {}).get(\"latency_ms\", 0)\n\n        records.append(\n            {\n                \"Call ID\": call.id,\n                \"Trace ID\": call.trace_id,  # this is a unique ID for the trace that can be used to retrieve it\n                \"Display Name\": call.display_name,  # this is an optional name you can set in the UI or programatically\n                \"Latency (ms)\": latency,\n                \"Thumbs Up\": thumbs_up,\n                \"Thumbs Down\": thumbs_down,\n                \"Started At\": pd.to_datetime(getattr(call, \"started_at\", datetime.min)),\n                \"Inputs\": json.dumps(call.inputs, default=str),\n                \"Outputs\": json.dumps(call.output, default=str),\n            }\n        )\n    return pd.DataFrame(records)\n```\n\n\n```python\ndf_calls = process_calls(calls)\ndf_calls.head(3)\n```\n\n### 2.2.2 Using high-level APIs\n\nInstead of goin through every call Weave also provides high-level APIs to directly access model costs, feedback, and other metrics.\nFor example, for the cost, we'll use the `query_costs` API to fetch the costs of all used LLMs using in project:\n\n\n\n```python\n# Use cost API to get costs\ncosts = client.query_costs()\ndf_costs = pd.DataFrame([cost.dict() for cost in costs])\ndf_costs[\"total_cost\"] = (\n    df_costs[\"prompt_token_cost\"] + df_costs[\"completion_token_cost\"]\n)\n\n# only show the first row for every unqiue llm_id\ndf_costs\n```\n\n## 2.4 Gathering inputs and generating visualizations\n\nNext, we can generate the visualizations using plotly. This is the most basic dashboard, but you can customize it as you like! For a more complex example, check out a Streamlit example [here](https://github.com/NiWaRe/knowledge-worker-weave/blob/master/prod_dashboard.py).\n\n\n\n```python\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n\ndef plot_feedback_pie_chart(thumbs_up, thumbs_down):\n    fig = go.Figure(\n        data=[\n            go.Pie(\n                labels=[\"Thumbs Up\", \"Thumbs Down\"],\n                values=[thumbs_up, thumbs_down],\n                marker={\"colors\": [\"#66b3ff\", \"#ff9999\"]},\n                hole=0.3,\n            )\n        ]\n    )\n    fig.update_traces(textinfo=\"percent+label\", hoverinfo=\"label+percent\")\n    fig.update_layout(showlegend=False, title=\"Feedback Summary\")\n    return fig\n\n\ndef plot_model_cost_distribution(df):\n    fig = px.bar(\n        df,\n        x=\"llm_id\",\n        y=\"total_cost\",\n        color=\"llm_id\",\n        title=\"Cost Distribution by Model\",\n    )\n    fig.update_layout(xaxis_title=\"Model\", yaxis_title=\"Cost (USD)\")\n    return fig\n\n\n# See the source code for all the plots\n```\n\n\n```python\nplot_feedback_pie_chart(df_calls[\"Thumbs Up\"].sum(), df_calls[\"Thumbs Down\"].sum())\n```\n\n\n```python\nplot_model_cost_distribution(df_costs)\n```\n\n# Conclusion\n\nIn this cookbook, we demonstrated how to create a custom production monitoring dashboard using Weave's APIs and functions. Weave currently focuses on fast integrations for easy input of data as well as extraction of the data for custom processes.\n\n- **Data Input:**\n  - Framework-agnostic tracing with [@weave-op()](https://weave-docs.wandb.ai/quickstart#2-log-a-trace-to-a-new-project) decorator and the possibility to import calls from CSV (see related [import cookbook](https://weave-docs.wandb.ai/reference/gen_notebooks/import_from_csv))\n  - Service API endpoints to log to Weave from for various programming frameworks and languages, see [here](https://weave-docs.wandb.ai/reference/service-api/call-start-call-start-post) for more details.\n- **Data Output:**\n  - Easy download of the data in CSV, TSV, JSONL, JSON formats - see [here](https://weave-docs.wandb.ai/guides/tracking/tracing#querying--exporting-calls) for more details.\n  - Easy export using programmatic access to the data - see \"Use Python\" section in the export panel as described in this cookbook. See [here](https://weave-docs.wandb.ai/guides/tracking/tracing#querying--exporting-calls) for more details.\n\nThis custom dashboard extends Weave's native Traces view, allowing for tailored monitoring of LLM applications in production. If you're interested in viewing a more complex dashboard, check out a Streamlit example where you can add your own Weave project URL [in this repo](https://github.com/NiWaRe/agent-dev-collection)."
  },
  {
    "title": "Using HuggingFace Datasets in evaluations with `preprocess_model_input`",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/hf_dataset_evals",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n\n# Using HuggingFace Datasets in evaluations with `preprocess_model_input`\n\n## Note: This is a temporary workaround\n> This guide demonstrates a workaround for using HuggingFace Datasets with Weave evaluations.\nWe are actively working on developing more seamless integrations that will simplify this process.\\\n> While this approach works, expect improvements and updates in the near future that will make working with external datasets more straightforward.\n\n## Setup and imports\nFirst, we initialize Weave and connect to Weights & Biases for tracking experiments.\n\n\n```python\n!pip install datasets wandb weave\n```\n\n\n```python\n# Initialize variables\nHUGGINGFACE_DATASET = \"wandb/ragbench-test-sample\"\nWANDB_KEY = \"\"\nWEAVE_TEAM = \"\"\nWEAVE_PROJECT = \"\"\n\n# Init weave and required libraries\nimport asyncio\n\nimport nest_asyncio\nimport wandb\nfrom datasets import load_dataset\n\nimport weave\nfrom weave import Evaluation\n\n# Login to wandb and initialize weave\nwandb.login(key=WANDB_KEY)\nclient = weave.init(f\"{WEAVE_TEAM}/{WEAVE_PROJECT}\")\n\n# Apply nest_asyncio to allow nested event loops (needed for some notebook environments)\nnest_asyncio.apply()\n```\n\n## Load and prepare HuggingFace dataset\n\n- We load a HuggingFace dataset.\n- Create an index mapping to reference the dataset rows.\n- This index approach allows us to maintain references to the original dataset.\n\n> **Note:**\nIn the index, we encode the `hf_hub_name` along with the `hf_id` to ensure each row has a unique identifier.\\\nThis unique digest value is used for tracking and referencing specific dataset entries during evaluations.\n\n\n```python\n# Load the HuggingFace dataset\nds = load_dataset(HUGGINGFACE_DATASET)\nrow_count = ds[\"train\"].num_rows\n\n# Create an index mapping for the dataset\n# This creates a list of dictionaries with HF dataset indices\n# Example: [{\"hf_id\": 0}, {\"hf_id\": 1}, {\"hf_id\": 2}, ...]\nhf_index = [{\"hf_id\": i, \"hf_hub_name\": HUGGINGFACE_DATASET} for i in range(row_count)]\n```\n\n## Define processing and evaluation functions\n\n### Processing pipeline\n- `preprocess_example`: Transforms the index reference into the actual data needed for evaluation\n- `hf_eval`: Defines how to score the model outputs\n- `function_to_evaluate`: The actual function/model being evaluated\n\n\n```python\n@weave.op()\ndef preprocess_example(example):\n    \"\"\"\n    Preprocesses each example before evaluation.\n    Args:\n        example: Dict containing hf_id\n    Returns:\n        Dict containing the prompt from the HF dataset\n    \"\"\"\n    hf_row = ds[\"train\"][example[\"hf_id\"]]\n    return {\"prompt\": hf_row[\"question\"], \"answer\": hf_row[\"response\"]}\n\n\n@weave.op()\ndef hf_eval(hf_id: int, output: dict) -> dict:\n    \"\"\"\n    Scoring function for evaluating model outputs.\n    Args:\n        hf_id: Index in the HF dataset\n        output: The output from the model to evaluate\n    Returns:\n        Dict containing evaluation scores\n    \"\"\"\n    hf_row = ds[\"train\"][hf_id]\n    return {\"scorer_value\": True}\n\n\n@weave.op()\ndef function_to_evaluate(prompt: str):\n    \"\"\"\n    The function that will be evaluated (e.g., your model or pipeline).\n    Args:\n        prompt: Input prompt from the dataset\n    Returns:\n        Dict containing model output\n    \"\"\"\n    return {\"generated_text\": \"testing \"}\n```\n\n### Create and run evaluation\n\n- For each index in hf_index:\n  1. `preprocess_example` gets the corresponding data from the HF dataset.\n  2. The preprocessed data is passed to `function_to_evaluate`.\n  3. The output is scored using `hf_eval`.\n  4. Results are tracked in Weave.\n\n\n```python\n# Create evaluation object\nevaluation = Evaluation(\n    dataset=hf_index,  # Use our index mapping\n    scorers=[hf_eval],  # List of scoring functions\n    preprocess_model_input=preprocess_example,  # Function to prepare inputs\n)\n\n\n# Run evaluation asynchronously\nasync def main():\n    await evaluation.evaluate(function_to_evaluate)\n\n\nasyncio.run(main())\n```"
  },
  {
    "title": "Log Calls from Existing CSV",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/import_from_csv",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n\n\n\n# Import Traces from 3rd Party Systems\n\nIn ocassion, it is not possible to instrument your Python or Javascript code with Weave's simple integration to obtain real-time traces of your GenAI application. It is often the case that these traces are later on available to you in `csv` or `json` format.\n\nIn this cookbook we explore the lower level Weave Python API to extract data from a CSV file and import it into Weave to drive insights and rigorous evaluations.\n\nThe sample dataset assumed in this cookbook has the following structure:\n\n```\nconversation_id,turn_index,start_time,user_input,ground_truth,answer_text\n1234,1,2024-09-04 13:05:39,This is the beginning, ['This was the beginning'], That was the beginning\n1235,1,2024-09-04 13:02:11,This is another trace,, That was another trace\n1235,2,2024-09-04 13:04:19,This is the next turn,, That was the next turn\n1236,1,2024-09-04 13:02:10,This is a 3 turn conversation,, Woah thats a lot of turns\n1236,2,2024-09-04 13:02:30,This is the second turn, ['That was definitely the second turn'], You are correct\n1236,3,2024-09-04 13:02:53,This is the end,, Well good riddance!\n\n```\n\nTo understand the decisions for import in this cookbook, one should know that Weave traces have parent-child relationships that are 1:Many and continuous. Meaning a single parent may have multiple children, but that parent may itself be a children of another parent.\n\nWe therefore use `conversation_id` as the parent identifier, and the `turn_index` as the child identifier to provide us complete conversation logging.\n\n\nEnsure to modify the variables as needed.\n\n# Set up the environment\n\nWe install and import all needed packages.\nWe set `WANDB_API_KEY` in our env so that we may easily login with `wandb.login()` (this should be given to the colab as a secret).\n\nWe set the name of the file we upload to colab in `name_of_file` and set the project in W&B we want to log this into in `name_of_wandb_project`.\n\n**_NOTE:_** `name_of_wandb_project` may also be in the format of `{team_name}/{project_name}` to specify a team to log the traces into.\n\nWe then fetch a weave client by calling `weave.init()`\n\n\n```python\n%pip install wandb weave pandas datetime --quiet\n```\n\n\n```python\nimport os\n\nimport pandas as pd\nimport wandb\nfrom google.colab import userdata\n\nimport weave\n\n## Write samples file to disk\nwith open(\"/content/import_cookbook_data.csv\", \"w\") as f:\n    f.write(\n        \"conversation_id,turn_index,start_time,user_input,ground_truth,answer_text\\n\"\n    )\n    f.write(\n        '1234,1,2024-09-04 13:05:39,This is the beginning, [\"This was the beginning\"], That was the beginning\\n'\n    )\n    f.write(\n        \"1235,1,2024-09-04 13:02:11,This is another trace,, That was another trace\\n\"\n    )\n    f.write(\n        \"1235,2,2024-09-04 13:04:19,This is the next turn,, That was the next turn\\n\"\n    )\n    f.write(\n        \"1236,1,2024-09-04 13:02:10,This is a 3 turn conversation,, Woah thats a lot of turns\\n\"\n    )\n    f.write(\n        '1236,2,2024-09-04 13:02:30,This is the second turn, [\"That was definitely the second turn\"], You are correct\\n'\n    )\n    f.write(\"1236,3,2024-09-04 13:02:53,This is the end,, Well good riddance!\\n\")\n\n\nos.environ[\"WANDB_API_KEY\"] = userdata.get(\"WANDB_API_KEY\")\nname_of_file = \"/content/import_cookbook_data.csv\"\nname_of_wandb_project = \"import-weave-traces-cookbook\"\n\nwandb.login()\n```\n\n\n```python\nweave_client = weave.init(name_of_wandb_project)\n```\n\n# Data Loading\n\nWe load the data into a Pandas dataframe, and ensure we sort it by the `conversation_id` and `turn_index` to ensure the parents and childs are correctly ordered.\n\nThis will result in a two column pandas DF with our conversation turns as an array under `conversation_data`.\n\n\n```python\n## Load data and shape it\ndf = pd.read_csv(name_of_file)\n\nsorted_df = df.sort_values([\"conversation_id\", \"turn_index\"])\n\n\n# Function to create an array of dictionaries for each conversation\ndef create_conversation_dict_array(group):\n    return group.drop(\"conversation_id\", axis=1).to_dict(\"records\")\n\n\n# Group the dataframe by conversation_id and apply the aggregation\nresult_df = (\n    sorted_df.groupby(\"conversation_id\")\n    .apply(create_conversation_dict_array)\n    .reset_index()\n)\nresult_df.columns = [\"conversation_id\", \"conversation_data\"]\n\n# Show how our aggregation looks\nresult_df.head()\n```\n\n# Log the Traces to Weave\n\nWe now iterate through our pandas DF:\n- We create a parent call for every `conversation_id`\n- We iterate through the turn array to create child calls sorted by their `turn_index`\n\nImportant concepts of the lower level python API:\n- A Weave call is equivalent to a Weave trace, this call may have a parent or children associated with it\n- A Weave call may have other things associated with it: Feedback, Metadata, etc. We only associate inputs and outputs to it here, but you may want to add these things in your import if the data provides it.\n- A weave call is `created` and `finished` as these are meant to be tracked real time. Because this is an after-the-fact import, we create and finish once our objects are defined and tied to one another.\n- The `op` value of a call is how Weave categorizes calls of the same make up. In this example, all parent calls are of `Conversation` type, and all children calls are of `Turn` type. You may modify this as you see fit.\n- A call may have `inputs` and `output`. `inputs` are defined at creation an `output` is defined when the call is finished.\n\n\n```python\n# Log traces to weave\n\n# Iterate through our aggregated conversations\nfor _, row in result_df.iterrows():\n    # Define our conversation parent,\n    # we are now creating a \"call\" with the weave_client we defined before\n    parent_call = weave_client.create_call(\n        # The Op value will register this as a Weave Op, which will allow us to retrieve these as a group easily in the future\n        op=\"Conversation\",\n        # We set the inputs of our high level conversation as all the turns under it\n        inputs={\n            \"conversation_data\": row[\"conversation_data\"][:-1]\n            if len(row[\"conversation_data\"]) > 1\n            else row[\"conversation_data\"]\n        },\n        # Our Conversation parent does not have a further parent\n        parent=None,\n        # The name of how this specific conversation will appear in the UI\n        display_name=f\"conversation-{row['conversation_id']}\",\n    )\n\n    # We set the output of the parent to be the last trace in the conversation\n    parent_output = row[\"conversation_data\"][len(row[\"conversation_data\"]) - 1]\n\n    # We now iterate through all the conversation turns for the parent\n    # and log them as children of the conversation\n    for item in row[\"conversation_data\"]:\n        item_id = f\"{row['conversation_id']}-{item['turn_index']}\"\n\n        # We create a call again here to be categorized under the conversation\n        call = weave_client.create_call(\n            # We qualify a single conversation trace as a \"Turn\"\n            op=\"Turn\",\n            # We provide all inputs of the turn, including RAG 'ground_truth'\n            inputs={\n                \"turn_index\": item[\"turn_index\"],\n                \"start_time\": item[\"start_time\"],\n                \"user_input\": item[\"user_input\"],\n                \"ground_truth\": item[\"ground_truth\"],\n            },\n            # We set this to be a child of the parent we defined\n            parent=parent_call,\n            # We provide it a name to be id'ed by in Weave\n            display_name=item_id,\n        )\n\n        # We set the output of the call as the answer\n        output = {\n            \"answer_text\": item[\"answer_text\"],\n        }\n\n        # Because these are traces that already happened, we finish the single turn call\n        weave_client.finish_call(call=call, output=output)\n    # Now that we have logged all its children, we also finish the parent call\n    weave_client.finish_call(call=parent_call, output=parent_output)\n```\n\n# Result: Traces are Logged to Weave\n\nTraces:\n\n\n\n\nOperations:\n\n\n\n# Bonus: Export your traces to run rigorous evaluations!\n\nOnce our traces are in Weave and we have an understanding on how the conversations are looking, we may want to later on export them to another process to run Weave Evaluations\n\n\n\nTo do this, we fetch all conversations from W&B through our simple query API and create a dataset from it.\n\n\n```python\n## This cell does not run by default, comment the below line to execute this script\n%%script false --no-raise-error\n## Get all Conversation traces for evaluation and prepare dataset for eval\n\n# We create a query filter that brings us all our Conversation objects\n# The ref shown below is specific to your project, and you can obtain it by\n# going into your project's Operations in the UI, clicking on the \"Conversations\"\n# object, then the \"Use\" tab in the side panel.\nweave_ref_for_conversation_op = \"weave:///wandb-smle/import-weave-traces-cookbook/op/Conversation:tzUhDyzVm5bqQsuqh5RT4axEXSosyLIYZn9zbRyenaw\"\nfilter = weave.trace_server.trace_server_interface.CallsFilter(\n    op_names=[weave_ref_for_conversation_op],\n  )\n\n# We execute the query\nconversation_traces = weave_client.get_calls(filter=filter)\n\nrows = []\n\n# We go through our conversation traces and construct dataset rows from it\nfor single_conv in conversation_traces:\n  # In this example, we may only care for conversations that utilized our RAG\n  # pipeline, so we filter for such types of conversations\n  is_rag = False\n  for single_trace in single_conv.inputs['conversation_data']:\n    if single_trace['ground_truth'] is not None:\n      is_rag = True\n      break\n  if single_conv.output['ground_truth'] is not None:\n      is_rag = True\n\n  # Once we've identified a converation to have used RAG, we add it to our dataset\n  if is_rag:\n    inputs = []\n    ground_truths = []\n    answers = []\n\n    # We go through every turn in the conversation\n    for turn in single_conv.inputs['conversation_data']:\n      inputs.append(turn.get('user_input', ''))\n      ground_truths.append(turn.get('ground_truth', ''))\n      answers.append(turn.get('answer_text', ''))\n    ## Account for when conversations are a single turn\n    if len(single_conv.inputs) != 1 or single_conv.inputs['conversation_data'][0].get('turn_index') != single_conv.output.get('turn_index'):\n      inputs.append(single_conv.output.get('user_input', ''))\n      ground_truths.append(single_conv.output.get('ground_truth', ''))\n      answers.append(single_conv.output.get('answer_text', ''))\n\n    data = {\n        'question': inputs,\n        'contexts': ground_truths,\n        'answer': answers\n    }\n\n    rows.append(data)\n\n# With our dataset rows created, we create the Dataset object and\n# publish it back to Weave for later retrieval\ndset = weave.Dataset(name = \"conv_traces_for_eval\", rows=rows)\nweave.publish(dset)\n```\n\n# Result\n\n\n\nTo learn more about evaluations, check out our [Quickstart](https://weave-docs.wandb.ai/tutorial-rag) on using your newly created dataset to evaluate your RAG application!"
  },
  {
    "title": "Structured Outputs for Multi-Agent Systems",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/multi-agent-structured-output",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook] Open in Colab View in Github ::: # Structured Outputs for Multi-Agent Systems OpenAI relased [Structured Outputs](https://openai.com/index/introducing-structured-outputs-in-the-api/) to enable users to ensure the model will always generate responses that adhere to your supplied JSON Schema without strongly worded prompts. With Structured Outputs, we don't need to validate or retry incorrectly formatted responses. By using the new parameter `strict: true`, we are able to guarantee the response abides by a provided schema. The use of structured outputs in a multi-agent system enhances communication by ensuring consistent, easily processed data between agents. It also improves safety by allowing explicit refusals and boosts performance by eliminating the need for retries or validations. This simplifies interactions and increases overall system efficiency. This tutorial demonstrates how we can utilize structured outputs in multi-agent system and trace them with [Weave](https://weave-docs.wandb.ai/). :::tip [Source](https://cookbook.openai.com/examples/structured_outputs_multi_agent) This cookbook is based on [sample code from OpenAI's structured outputs](https://cookbook.openai.com/examples/structured_outputs_multi_agent), with some modifications added for improved visualization using Weave. ::: ## Installing the Dependencies We need the following libraries for this tutorial: - [OpenAI](https://openai.com/index/openai-api/) to create multi-agent system. - [Weave](../../introduction.md) to track our LLM workflow and evaluate our prompting strategies. ```python !pip install -qU openai weave wandb ``` ```python %%capture # Temporary workaround to fix bug in openai: # TypeError: Client.__init__() got an unexpected keyword argument 'proxies' # See https://community.openai.com/t/error-with-openai-1-56-0-client-init-got-an-unexpected-keyword-argument-proxies/1040332/15 !pip install \"httpx<0.28\" ``` We set `WANDB_API_KEY` in our env so that we may easily login with wandb.login() (this should be given to the colab as a secret). We set the project in W&B we want to log this into in `name_of_wandb_project`. **NOTE**: `name_of_wandb_project` may also be in the format of `{team_name}/{project_name}` to specify a team to log the traces into. We then fetch a weave client by calling weave.init() Since we'll be using [OpenAI API](https://openai.com/index/openai-api/), we will also need an OpenAI API key. You can [sign up](https://platform.openai.com/signup) on the OpenAI platform to get your own API key. (this should be given to the colab as a secret too.) ```python import base64 import json import os from io import BytesIO, StringIO import matplotlib.pyplot as plt import numpy as np import pandas as pd import wandb from google.colab import userdata from openai import OpenAI import weave ``` ```python os.environ[\"WANDB_API_KEY\"] = userdata.get(\"WANDB_API_KEY\") os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\") wandb.login() name_of_wandb_project = \"multi-agent-structured-output\" weave.init(name_of_wandb_project) client = OpenAI() MODEL = \"gpt-4o-2024-08-06\" ``` ## Agents set up The use case we will tackle is a data analysis task. Let's first set up our 4-agents system: * Triaging agent: Decides which agent(s) to call * Data pre-processing Agent: Prepares data for analysis - for example by cleaning it up * Data Analysis Agent: Performs analysis on the data * Data Visualization Agent: Visualizes the output of the analysis to extract insights We will start by defining the system prompts for each of these agents. ```python triaging_system_prompt = \"\"\"You are a Triaging Agent. Your role is to assess the user's query and route it to the relevant agents. The agents available are: - Data Processing Agent: Cleans, transforms, and aggregates data. - Analysis Agent: Performs statistical, correlation, and regression analysis. - Visualization Agent: Creates bar charts, line charts, and pie charts. Use the send_query_to_agents tool to forward the user's query to the relevant agents. Also, use the speak_to_user tool to get more information from the user if needed.\"\"\" processing_system_prompt = \"\"\"You are a Data Processing Agent. Your role is to clean, transform, and aggregate data using the following tools: - clean_data - transform_data - aggregate_data\"\"\" analysis_system_prompt = \"\"\"You are an Analysis Agent. Your role is to perform statistical, correlation, and regression analysis using the following tools: - stat_analysis - correlation_analysis - regression_analysis\"\"\" visualization_system_prompt = \"\"\"You are a Visualization Agent. Your role is to create bar charts, line charts, and pie charts using the following tools: - create_bar_chart - create_line_chart - create_pie_chart\"\"\" ``` We will then define the tools for each agent. Apart from the triaging agent, each agent will be equipped with tools specific to their role: **Data pre-processing agent** : 1. Clean data, 2. Transform data, 3. Aggregate data **Data analysis agent** : 1. Statistical analysis, 2. Correlation analysis, 3. Regression Analysis **Data visualization agent** : 1. Create bar chart, 2. Create line chart, 3. Create pie chart ```python triage_tools = [ { \"type\": \"function\", \"function\": { \"name\": \"send_query_to_agents\", \"description\": \"Sends the user query to relevant agents based on their capabilities.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"agents\": { \"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"An array of agent names to send the query to.\", }, \"query\": { \"type\": \"string\", \"description\": \"The user query to send.\", }, }, \"required\": [\"agents\", \"query\"], }, }, \"strict\": True, } ] preprocess_tools = [ { \"type\": \"function\", \"function\": { \"name\": \"clean_data\", \"description\": \"Cleans the provided data by removing duplicates and handling missing values.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"data\": { \"type\": \"string\", \"description\": \"The dataset to clean. Should be in a suitable format such as JSON or CSV.\", } }, \"required\": [\"data\"], \"additionalProperties\": False, }, }, \"strict\": True, }, { \"type\": \"function\", \"function\": { \"name\": \"transform_data\", \"description\": \"Transforms data based on specified rules.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"data\": { \"type\": \"string\", \"description\": \"The data to transform. Should be in a suitable format such as JSON or CSV.\", }, \"rules\": { \"type\": \"string\", \"description\": \"Transformation rules to apply, specified in a structured format.\", }, }, \"required\": [\"data\", \"rules\"], \"additionalProperties\": False, }, }, \"strict\": True, }, { \"type\": \"function\", \"function\": { \"name\": \"aggregate_data\", \"description\": \"Aggregates data by specified columns and operations.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"data\": { \"type\": \"string\", \"description\": \"The data to aggregate. Should be in a suitable format such as JSON or CSV.\", }, \"group_by\": { \"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"Columns to group by.\", }, \"operations\": { \"type\": \"string\", \"description\": \"Aggregation operations to perform, specified in a structured format.\", }, }, \"required\": [\"data\", \"group_by\", \"operations\"], \"additionalProperties\": False, }, }, \"strict\": True, }, ] analysis_tools = [ { \"type\": \"function\", \"function\": { \"name\": \"stat_analysis\", \"description\": \"Performs statistical analysis on the given dataset.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"data\": { \"type\": \"string\", \"description\": \"The dataset to analyze. Should be in a suitable format such as JSON or CSV.\", } }, \"required\": [\"data\"], \"additionalProperties\": False, }, }, \"strict\": True, }, { \"type\": \"function\", \"function\": { \"name\": \"correlation_analysis\", \"description\": \"Calculates correlation coefficients between variables in the dataset.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"data\": { \"type\": \"string\", \"description\": \"The dataset to analyze. Should be in a suitable format such as JSON or CSV.\", }, \"variables\": { \"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"List of variables to calculate correlations for.\", }, }, \"required\": [\"data\", \"variables\"], \"additionalProperties\": False, }, }, \"strict\": True, }, { \"type\": \"function\", \"function\": { \"name\": \"regression_analysis\", \"description\": \"Performs regression analysis on the dataset.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"data\": { \"type\": \"string\", \"description\": \"The dataset to analyze. Should be in a suitable format such as JSON or CSV.\", }, \"dependent_var\": { \"type\": \"string\", \"description\": \"The dependent variable for regression.\", }, \"independent_vars\": { \"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"List of independent variables.\", }, }, \"required\": [\"data\", \"dependent_var\", \"independent_vars\"], \"additionalProperties\": False, }, }, \"strict\": True, }, ] visualization_tools = [ { \"type\": \"function\", \"function\": { \"name\": \"create_bar_chart\", \"description\": \"Creates a bar chart from the provided data.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"data\": { \"type\": \"string\", \"description\": \"The data for the bar chart. Should be in a suitable format such as JSON or CSV.\", }, \"x\": {\"type\": \"string\", \"description\": \"Column for the x-axis.\"}, \"y\": {\"type\": \"string\", \"description\": \"Column for the y-axis.\"}, }, \"required\": [\"data\", \"x\", \"y\"], \"additionalProperties\": False, }, }, \"strict\": True, }, { \"type\": \"function\", \"function\": { \"name\": \"create_line_chart\", \"description\": \"Creates a line chart from the provided data.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"data\": { \"type\": \"string\", \"description\": \"The data for the line chart. Should be in a suitable format such as JSON or CSV.\", }, \"x\": {\"type\": \"string\", \"description\": \"Column for the x-axis.\"}, \"y\": {\"type\": \"string\", \"description\": \"Column for the y-axis.\"}, }, \"required\": [\"data\", \"x\", \"y\"], \"additionalProperties\": False, }, }, \"strict\": True, }, { \"type\": \"function\", \"function\": { \"name\": \"create_pie_chart\", \"description\": \"Creates a pie chart from the provided data.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"data\": { \"type\": \"string\", \"description\": \"The data for the pie chart. Should be in a suitable format such as JSON or CSV.\", }, \"labels\": { \"type\": \"string\", \"description\": \"Column for the labels.\", }, \"values\": { \"type\": \"string\", \"description\": \"Column for the values.\", }, }, \"required\": [\"data\", \"labels\", \"values\"], \"additionalProperties\": False, }, }, \"strict\": True, }, ] ``` ## Enable tracking of multi-agent using Weave We need to write the code logic to: * handle passing the user query to the multi-agent system * handle the internal workings of the multi-agent system * execute the tool calls ```python # Example query user_query = \"\"\" Below is some data. I want you to first remove the duplicates then analyze the statistics of the data as well as plot a line chart. house_size (m3), house_price ($) 90, 100 80, 90 100, 120 90, 100 \"\"\" ``` From the user query, we can infer that the tools we would need to call are `clean_data`, `start_analysis` and `use_line_chart`. We will begin by defining the execution function responsible for running tool calls. By decorating Python functions with `@weave.op()`, we can log and debug language model inputs, outputs, and traces. When creating a multi-agent system, many functions will appear, but it's sufficient to simply add `@weave.op()` on top of them. ```python @weave.op() def clean_data(data): data_io = StringIO(data) df = pd.read_csv(data_io, sep=\",\") df_deduplicated = df.drop_duplicates() return df_deduplicated @weave.op() def stat_analysis(data): data_io = StringIO(data) df = pd.read_csv(data_io, sep=\",\") return df.describe() @weave.op() def plot_line_chart(data): data_io = StringIO(data) df = pd.read_csv(data_io, sep=\",\") x = df.iloc[:, 0] y = df.iloc[:, 1] coefficients = np.polyfit(x, y, 1) polynomial = np.poly1d(coefficients) y_fit = polynomial(x) plt.figure(figsize=(10, 6)) plt.plot(x, y, \"o\", label=\"Data Points\") plt.plot(x, y_fit, \"-\", label=\"Best Fit Line\") plt.title(\"Line Chart with Best Fit Line\") plt.xlabel(df.columns[0]) plt.ylabel(df.columns[1]) plt.legend() plt.grid(True) # Save the plot to a BytesIO buffer before showing it buf = BytesIO() plt.savefig(buf, format=\"png\") buf.seek(0) # Display the plot plt.show() # Encode the image in base64 for the data URL image_data = buf.getvalue() base64_encoded_data = base64.b64encode(image_data) base64_string = base64_encoded_data.decode(\"utf-8\") data_url = f\"data:image/png;base64,{base64_string}\" return data_url # Define the function to execute the tools @weave.op() def execute_tool(tool_calls, messages): for tool_call in tool_calls: tool_name = tool_call.function.name tool_arguments = json.loads(tool_call.function.arguments) if tool_name == \"clean_data\": # Simulate data cleaning cleaned_df = clean_data(tool_arguments[\"data\"]) cleaned_data = {\"cleaned_data\": cleaned_df.to_dict()} messages.append( {\"role\": \"tool\", \"name\": tool_name, \"content\": json.dumps(cleaned_data)} ) print(\"Cleaned data: \", cleaned_df) elif tool_name == \"transform_data\": # Simulate data transformation transformed_data = {\"transformed_data\": \"sample_transformed_data\"} messages.append( { \"role\": \"tool\", \"name\": tool_name, \"content\": json.dumps(transformed_data), } ) elif tool_name == \"aggregate_data\": # Simulate data aggregation aggregated_data = {\"aggregated_data\": \"sample_aggregated_data\"} messages.append( { \"role\": \"tool\", \"name\": tool_name, \"content\": json.dumps(aggregated_data), } ) elif tool_name == \"stat_analysis\": # Simulate statistical analysis stats_df = stat_analysis(tool_arguments[\"data\"]) stats = {\"stats\": stats_df.to_dict()} messages.append( {\"role\": \"tool\", \"name\": tool_name, \"content\": json.dumps(stats)} ) print(\"Statistical Analysis: \", stats_df) elif tool_name == \"correlation_analysis\": # Simulate correlation analysis correlations = {\"correlations\": \"sample_correlations\"} messages.append( {\"role\": \"tool\", \"name\": tool_name, \"content\": json.dumps(correlations)} ) elif tool_name == \"regression_analysis\": # Simulate regression analysis regression_results = {\"regression_results\": \"sample_regression_results\"} messages.append( { \"role\": \"tool\", \"name\": tool_name, \"content\": json.dumps(regression_results), } ) elif tool_name == \"create_bar_chart\": # Simulate bar chart creation bar_chart = {\"bar_chart\": \"sample_bar_chart\"} messages.append( {\"role\": \"tool\", \"name\": tool_name, \"content\": json.dumps(bar_chart)} ) elif tool_name == \"create_line_chart\": # Simulate line chart creation line_chart = {\"line_chart\": plot_line_chart(tool_arguments[\"data\"])} messages.append( {\"role\": \"tool\", \"name\": tool_name, \"content\": json.dumps(line_chart)} ) elif tool_name == \"create_pie_chart\": # Simulate pie chart creation pie_chart = {\"pie_chart\": \"sample_pie_chart\"} messages.append( {\"role\": \"tool\", \"name\": tool_name, \"content\": json.dumps(pie_chart)} ) return messages ``` Next, we will create the tool handlers for each of the sub-agents. These have a unique prompt and tool set passed to the model. The output is then passed to an execution function which runs the tool calls. ```python # Define the functions to handle each agent's processing @weave.op() def handle_data_processing_agent(query, conversation_messages): messages = [{\"role\": \"system\", \"content\": processing_system_prompt}] messages.append({\"role\": \"user\", \"content\": query}) response = client.chat.completions.create( model=MODEL, messages=messages, temperature=0, tools=preprocess_tools, ) conversation_messages.append( [tool_call.function for tool_call in response.choices[0].message.tool_calls] ) execute_tool(response.choices[0].message.tool_calls, conversation_messages) @weave.op() def\n\n> Content truncated."
  },
  {
    "title": "Ocr Pipeline",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/ocr-pipeline",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": "# Trace and Evaluate a Computer Vision Pipeline\n\n:::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\nIn this guide, you will learn how to use Weights & Biases (W&B) Weave to track and evaluate a computer vision pipeline that uses vision language model (VLMs) to perform optical character recognition (OCR) for a named entity recognition (NER) applications.\nSpecifically, OpenAI's GPT-4.1's vision capabilities are used to extract named entities from handwritten notes.\n\nThis guide demonstrates how to:\n\n1. Track different versions of a system prompts using Weave\n2. Get an image dataset from Weave\n3. Create a NER pipeline\n4. Set up Weave [Scorers](https://weave-docs.wandb.ai/guides/evaluation/scorers) to peform a [Weave Evaluation](https://weave-docs.wandb.ai/guides/core-types/evaluations) on the pipeline\n5. Run an evaluation against our dataset of handwritten notes\n\n##  Prerequisites\n\nBefore you begin, install and import the required libraries, get your W&B API key, and initialize your Weave project.\n\n\n```python\n# Install the required dependencies\n!pip install openai weave -q\n```\n\n\n```python\nimport json\nimport os\n\nfrom google.colab import userdata\nfrom openai import OpenAI\n\nimport weave\n```\n\n\n```python\n# Get API Keys\nos.environ[\"OPENAI_API_KEY\"] = userdata.get(\n    \"OPENAI_API_KEY\"\n)  # please set the keys as collab environment secrets from the menu on the left\nos.environ[\"WANDB_API_KEY\"] = userdata.get(\"WANDB_API_KEY\")\n\n# Set project name\n# Replace the PROJECT value with your project name\nPROJECT = \"vlm-handwritten-ner\"\n\n# Initiatlize the Weave project\nweave.init(PROJECT)\n```\n\n## 1. Create and iterate on prompts with Weave\n\nGood prompt engineering is critical to guiding the model to properly extract entities. First, you'll create basic prompt that gives the model the instructions on what to extract from our image data and how to format it. Then, you'll store the promp in Weave for tracking and iteration.\n\n\n```python\n# Create your prompt object with Weave\nprompt = \"\"\"\nExtract all readable text from this image. Format the extracted entities as a valid JSON.\nDo not return any extra text, just the JSON. Do not include ```json```\nUse the following format:\n{\"Patient Name\": \"James James\",\"Date\": \"4/22/2025\",\"Patient ID\": \"ZZZZZZZ123\",\"Group Number\": \"3452542525\"}\n\"\"\"\nsystem_prompt = weave.StringPrompt(prompt)\n# Publish your prompt to Weave\nweave.publish(system_prompt, name=\"NER-prompt\")\n```\n\nNext, improve the prompt by adding more instructions and validation rules to help reduce errors in the output.\n\n\n```python\nbetter_prompt = \"\"\"\nYou are a precision OCR assistant. Given an image of patient information, extract exactly these fields into a single JSON object\u2014and nothing else:\n\n- Patient Name\n- Date (MM/DD/YYYY)\n- Patient ID\n- Group Number\n\nValidation rules:\n1. Date must match MM/DD/YY; if not, set Date to \"\".\n2. Patient ID must be alphanumeric; if unreadable, set to \"\".\n3. Always zero-pad months and days (e.g. \"04/07/25\").\n4. Omit any markup, commentary, or code fences.\n5. Return strictly valid JSON with only those four keys.\n\nDo not return any extra text, just the JSON. Do not include ```json```\nExample output:\n{\"Patient Name\":\"James James\",\"Date\":\"04/22/25\",\"Patient ID\":\"ZZZZZZZ123\",\"Group Number\":\"3452542525\"}\n\"\"\"\n# Edit the prompt\nsystem_prompt = weave.StringPrompt(better_prompt)\n# Publish the edited prompt to Weave\nweave.publish(system_prompt, name=\"NER-prompt\")\n```\n\n## 2. Get the dataset\n\nNext, retrieve the dataset of handwritten notes to serve as input for the OCR pipeline. \n\nThe images in the dataset are already `base64` encoded, which means the data can be used by the LLM without any pre-processing.\n\n\n\n```python\n# Retrieve the dataset from the following Weave project\ndataset = weave.ref(\n    \"weave:///wandb-smle/vlm-handwritten-ner/object/NER-eval-dataset:G8MEkqWBtvIxPYAY23sXLvqp8JKZ37Cj0PgcG19dGjw\"\n).get()\n\n# Access a specific example in the dataset\nexample_image = dataset.rows[3][\"image_base64\"]\n\n# Display the example_image\nfrom IPython.display import HTML, display\n\nhtml = f''\ndisplay(HTML(html))\n```\n\n## 3. Build the NER pipeline\n\nNext, build the NER pipeline. The pipeline will consist of two functions:\n\n1. An `encode_image` function that takes a PIL image from the dataset and returns a `base64` encoded string representation of the image that can be passed to the VLM\n2. An `extract_named_entities_from_image` function that takes an image and system prompt and returns the extracted entities from that image as described by the system prompt\n\n\n```python\n# Traceable function using GPT-4-Vision\ndef extract_named_entities_from_image(image_base64) -> dict:\n    # init LLM Client\n    client = OpenAI()\n\n    # Setup the instruction prompt\n    # You can optionally use a prompt stored in Weave withweave.ref(\"weave:///wandb-smle/vlm-handwritten-ner/object/NER-prompt:FmCv4xS3RFU21wmNHsIYUFal3cxjtAkegz2ylM25iB8\").get().content.strip()\n    prompt = better_prompt\n\n    response = client.responses.create(\n        model=\"gpt-4.1\",\n        input=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"input_text\", \"text\": prompt},\n                    {\n                        \"type\": \"input_image\",\n                        \"image_url\": image_base64,\n                    },\n                ],\n            }\n        ],\n    )\n\n    return response.output_text\n```\n\nNow, create a function called `named_entity_recognation` that:\n- Passes the image data to the NER pipeline\n- Returns correctly formatted JSON with the results\n\nUse the [`@weave.op()` decorator](https://weave-docs.wandb.ai/reference/python-sdk/weave/trace/weave.trace.op) decorator to automatically track and trace function execution in the W&B UI. \n\nEvery `named_entity_recognation` is run, the full trace results are visible in the Weave UI. To view the traces, navigate to the **Traces** tab of your Weave project. \n\n\n```python\n# NER Function for evaluations\n@weave.op()\ndef named_entity_recognation(image_base64, id):\n    result = {}\n    try:\n        # 1) call the vision op, get back a JSON string\n        output_text = extract_named_entities_from_image(image_base64)\n\n        # 2) parse JSON exactly once\n        result = json.loads(output_text)\n\n        print(f\"Processed: {str(id)}\")\n    except Exception as e:\n        print(f\"Failed to process {str(id)}: {e}\")\n    return result\n```\n\nFinally, run the pipeline over the dataset, and view the results.\n\nThe following code loops over the dataset and stores the results in a local file `processing_results.json`. The results are also viewable in the Weave UI.\n\n\n```python\n# Output results\nresults = []\n\n# loop over all images in the dataset\nfor row in dataset.rows:\n    result = named_entity_recognation(row[\"image_base64\"], str(row[\"id\"]))\n    result[\"image_id\"] = str(row[\"id\"])\n    results.append(result)\n\n# Save all results to a JSON file\noutput_file = \"processing_results.json\"\nwith open(output_file, \"w\") as f:\n    json.dump(results, f, indent=2)\n\nprint(f\"Results saved to: {output_file}\")\n```\n\nYou will see something similar to the following in the **Traces** table in the Weave UI.\n\n\n\n## 4. Evaluate the pipeline using Weave\n\nNow that you have created a pipeline to perform NER using a VLM, you can use Weave to systematically evaluate it and find out how well it performs. You can learn more about Evaluations in Weave in [Evaluations Overview](https://weave-docs.wandb.ai/guides/core-types/evaluations). \n\nA fundamental part of a Weave Evaluation are [Scorers](https://weave-docs.wandb.ai/guides/evaluation/scorers). Scorers are used to evaluate AI outputs and return evaluation metrics. They take the AI's output, analyze it, and return a dictionary of results. Scorers can use your input data as reference if needed and can also output extra information, such as explanations or reasonings from the evaluation.\n\nIn this section, you will create two Scorers to evaluate the pipeline:\n1. Programatic Scorer \n2. LLM-as-a-judge Scorer\n\n\n\n### Programatic scorer\n\nThe programmatic scorer, `check_for_missing_fields_programatically`, will take the model output (the output of the `named_entity_recognition` function), and identify which `keys` are missing or empty in the results.\n\nThis check is great for identifying samples where the model missed capturing any fields.\n\n\n```python\n# Add weave.op() to track execution of the scorer\n@weave.op()\ndef check_for_missing_fields_programatically(model_output):\n    # Required keys for every entry\n    required_fields = {\"Patient Name\", \"Date\", \"Patient ID\", \"Group Number\"}\n\n    for key in required_fields:\n        if (\n            key not in model_output\n            or model_output[key] is None\n            or str(model_output[key]).strip() == \"\"\n        ):\n            return False  # This entry has a missing or empty field\n\n    return True  # All required fields are present and non-empty\n```\n\n### LLM-as-a-judge scorer\n\nIn the next step of the evaluation, both the image data and the model's output are provided to ensure the assessment reflects actual NER performance. The image content is explicitly referenced, not just the model output.\n\nThe Scorer used for this step, `check_for_missing_fields_with_llm`, use an LLM to perform scoring (specifically OpenAI's `gpt-4o`). As specified by the contents of the `eval_prompt`, `check_for_missing_fields_with_llm` outputs a `Boolean` value. If all fields match the information in the image and formatting is correct, the Scorer returns `true`. If any field is missing, empty, incorrect, or mismatched, the result is `false`, and the scorer also returns a message explaining the problem.\n\n\n```python\n# The system prompt for the LLM-as-a-judge\n\neval_prompt = \"\"\"\nYou are an OCR validation system. Your role is to assess whether the structured text extracted from an image accurately reflects the information in that image.\nOnly validate the structured text and use the image as your source of truth.\n\nExpected input text format:\n{\"Patient Name\": \"First Last\", \"Date\": \"04/23/25\", \"Patient ID\": \"131313JJH\", \"Group Number\": \"35453453\"}\n\nEvaluation criteria:\n- All four fields must be present.\n- No field should be empty or contain placeholder/malformed values.\n- The \"Date\" should be in MM/DD/YY format (e.g., \"04/07/25\") (zero padding the date is allowed)\n\nScoring:\n- Return: {\"Correct\": true, \"Reason\": \"\"} if **all fields** match the information in the image and formatting is correct.\n- Return: {\"Correct\": false, \"Reason\": \"EXPLANATION\"} if **any** field is missing, empty, incorrect, or mismatched.\n\nOutput requirements:\n- Respond with a valid JSON object only.\n- \"Correct\" must be a JSON boolean: true or false (not a string or number).\n- \"Reason\" must be a short, specific string indicating all the problem \u2014 e.g., \"Patient Name mismatch\", \"Date not zero-padded\", or \"Missing Group Number\".\n- Do not return any additional explanation or formatting.\n\nYour response must be exactly one of the following:\n{\"Correct\": true, \"Reason\": null}\nOR\n{\"Correct\": false, \"Reason\": \"EXPLANATION_HERE\"}\n\"\"\"\n\n\n# Add weave.op() to track execution of the Scorer\n@weave.op()\ndef check_for_missing_fields_with_llm(model_output, image_base64):\n    client = OpenAI()\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"developer\", \"content\": [{\"text\": eval_prompt, \"type\": \"text\"}]},\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\n                            \"url\": image_base64,\n                        },\n                    },\n                    {\"type\": \"text\", \"text\": str(model_output)},\n                ],\n            },\n        ],\n        response_format={\"type\": \"json_object\"},\n    )\n    response = json.loads(response.choices[0].message.content)\n    return response\n```\n\n## 5. Run the Evaluation\n\nFinally, define an evaluation call that will automatically loop over the `dataset` passed and log the results together in the Weave UI.\n\nThe following code kicks off the evaluation and applies the two Scorers to every output from the NER pipeline. Results are visible in the **Evals** tab in the Weave UI.\n\n\n```python\nevaluation = weave.Evaluation(\n    dataset=dataset,\n    scorers=[\n        check_for_missing_fields_with_llm,\n        check_for_missing_fields_programatically,\n    ],\n    name=\"Evaluate_4.1_NER\",\n)\n\nprint(await evaluation.evaluate(named_entity_recognation))\n```\n\nWhen the above code is run, a link to the Evaluation table in the Weave UI is generated. Follow the link to view the results and compare different iterations of the pipeline across models, prompts, and datasets of your choice. The Weave UI automatically creates a visualization like the one shown below for your team."
  },
  {
    "title": "Chain of Density Summarization",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/chain_of_density",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n\n\n\n# Summarization using Chain of Density\n\nSummarizing complex technical documents while preserving crucial details is a challenging task. The Chain of Density (CoD) summarization technique offers a solution by iteratively refining summaries to be more concise and information-dense. This guide demonstrates how to implement CoD using Weave for tracking and evaluating the application. \n\n\n\n## What is Chain of Density Summarization?\n\n[](https://arxiv.org/abs/2309.04269)\n\nChain of Density (CoD) is an iterative summarization technique that produces increasingly concise and information-dense summaries. It works by:\n\n1. Starting with an initial summary\n2. Iteratively refining the summary, making it more concise while preserving key information\n3. Increasing the density of entities and technical details with each iteration\n\nThis approach is particularly useful for summarizing scientific papers or technical documents where preserving detailed information is crucial.\n\n## Why use Weave?\n\nIn this tutorial, we'll use Weave to implement and evaluate a Chain of Density summarization pipeline for ArXiv papers. You'll learn how to:\n\n1. **Track your LLM pipeline**: Use Weave to automatically log inputs, outputs, and intermediate steps of your summarization process.\n2. **Evaluate LLM outputs**: Create rigorous, apples-to-apples evaluations of your summaries using Weave's built-in tools.\n3. **Build composable operations**: Combine and reuse Weave operations across different parts of your summarization pipeline.\n4. **Integrate seamlessly**: Add Weave to your existing Python code with minimal overhead.\n\nBy the end of this tutorial, you'll have created a CoD summarization pipeline that leverages Weave's capabilities for model serving, evaluation, and result tracking.\n\n## Set up the environment\n\nFirst, let's set up our environment and import the necessary libraries:\n\n\n```python\n!pip install -qU anthropic weave pydantic requests PyPDF2 set-env-colab-kaggle-dotenv\n```\n\n>To get an Anthropic API key:\n> 1. Sign up for an account at https://www.anthropic.com\n> 2. Navigate to the API section in your account settings\n> 3. Generate a new API key\n> 4. Store the API key securely in your .env file\n\n\n```python\nimport io\nimport os\nfrom datetime import datetime, timezone\n\nimport anthropic\nimport requests\nfrom pydantic import BaseModel\nfrom PyPDF2 import PdfReader\nfrom set_env import set_env\n\nimport weave\n\nset_env(\"WANDB_API_KEY\")\nset_env(\"ANTHROPIC_API_KEY\")\n\nweave.init(\"summarization-chain-of-density-cookbook\")\nanthropic_client = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n```\n\nWe're using Weave to track our experiment and Anthropic's Claude model for text generation. The `weave.init()` call sets up a new Weave project for our summarization task.\n\n## Define the ArxivPaper model\n\nWe'll create a simple `ArxivPaper` class to represent our data:\n\n\n```python\n# Define ArxivPaper model\nclass ArxivPaper(BaseModel):\n    entry_id: str\n    updated: datetime\n    published: datetime\n    title: str\n    authors: list[str]\n    summary: str\n    pdf_url: str\n\n\n# Create sample ArxivPaper\narxiv_paper = ArxivPaper(\n    entry_id=\"http://arxiv.org/abs/2406.04744v1\",\n    updated=datetime(2024, 6, 7, 8, 43, 7, tzinfo=timezone.utc),\n    published=datetime(2024, 6, 7, 8, 43, 7, tzinfo=timezone.utc),\n    title=\"CRAG -- Comprehensive RAG Benchmark\",\n    authors=[\"Xiao Yang\", \"Kai Sun\", \"Hao Xin\"],  # Truncated for brevity\n    summary=\"Retrieval-Augmented Generation (RAG) has recently emerged as a promising solution...\",  # Truncated\n    pdf_url=\"https://arxiv.org/pdf/2406.04744\",\n)\n```\n\nThis class encapsulates the metadata and content of an ArXiv paper, which will be the input to our summarization pipeline.\n\n## Load PDF content\n\nTo work with the full paper content, we'll add a function to load and extract text from PDFs:\n\n\n```python\n@weave.op()\ndef load_pdf(pdf_url: str) -> str:\n    # Download the PDF\n    response = requests.get(pdf_url)\n    pdf_file = io.BytesIO(response.content)\n\n    # Read the PDF\n    pdf_reader = PdfReader(pdf_file)\n\n    # Extract text from all pages\n    text = \"\"\n    for page in pdf_reader.pages:\n        text += page.extract_text()\n\n    return text\n```\n\n## Implement Chain of Density summarization\n\nNow, let's implement the core CoD summarization logic using Weave operations:\n\n\n\n\n```python\n# Chain of Density Summarization\n@weave.op()\ndef summarize_current_summary(\n    document: str,\n    instruction: str,\n    current_summary: str = \"\",\n    iteration: int = 1,\n    model: str = \"claude-3-sonnet-20240229\",\n):\n    prompt = f\"\"\"\n    Document: {document}\n    Current summary: {current_summary}\n    Instruction to focus on: {instruction}\n    Iteration: {iteration}\n\n    Generate an increasingly concise, entity-dense, and highly technical summary from the provided document that specifically addresses the given instruction.\n    \"\"\"\n    response = anthropic_client.messages.create(\n        model=model, max_tokens=4096, messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    return response.content[0].text\n\n\n@weave.op()\ndef iterative_density_summarization(\n    document: str,\n    instruction: str,\n    current_summary: str,\n    density_iterations: int,\n    model: str = \"claude-3-sonnet-20240229\",\n):\n    iteration_summaries = []\n    for iteration in range(1, density_iterations + 1):\n        current_summary = summarize_current_summary(\n            document, instruction, current_summary, iteration, model\n        )\n        iteration_summaries.append(current_summary)\n    return current_summary, iteration_summaries\n\n\n@weave.op()\ndef final_summary(\n    instruction: str, current_summary: str, model: str = \"claude-3-sonnet-20240229\"\n):\n    prompt = f\"\"\"\n    Given this summary: {current_summary}\n    And this instruction to focus on: {instruction}\n    Create an extremely dense, final summary that captures all key technical information in the most concise form possible, while specifically addressing the given instruction.\n    \"\"\"\n    return (\n        anthropic_client.messages.create(\n            model=model, max_tokens=4096, messages=[{\"role\": \"user\", \"content\": prompt}]\n        )\n        .content[0]\n        .text\n    )\n\n\n@weave.op()\ndef chain_of_density_summarization(\n    document: str,\n    instruction: str,\n    current_summary: str = \"\",\n    model: str = \"claude-3-sonnet-20240229\",\n    density_iterations: int = 2,\n):\n    current_summary, iteration_summaries = iterative_density_summarization(\n        document, instruction, current_summary, density_iterations, model\n    )\n    final_summary_text = final_summary(instruction, current_summary, model)\n    return {\n        \"final_summary\": final_summary_text,\n        \"accumulated_summary\": current_summary,\n        \"iteration_summaries\": iteration_summaries,\n    }\n```\n\nHere's what each function does:\n\n- `summarize_current_summary`: Generates a single summary iteration based on the current state.\n- `iterative_density_summarization`: Applies the CoD technique by calling `summarize_current_summary` multiple times.\n- `chain_of_density_summarization`: Orchestrates the entire summarization process and returns the results.\n\nBy using `@weave.op()` decorators, we ensure that Weave tracks the inputs, outputs, and execution of these functions.\n\n\n## Create a Weave Model\n\nNow, let's wrap our summarization pipeline in a Weave Model:\n\n\n\n\n```python\n# Weave Model\nclass ArxivChainOfDensityPipeline(weave.Model):\n    model: str = \"claude-3-sonnet-20240229\"\n    density_iterations: int = 3\n\n    @weave.op()\n    def predict(self, paper: ArxivPaper, instruction: str) -> dict:\n        text = load_pdf(paper.pdf_url)\n        result = chain_of_density_summarization(\n            text,\n            instruction,\n            model=self.model,\n            density_iterations=self.density_iterations,\n        )\n        return result\n```\n\nThis `ArxivChainOfDensityPipeline` class encapsulates our summarization logic as a Weave Model, providing several key benefits:\n\n1. Automatic experiment tracking: Weave captures inputs, outputs, and parameters for each run of the model.\n2. Versioning: Changes to the model's attributes or code are automatically versioned, creating a clear history of how your summarization pipeline evolves over time.\n3. Reproducibility: The versioning and tracking make it easy to reproduce any previous result or configuration of your summarization pipeline.\n4. Hyperparameter management: Model attributes (like `model` and `density_iterations`) are clearly defined and tracked across different runs, facilitating experimentation.\n5. Integration with Weave ecosystem: Using `weave.Model` allows seamless integration with other Weave tools, such as evaluations and serving capabilities.\n\n## Implement evaluation metrics\n\nTo assess the quality of our summaries, we'll implement simple evaluation metrics:\n\n\n```python\nimport json\n\n\n@weave.op()\ndef evaluate_summary(\n    summary: str, instruction: str, model: str = \"claude-3-sonnet-20240229\"\n) -> dict:\n    prompt = f\"\"\"\n    Summary: {summary}\n    Instruction: {instruction}\n\n    Evaluate the summary based on the following criteria:\n    1. Relevance (1-5): How well does the summary address the given instruction?\n    2. Conciseness (1-5): How concise is the summary while retaining key information?\n    3. Technical Accuracy (1-5): How accurately does the summary convey technical details?\n\n    Your response MUST be in the following JSON format:\n    {{\n        \"relevance\": {{\n            \"score\": ,\n            \"explanation\": \"\"\n        }},\n        \"conciseness\": {{\n            \"score\": ,\n            \"explanation\": \"\"\n        }},\n        \"technical_accuracy\": {{\n            \"score\": ,\n            \"explanation\": \"\"\n        }}\n    }}\n\n    Ensure that the scores are integers between 1 and 5, and that the explanations are concise.\n    \"\"\"\n    response = anthropic_client.messages.create(\n        model=model, max_tokens=1000, messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    print(response.content[0].text)\n\n    eval_dict = json.loads(response.content[0].text)\n\n    return {\n        \"relevance\": eval_dict[\"relevance\"][\"score\"],\n        \"conciseness\": eval_dict[\"conciseness\"][\"score\"],\n        \"technical_accuracy\": eval_dict[\"technical_accuracy\"][\"score\"],\n        \"average_score\": sum(eval_dict[k][\"score\"] for k in eval_dict) / 3,\n        \"evaluation_text\": response.content[0].text,\n    }\n```\n\nThese evaluation functions use the Claude model to assess the quality of the generated summaries based on relevance, conciseness, and technical accuracy.\n\n## Create a Weave Dataset and run evaluation\n\nTo evaluate our pipeline, we'll create a Weave Dataset and run an evaluation:\n\n\n\n\n```python\n# Create a Weave Dataset\ndataset = weave.Dataset(\n    name=\"arxiv_papers\",\n    rows=[\n        {\n            \"paper\": arxiv_paper,\n            \"instruction\": \"What was the approach to experimenting with different data mixtures?\",\n        },\n    ],\n)\n\nweave.publish(dataset)\n```\n\nFor our evaluation, we'll use an LLM-as-a-judge approach. This technique involves using a language model to assess the quality of outputs generated by another model or system. It leverages the LLM's understanding and reasoning capabilities to provide nuanced evaluations, especially for tasks where traditional metrics may fall short.\n\n[](https://arxiv.org/abs/2306.05685)\n\n\n\n\n```python\n# Define the scorer function\n@weave.op()\ndef quality_scorer(instruction: str, output: dict) -> dict:\n    result = evaluate_summary(output[\"final_summary\"], instruction)\n    return result\n```\n\n\n```python\n# Run evaluation\nevaluation = weave.Evaluation(dataset=dataset, scorers=[quality_scorer])\narxiv_chain_of_density_pipeline = ArxivChainOfDensityPipeline()\nresults = await evaluation.evaluate(arxiv_chain_of_density_pipeline)\n```\n\nThis code creates a dataset with our sample ArXiv paper, defines a quality scorer, and runs an evaluation of our summarization pipeline.\n\n## Conclusion\n\nIn this example, we've demonstrated how to implement a Chain of Density summarization pipeline for ArXiv papers using Weave. We've shown how to:\n\n1. Create Weave operations for each step of the summarization process\n2. Wrap the pipeline in a Weave Model for easy tracking and evaluation\n3. Implement custom evaluation metrics using Weave operations\n4. Create a dataset and run an evaluation of the pipeline\n\nWeave's seamless integration allows us to track inputs, outputs, and intermediate steps throughout the summarization process, making it easier to debug, optimize, and evaluate our LLM application.\nYou can extend this example to handle larger datasets, implement more sophisticated evaluation metrics, or integrate with other LLM workflows.\n\n<a \n  href=\"https://wandb.ai/wandb_fc/arxiv-reader/reports/Building-a-bot-to-summarize-arXiv-papers-as-PDFs-using-Anthrophic-and-W-B-Weave--Vmlldzo4Nzg0ODI4\"\n  target=\"_blank\"\n  rel=\"noopener noreferrer\"\n  className=\"button button--primary button--lg\"\n>\n  View Full Report on W&B"
  },
  {
    "title": "Log Audio With Weave",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/audio_with_weave",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook] Open in Colab View in Github ::: # How to use Weave with Audio Data: An OpenAI Example This demo uses the OpenAI chat completions API with GPT 4o Audio Preview to generate audio responses to text prompts and track these in Weave. For the advanced use case, we leverage the OpenAI Realtime API to stream audio in realtime. Click the following thumbnail to view the video demonstration, or click [here](https://www.youtube.com/watch?v=lnnd73xDElw). [](https://www.youtube.com/watch?v=lnnd73xDElw \"Everything Is AWESOME\") ## Setup Start by installing the OpenAI (`openai`) and Weave (`weave`) dependencies, as well as API key management dependencey `set-env`. ```python %%capture !pip install openai !pip install weave !pip install set-env-colab-kaggle-dotenv -q # for env var ``` ```python %%capture # Temporary workaround to fix bug in openai: # TypeError: Client.__init__() got an unexpected keyword argument 'proxies' # See https://community.openai.com/t/error-with-openai-1-56-0-client-init-got-an-unexpected-keyword-argument-proxies/1040332/15 !pip install \"httpx<0.28\" ``` Next, load the required API keys for OpenAI and Weave. Here, we use set_env which is compatible with google colab's secret keys manager, and is an alternative to colab's specific `google.colab.userdata`. See: [here](https://pypi.org/project/set-env-colab-kaggle-dotenv/) for usage instructions. ```python # Set environment variables. from set_env import set_env _ = set_env(\"OPENAI_API_KEY\") _ = set_env(\"WANDB_API_KEY\") ``` And finally import the required libraries. ```python import base64 import os import time import wave import numpy as np from IPython.display import display from openai import OpenAI import weave ``` ## Audio Streaming and Storage Example Now we will setup a call to OpenAI's completions endpoint with audio modality enabled. First create the OpenAI client and initiate a Weave project. ```python client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\")) weave.init(\"openai-audio-chat\") ``` Now we will define our OpenAI completions request and add our Weave decorator (op). Here, we define the function `prompt_endpont_and_log_trace`. This function has three primary steps: 1. We make a completion object using the `GPT 4o Audio Preview` model that supports text and audio inputs and outputs. - We prompt the model to count to 13 slowly with varying accents. - We set the completion to \"stream\". 2. We open a new output file to which the streamed data is writen chunk by chunk. 3. We return an open file handler to the audio file so Weave logs the audio data in the trace. ```python SAMPLE_RATE = 22050 @weave.op() def prompt_endpoint_and_log_trace(system_prompt=None, user_prompt=None): if not system_prompt: system_prompt = \"You're the fastest counter in the world\" if not user_prompt: user_prompt = \"Count to 13 super super slow, enunciate each number with a dramatic flair, changing up accents as you go along. British, French, German, Spanish, etc.\" # Request from the OpenAI API with audio modality completion = client.chat.completions.create( model=\"gpt-4o-audio-preview\", modalities=[\"text\", \"audio\"], audio={\"voice\": \"fable\", \"format\": \"pcm16\"}, stream=True, messages=[ {\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}, ], ) # Open a wave file for writing with wave.open(\"./output.wav\", \"wb\") as wav_file: wav_file.setnchannels(1) # Mono wav_file.setsampwidth(2) # 16-bit wav_file.setframerate(SAMPLE_RATE) # Sample rate (adjust if needed) # Write chunks as they are streamed in from the API for chunk in completion: if ( hasattr(chunk, \"choices\") and chunk.choices is not None and len(chunk.choices) > 0 ): if ( hasattr(chunk.choices[0].delta, \"audio\") and chunk.choices[0].delta.audio.get(\"data\") is not None ): # Decode the base64 audio data audio_data = base64.b64decode( chunk.choices[0].delta.audio.get(\"data\") ) # Write the current chunk to the wave file wav_file.writeframes(audio_data) # Return the file to Weave op return wave.open(\"output.wav\", \"rb\") ``` ## Testing Run the following cell. The system and user prompt will be stored in a Weave trace as well as the output audio. After running the cell, click the link next to the \"\ud83c\udf69\" emoji to view your trace. ```python from IPython.display import Audio, display # Call the function to write the audio stream prompt_endpoint_and_log_trace( system_prompt=\"You're the fastest counter in the world\", user_prompt=\"Count to 13 super super slow, enunciate each number with a dramatic flair, changing up accents as you go along. British, French, German, Spanish, etc.\", ) # Display the updated audio stream display(Audio(\"output.wav\", rate=SAMPLE_RATE, autoplay=True)) ``` # Advanced Usage: Realtime Audio API with Weave (Advanced) Realtime Audio API with Weave OpenAI's realtime API is a highly functional and reliable conversational API for building realtime audio and text assistants. Please note: - Review the cells in [Microphone Configuration](#microphone-configuration) - Due to limitations of the Google Colab execution environment, **this must be run on your host machine** as a Jupyter Notebook. This cannot be ran in the browser. - On MacOS you will need to install `portaudio` via Brew (see [here](https://formulae.brew.sh/formula/portaudio)) for Pyaudio to function. - OpenAI's Python SDK does not yet provide Realtime API support. We implement the complete OAI Realtime API schema in Pydantic for greater legibility, and may deprecate once official support is released. - The `enable_audio_playback` toggle will cause playback of assistant outputted audio. Please note that **headphones are required if this is enabled**, as echo detection requires a highly complex implementation. ## Requirements Setup ```python %%capture !pip install numpy==2.0 !pip install weave !pip install pyaudio # On mac, you may need to install portaudio first with `brew install portaudio` !pip install websocket-client !pip install set-env-colab-kaggle-dotenv -q # for env var !pip install resampy ``` ```python import base64 import io import json import os import threading import time import wave from typing import Optional import numpy as np import pyaudio import resampy import websocket from set_env import set_env import weave ``` ```python # Set environment variables. # See: https://pypi.org/project/set-env-colab-kaggle-dotenv/ for usage instructions. _ = set_env(\"OPENAI_API_KEY\") _ = set_env(\"WANDB_API_KEY\") ``` ## Microphone Configuration Run the following cell to find all available audio devices. Then, populate the `INPUT_DEVICE_INDEX` and the `OUTPUT_DEVICE_INDEX` based on the devices listed. Your input device will have at least 1 input channels, and your output device will have at least 1 output channels. ```python # Get device list from pyaudio so we can configure the next cell p = pyaudio.PyAudio() devices_data = {i: p.get_device_info_by_index(i) for i in range(p.get_device_count())} for i, device in devices_data.items(): print( f\"Found device @{i}: {device['name']} with sample rate: {device['defaultSampleRate']} and input channels: {device['maxInputChannels']} and output channels: {device['maxOutputChannels']}\" ) ``` ```python INPUT_DEVICE_INDEX = 3 # @param # Choose based on device list above. Make sure device has > 0 input channels. OUTPUT_DEVICE_INDEX = 12 # @param # Chose based on device list above. Make sure device has > 0 output channels. enable_audio_playback = True # @param {type:\"boolean\"} # Toggle on assistant audio playback. Requires headphones. # Audio recording and streaming parameters INPUT_DEVICE_CHANNELS = devices_data[INPUT_DEVICE_INDEX][ \"maxInputChannels\" ] # From device list above SAMPLE_RATE = int( devices_data[INPUT_DEVICE_INDEX][\"defaultSampleRate\"] ) # From device list above CHUNK = int(SAMPLE_RATE / 10) # Samples per frame SAMPLE_WIDTH = p.get_sample_size(pyaudio.paInt16) # Samples per frame for the format CHUNK_DURATION = 0.3 # Seconds of audio per chunk sent to OAI API OAI_SAMPLE_RATE = ( 24000 # OAI Sample Rate is 24kHz, we need this to play or save assistant audio ) OUTPUT_DEVICE_CHANNELS = 1 # Set to 1 for mono output ``` ## OpenAI Realtime API Schema Implementation The OpenAI Python SDK does not yet provide Realtime API support. We implement the complete OAI Realtime API schema in Pydantic for greater legibility, and may deprecate once official support is released. Pydantic Schema for OpenAI Realtime API (OpenAI's SDK lacks Realtime API support) ```python from enum import Enum from typing import Any, Literal, Optional, Union from pydantic import BaseModel, Field, ValidationError class BaseEvent(BaseModel): type: Union[\"ClientEventTypes\", \"ServerEventTypes\"] event_id: Optional[str] = None # Add event_id as an optional field for all events # def model_dump_json(self, *args, **kwargs): # # Only include non-None fields # return super().model_dump_json(*args, exclude_none=True, **kwargs) class ChatMessage(BaseModel): role: Literal[\"user\", \"assistant\"] content: str timestamp: float \"\"\" CLIENT EVENTS \"\"\" class ClientEventTypes(str, Enum): SESSION_UPDATE = \"session.update\" CONVERSATION_ITEM_CREATE = \"conversation.item.create\" CONVERSATION_ITEM_TRUNCATE = \"conversation.item.truncate\" CONVERSATION_ITEM_DELETE = \"conversation.item.delete\" RESPONSE_CREATE = \"response.create\" RESPONSE_CANCEL = \"response.cancel\" INPUT_AUDIO_BUFFER_APPEND = \"input_audio_buffer.append\" INPUT_AUDIO_BUFFER_COMMIT = \"input_audio_buffer.commit\" INPUT_AUDIO_BUFFER_CLEAR = \"input_audio_buffer.clear\" ERROR = \"error\" #### Session Update class TurnDetection(BaseModel): type: Literal[\"server_vad\"] threshold: float = Field(..., ge=0.0, le=1.0) prefix_padding_ms: int silence_duration_ms: int class InputAudioTranscription(BaseModel): model: Optional[str] = None class ToolParameterProperty(BaseModel): type: str class ToolParameter(BaseModel): type: str properties: dict[str, ToolParameterProperty] required: list[str] class Tool(BaseModel): type: Literal[\"function\", \"code_interpreter\", \"file_search\"] name: Optional[str] = None description: Optional[str] = None parameters: Optional[ToolParameter] = None class Session(BaseModel): modalities: Optional[list[str]] = None instructions: Optional[str] = None voice: Optional[str] = None input_audio_format: Optional[str] = None output_audio_format: Optional[str] = None input_audio_transcription: Optional[InputAudioTranscription] = None turn_detection: Optional[TurnDetection] = None tools: Optional[list[Tool]] = None tool_choice: Optional[str] = None temperature: Optional[float] = None max_output_tokens: Optional[int] = None class SessionUpdate(BaseEvent): type: Literal[ClientEventTypes.SESSION_UPDATE] = ClientEventTypes.SESSION_UPDATE session: Session #### Audio Buffers class InputAudioBufferAppend(BaseEvent): type: Literal[ClientEventTypes.INPUT_AUDIO_BUFFER_APPEND] = ( ClientEventTypes.INPUT_AUDIO_BUFFER_APPEND ) audio: str class InputAudioBufferCommit(BaseEvent): type: Literal[ClientEventTypes.INPUT_AUDIO_BUFFER_COMMIT] = ( ClientEventTypes.INPUT_AUDIO_BUFFER_COMMIT ) class InputAudioBufferClear(BaseEvent): type: Literal[ClientEventTypes.INPUT_AUDIO_BUFFER_CLEAR] = ( ClientEventTypes.INPUT_AUDIO_BUFFER_CLEAR ) #### Messages class MessageContent(BaseModel): type: Literal[\"input_audio\"] audio: str class ConversationItemContent(BaseModel): type: Literal[\"input_text\", \"input_audio\", \"text\", \"audio\"] text: Optional[str] = None audio: Optional[str] = None transcript: Optional[str] = None class FunctionCallContent(BaseModel): call_id: str name: str arguments: str class FunctionCallOutputContent(BaseModel): output: str class ConversationItem(BaseModel): id: Optional[str] = None type: Literal[\"message\", \"function_call\", \"function_call_output\"] status: Optional[Literal[\"completed\", \"in_progress\", \"incomplete\"]] = None role: Literal[\"user\", \"assistant\", \"system\"] content: list[ Union[ConversationItemContent, FunctionCallContent, FunctionCallOutputContent] ] call_id: Optional[str] = None name: Optional[str] = None arguments: Optional[str] = None output: Optional[str] = None class ConversationItemCreate(BaseEvent): type: Literal[ClientEventTypes.CONVERSATION_ITEM_CREATE] = ( ClientEventTypes.CONVERSATION_ITEM_CREATE ) item: ConversationItem class ConversationItemTruncate(BaseEvent): type: Literal[ClientEventTypes.CONVERSATION_ITEM_TRUNCATE] = ( ClientEventTypes.CONVERSATION_ITEM_TRUNCATE ) item_id: str content_index: int audio_end_ms: int class ConversationItemDelete(BaseEvent): type: Literal[ClientEventTypes.CONVERSATION_ITEM_DELETE] = ( ClientEventTypes.CONVERSATION_ITEM_DELETE ) item_id: str #### Responses class ResponseCreate(BaseEvent): type: Literal[ClientEventTypes.RESPONSE_CREATE] = ClientEventTypes.RESPONSE_CREATE class ResponseCancel(BaseEvent): type: Literal[ClientEventTypes.RESPONSE_CANCEL] = ClientEventTypes.RESPONSE_CANCEL # Update the Event union to include all event types ClientEvent = Union[ SessionUpdate, InputAudioBufferAppend, InputAudioBufferCommit, InputAudioBufferClear, ConversationItemCreate, ConversationItemTruncate, ConversationItemDelete, ResponseCreate, ResponseCancel, ] \"\"\" SERVER EVENTS \"\"\" class ServerEventTypes(str, Enum): ERROR = \"error\" RESPONSE_AUDIO_TRANSCRIPT_DONE = \"response.audio_transcript.done\" RESPONSE_AUDIO_TRANSCRIPT_DELTA = \"response.audio_transcript.delta\" RESPONSE_AUDIO_DELTA = \"response.audio.delta\" SESSION_CREATED = \"session.created\" SESSION_UPDATED = \"session.updated\" CONVERSATION_CREATED = \"conversation.created\" INPUT_AUDIO_BUFFER_COMMITTED = \"input_audio_buffer.committed\" INPUT_AUDIO_BUFFER_CLEARED = \"input_audio_buffer.cleared\" INPUT_AUDIO_BUFFER_SPEECH_STARTED = \"input_audio_buffer.speech_started\" INPUT_AUDIO_BUFFER_SPEECH_STOPPED = \"input_audio_buffer.speech_stopped\" CONVERSATION_ITEM_CREATED = \"conversation.item.created\" CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_COMPLETED = ( \"conversation.item.input_audio_transcription.completed\" ) CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_FAILED = ( \"conversation.item.input_audio_transcription.failed\" ) CONVERSATION_ITEM_TRUNCATED = \"conversation.item.truncated\" CONVERSATION_ITEM_DELETED = \"conversation.item.deleted\" RESPONSE_CREATED = \"response.created\" RESPONSE_DONE = \"response.done\" RESPONSE_OUTPUT_ITEM_ADDED = \"response.output_item.added\" RESPONSE_OUTPUT_ITEM_DONE = \"response.output_item.done\" RESPONSE_CONTENT_PART_ADDED = \"response.content_part.added\" RESPONSE_CONTENT_PART_DONE = \"response.content_part.done\" RESPONSE_TEXT_DELTA = \"response.text.delta\" RESPONSE_TEXT_DONE = \"response.text.done\" RESPONSE_AUDIO_DONE = \"response.audio.done\" RESPONSE_FUNCTION_CALL_ARGUMENTS_DELTA = \"response.function_call_arguments.delta\" RESPONSE_FUNCTION_CALL_ARGUMENTS_DONE = \"response.function_call_arguments.done\" RATE_LIMITS_UPDATED = \"rate_limits.updated\" #### Errors class ErrorDetails(BaseModel): type: Optional[str] = None code: Optional[str] = None message: Optional[str] = None param: Optional[str] = None class ErrorEvent(BaseEvent): type: Literal[ServerEventTypes.ERROR] = ServerEventTypes.ERROR error: ErrorDetails #### Session class SessionCreated(BaseEvent): type: Literal[ServerEventTypes.SESSION_CREATED] = ServerEventTypes.SESSION_CREATED session: Session class SessionUpdated(BaseEvent): type: Literal[ServerEventTypes.SESSION_UPDATED] = ServerEventTypes.SESSION_UPDATED session: Session #### Conversation class Conversation(BaseModel): id: str object: Literal[\"realtime.conversation\"] class ConversationCreated(BaseEvent): type: Literal[ServerEventTypes.CONVERSATION_CREATED] = ( ServerEventTypes.CONVERSATION_CREATED ) conversation: Conversation class ConversationItemCreated(BaseEvent): type: Literal[ServerEventTypes.CONVERSATION_ITEM_CREATED] = ( ServerEventTypes.CONVERSATION_ITEM_CREATED ) previous_item_id: Optional[str] = None item: ConversationItem class ConversationItemInputAudioTranscriptionCompleted(BaseEvent): type: Literal[ ServerEventTypes.CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_COMPLETED ] = ServerEventTypes.CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_COMPLETED item_id: str content_index: int transcript: str class ConversationItemInputAudioTranscriptionFailed(BaseEvent): type: Literal[ ServerEventTypes.CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_FAILED ] = ServerEventTypes.CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_FAILED item_id: str content_index: int error: dict[str, Any] class ConversationItemTruncated(BaseEvent): type: Literal[ServerEventTypes.CONVERSATION_ITEM_TRUNCATED] = ( ServerEventTypes.CONVERSATION_ITEM_TRUNCATED ) item_id: str content_index: int audio_end_ms: int class ConversationItemDeleted(BaseEvent): type: Literal[ServerEventTypes.CONVERSATION_ITEM_DELETED] = ( ServerEventTypes.CONVERSATION_ITEM_DELETED ) item_id: str #### Response class ResponseUsage(BaseModel): total_tokens: int input_tokens: int output_tokens: int input_token_details: Optional[dict[str, int]] = None output_token_details: Optional[dict[str, int]] = None class ResponseOutput(BaseModel): id: str object: Literal[\"realtime.item\"] type: str status: str role: str content: list[dict[str, Any]] class ResponseContentPart(BaseModel): type: str text: Optional[str] = None class ResponseOutputItemContent(BaseModel): type: str text: Optional[str] = None class ResponseStatusDetails(BaseModel): type: str reason: str class ResponseOutputItem(BaseModel): id: str object: Literal[\"realtime.item\"] type: str status: str role: str content: list[ResponseOutputItemContent] class Response(BaseModel): id: str object: Literal[\"realtime.response\"] status: str status_details: Optional[ResponseStatusDetails] = None output: list[ResponseOutput] usage: Optional[ResponseUsage] class ResponseCreated(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_CREATED] = ServerEventTypes.RESPONSE_CREATED response: Response class ResponseDone(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_DONE] = ServerEventTypes.RESPONSE_DONE response: Response class ResponseOutputItemAdded(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_OUTPUT_ITEM_ADDED] = ( ServerEventTypes.RESPONSE_OUTPUT_ITEM_ADDED ) response_id: str output_index: int item: ResponseOutputItem class ResponseOutputItemDone(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_OUTPUT_ITEM_DONE] = ( ServerEventTypes.RESPONSE_OUTPUT_ITEM_DONE ) response_id: str output_index: int item: ResponseOutputItem class ResponseContentPartAdded(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_CONTENT_PART_ADDED] = ( ServerEventTypes.RESPONSE_CONTENT_PART_ADDED ) response_id: str item_id: str output_index: int content_index: int part: ResponseContentPart class ResponseContentPartDone(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_CONTENT_PART_DONE] = ( ServerEventTypes.RESPONSE_CONTENT_PART_DONE ) response_id: str item_id: str output_index: int content_index: int part: ResponseContentPart #### Response Text class ResponseTextDelta(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_TEXT_DELTA] = ( ServerEventTypes.RESPONSE_TEXT_DELTA ) response_id: str item_id: str output_index: int content_index: int delta: str class ResponseTextDone(BaseEvent): type: Literal[ServerEventTypes.RESPONSE_TEXT_DONE] = ( ServerEventTypes.RESPONSE_TEXT_DONE ) response_id: str item_id: str output_index: int content_index: int text: str #### Response Audio class ResponseAudioTranscriptDone(BaseEvent): type:\n\n> Content truncated."
  },
  {
    "title": "Leaderboard Quickstart",
    "url": "https://weave-docs.wandb.ai/reference/gen_notebooks/leaderboard_quickstart",
    "section": "Optional",
    "category": "Example Notebooks",
    "content": ":::tip[This is a notebook]\n\nOpen in Colab\n\nView in Github\n\n:::\n\n\n\n\n\n# Leaderboard Quickstart\n\nIn this notebook we will learn to use Weave's Leaderboard to compare model performance across different datasets and scoring functions. Specifically, we will:\n\n1. Generate a dataset of fake zip code data\n2. Author some scoring functions and evaluate a baseline model.\n3. Use these techniques to evaluate a matrix of models vs evaluations.\n4. Review the leaderboard in the Weave UI.\n\n## Step 1: Generate a dataset of fake zip code data\n\nFirst we will create a function `generate_dataset_rows` that generates a list of fake zip code data.\n\n\n```python\nimport json\n\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\n\nclass Row(BaseModel):\n    zip_code: str\n    city: str\n    state: str\n    avg_temp_f: float\n    population: int\n    median_income: int\n    known_for: str\n\n\nclass Rows(BaseModel):\n    rows: list[Row]\n\n\ndef generate_dataset_rows(\n    location: str = \"United States\", count: int = 5, year: int = 2022\n):\n    client = OpenAI()\n\n    completion = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n            {\n                \"role\": \"user\",\n                \"content\": f\"Please generate {count} rows of data for random zip codes in {location} for the year {year}.\",\n            },\n        ],\n        response_format={\n            \"type\": \"json_schema\",\n            \"json_schema\": {\n                \"name\": \"response_format\",\n                \"schema\": Rows.model_json_schema(),\n            },\n        },\n    )\n\n    return json.loads(completion.choices[0].message.content)[\"rows\"]\n```\n\n\n```python\nimport weave\n\nweave.init(\"leaderboard-demo\")\n```\n\n## Step 2: Author scoring functions\n\nNext we will author 3 scoring functions:\n\n1. `check_concrete_fields`: Checks if the model output matches the expected city and state.\n2. `check_value_fields`: Checks if the model output is within 10% of the expected population and median income.\n3. `check_subjective_fields`: Uses a LLM to check if the model output matches the expected \"known for\" field.\n\n\n\n```python\n@weave.op\ndef check_concrete_fields(city: str, state: str, output: dict):\n    return {\n        \"city_match\": city == output[\"city\"],\n        \"state_match\": state == output[\"state\"],\n    }\n\n\n@weave.op\ndef check_value_fields(\n    avg_temp_f: float, population: int, median_income: int, output: dict\n):\n    return {\n        \"avg_temp_f_err\": abs(avg_temp_f - output[\"avg_temp_f\"]) / avg_temp_f,\n        \"population_err\": abs(population - output[\"population\"]) / population,\n        \"median_income_err\": abs(median_income - output[\"median_income\"])\n        / median_income,\n    }\n\n\n@weave.op\ndef check_subjective_fields(zip_code: str, known_for: str, output: dict):\n    client = OpenAI()\n\n    class Response(BaseModel):\n        correct_known_for: bool\n\n    completion = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n            {\n                \"role\": \"user\",\n                \"content\": f\"My student was asked what the zip code {zip_code} is best known best for. The right answer is '{known_for}', and they said '{output['known_for']}'. Is their answer correct?\",\n            },\n        ],\n        response_format={\n            \"type\": \"json_schema\",\n            \"json_schema\": {\n                \"name\": \"response_format\",\n                \"schema\": Response.model_json_schema(),\n            },\n        },\n    )\n\n    return json.loads(completion.choices[0].message.content)\n```\n\n## Step 3: Create a simple Evaluation\n\nNext we define a simple evaliation using our fake data and scoring functions.\n\n\n\n```python\nrows = generate_dataset_rows()\nevaluation = weave.Evaluation(\n    name=\"United States - 2022\",\n    dataset=rows,\n    scorers=[\n        check_concrete_fields,\n        check_value_fields,\n        check_subjective_fields,\n    ],\n)\n```\n\n## Step 4: Evaluate a baseline model\n\nNow we will evaluate a baseline model which returns a static response.\n\n\n\n```python\n@weave.op\ndef baseline_model(zip_code: str):\n    return {\n        \"city\": \"New York\",\n        \"state\": \"NY\",\n        \"avg_temp_f\": 50.0,\n        \"population\": 1000000,\n        \"median_income\": 100000,\n        \"known_for\": \"The Big Apple\",\n    }\n\n\nawait evaluation.evaluate(baseline_model)\n```\n\n## Step 5: Create more Models\n\nNow we will create 2 more models to compare against the baseline.\n\n\n```python\n@weave.op\ndef gpt_4o_mini_no_context(zip_code: str):\n    client = OpenAI()\n\n    completion = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[{\"role\": \"user\", \"content\": f\"\"\"Zip code {zip_code}\"\"\"}],\n        response_format={\n            \"type\": \"json_schema\",\n            \"json_schema\": {\n                \"name\": \"response_format\",\n                \"schema\": Row.model_json_schema(),\n            },\n        },\n    )\n\n    return json.loads(completion.choices[0].message.content)\n\n\nawait evaluation.evaluate(gpt_4o_mini_no_context)\n```\n\n\n```python\n@weave.op\ndef gpt_4o_mini_with_context(zip_code: str):\n    client = OpenAI()\n\n    completion = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"\"\"Please answer the following questions about the zip code {zip_code}:\n                   1. What is the city?\n                   2. What is the state?\n                   3. What is the average temperature in Fahrenheit?\n                   4. What is the population?\n                   5. What is the median income?\n                   6. What is the most well known thing about this zip code?\n                   \"\"\",\n            }\n        ],\n        response_format={\n            \"type\": \"json_schema\",\n            \"json_schema\": {\n                \"name\": \"response_format\",\n                \"schema\": Row.model_json_schema(),\n            },\n        },\n    )\n\n    return json.loads(completion.choices[0].message.content)\n\n\nawait evaluation.evaluate(gpt_4o_mini_with_context)\n```\n\n## Step 6: Create more Evaluations\n\nNow we will evaluate a matrix of models vs evaluations.\n\n\n\n```python\nscorers = [\n    check_concrete_fields,\n    check_value_fields,\n    check_subjective_fields,\n]\nevaluations = [\n    weave.Evaluation(\n        name=\"United States - 2022\",\n        dataset=weave.Dataset(\n            name=\"United States - 2022\",\n            rows=generate_dataset_rows(\"United States\", 5, 2022),\n        ),\n        scorers=scorers,\n    ),\n    weave.Evaluation(\n        name=\"California - 2022\",\n        dataset=weave.Dataset(\n            name=\"California - 2022\", rows=generate_dataset_rows(\"California\", 5, 2022)\n        ),\n        scorers=scorers,\n    ),\n    weave.Evaluation(\n        name=\"United States - 2000\",\n        dataset=weave.Dataset(\n            name=\"United States - 2000\",\n            rows=generate_dataset_rows(\"United States\", 5, 2000),\n        ),\n        scorers=scorers,\n    ),\n]\nmodels = [\n    baseline_model,\n    gpt_4o_mini_no_context,\n    gpt_4o_mini_with_context,\n]\n\nfor evaluation in evaluations:\n    for model in models:\n        await evaluation.evaluate(\n            model, __weave={\"display_name\": evaluation.name + \":\" + model.__name__}\n        )\n```\n\n## Step 7: Review the Leaderboard\n\nYou can create a new leaderboard by navigating to the leaderboard tab in the UI and clicking \"Create Leaderboard\".\n\nWe can also generate a leaderboard directly from Python:\n\n\n```python\nfrom weave.flow import leaderboard\nfrom weave.trace.ref_util import get_ref\n\nspec = leaderboard.Leaderboard(\n    name=\"Zip Code World Knowledge\",\n    description=\"\"\"\nThis leaderboard compares the performance of models in terms of world knowledge about zip codes.\n\n### Columns\n\n1. **State Match against `United States - 2022`**: The fraction of zip codes that the model correctly identified the state for.\n2. **Avg Temp F Error against `California - 2022`**: The mean absolute error of the model's average temperature prediction.\n3. **Correct Known For against `United States - 2000`**: The fraction of zip codes that the model correctly identified the most well known thing about the zip code.\n\"\"\",\n    columns=[\n        leaderboard.LeaderboardColumn(\n            evaluation_object_ref=get_ref(evaluations[0]).uri(),\n            scorer_name=\"check_concrete_fields\",\n            summary_metric_path=\"state_match.true_fraction\",\n        ),\n        leaderboard.LeaderboardColumn(\n            evaluation_object_ref=get_ref(evaluations[1]).uri(),\n            scorer_name=\"check_value_fields\",\n            should_minimize=True,\n            summary_metric_path=\"avg_temp_f_err.mean\",\n        ),\n        leaderboard.LeaderboardColumn(\n            evaluation_object_ref=get_ref(evaluations[2]).uri(),\n            scorer_name=\"check_subjective_fields\",\n            summary_metric_path=\"correct_known_for.true_fraction\",\n        ),\n    ],\n)\n\nref = weave.publish(spec)\n```"
  },
  {
    "title": "Readme",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/README",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "**weave** \u2022 **Docs**\n\n***\n\n# weave\n\n## Classes\n\n- [Dataset](classes/Dataset.md)\n- [Evaluation](classes/Evaluation.md)\n- [WeaveClient](classes/WeaveClient.md)\n- [WeaveObject](classes/WeaveObject.md)\n\n## Interfaces\n\n- [CallSchema](interfaces/CallSchema.md)\n- [CallsFilter](interfaces/CallsFilter.md)\n\n## Type Aliases\n\n- [Op](type-aliases/Op.md)\n\n## Functions\n\n- [init](functions/init.md)\n- [login](functions/login.md)\n- [op](functions/op.md)\n- [requireCurrentCallStackEntry](functions/requireCurrentCallStackEntry.md)\n- [requireCurrentChildSummary](functions/requireCurrentChildSummary.md)\n- [weaveAudio](functions/weaveAudio.md)\n- [weaveImage](functions/weaveImage.md)\n- [wrapOpenAI](functions/wrapOpenAI.md)"
  },
  {
    "title": "Weaveclient",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/classes/WeaveClient",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "[**weave**](../README.md) \u2022 **Docs**\n\n***\n\n[weave](../README.md) / WeaveClient\n\n# Class: WeaveClient\n\n## Constructors\n\n### new WeaveClient()\n\n> **new WeaveClient**(`traceServerApi`, `wandbServerApi`, `projectId`, `settings`): [`WeaveClient`](WeaveClient.md)\n\n#### Parameters\n\n\u2022 **traceServerApi**: `Api`\\\n\n\u2022 **wandbServerApi**: `WandbServerApi`\n\n\u2022 **projectId**: `string`\n\n\u2022 **settings**: `Settings` = `...`\n\n#### Returns\n\n[`WeaveClient`](WeaveClient.md)\n\n#### Defined in\n\n[weaveClient.ts:82](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L82)\n\n## Properties\n\n### projectId\n\n> **projectId**: `string`\n\n#### Defined in\n\n[weaveClient.ts:85](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L85)\n\n***\n\n### settings\n\n> **settings**: `Settings`\n\n#### Defined in\n\n[weaveClient.ts:86](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L86)\n\n***\n\n### traceServerApi\n\n> **traceServerApi**: `Api`\\\n\n#### Defined in\n\n[weaveClient.ts:83](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L83)\n\n## Methods\n\n### createCall()\n\n> **createCall**(`opRef`, `params`, `parameterNames`, `thisArg`, `currentCall`, `parentCall`, `startTime`, `displayName`?): `Promise`\\\n\n#### Parameters\n\n\u2022 **opRef**: `any`\n\n\u2022 **params**: `any`[]\n\n\u2022 **parameterNames**: `ParameterNamesOption`\n\n\u2022 **thisArg**: `any`\n\n\u2022 **currentCall**: `CallStackEntry`\n\n\u2022 **parentCall**: `undefined` \\| `CallStackEntry`\n\n\u2022 **startTime**: `Date`\n\n\u2022 **displayName?**: `string`\n\n#### Returns\n\n`Promise`\\\n\n#### Defined in\n\n[weaveClient.ts:610](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L610)\n\n***\n\n### finishCall()\n\n> **finishCall**(`result`, `currentCall`, `parentCall`, `summarize`, `endTime`, `startCallPromise`): `Promise`\\\n\n#### Parameters\n\n\u2022 **result**: `any`\n\n\u2022 **currentCall**: `CallStackEntry`\n\n\u2022 **parentCall**: `undefined` \\| `CallStackEntry`\n\n\u2022 **summarize**: `undefined` \\| (`result`) => `Record`\\\n\n\u2022 **endTime**: `Date`\n\n\u2022 **startCallPromise**: `Promise`\\\n\n#### Returns\n\n`Promise`\\\n\n#### Defined in\n\n[weaveClient.ts:648](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L648)\n\n***\n\n### finishCallWithException()\n\n> **finishCallWithException**(`error`, `currentCall`, `parentCall`, `endTime`, `startCallPromise`): `Promise`\\\n\n#### Parameters\n\n\u2022 **error**: `any`\n\n\u2022 **currentCall**: `CallStackEntry`\n\n\u2022 **parentCall**: `undefined` \\| `CallStackEntry`\n\n\u2022 **endTime**: `Date`\n\n\u2022 **startCallPromise**: `Promise`\\\n\n#### Returns\n\n`Promise`\\\n\n#### Defined in\n\n[weaveClient.ts:677](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L677)\n\n***\n\n### get()\n\n> **get**(`ref`): `Promise`\\\n\n#### Parameters\n\n\u2022 **ref**: `ObjectRef`\n\n#### Returns\n\n`Promise`\\\n\n#### Defined in\n\n[weaveClient.ts:229](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L229)\n\n***\n\n### getCalls()\n\n> **getCalls**(`filter`, `includeCosts`, `limit`): `Promise`\\\n\n#### Parameters\n\n\u2022 **filter**: [`CallsFilter`](../interfaces/CallsFilter.md) = `{}`\n\n\u2022 **includeCosts**: `boolean` = `false`\n\n\u2022 **limit**: `number` = `1000`\n\n#### Returns\n\n`Promise`\\\n\n#### Defined in\n\n[weaveClient.ts:172](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L172)\n\n***\n\n### getCallsIterator()\n\n> **getCallsIterator**(`filter`, `includeCosts`, `limit`): `AsyncIterableIterator`\\\n\n#### Parameters\n\n\u2022 **filter**: [`CallsFilter`](../interfaces/CallsFilter.md) = `{}`\n\n\u2022 **includeCosts**: `boolean` = `false`\n\n\u2022 **limit**: `number` = `1000`\n\n#### Returns\n\n`AsyncIterableIterator`\\\n\n#### Defined in\n\n[weaveClient.ts:184](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L184)\n\n***\n\n### getCallStack()\n\n> **getCallStack**(): `CallStack`\n\n#### Returns\n\n`CallStack`\n\n#### Defined in\n\n[weaveClient.ts:537](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L537)\n\n***\n\n### publish()\n\n> **publish**(`obj`, `objId`?): `Promise`\\\n\n#### Parameters\n\n\u2022 **obj**: `any`\n\n\u2022 **objId?**: `string`\n\n#### Returns\n\n`Promise`\\\n\n#### Defined in\n\n[weaveClient.ts:160](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L160)\n\n***\n\n### pushNewCall()\n\n> **pushNewCall**(): `object`\n\n#### Returns\n\n`object`\n\n##### currentCall\n\n> **currentCall**: `CallStackEntry`\n\n##### newStack\n\n> **newStack**: `CallStack`\n\n##### parentCall?\n\n> `optional` **parentCall**: `CallStackEntry`\n\n#### Defined in\n\n[weaveClient.ts:541](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L541)\n\n***\n\n### runWithCallStack()\n\n> **runWithCallStack**\\(`callStack`, `fn`): `T`\n\n#### Type Parameters\n\n\u2022 **T**\n\n#### Parameters\n\n\u2022 **callStack**: `CallStack`\n\n\u2022 **fn**\n\n#### Returns\n\n`T`\n\n#### Defined in\n\n[weaveClient.ts:545](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L545)\n\n***\n\n### saveOp()\n\n> **saveOp**(`op`, `objId`?): `Promise`\\\n\n#### Parameters\n\n\u2022 **op**: [`Op`](../type-aliases/Op.md)\\ `any`\\>\n\n\u2022 **objId?**: `string`\n\n#### Returns\n\n`Promise`\\\n\n#### Defined in\n\n[weaveClient.ts:575](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L575)\n\n***\n\n### waitForBatchProcessing()\n\n> **waitForBatchProcessing**(): `Promise`\\\n\n#### Returns\n\n`Promise`\\\n\n#### Defined in\n\n[weaveClient.ts:103](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveClient.ts#L103)"
  },
  {
    "title": "Dataset",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/classes/Dataset",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "[**weave**](../README.md) \u2022 **Docs**\n\n***\n\n[weave](../README.md) / Dataset\n\n# Class: Dataset\\\n\nDataset object with easy saving and automatic versioning\n\n## Example\n\n```ts\n// Create a dataset\nconst dataset = new Dataset({\n  id: 'grammar-dataset',\n  rows: [\n    { id: '0', sentence: \"He no likes ice cream.\", correction: \"He doesn't like ice cream.\" },\n    { id: '1', sentence: \"She goed to the store.\", correction: \"She went to the store.\" },\n    { id: '2', sentence: \"They plays video games all day.\", correction: \"They play video games all day.\" }\n  ]\n})\n\n// Access a specific example\nconst exampleLabel = dataset.getRow(2).sentence;\n\n// Save the dataset\nconst ref = await dataset.save()\n```\n\n## Extends\n\n- [`WeaveObject`](WeaveObject.md)\n\n## Type Parameters\n\n\u2022 **R** *extends* `DatasetRow`\n\n## Constructors\n\n### new Dataset()\n\n> **new Dataset**\\(`parameters`): [`Dataset`](Dataset.md)\\\n\n#### Parameters\n\n\u2022 **parameters**: `DatasetParameters`\\\n\n#### Returns\n\n[`Dataset`](Dataset.md)\\\n\n#### Overrides\n\n[`WeaveObject`](WeaveObject.md).[`constructor`](WeaveObject.md#constructors)\n\n#### Defined in\n\n[dataset.ts:51](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/dataset.ts#L51)\n\n## Properties\n\n### \\_\\_savedRef?\n\n> `optional` **\\_\\_savedRef**: `ObjectRef` \\| `Promise`\\\n\n#### Inherited from\n\n[`WeaveObject`](WeaveObject.md).[`__savedRef`](WeaveObject.md#__savedref)\n\n#### Defined in\n\n[weaveObject.ts:49](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L49)\n\n***\n\n### \\_baseParameters\n\n> `protected` **\\_baseParameters**: `WeaveObjectParameters`\n\n#### Inherited from\n\n[`WeaveObject`](WeaveObject.md).[`_baseParameters`](WeaveObject.md#_baseparameters)\n\n#### Defined in\n\n[weaveObject.ts:51](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L51)\n\n***\n\n### rows\n\n> **rows**: `Table`\\\n\n#### Defined in\n\n[dataset.ts:49](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/dataset.ts#L49)\n\n## Accessors\n\n### description\n\n> `get` **description**(): `undefined` \\| `string`\n\n#### Returns\n\n`undefined` \\| `string`\n\n#### Inherited from\n\n[`WeaveObject`](WeaveObject.md).[`description`](WeaveObject.md#description)\n\n#### Defined in\n\n[weaveObject.ts:89](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L89)\n\n***\n\n### id\n\n> `get` **id**(): `string`\n\n#### Returns\n\n`string`\n\n#### Inherited from\n\n[`WeaveObject`](WeaveObject.md).[`id`](WeaveObject.md#id)\n\n#### Defined in\n\n[weaveObject.ts:85](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L85)\n\n***\n\n### length\n\n> `get` **length**(): `number`\n\n#### Returns\n\n`number`\n\n#### Defined in\n\n[dataset.ts:64](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/dataset.ts#L64)\n\n## Methods\n\n### \\[asyncIterator\\]()\n\n> **\\[asyncIterator\\]**(): `AsyncIterator`\\\n\n#### Returns\n\n`AsyncIterator`\\\n\n#### Defined in\n\n[dataset.ts:68](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/dataset.ts#L68)\n\n***\n\n### className()\n\n> **className**(): `any`\n\n#### Returns\n\n`any`\n\n#### Inherited from\n\n[`WeaveObject`](WeaveObject.md).[`className`](WeaveObject.md#classname)\n\n#### Defined in\n\n[weaveObject.ts:53](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L53)\n\n***\n\n### getRow()\n\n> **getRow**(`index`): `R`\n\n#### Parameters\n\n\u2022 **index**: `number`\n\n#### Returns\n\n`R`\n\n#### Defined in\n\n[dataset.ts:74](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/dataset.ts#L74)\n\n***\n\n### save()\n\n> **save**(): `Promise`\\\n\n#### Returns\n\n`Promise`\\\n\n#### Defined in\n\n[dataset.ts:60](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/dataset.ts#L60)\n\n***\n\n### saveAttrs()\n\n> **saveAttrs**(): `object`\n\n#### Returns\n\n`object`\n\n#### Inherited from\n\n[`WeaveObject`](WeaveObject.md).[`saveAttrs`](WeaveObject.md#saveattrs)\n\n#### Defined in\n\n[weaveObject.ts:57](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L57)"
  },
  {
    "title": "Weaveobject",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/classes/WeaveObject",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "[**weave**](../README.md) \u2022 **Docs**\n\n***\n\n[weave](../README.md) / WeaveObject\n\n# Class: WeaveObject\n\n## Extended by\n\n- [`Dataset`](Dataset.md)\n- [`Evaluation`](Evaluation.md)\n\n## Constructors\n\n### new WeaveObject()\n\n> **new WeaveObject**(`_baseParameters`): [`WeaveObject`](WeaveObject.md)\n\n#### Parameters\n\n\u2022 **\\_baseParameters**: `WeaveObjectParameters`\n\n#### Returns\n\n[`WeaveObject`](WeaveObject.md)\n\n#### Defined in\n\n[weaveObject.ts:51](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L51)\n\n## Properties\n\n### \\_\\_savedRef?\n\n> `optional` **\\_\\_savedRef**: `ObjectRef` \\| `Promise`\\\n\n#### Defined in\n\n[weaveObject.ts:49](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L49)\n\n***\n\n### \\_baseParameters\n\n> `protected` **\\_baseParameters**: `WeaveObjectParameters`\n\n#### Defined in\n\n[weaveObject.ts:51](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L51)\n\n## Accessors\n\n### description\n\n> `get` **description**(): `undefined` \\| `string`\n\n#### Returns\n\n`undefined` \\| `string`\n\n#### Defined in\n\n[weaveObject.ts:89](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L89)\n\n***\n\n### id\n\n> `get` **id**(): `string`\n\n#### Returns\n\n`string`\n\n#### Defined in\n\n[weaveObject.ts:85](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L85)\n\n## Methods\n\n### className()\n\n> **className**(): `any`\n\n#### Returns\n\n`any`\n\n#### Defined in\n\n[weaveObject.ts:53](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L53)\n\n***\n\n### saveAttrs()\n\n> **saveAttrs**(): `object`\n\n#### Returns\n\n`object`\n\n#### Defined in\n\n[weaveObject.ts:57](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L57)"
  },
  {
    "title": "Evaluation",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/classes/Evaluation",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "[**weave**](../README.md) \u2022 **Docs**\n\n***\n\n[weave](../README.md) / Evaluation\n\n# Class: Evaluation\\\n\nSets up an evaluation which includes a set of scorers and a dataset.\n\nCalling evaluation.evaluate(model) will pass in rows form a dataset into a model matching\nthe names of the columns of the dataset to the argument names in model.predict.\n\nThen it will call all of the scorers and save the results in weave.\n\n## Example\n\n```ts\n// Collect your examples into a dataset\nconst dataset = new weave.Dataset({\n  id: 'my-dataset',\n  rows: [\n    { question: 'What is the capital of France?', expected: 'Paris' },\n    { question: 'Who wrote \"To Kill a Mockingbird\"?', expected: 'Harper Lee' },\n    { question: 'What is the square root of 64?', expected: '8' },\n  ],\n});\n\n// Define any custom scoring function\nconst scoringFunction = weave.op(function isEqual({ modelOutput, datasetRow }) {\n  return modelOutput == datasetRow.expected;\n});\n\n// Define the function to evaluate\nconst model = weave.op(async function alwaysParisModel({ question }) {\n  return 'Paris';\n});\n\n// Start evaluating\nconst evaluation = new weave.Evaluation({\n  id: 'my-evaluation',\n  dataset: dataset,\n  scorers: [scoringFunction],\n});\n\nconst results = await evaluation.evaluate({ model });\n```\n\n## Extends\n\n- [`WeaveObject`](WeaveObject.md)\n\n## Type Parameters\n\n\u2022 **R** *extends* `DatasetRow`\n\n\u2022 **E** *extends* `DatasetRow`\n\n\u2022 **M**\n\n## Constructors\n\n### new Evaluation()\n\n> **new Evaluation**\\(`parameters`): [`Evaluation`](Evaluation.md)\\\n\n#### Parameters\n\n\u2022 **parameters**: `EvaluationParameters`\\\n\n#### Returns\n\n[`Evaluation`](Evaluation.md)\\\n\n#### Overrides\n\n[`WeaveObject`](WeaveObject.md).[`constructor`](WeaveObject.md#constructors)\n\n#### Defined in\n\n[evaluation.ts:148](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/evaluation.ts#L148)\n\n## Properties\n\n### \\_\\_savedRef?\n\n> `optional` **\\_\\_savedRef**: `ObjectRef` \\| `Promise`\\\n\n#### Inherited from\n\n[`WeaveObject`](WeaveObject.md).[`__savedRef`](WeaveObject.md#__savedref)\n\n#### Defined in\n\n[weaveObject.ts:49](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L49)\n\n***\n\n### \\_baseParameters\n\n> `protected` **\\_baseParameters**: `WeaveObjectParameters`\n\n#### Inherited from\n\n[`WeaveObject`](WeaveObject.md).[`_baseParameters`](WeaveObject.md#_baseparameters)\n\n#### Defined in\n\n[weaveObject.ts:51](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L51)\n\n## Accessors\n\n### description\n\n> `get` **description**(): `undefined` \\| `string`\n\n#### Returns\n\n`undefined` \\| `string`\n\n#### Inherited from\n\n[`WeaveObject`](WeaveObject.md).[`description`](WeaveObject.md#description)\n\n#### Defined in\n\n[weaveObject.ts:89](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L89)\n\n***\n\n### id\n\n> `get` **id**(): `string`\n\n#### Returns\n\n`string`\n\n#### Inherited from\n\n[`WeaveObject`](WeaveObject.md).[`id`](WeaveObject.md#id)\n\n#### Defined in\n\n[weaveObject.ts:85](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L85)\n\n## Methods\n\n### className()\n\n> **className**(): `any`\n\n#### Returns\n\n`any`\n\n#### Inherited from\n\n[`WeaveObject`](WeaveObject.md).[`className`](WeaveObject.md#classname)\n\n#### Defined in\n\n[weaveObject.ts:53](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L53)\n\n***\n\n### evaluate()\n\n> **evaluate**(`__namedParameters`): `Promise`\\\\>\n\n#### Parameters\n\n\u2022 **\\_\\_namedParameters**\n\n\u2022 **\\_\\_namedParameters.maxConcurrency?**: `number` = `5`\n\n\u2022 **\\_\\_namedParameters.model**: `WeaveCallable`\\ `Promise`\\\\>\n\n\u2022 **\\_\\_namedParameters.nTrials?**: `number` = `1`\n\n#### Returns\n\n`Promise`\\\\>\n\n#### Defined in\n\n[evaluation.ts:163](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/evaluation.ts#L163)\n\n***\n\n### predictAndScore()\n\n> **predictAndScore**(`__namedParameters`): `Promise`\\\n\n#### Parameters\n\n\u2022 **\\_\\_namedParameters**\n\n\u2022 **\\_\\_namedParameters.columnMapping?**: `ColumnMapping`\\\n\n\u2022 **\\_\\_namedParameters.example**: `R`\n\n\u2022 **\\_\\_namedParameters.model**: `WeaveCallable`\\ `Promise`\\\\>\n\n#### Returns\n\n`Promise`\\\n\n##### model\\_latency\n\n> **model\\_latency**: `number` = `modelLatency`\n\n##### model\\_output\n\n> **model\\_output**: `any` = `modelOutput`\n\n##### model\\_success\n\n> **model\\_success**: `boolean` = `!modelError`\n\n##### scores\n\n> **scores**: `object`\n\n###### Index Signature\n\n \\[`key`: `string`\\]: `any`\n\n#### Defined in\n\n[evaluation.ts:232](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/evaluation.ts#L232)\n\n***\n\n### saveAttrs()\n\n> **saveAttrs**(): `object`\n\n#### Returns\n\n`object`\n\n#### Inherited from\n\n[`WeaveObject`](WeaveObject.md).[`saveAttrs`](WeaveObject.md#saveattrs)\n\n#### Defined in\n\n[weaveObject.ts:57](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/weaveObject.ts#L57)"
  },
  {
    "title": "Op",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/type-aliases/Op",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "[**weave**](../README.md) \u2022 **Docs**\n\n***\n\n[weave](../README.md) / Op\n\n# Type Alias: Op\\\n\n> **Op**\\: `object` & `T`\n\n## Type declaration\n\n### \\_\\_boundThis?\n\n> `optional` **\\_\\_boundThis**: [`WeaveObject`](../classes/WeaveObject.md)\n\n### \\_\\_isOp\n\n> **\\_\\_isOp**: `true`\n\n### \\_\\_name\n\n> **\\_\\_name**: `string`\n\n### \\_\\_savedRef?\n\n> `optional` **\\_\\_savedRef**: `OpRef` \\| `Promise`\\\n\n### \\_\\_wrappedFunction\n\n> **\\_\\_wrappedFunction**: `T`\n\n## Type Parameters\n\n\u2022 **T** *extends* (...`args`) => `any`\n\n## Defined in\n\n[opType.ts:6](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/opType.ts#L6)"
  },
  {
    "title": "Requirecurrentcallstackentry",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/requireCurrentCallStackEntry",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "[**weave**](../README.md) \u2022 **Docs**\n\n***\n\n[weave](../README.md) / requireCurrentCallStackEntry\n\n# Function: requireCurrentCallStackEntry()\n\n> **requireCurrentCallStackEntry**(): `CallStackEntry`\n\n## Returns\n\n`CallStackEntry`\n\n## Defined in\n\n[clientApi.ts:119](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/clientApi.ts#L119)"
  },
  {
    "title": "Weaveaudio",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/weaveAudio",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "[**weave**](../README.md) \u2022 **Docs**\n\n***\n\n[weave](../README.md) / weaveAudio\n\n# Function: weaveAudio()\n\n> **weaveAudio**(`options`): `WeaveAudio`\n\nCreate a new WeaveAudio object\n\n## Parameters\n\n\u2022 **options**: `WeaveAudioInput`\n\nThe options for this media type\n   - data: The raw audio data as a Buffer\n   - audioType: (Optional) The type of audio file, currently only 'wav' is supported\n\n## Returns\n\n`WeaveAudio`\n\n## Example\n\n```ts\nconst audioBuffer = fs.readFileSync('path/to/audio.wav');\nconst weaveAudio = weaveAudio({ data: audioBuffer });\n```\n\n## Defined in\n\n[media.ts:62](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/media.ts#L62)"
  },
  {
    "title": "Weaveimage",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/weaveImage",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "[**weave**](../README.md) \u2022 **Docs**\n\n***\n\n[weave](../README.md) / weaveImage\n\n# Function: weaveImage()\n\n> **weaveImage**(`options`): `WeaveImage`\n\nCreate a new WeaveImage object\n\n## Parameters\n\n\u2022 **options**: `WeaveImageInput`\n\nThe options for this media type\n   - data: The raw image data as a Buffer\n   - imageType: (Optional) The type of image file, currently only 'png' is supported\n\n## Returns\n\n`WeaveImage`\n\n## Example\n\n```ts\nconst imageBuffer = fs.readFileSync('path/to/image.png');\nconst weaveImage = weaveImage({ data: imageBuffer });\n```\n\n## Defined in\n\n[media.ts:28](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/media.ts#L28)"
  },
  {
    "title": "Op",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/op",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "[**weave**](../README.md) \u2022 **Docs**\n\n***\n\n[weave](../README.md) / op\n\n# Function: op()\n\n## op(fn, options)\n\n> **op**\\(`fn`, `options`?): [`Op`](../type-aliases/Op.md)\\ `Promise`\\\\>\\>\\>\n\nA wrapper to weave op-ify a function or method that works on sync and async functions.\n\nWrapped functions:\n 1. Take the same inputs and return the same outputs as the original function.\n 2. Will automatically track calls in the Weave UI.\n\nIf you don't call `weave.init` then the function will behave as if it were not wrapped.\n\n### Type Parameters\n\n\u2022 **T** *extends* (...`args`) => `any`\n\n### Parameters\n\n\u2022 **fn**: `T`\n\nThe function to wrap\n\n\u2022 **options?**: `OpOptions`\\\n\nOptional configs like call and param naming\n\n### Returns\n\n[`Op`](../type-aliases/Op.md)\\ `Promise`\\\\>\\>\\>\n\nThe wrapped function\n\n### Example\n\n```ts\n// Basic usage\n\nconst client = await weave.init({ project: 'my-project' });\nconst oaiClient = weave.wrapOpenAI(new OpenAI());\n\nconst extract = weave.op(async function extract() {\n  return await oaiClient.chat.completions.create({\n    model: 'gpt-4-turbo',\n    messages: [{ role: 'user', content: 'Create a user as JSON' }],\n  });\n});\n\nawait extract();\n\n// You can also wrap methods by passing the object as the first argument.\n// This will bind the method to the object and wrap it with op.\nclass MyModel {\n  private oaiClient: OpenAI;\n\n  constructor() {\n    this.oaiClient = weave.wrapOpenAI(new OpenAI());\n    this.invoke = weave.op(this, this.invoke);\n  }\n\n  async invoke() {\n    return await this.oaiClient.chat.completions.create({\n      model: 'gpt-4-turbo',\n      messages: [{ role: 'user', content: 'Create a user as JSON' }],\n    });\n  }\n}\n\nconst model = new MyModel();\nconst res = await model.invoke();\n```\n\n### Defined in\n\n[op.ts:58](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/op.ts#L58)\n\n## op(thisArg, fn, options)\n\n> **op**\\(`thisArg`, `fn`, `options`?): [`Op`](../type-aliases/Op.md)\\ `Promise`\\\\>\\>\\>\n\n### Type Parameters\n\n\u2022 **T** *extends* (...`args`) => `any`\n\n### Parameters\n\n\u2022 **thisArg**: `any`\n\n\u2022 **fn**: `T`\n\n\u2022 **options?**: `OpOptions`\\\n\n### Returns\n\n[`Op`](../type-aliases/Op.md)\\ `Promise`\\\\>\\>\\>\n\n### Defined in\n\n[op.ts:62](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/op.ts#L62)"
  },
  {
    "title": "Login",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/login",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "[**weave**](../README.md) \u2022 **Docs**\n\n***\n\n[weave](../README.md) / login\n\n# Function: login()\n\n> **login**(`apiKey`, `host`?): `Promise`\\\n\nLog in to Weights & Biases (W&B) using the provided API key.\nThis function saves the credentials to your netrc file for future use.\n\n## Parameters\n\n\u2022 **apiKey**: `string`\n\nYour W&B API key.\n\n\u2022 **host?**: `string` = `defaultHost`\n\n(Optional) The host name (usually only needed if you're using a custom W&B server).\n\n## Returns\n\n`Promise`\\\n\n## Throws\n\nIf the API key is not specified or if the connection to the weave trace server cannot be verified.\n\n## Defined in\n\n[clientApi.ts:22](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/clientApi.ts#L22)"
  },
  {
    "title": "Init",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/init",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "[**weave**](../README.md) \u2022 **Docs**\n\n***\n\n[weave](../README.md) / init\n\n# Function: init()\n\n> **init**(`project`, `settings`?): `Promise`\\\n\nInitialize the Weave client, which is required for weave tracing to work.\n\n## Parameters\n\n\u2022 **project**: `string`\n\nThe W&B project name (can be project or entity/project).\n\n\u2022 **settings?**: `Settings`\n\n(Optional) Weave tracing settings\n\n## Returns\n\n`Promise`\\\n\nA promise that resolves to the initialized Weave client.\n\n## Throws\n\nIf the initialization fails\n\n## Defined in\n\n[clientApi.ts:57](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/clientApi.ts#L57)"
  },
  {
    "title": "Wrapopenai",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/wrapOpenAI",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "[**weave**](../README.md) \u2022 **Docs**\n\n***\n\n[weave](../README.md) / wrapOpenAI\n\n# Function: wrapOpenAI()\n\n> **wrapOpenAI**\\(`openai`): `T`\n\nWraps the OpenAI API to enable function tracing for OpenAI calls.\n\n## Type Parameters\n\n\u2022 **T** *extends* `OpenAIAPI`\n\n## Parameters\n\n\u2022 **openai**: `T`\n\n## Returns\n\n`T`\n\n## Example\n\n```ts\nconst openai = wrapOpenAI(new OpenAI());\nconst result = await openai.chat.completions.create({\n  model: 'gpt-3.5-turbo',\n  messages: [{ role: 'user', content: 'Hello, world!' }]\n});\n```\n\n## Defined in\n\n[integrations/openai.ts:159](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/integrations/openai.ts#L159)"
  },
  {
    "title": "Requirecurrentchildsummary",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/functions/requireCurrentChildSummary",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "[**weave**](../README.md) \u2022 **Docs**\n\n***\n\n[weave](../README.md) / requireCurrentChildSummary\n\n# Function: requireCurrentChildSummary()\n\n> **requireCurrentChildSummary**(): `object`\n\n## Returns\n\n`object`\n\n## Defined in\n\n[clientApi.ts:131](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/clientApi.ts#L131)"
  },
  {
    "title": "Callsfilter",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/interfaces/CallsFilter",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "[**weave**](../README.md) \u2022 **Docs**\n\n***\n\n[weave](../README.md) / CallsFilter\n\n# Interface: CallsFilter\n\nCallsFilter\n\n## Properties\n\n### call\\_ids?\n\n> `optional` **call\\_ids**: `null` \\| `string`[]\n\nCall Ids\n\n#### Defined in\n\n[generated/traceServerApi.ts:197](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L197)\n\n***\n\n### input\\_refs?\n\n> `optional` **input\\_refs**: `null` \\| `string`[]\n\nInput Refs\n\n#### Defined in\n\n[generated/traceServerApi.ts:189](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L189)\n\n***\n\n### op\\_names?\n\n> `optional` **op\\_names**: `null` \\| `string`[]\n\nOp Names\n\n#### Defined in\n\n[generated/traceServerApi.ts:187](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L187)\n\n***\n\n### output\\_refs?\n\n> `optional` **output\\_refs**: `null` \\| `string`[]\n\nOutput Refs\n\n#### Defined in\n\n[generated/traceServerApi.ts:191](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L191)\n\n***\n\n### parent\\_ids?\n\n> `optional` **parent\\_ids**: `null` \\| `string`[]\n\nParent Ids\n\n#### Defined in\n\n[generated/traceServerApi.ts:193](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L193)\n\n***\n\n### trace\\_ids?\n\n> `optional` **trace\\_ids**: `null` \\| `string`[]\n\nTrace Ids\n\n#### Defined in\n\n[generated/traceServerApi.ts:195](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L195)\n\n***\n\n### trace\\_roots\\_only?\n\n> `optional` **trace\\_roots\\_only**: `null` \\| `boolean`\n\nTrace Roots Only\n\n#### Defined in\n\n[generated/traceServerApi.ts:199](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L199)\n\n***\n\n### wb\\_run\\_ids?\n\n> `optional` **wb\\_run\\_ids**: `null` \\| `string`[]\n\nWb Run Ids\n\n#### Defined in\n\n[generated/traceServerApi.ts:203](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L203)\n\n***\n\n### wb\\_user\\_ids?\n\n> `optional` **wb\\_user\\_ids**: `null` \\| `string`[]\n\nWb User Ids\n\n#### Defined in\n\n[generated/traceServerApi.ts:201](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L201)"
  },
  {
    "title": "Callschema",
    "url": "https://weave-docs.wandb.ai/reference/typescript-sdk/weave/interfaces/CallSchema",
    "section": "Docs",
    "category": "TypeScript SDK",
    "content": "[**weave**](../README.md) \u2022 **Docs**\n\n***\n\n[weave](../README.md) / CallSchema\n\n# Interface: CallSchema\n\nCallSchema\n\n## Properties\n\n### attributes\n\n> **attributes**: `object`\n\nAttributes\n\n#### Defined in\n\n[generated/traceServerApi.ts:119](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L119)\n\n***\n\n### deleted\\_at?\n\n> `optional` **deleted\\_at**: `null` \\| `string`\n\nDeleted At\n\n#### Defined in\n\n[generated/traceServerApi.ts:134](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L134)\n\n***\n\n### display\\_name?\n\n> `optional` **display\\_name**: `null` \\| `string`\n\nDisplay Name\n\n#### Defined in\n\n[generated/traceServerApi.ts:108](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L108)\n\n***\n\n### ended\\_at?\n\n> `optional` **ended\\_at**: `null` \\| `string`\n\nEnded At\n\n#### Defined in\n\n[generated/traceServerApi.ts:123](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L123)\n\n***\n\n### exception?\n\n> `optional` **exception**: `null` \\| `string`\n\nException\n\n#### Defined in\n\n[generated/traceServerApi.ts:125](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L125)\n\n***\n\n### id\n\n> **id**: `string`\n\nId\n\n#### Defined in\n\n[generated/traceServerApi.ts:102](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L102)\n\n***\n\n### inputs\n\n> **inputs**: `object`\n\nInputs\n\n#### Defined in\n\n[generated/traceServerApi.ts:121](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L121)\n\n***\n\n### op\\_name\n\n> **op\\_name**: `string`\n\nOp Name\n\n#### Defined in\n\n[generated/traceServerApi.ts:106](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L106)\n\n***\n\n### output?\n\n> `optional` **output**: `null`\n\nOutput\n\n#### Defined in\n\n[generated/traceServerApi.ts:127](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L127)\n\n***\n\n### parent\\_id?\n\n> `optional` **parent\\_id**: `null` \\| `string`\n\nParent Id\n\n#### Defined in\n\n[generated/traceServerApi.ts:112](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L112)\n\n***\n\n### project\\_id\n\n> **project\\_id**: `string`\n\nProject Id\n\n#### Defined in\n\n[generated/traceServerApi.ts:104](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L104)\n\n***\n\n### started\\_at\n\n> **started\\_at**: `string`\n\nStarted At\n\n#### Format\n\ndate-time\n\n#### Defined in\n\n[generated/traceServerApi.ts:117](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L117)\n\n***\n\n### summary?\n\n> `optional` **summary**: `object`\n\n#### Defined in\n\n[generated/traceServerApi.ts:128](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L128)\n\n***\n\n### trace\\_id\n\n> **trace\\_id**: `string`\n\nTrace Id\n\n#### Defined in\n\n[generated/traceServerApi.ts:110](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L110)\n\n***\n\n### wb\\_run\\_id?\n\n> `optional` **wb\\_run\\_id**: `null` \\| `string`\n\nWb Run Id\n\n#### Defined in\n\n[generated/traceServerApi.ts:132](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L132)\n\n***\n\n### wb\\_user\\_id?\n\n> `optional` **wb\\_user\\_id**: `null` \\| `string`\n\nWb User Id\n\n#### Defined in\n\n[generated/traceServerApi.ts:130](https://github.com/wandb/weave/blob/e2313369cb35bc1b6f97c70539926dd951ead21e/sdks/node/src/generated/traceServerApi.ts#L130)"
  },
  {
    "title": "Index",
    "url": "https://weave-docs.wandb.ai/reference/python-sdk/weave/index",
    "section": "Docs",
    "category": "Python SDK",
    "content": "# weave\n\nThe top-level functions and classes for working with Weave.\n\n---\n\n\n# API Overview\n\n\n\n## Classes\n\n- [`obj.Object`](#class-object)\n- [`dataset.Dataset`](#class-dataset): Dataset object with easy saving and automatic versioning\n- [`model.Model`](#class-model): Intended to capture a combination of code and data the operates on an input.\n- [`prompt.Prompt`](#class-prompt)\n- [`prompt.StringPrompt`](#class-stringprompt)\n- [`prompt.MessagesPrompt`](#class-messagesprompt)\n- [`eval.Evaluation`](#class-evaluation): Sets up an evaluation which includes a set of scorers and a dataset.\n- [`eval_imperative.EvaluationLogger`](#class-evaluationlogger): This class provides an imperative interface for logging evaluations.\n- [`scorer.Scorer`](#class-scorer)\n- [`annotation_spec.AnnotationSpec`](#class-annotationspec)\n- [`markdown.Markdown`](#class-markdown): A Markdown renderable.\n- [`monitor.Monitor`](#class-monitor): Sets up a monitor to score incoming calls automatically.\n- [`saved_view.SavedView`](#class-savedview): A fluent-style class for working with SavedView objects.\n\n## Functions\n\n- [`api.init`](#function-init): Initialize weave tracking, logging to a wandb project.\n- [`api.publish`](#function-publish): Save and version a python object.\n- [`api.ref`](#function-ref): Construct a Ref to a Weave object.\n- [`call_context.require_current_call`](#function-require_current_call): Get the Call object for the currently executing Op, within that Op.\n- [`call_context.get_current_call`](#function-get_current_call): Get the Call object for the currently executing Op, within that Op.\n- [`api.finish`](#function-finish): Stops logging to weave.\n- [`op.op`](#function-op): A decorator to weave op-ify a function or method. Works for both sync and async.\n- [`api.attributes`](#function-attributes): Context manager for setting attributes on a call.\n\n\n---\n\n\n\n\n### function `init`\n\n```python\ninit(\n    project_name: 'str',\n    settings: 'UserSettings | dict[str, Any] | None' = None,\n    autopatch_settings: 'AutopatchSettings | None' = None,\n    global_postprocess_inputs: 'PostprocessInputsFunc | None' = None,\n    global_postprocess_output: 'PostprocessOutputFunc | None' = None,\n    global_attributes: 'dict[str, Any] | None' = None\n) \u2192 WeaveClient\n```\n\nInitialize weave tracking, logging to a wandb project. \n\nLogging is initialized globally, so you do not need to keep a reference to the return value of init. \n\nFollowing init, calls of weave.op() decorated functions will be logged to the specified project. \n\n\n\n**Args:**\n \n - `project_name`:  The name of the Weights & Biases project to log to. \n - `settings`:  Configuration for the Weave client generally. \n - `autopatch_settings`:  Configuration for autopatch integrations, e.g. openai \n - `global_postprocess_inputs`:  A function that will be applied to all inputs of all ops. \n - `global_postprocess_output`:  A function that will be applied to all outputs of all ops. \n - `global_attributes`:  A dictionary of attributes that will be applied to all traces. \n\nNOTE: Global postprocessing settings are applied to all ops after each op's own postprocessing.  The order is always: 1. Op-specific postprocessing 2. Global postprocessing \n\n\n\n**Returns:**\n A Weave client. \n\n---\n\n\n\n### function `publish`\n\n```python\npublish(obj: 'Any', name: 'str | None' = None) \u2192 ObjectRef\n```\n\nSave and version a python object. \n\nIf an object with name already exists, and the content hash of obj does not match the latest version of that object, a new version will be created. \n\nTODO: Need to document how name works with this change. \n\n\n\n**Args:**\n \n - `obj`:  The object to save and version. \n - `name`:  The name to save the object under. \n\n\n\n**Returns:**\n A weave Ref to the saved object. \n\n---\n\n\n\n### function `ref`\n\n```python\nref(location: 'str') \u2192 ObjectRef\n```\n\nConstruct a Ref to a Weave object. \n\nTODO: what happens if obj does not exist \n\n\n\n**Args:**\n \n - `location`:  A fully-qualified weave ref URI, or if weave.init() has been called, \"name:version\" or just \"name\" (\"latest\" will be used for version in this case). \n\n\n\n\n\n**Returns:**\n A weave Ref to the object. \n\n---\n\n\n\n### function `require_current_call`\n\n```python\nrequire_current_call() \u2192 Call\n```\n\nGet the Call object for the currently executing Op, within that Op. \n\nThis allows you to access attributes of the Call such as its id or feedback while it is running. \n\n```python\n@weave.op\ndef hello(name: str) -> None:\n     print(f\"Hello {name}!\")\n     current_call = weave.require_current_call()\n     print(current_call.id)\n``` \n\nIt is also possible to access a Call after the Op has returned. \n\nIf you have the Call's id, perhaps from the UI, you can use the `get_call` method on the `WeaveClient` returned from `weave.init` to retrieve the Call object. \n\n```python\nclient = weave.init(\"\")\nmycall = client.get_call(\"\")\n``` \n\nAlternately, after defining your Op you can use its `call` method. For example: \n\n```python\n@weave.op\ndef add(a: int, b: int) -> int:\n     return a + b\n\nresult, call = add.call(1, 2)\nprint(call.id)\n``` \n\n\n\n**Returns:**\n  The Call object for the currently executing Op \n\n\n\n**Raises:**\n \n - `NoCurrentCallError`:  If tracking has not been initialized or this method is  invoked outside an Op. \n\n---\n\n\n\n### function `get_current_call`\n\n```python\nget_current_call() \u2192 Call | None\n```\n\nGet the Call object for the currently executing Op, within that Op. \n\n\n\n**Returns:**\n  The Call object for the currently executing Op, or  None if tracking has not been initialized or this method is  invoked outside an Op. \n\n---\n\n\n\n### function `finish`\n\n```python\nfinish() \u2192 None\n```\n\nStops logging to weave. \n\nFollowing finish, calls of weave.op() decorated functions will no longer be logged. You will need to run weave.init() again to resume logging. \n\n---\n\n\n\n### function `op`\n\n```python\nop(\n    func: 'Callable[P, R] | None' = None,\n    name: 'str | None' = None,\n    call_display_name: 'str | CallDisplayNameFunc | None' = None,\n    postprocess_inputs: 'PostprocessInputsFunc | None' = None,\n    postprocess_output: 'PostprocessOutputFunc | None' = None,\n    tracing_sample_rate: 'float' = 1.0,\n    enable_code_capture: 'bool' = True\n) \u2192 Callable[[Callable[P, R]], Op[P, R]] | Op[P, R]\n```\n\nA decorator to weave op-ify a function or method. Works for both sync and async. Automatically detects iterator functions and applies appropriate behavior. \n\n---\n\n\n\n### function `attributes`\n\n```python\nattributes(attributes: 'dict[str, Any]') \u2192 Iterator\n```\n\nContext manager for setting attributes on a call. \n\n\n\n**Example:**\n \n\n```python\nwith weave.attributes({'env': 'production'}):\n     print(my_function.call(\"World\"))\n``` \n\n---\n\n\n\n## class `Object`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `name`: `typing.Optional[str]`\n- `description`: `typing.Optional[str]`\n- `ref`: `typing.Optional[trace.refs.ObjectRef]`\n---\n\n\n\n### classmethod `from_uri`\n\n```python\nfrom_uri(uri: str, objectify: bool = True) \u2192 Self\n```\n\n\n\n\n\n---\n\n\n\n### classmethod `handle_relocatable_object`\n\n```python\nhandle_relocatable_object(\n    v: Any,\n    handler: ValidatorFunctionWrapHandler,\n    info: ValidationInfo\n) \u2192 Any\n```\n\n\n\n\n\n\n---\n\n\n\n## class `Dataset`\nDataset object with easy saving and automatic versioning \n\n\n\n**Examples:**\n \n\n```python\n# Create a dataset\ndataset = Dataset(name='grammar', rows=[\n     {'id': '0', 'sentence': \"He no likes ice cream.\", 'correction': \"He doesn't like ice cream.\"},\n     {'id': '1', 'sentence': \"She goed to the store.\", 'correction': \"She went to the store.\"},\n     {'id': '2', 'sentence': \"They plays video games all day.\", 'correction': \"They play video games all day.\"}\n])\n\n# Publish the dataset\nweave.publish(dataset)\n\n# Retrieve the dataset\ndataset_ref = weave.ref('grammar').get()\n\n# Access a specific example\nexample_label = dataset_ref.rows[2]['sentence']\n``` \n\n\n**Pydantic Fields:**\n\n- `name`: `typing.Optional[str]`\n- `description`: `typing.Optional[str]`\n- `ref`: `typing.Optional[trace.refs.ObjectRef]`\n- `rows`: `typing.Union[trace.table.Table, trace.vals.WeaveTable]`\n---\n\n\n\n### method `add_rows`\n\n```python\nadd_rows(rows: Iterable[dict]) \u2192 Dataset\n```\n\nCreate a new dataset version by appending rows to the existing dataset. \n\nThis is useful for adding examples to large datasets without having to load the entire dataset into memory. \n\n\n\n**Args:**\n \n - `rows`:  The rows to add to the dataset. \n\n\n\n**Returns:**\n The updated dataset. \n\n---\n\n\n\n### classmethod `convert_to_table`\n\n```python\nconvert_to_table(rows: Any) \u2192 Union[Table, WeaveTable]\n```\n\n\n\n\n\n---\n\n\n\n### classmethod `from_calls`\n\n```python\nfrom_calls(calls: Iterable[Call]) \u2192 Self\n```\n\n\n\n\n\n---\n\n\n\n### classmethod `from_obj`\n\n```python\nfrom_obj(obj: WeaveObject) \u2192 Self\n```\n\n\n\n\n\n---\n\n\n\n### classmethod `from_pandas`\n\n```python\nfrom_pandas(df: 'DataFrame') \u2192 Self\n```\n\n\n\n\n\n---\n\n\n\n### method `to_pandas`\n\n```python\nto_pandas() \u2192 DataFrame\n```\n\n\n\n\n\n\n---\n\n\n\n## class `Model`\nIntended to capture a combination of code and data the operates on an input. For example it might call an LLM with a prompt to make a prediction or generate text. \n\nWhen you change the attributes or the code that defines your model, these changes will be logged and the version will be updated. This ensures that you can compare the predictions across different versions of your model. Use this to iterate on prompts or to try the latest LLM and compare predictions across different settings \n\n\n\n**Examples:**\n \n\n```python\nclass YourModel(Model):\n     attribute1: str\n     attribute2: int\n\n     @weave.op()\n     def predict(self, input_data: str) -> dict:\n         # Model logic goes here\n         prediction = self.attribute1 + ' ' + input_data\n         return {'pred': prediction}\n``` \n\n\n**Pydantic Fields:**\n\n- `name`: `typing.Optional[str]`\n- `description`: `typing.Optional[str]`\n- `ref`: `typing.Optional[trace.refs.ObjectRef]`\n---\n\n\n\n### method `get_infer_method`\n\n```python\nget_infer_method() \u2192 Callable\n```\n\n\n\n\n\n\n---\n\n\n\n## class `Prompt`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `name`: `typing.Optional[str]`\n- `description`: `typing.Optional[str]`\n- `ref`: `typing.Optional[trace.refs.ObjectRef]`\n---\n\n\n\n### method `format`\n\n```python\nformat(**kwargs: Any) \u2192 Any\n```\n\n\n\n\n\n\n---\n\n\n\n## class `StringPrompt`\n\n\n\n\n\n\n### method `__init__`\n\n```python\n__init__(content: str)\n```\n\n\n\n\n\n\n**Pydantic Fields:**\n\n- `name`: `typing.Optional[str]`\n- `description`: `typing.Optional[str]`\n- `ref`: `typing.Optional[trace.refs.ObjectRef]`\n- `content`: ``\n---\n\n\n\n### method `format`\n\n```python\nformat(**kwargs: Any) \u2192 str\n```\n\n\n\n\n\n---\n\n\n\n### classmethod `from_obj`\n\n```python\nfrom_obj(obj: WeaveObject) \u2192 Self\n```\n\n\n\n\n\n\n---\n\n\n\n## class `MessagesPrompt`\n\n\n\n\n\n\n### method `__init__`\n\n```python\n__init__(messages: list[dict])\n```\n\n\n\n\n\n\n**Pydantic Fields:**\n\n- `name`: `typing.Optional[str]`\n- `description`: `typing.Optional[str]`\n- `ref`: `typing.Optional[trace.refs.ObjectRef]`\n- `messages`: `list[dict]`\n---\n\n\n\n### method `format`\n\n```python\nformat(**kwargs: Any) \u2192 list\n```\n\n\n\n\n\n---\n\n\n\n### method `format_message`\n\n```python\nformat_message(message: dict, **kwargs: Any) \u2192 dict\n```\n\n\n\n\n\n---\n\n\n\n### classmethod `from_obj`\n\n```python\nfrom_obj(obj: WeaveObject) \u2192 Self\n```\n\n\n\n\n\n\n---\n\n\n\n## class `Evaluation`\nSets up an evaluation which includes a set of scorers and a dataset. \n\nCalling evaluation.evaluate(model) will pass in rows from a dataset into a model matching  the names of the columns of the dataset to the argument names in model.predict. \n\nThen it will call all of the scorers and save the results in weave. \n\nIf you want to preprocess the rows from the dataset you can pass in a function to preprocess_model_input. \n\n\n\n**Examples:**\n \n\n```python\n# Collect your examples\nexamples = [\n     {\"question\": \"What is the capital of France?\", \"expected\": \"Paris\"},\n     {\"question\": \"Who wrote 'To Kill a Mockingbird'?\", \"expected\": \"Harper Lee\"},\n     {\"question\": \"What is the square root of 64?\", \"expected\": \"8\"},\n]\n\n# Define any custom scoring function\n@weave.op()\ndef match_score1(expected: str, model_output: dict) -> dict:\n     # Here is where you'd define the logic to score the model output\n     return {'match': expected == model_output['generated_text']}\n\n@weave.op()\ndef function_to_evaluate(question: str):\n     # here's where you would add your LLM call and return the output\n     return  {'generated_text': 'Paris'}\n\n# Score your examples using scoring functions\nevaluation = Evaluation(\n     dataset=examples, scorers=[match_score1]\n)\n\n# Start tracking the evaluation\nweave.init('intro-example')\n# Run the evaluation\nasyncio.run(evaluation.evaluate(function_to_evaluate))\n``` \n\n\n**Pydantic Fields:**\n\n- `name`: `typing.Optional[str]`\n- `description`: `typing.Optional[str]`\n- `ref`: `typing.Optional[trace.refs.ObjectRef]`\n- `dataset`: ``\n- `scorers`: `typing.Optional[list[typing.Annotated[typing.Union[trace.op.Op, flow.scorer.Scorer], BeforeValidator(func=, json_schema_input_type=PydanticUndefined)]]]`\n- `preprocess_model_input`: `typing.Optional[typing.Callable[[dict], dict]]`\n- `trials`: ``\n- `evaluation_name`: `typing.Union[str, typing.Callable[[trace.weave_client.Call], str], NoneType]`\n---\n\n\n\n### method `evaluate`\n\n```python\nevaluate(model: Union[Op, Model]) \u2192 dict\n```\n\n\n\n\n\n---\n\n\n\n### classmethod `from_obj`\n\n```python\nfrom_obj(obj: WeaveObject) \u2192 Self\n```\n\n\n\n\n\n---\n\n\n\n### method `get_eval_results`\n\n```python\nget_eval_results(model: Union[Op, Model]) \u2192 EvaluationResults\n```\n\n\n\n\n\n---\n\n\n\n### method `predict_and_score`\n\n```python\npredict_and_score(model: Union[Op, Model], example: dict) \u2192 dict\n```\n\n\n\n\n\n---\n\n\n\n### method `summarize`\n\n```python\nsummarize(eval_table: EvaluationResults) \u2192 dict\n```\n\n\n\n\n\n\n---\n\n\n\n## class `EvaluationLogger`\nThis class provides an imperative interface for logging evaluations. \n\nAn evaluation is started automatically when the first prediction is logged using the `log_prediction` method, and finished when the `log_summary` method is called. \n\nEach time you log a prediction, you will get back a `ScoreLogger` object. You can use this object to log scores and metadata for that specific prediction. For more information, see the `ScoreLogger` class. \n\n\n\n**Example:**\n ```python\n     ev = EvaluationLogger()\n     pred = ev.log_prediction(inputs, output)\n     pred.log_score(scorer_name, score)\n     ev.log_summary(summary)\n    ``` \n\n\n**Pydantic Fields:**\n\n- `name`: `str | None`\n- `model`: `flow.model.Model | dict | str`\n- `dataset`: `flow.dataset.Dataset | list[dict] | str`\n---\n\n#### property ui_url\n\n\n\n\n\n\n\n---\n\n\n\n### method `finish`\n\n```python\nfinish() \u2192 None\n```\n\nClean up the evaluation resources explicitly without logging a summary. \n\nEnsures all prediction calls and the main evaluation call are finalized. This is automatically called if the logger is used as a context manager. \n\n---\n\n\n\n### method `log_prediction`\n\n```python\nlog_prediction(inputs: 'dict', output: 'Any') \u2192 ScoreLogger\n```\n\nLog a prediction to the Evaluation, and return a reference. \n\nThe reference can be used to log scores which are attached to the specific prediction instance. \n\n---\n\n\n\n### method `log_summary`\n\n```python\nlog_summary(summary: 'dict | None' = None) \u2192 None\n```\n\nLog a summary dict to the Evaluation. \n\nThis will calculate the summary, call the summarize op, and then finalize the evaluation, meaning no more predictions or scores can be logged. \n\n\n---\n\n\n\n## class `Scorer`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `name`: `typing.Optional[str]`\n- `description`: `typing.Optional[str]`\n- `ref`: `typing.Optional[trace.refs.ObjectRef]`\n- `column_map`: `typing.Optional[dict[str, str]]`\n---\n\n\n\n### method `model_post_init`\n\n```python\nmodel_post_init(_Scorer__context: Any) \u2192 None\n```\n\n\n\n\n\n---\n\n\n\n### method `score`\n\n```python\nscore(output: Any, **kwargs: Any) \u2192 Any\n```\n\n\n\n\n\n---\n\n\n\n### method `summarize`\n\n```python\nsummarize(score_rows: list) \u2192 Optional[dict]\n```\n\n\n\n\n\n\n---\n\n\n\n## class `AnnotationSpec`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `name`: `typing.Optional[str]`\n- `description`: `typing.Optional[str]`\n- `field_schema`: `dict[str, typing.Any]`\n- `unique_among_creators`: ``\n- `op_scope`: `typing.Optional[list[str]]`\n---\n\n\n\n### classmethod `preprocess_field_schema`\n\n```python\npreprocess_field_schema(data: dict[str, Any]) \u2192 dict[str, Any]\n```\n\n\n\n\n\n---\n\n\n\n### classmethod `validate_field_schema`\n\n```python\nvalidate_field_schema(schema: dict[str, Any]) \u2192 dict[str, Any]\n```\n\n\n\n\n\n---\n\n\n\n### method `value_is_valid`\n\n```python\nvalue_is_valid(payload: Any) \u2192 bool\n```\n\nValidates a payload against this annotation spec's schema. \n\n\n\n**Args:**\n \n - `payload`:  The data to validate against the schema \n\n\n\n**Returns:**\n \n - `bool`:  True if validation succeeds, False otherwise \n\n\n---\n\n\n\n## class `Markdown`\nA Markdown renderable. \n\n\n\n**Args:**\n \n - `markup` (str):  A string containing markdown. \n - `code_theme` (str, optional):  Pygments theme for code blocks. Defaults to \"monokai\". See https://pygments.org/styles/ for code themes. \n - `justify` (JustifyMethod, optional):  Justify value for paragraphs. Defaults to None. \n - `style` (Union[str, Style], optional):  Optional style to apply to markdown. \n - `hyperlinks` (bool, optional):  Enable hyperlinks. Defaults to ``True``. \n - `inline_code_lexer`:  (str, optional): Lexer to use if inline code highlighting is  enabled. Defaults to None. \n - `inline_code_theme`:  (Optional[str], optional): Pygments theme for inline code  highlighting, or None for no highlighting. Defaults to None. \n\n\n\n### method `__init__`\n\n```python\n__init__(\n    markup: 'str',\n    code_theme: 'str' = 'monokai',\n    justify: 'JustifyMethod | None' = None,\n    style: 'str | Style' = 'none',\n    hyperlinks: 'bool' = True,\n    inline_code_lexer: 'str | None' = None,\n    inline_code_theme: 'str | None' = None\n) \u2192 None\n```\n\n\n\n\n\n\n\n\n\n---\n\n\n\n## class `Monitor`\nSets up a monitor to score incoming calls automatically. \n\n\n\n**Examples:**\n \n\n```python\nimport weave\nfrom weave.scorers import ValidJSONScorer\n\njson_scorer = ValidJSONScorer()\n\nmy_monitor = weave.Monitor(\n     name=\"my-monitor\",\n     description=\"This is a test monitor\",\n     sampling_rate=0.5,\n     op_names=[\"my_op\"],\n     query={\n         \"$expr\": {\n             \"$gt\": [\n                 {\n                         \"$getField\": \"started_at\"\n                     },\n                     {\n                         \"$literal\": 1742540400\n                     }\n                 ]\n             }\n         }\n     },\n     scorers=[json_scorer],\n)\n\nmy_monitor.activate()\n``` \n\n\n**Pydantic Fields:**\n\n- `name`: `typing.Optional[str]`\n- `description`: `typing.Optional[str]`\n- `ref`: `typing.Optional[trace.refs.ObjectRef]`\n- `sampling_rate`: ``\n- `scorers`: `list[flow.scorer.Scorer]`\n- `op_names`: `list[str]`\n- `query`: `typing.Optional[trace_server.interface.query.Query]`\n- `active`: ``\n---\n\n\n\n### method `activate`\n\n```python\nactivate() \u2192 ObjectRef\n```\n\nActivates the monitor. \n\n\n\n**Returns:**\n  The ref to the monitor. \n\n---\n\n\n\n### method `deactivate`\n\n```python\ndeactivate() \u2192 ObjectRef\n```\n\nDeactivates the monitor. \n\n\n\n**Returns:**\n  The ref to the monitor. \n\n---\n\n\n\n### classmethod `from_obj`\n\n```python\nfrom_obj(obj: WeaveObject) \u2192 Self\n```\n\n\n\n\n\n\n---\n\n\n\n## class `SavedView`\nA fluent-style class for working with SavedView objects. \n\n\n\n### method `__init__`\n\n```python\n__init__(view_type: 'str' = 'traces', label: 'str' = 'SavedView') \u2192 None\n```\n\n\n\n\n\n\n---\n\n#### property entity\n\n\n\n\n\n---\n\n#### property label\n\n\n\n\n\n---\n\n#### property project\n\n\n\n\n\n---\n\n#### property view_type\n\n\n\n\n\n\n\n---\n\n\n\n### method `add_column`\n\n```python\nadd_column(path: 'str | ObjectPath', label: 'str | None' = None) \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### method `add_columns`\n\n```python\nadd_columns(*columns: 'str') \u2192 SavedView\n```\n\nConvenience method for adding multiple columns to the grid. \n\n---\n\n\n\n### method `add_filter`\n\n```python\nadd_filter(\n    field: 'str',\n    operator: 'str',\n    value: 'Any | None' = None\n) \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### method `add_sort`\n\n```python\nadd_sort(field: 'str', direction: 'SortDirection') \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### method `column_index`\n\n```python\ncolumn_index(path: 'int | str | ObjectPath') \u2192 int\n```\n\n\n\n\n\n---\n\n\n\n### method `filter_op`\n\n```python\nfilter_op(op_name: 'str | None') \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### method `get_calls`\n\n```python\nget_calls(\n    limit: 'int | None' = None,\n    offset: 'int | None' = None,\n    include_costs: 'bool' = False,\n    include_feedback: 'bool' = False,\n    all_columns: 'bool' = False\n) \u2192 CallsIter\n```\n\nGet calls matching this saved view's filters and settings. \n\n---\n\n\n\n### method `get_known_columns`\n\n```python\nget_known_columns(num_calls_to_query: 'int | None' = None) \u2192 list[str]\n```\n\nGet the set of columns that are known to exist. \n\n---\n\n\n\n### method `get_table_columns`\n\n```python\nget_table_columns() \u2192 list[TableColumn]\n```\n\n\n\n\n\n---\n\n\n\n### method `hide_column`\n\n```python\nhide_column(col_name: 'str') \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### method `insert_column`\n\n```python\ninsert_column(\n    idx: 'int',\n    path: 'str | ObjectPath',\n    label: 'str | None' = None\n) \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### classmethod `load`\n\n```python\nload(ref: 'str') \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### method `page_size`\n\n```python\npage_size(page_size: 'int') \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### method `pin_column_left`\n\n```python\npin_column_left(col_name: 'str') \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### method `pin_column_right`\n\n```python\npin_column_right(col_name: 'str') \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### method `remove_column`\n\n```python\nremove_column(path: 'int | str | ObjectPath') \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### method `remove_columns`\n\n```python\nremove_columns(*columns: 'str') \u2192 SavedView\n```\n\nRemove columns from the saved view. \n\n---\n\n\n\n### method `remove_filter`\n\n```python\nremove_filter(index_or_field: 'int | str') \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### method `remove_filters`\n\n```python\nremove_filters() \u2192 SavedView\n```\n\nRemove all filters from the saved view. \n\n---\n\n\n\n### method `rename`\n\n```python\nrename(label: 'str') \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### method `rename_column`\n\n```python\nrename_column(path: 'int | str | ObjectPath', label: 'str') \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### method `save`\n\n```python\nsave() \u2192 SavedView\n```\n\nPublish the saved view to the server. \n\n---\n\n\n\n### method `set_columns`\n\n```python\nset_columns(*columns: 'str') \u2192 SavedView\n```\n\nSet the columns to be displayed in the grid. \n\n---\n\n\n\n### method `show_column`\n\n```python\nshow_column(col_name: 'str') \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### method `sort_by`\n\n```python\nsort_by(field: 'str', direction: 'SortDirection') \u2192 SavedView\n```\n\n\n\n\n\n---\n\n\n\n### method `to_grid`\n\n```python\nto_grid(limit: 'int | None' = None) \u2192 Grid\n```\n\n\n\n\n\n---\n\n\n\n### method `to_rich_table_str`\n\n```python\nto_rich_table_str() \u2192 str\n```\n\n\n\n\n\n---\n\n\n\n### method `ui_url`\n\n```python\nui_url() \u2192 str | None\n```\n\nURL to show this saved view in the UI. \n\nNote this is the \"result\" page with traces etc, not the URL for the view object. \n\n---\n\n\n\n### method `unpin_column`\n\n```python\nunpin_column(col_name: 'str') \u2192 SavedView\n```"
  },
  {
    "title": "Weave.Trace.Op",
    "url": "https://weave-docs.wandb.ai/reference/python-sdk/weave/trace/weave.trace.op",
    "section": "Docs",
    "category": "Python SDK",
    "content": "# weave.trace.op\n\nDefines the Op protocol and related functions.\n\n---\n\n\n# API Overview\n\n\n\n\n\n## Functions\n\n- [`op.call`](#function-call): Executes the op and returns both the result and a Call representing the execution.\n- [`op.calls`](#function-calls): Get an iterator over all calls to this op.\n\n\n---\n\n\n\n\n### function `call`\n\n```python\ncall(\n    op: 'Op',\n    *args: 'Any',\n    __weave: 'WeaveKwargs | None' = None,\n    __should_raise: 'bool' = False,\n    __require_explicit_finish: 'bool' = False,\n    **kwargs: 'Any'\n) \u2192 tuple[Any, Call] | Coroutine[Any, Any, tuple[Any, Call]]\n```\n\nExecutes the op and returns both the result and a Call representing the execution. \n\nThis function will never raise.  Any errors are captured in the Call object. \n\nThis method is automatically bound to any function decorated with `@weave.op`, allowing for usage like: \n\n```python\n@weave.op\ndef add(a: int, b: int) -> int:\n     return a + b\n\nresult, call = add.call(1, 2)\n``` \n\n---\n\n\n\n### function `calls`\n\n```python\ncalls(op: 'Op') \u2192 CallsIter\n```\n\nGet an iterator over all calls to this op. \n\nThis method is automatically bound to any function decorated with `@weave.op`, allowing for usage like: \n\n```python\n@weave.op\ndef add(a: int, b: int) -> int:\n     return a + b\n\ncalls = add.calls()\nfor call in calls:\n     print(call)\n```"
  },
  {
    "title": "Weave.Trace.Weave Client",
    "url": "https://weave-docs.wandb.ai/reference/python-sdk/weave/trace/weave.trace.weave_client",
    "section": "Docs",
    "category": "Python SDK",
    "content": "# weave.trace.weave_client\n\n\n\n---\n\n\n# API Overview\n\n\n\n## Classes\n\n- [`weave_client.WeaveClient`](#class-weaveclient)\n- [`weave_client.Call`](#class-call): A Call represents a single operation that was executed as part of a trace.\n\n## Functions\n\n- [`weave_client.PaginatedIterator`](#function-paginatediterator)\n\n\n---\n\n\n\n\n## class `WeaveClient`\n\n\n\n\n\n\n### method `__init__`\n\n```python\n__init__(\n    entity: 'str',\n    project: 'str',\n    server: 'TraceServerInterface',\n    ensure_project_exists: 'bool' = True\n)\n```\n\n\n\n\n\n\n---\n\n#### property num_outstanding_jobs\n\nReturns the total number of pending jobs across all executors and the server. \n\nThis property can be used to check the progress of background tasks without blocking the main thread. \n\n\n\n**Returns:**\n \n - `int`:  The total number of pending jobs \n\n\n\n---\n\n\n\n### method `add_cost`\n\n```python\nadd_cost(\n    llm_id: 'str',\n    prompt_token_cost: 'float',\n    completion_token_cost: 'float',\n    effective_date: 'datetime | None' = datetime.datetime(2025, 4, 30, 23, 50, 40, 886784, tzinfo=datetime.timezone.utc),\n    prompt_token_cost_unit: 'str | None' = 'USD',\n    completion_token_cost_unit: 'str | None' = 'USD',\n    provider_id: 'str | None' = 'default'\n) \u2192 CostCreateRes\n```\n\nAdd a cost to the current project. \n\n\n\n**Examples:**\n \n\n```python\n     client.add_cost(llm_id=\"my_expensive_custom_model\", prompt_token_cost=1, completion_token_cost=2)\n     client.add_cost(llm_id=\"my_expensive_custom_model\", prompt_token_cost=500, completion_token_cost=1000, effective_date=datetime(1998, 10, 3))\n    ``` \n\n\n\n**Args:**\n \n - `llm_id`:  The ID of the LLM. eg \"gpt-4o-mini-2024-07-18\" \n - `prompt_token_cost`:  The cost per prompt token. eg .0005 \n - `completion_token_cost`:  The cost per completion token. eg .0015 \n - `effective_date`:  Defaults to the current date. A datetime.datetime object. \n - `provider_id`:  The provider of the LLM. Defaults to \"default\". eg \"openai\" \n - `prompt_token_cost_unit`:  The unit of the cost for the prompt tokens. Defaults to \"USD\". (Currently unused, will be used in the future to specify the currency type for the cost eg \"tokens\" or \"time\") \n - `completion_token_cost_unit`:  The unit of the cost for the completion tokens. Defaults to \"USD\". (Currently unused, will be used in the future to specify the currency type for the cost eg \"tokens\" or \"time\") \n\n\n\n**Returns:**\n A CostCreateRes object. Which has one field called a list of tuples called ids. Each tuple contains the llm_id and the id of the created cost object. \n\n---\n\n\n\n### method `call`\n\n```python\ncall(call_id: 'str', include_costs: 'bool' = False) \u2192 WeaveObject\n```\n\n\n\n\n\n---\n\n\n\n### method `calls`\n\n```python\ncalls(\n    filter: 'CallsFilter | None' = None,\n    include_costs: 'bool' = False\n) \u2192 CallsIter\n```\n\n\n\n\n\n---\n\n\n\n### method `create_call`\n\n```python\ncreate_call(\n    op: 'str | Op',\n    inputs: 'dict',\n    parent: 'Call | None' = None,\n    attributes: 'dict | None' = None,\n    display_name: 'str | Callable[[Call], str] | None' = None,\n    use_stack: 'bool' = True\n) \u2192 Call\n```\n\nCreate, log, and push a call onto the runtime stack. \n\n\n\n**Args:**\n \n - `op`:  The operation producing the call, or the name of an anonymous operation. \n - `inputs`:  The inputs to the operation. \n - `parent`:  The parent call. If parent is not provided, the current run is used as the parent. \n - `display_name`:  The display name for the call. Defaults to None. \n - `attributes`:  The attributes for the call. Defaults to None. \n - `use_stack`:  Whether to push the call onto the runtime stack. Defaults to True. \n\n\n\n**Returns:**\n The created Call object. \n\n---\n\n\n\n### method `delete_call`\n\n```python\ndelete_call(call: 'Call') \u2192 None\n```\n\n\n\n\n\n---\n\n\n\n### method `delete_calls`\n\n```python\ndelete_calls(call_ids: 'list[str]') \u2192 None\n```\n\nDelete calls by their IDs. \n\nDeleting a call will also delete all of its children. \n\n\n\n**Args:**\n \n - `call_ids`:  A list of call IDs to delete. Ex: [\"2F0193e107-8fcf-7630-b576-977cc3062e2e\"] \n\n---\n\n\n\n### method `delete_object_version`\n\n```python\ndelete_object_version(object: 'ObjectRef') \u2192 None\n```\n\n\n\n\n\n---\n\n\n\n### method `delete_op_version`\n\n```python\ndelete_op_version(op: 'OpRef') \u2192 None\n```\n\n\n\n\n\n---\n\n\n\n### method `fail_call`\n\n```python\nfail_call(call: 'Call', exception: 'BaseException') \u2192 None\n```\n\nFail a call with an exception. This is a convenience method for finish_call. \n\n---\n\n\n\n### method `feedback`\n\n```python\nfeedback(\n    query: 'Query | str | None' = None,\n    reaction: 'str | None' = None,\n    offset: 'int' = 0,\n    limit: 'int' = 100\n) \u2192 FeedbackQuery\n```\n\n\n\n\n\n---\n\n\n\n### method `finish`\n\n```python\nfinish(\n    use_progress_bar: 'bool' = True,\n    callback: 'Callable[[FlushStatus], None] | None' = None\n) \u2192 None\n```\n\nFlushes all background tasks to ensure they are processed. \n\nThis method blocks until all currently enqueued jobs are processed, displaying a progress bar to show the status of the pending tasks. It ensures parallel processing during main thread execution and can improve performance when user code completes before data has been uploaded to the server. \n\n\n\n**Args:**\n \n - `use_progress_bar`:  Whether to display a progress bar during flush.  Set to False for environments where a progress bar  would not render well (e.g., CI environments). \n - `callback`:  Optional callback function that receives status updates.  Overrides use_progress_bar. \n\n---\n\n\n\n### method `finish_call`\n\n```python\nfinish_call(\n    call: 'Call',\n    output: 'Any' = None,\n    exception: 'BaseException | None' = None,\n    op: 'Op | None' = None\n) \u2192 None\n```\n\n\n\n\n\n---\n\n\n\n### method `flush`\n\n```python\nflush() \u2192 None\n```\n\nFlushes background asynchronous tasks, safe to call multiple times. \n\n---\n\n\n\n### method `get`\n\n```python\nget(ref: 'ObjectRef', objectify: 'bool' = True) \u2192 Any\n```\n\n\n\n\n\n---\n\n\n\n### method `get_call`\n\n```python\nget_call(\n    call_id: 'str',\n    include_costs: 'bool' = False,\n    include_feedback: 'bool' = False,\n    columns: 'list[str] | None' = None\n) \u2192 WeaveObject\n```\n\nGet a single call by its ID. \n\n\n\n**Args:**\n \n - `call_id`:  The ID of the call to get. \n - `include_costs`:  If true, cost info is included at summary.weave \n - `include_feedback`:  If true, feedback info is included at summary.weave.feedback \n - `columns`:  A list of columns to include in the response. If None,  all columns are included. Specifying fewer columns may be more performant. \n - `Some columns are always included`:  id, project_id, trace_id, op_name, started_at \n\n\n\n**Returns:**\n A call object. \n\n---\n\n\n\n### method `get_calls`\n\n```python\nget_calls(\n    filter: 'CallsFilter | None' = None,\n    limit: 'int | None' = None,\n    offset: 'int | None' = None,\n    sort_by: 'list[SortBy] | None' = None,\n    query: 'Query | None' = None,\n    include_costs: 'bool' = False,\n    include_feedback: 'bool' = False,\n    columns: 'list[str] | None' = None,\n    scored_by: 'str | list[str] | None' = None,\n    page_size: 'int' = 1000\n) \u2192 CallsIter\n```\n\nGet a list of calls. \n\n\n\n**Args:**\n \n - `filter`:  A filter to apply to the calls. \n - `limit`:  The maximum number of calls to return. \n - `offset`:  The number of calls to skip. \n - `sort_by`:  A list of fields to sort the calls by. \n - `query`:  A mongo-like query to filter the calls. \n - `include_costs`:  If true, cost info is included at summary.weave \n - `include_feedback`:  If true, feedback info is included at summary.weave.feedback \n - `columns`:  A list of columns to include in the response. If None,  all columns are included. Specifying fewer columns may be more performant. \n - `Some columns are always included`:  id, project_id, trace_id, op_name, started_at \n - `scored_by`:  Accepts a list or single item. Each item is a name or ref uri of a scorer  to filter by. Multiple scorers are ANDed together. If passing in just the name,  then scores for all versions of the scorer are returned. If passing in the full ref  URI, then scores for a specific version of the scorer are returned. \n - `page_size`:  Tune performance by changing the number of calls fetched at a time. \n\n\n\n**Returns:**\n An iterator of calls. \n\n---\n\n\n\n### method `get_feedback`\n\n```python\nget_feedback(\n    query: 'Query | str | None' = None,\n    reaction: 'str | None' = None,\n    offset: 'int' = 0,\n    limit: 'int' = 100\n) \u2192 FeedbackQuery\n```\n\nQuery project for feedback. \n\n\n\n**Examples:**\n ```python\n     # Fetch a specific feedback object.\n     # Note that this still returns a collection, which is expected\n     # to contain zero or one item(s).\n     client.get_feedback(\"1B4082A3-4EDA-4BEB-BFEB-2D16ED59AA07\")\n\n     # Find all feedback objects with a specific reaction.\n     client.get_feedback(reaction=\"\ud83d\udc4d\", limit=10)\n    ``` \n\n\n\n**Args:**\n \n - `query`:  A mongo-style query expression. For convenience, also accepts a feedback UUID string. \n - `reaction`:  For convenience, filter by a particular reaction emoji. \n - `offset`:  The offset to start fetching feedback objects from. \n - `limit`:  The maximum number of feedback objects to fetch. \n\n\n\n**Returns:**\n A FeedbackQuery object. \n\n---\n\n\n\n### method `purge_costs`\n\n```python\npurge_costs(ids: 'list[str] | str') \u2192 None\n```\n\nPurge costs from the current project. \n\n\n\n**Examples:**\n \n\n```python\n     client.purge_costs([ids])\n     client.purge_costs(ids)\n    ``` \n\n\n\n**Args:**\n \n - `ids`:  The cost IDs to purge. Can be a single ID or a list of IDs. \n\n---\n\n\n\n### method `query_costs`\n\n```python\nquery_costs(\n    query: 'Query | str | None' = None,\n    llm_ids: 'list[str] | None' = None,\n    offset: 'int' = 0,\n    limit: 'int' = 100\n) \u2192 list[CostQueryOutput]\n```\n\nQuery project for costs. \n\n\n\n**Examples:**\n \n\n```python\n     # Fetch a specific cost object.\n     # Note that this still returns a collection, which is expected\n     # to contain zero or one item(s).\n     client.query_costs(\"1B4082A3-4EDA-4BEB-BFEB-2D16ED59AA07\")\n\n     # Find all cost objects with a specific reaction.\n     client.query_costs(llm_ids=[\"gpt-4o-mini-2024-07-18\"], limit=10)\n    ``` \n\n\n\n**Args:**\n \n - `query`:  A mongo-style query expression. For convenience, also accepts a cost UUID string. \n - `llm_ids`:  For convenience, filter for a set of llm_ids. \n - `offset`:  The offset to start fetching cost objects from. \n - `limit`:  The maximum number of cost objects to fetch. \n\n\n\n**Returns:**\n A CostQuery object. \n\n---\n\n\n\n### method `save`\n\n```python\nsave(val: 'Any', name: 'str', branch: 'str' = 'latest') \u2192 Any\n```\n\nDo not call directly, use weave.publish() instead. \n\n\n\n**Args:**\n \n - `val`:  The object to save. \n - `name`:  The name to save the object under. \n - `branch`:  The branch to save the object under. Defaults to \"latest\". \n\n\n\n**Returns:**\n A deserialized version of the saved object. \n\n\n---\n\n\n\n## class `Call`\nA Call represents a single operation that was executed as part of a trace. \n\n\">\n\n### method `__init__`\n\n```python\n__init__(\n    _op_name: 'str | Future[str]',\n    trace_id: 'str',\n    project_id: 'str',\n    parent_id: 'str | None',\n    inputs: 'dict',\n    id: 'str | None' = None,\n    output: 'Any' = None,\n    exception: 'str | None' = None,\n    summary: 'dict | None' = None,\n    _display_name: 'str | Callable[[Call], str] | None' = None,\n    attributes: 'dict | None' = None,\n    started_at: 'datetime | None' = None,\n    ended_at: 'datetime | None' = None,\n    deleted_at: 'datetime | None' = None,\n    _children: 'list[Call]' = &lt;factory&gt;,\n    _feedback: 'RefFeedbackQuery | None' = None\n) \u2192 None\n```\n\n\n\n\n\n\n---\n\n#### property display_name\n\n\n\n\n\n---\n\n#### property feedback\n\n\n\n\n\n---\n\n#### property func_name\n\nThe decorated function's name that produced this call. \n\nThis is different from `op_name` which is usually the ref of the op. \n\n---\n\n#### property op_name\n\n\n\n\n\n---\n\n#### property ref\n\n\n\n\n\n---\n\n#### property ui_url\n\n\n\n\n\n\n\n---\n\n\n\n### method `apply_scorer`\n\n```python\napply_scorer(\n    scorer: 'Op | Scorer',\n    additional_scorer_kwargs: 'dict | None' = None\n) \u2192 ApplyScorerResult\n```\n\n`apply_scorer` is a method that applies a Scorer to a Call. This is useful for guarding application logic with a scorer and/or monitoring the quality of critical ops. Scorers are automatically logged to Weave as Feedback and can be used in queries & analysis. \n\n\n\n**Args:**\n \n - `scorer`:  The Scorer to apply. \n - `additional_scorer_kwargs`:  Additional kwargs to pass to the scorer. This is  useful for passing in additional context that is not part of the call  inputs.useful for passing in additional context that is not part of the call  inputs. \n\n\n\n**Returns:**\n The result of the scorer application in the form of an `ApplyScorerResult`. \n\n```python\nclass ApplyScorerSuccess:\n\n - `    result`:  Any\n\n - `    score_call`:  Call\n``` \n\nExample usage: \n\n```python\nmy_scorer = ... # construct a scorer\nprediction, prediction_call = my_op.call(input_data)\nresult, score_call = prediction.apply_scorer(my_scorer)\n``` \n\n---\n\n\n\n### method `children`\n\n```python\nchildren(page_size: 'int' = 1000) \u2192 CallsIter\n```\n\nGet the children of the call. \n\n\n\n**Args:**\n \n - `page_size`:  Tune performance by changing the number of calls fetched at a time. \n\n\n\n**Returns:**\n An iterator of calls. \n\n---\n\n\n\n### method `delete`\n\n```python\ndelete() \u2192 bool\n```\n\nDelete the call. \n\n---\n\n\n\n### method `remove_display_name`\n\n```python\nremove_display_name() \u2192 None\n```\n\n\n\n\n\n---\n\n\n\n### method `set_display_name`\n\n```python\nset_display_name(name: 'str | None') \u2192 None\n```\n\nSet the display name for the call. \n\n\n\n**Args:**\n \n - `name`:  The display name to set for the call. \n\n\n\n**Example:**\n \n\n```python\nresult, call = my_function.call(\"World\")\ncall.set_display_name(\"My Custom Display Name\")\n``` \n\n---\n\n\n\n### method `to_dict`\n\n```python\nto_dict() \u2192 CallDict\n```\n\n\n\n\n\n\n---\n\n### function `PaginatedIterator`\n\n```python\nPaginatedIterator(*args, **kwargs)\n```"
  },
  {
    "title": "Weave.Trace.Util",
    "url": "https://weave-docs.wandb.ai/reference/python-sdk/weave/trace/weave.trace.util",
    "section": "Docs",
    "category": "Python SDK",
    "content": "# weave.trace.util\n\n\n\n---\n\n\n# API Overview\n\n\n\n## Classes\n\n- [`util.ContextAwareThreadPoolExecutor`](#class-contextawarethreadpoolexecutor): A ThreadPoolExecutor that runs functions with the context of the caller.\n- [`util.ContextAwareThread`](#class-contextawarethread): A Thread that runs functions with the context of the caller.\n\n\n\n\n---\n\n\n\n\n## class `ContextAwareThreadPoolExecutor`\nA ThreadPoolExecutor that runs functions with the context of the caller. \n\nThis is a drop-in replacement for concurrent.futures.ThreadPoolExecutor that ensures weave calls behave as expected inside the executor.  Weave requires certain contextvars to be set (see call_context.py), but new threads do not automatically copy context from the parent, which can cause the call context to be lost -- not good!  This class automates contextvar copying so using this executor \"just works\" as the user probably expects. \n\nYou can achieve the same effect without this class by instead writing: \n\n```python\nwith concurrent.futures.ThreadPoolExecutor() as executor:\n     contexts = [copy_context() for _ in range(len(vals))]\n\n     def _wrapped_fn(*args):\n         return contexts.pop().run(fn, *args)\n\n     executor.map(_wrapped_fn, vals)\n``` \n\n\n\n### method `__init__`\n\n```python\n__init__(*args: 'Any', **kwargs: 'Any') \u2192 None\n```\n\n\n\n\n\n\n\n\n---\n\n\n\n### method `map`\n\n```python\nmap(\n    fn: 'Callable',\n    *iterables: 'Iterable[Any]',\n    timeout: 'float | None' = None,\n    chunksize: 'int' = 1\n) \u2192 Iterator\n```\n\n\n\n\n\n---\n\n\n\n### method `submit`\n\n```python\nsubmit(fn: 'Callable', *args: 'Any', **kwargs: 'Any') \u2192 Any\n```\n\n\n\n\n\n\n---\n\n\n\n## class `ContextAwareThread`\nA Thread that runs functions with the context of the caller. \n\nThis is a drop-in replacement for threading.Thread that ensures calls behave as expected inside the thread.  Weave requires certain contextvars to be set (see call_context.py), but new threads do not automatically copy context from the parent, which can cause the call context to be lost -- not good!  This class automates contextvar copying so using this thread \"just works\" as the user probably expects. \n\nYou can achieve the same effect without this class by instead writing: \n\n```python\ndef run_with_context(func, *args, **kwargs):\n     context = copy_context()\n     def wrapper():\n         context.run(func, *args, **kwargs)\n     return wrapper\n\nthread = threading.Thread(target=run_with_context(your_func, *args, **kwargs))\nthread.start()\n``` \n\n\n\n### method `__init__`\n\n```python\n__init__(*args: 'Any', **kwargs: 'Any') \u2192 None\n```\n\n\n\n\n\n\n---\n\n#### property daemon\n\nA boolean value indicating whether this thread is a daemon thread. \n\nThis must be set before start() is called, otherwise RuntimeError is raised. Its initial value is inherited from the creating thread; the main thread is not a daemon thread and therefore all threads created in the main thread default to daemon = False. \n\nThe entire Python program exits when only daemon threads are left. \n\n---\n\n#### property ident\n\nThread identifier of this thread or None if it has not been started. \n\nThis is a nonzero integer. See the get_ident() function. Thread identifiers may be recycled when a thread exits and another thread is created. The identifier is available even after the thread has exited. \n\n---\n\n#### property name\n\nA string used for identification purposes only. \n\nIt has no semantics. Multiple threads may be given the same name. The initial name is set by the constructor. \n\n---\n\n#### property native_id\n\nNative integral thread ID of this thread, or None if it has not been started. \n\nThis is a non-negative integer. See the get_native_id() function. This represents the Thread ID as reported by the kernel. \n\n\n\n---\n\n\n\n### method `run`\n\n```python\nrun() \u2192 None\n```"
  },
  {
    "title": "Weave.Trace.Feedback",
    "url": "https://weave-docs.wandb.ai/reference/python-sdk/weave/trace/weave.trace.feedback",
    "section": "Docs",
    "category": "Python SDK",
    "content": "# weave.trace.feedback\n\nClasses for working with feedback on a project or ref level.\n\n---\n\n\n# API Overview\n\n\n\n## Classes\n\n- [`feedback.Feedbacks`](#class-feedbacks): A collection of Feedback objects with utilities.\n- [`feedback.FeedbackQuery`](#class-feedbackquery): Lazy-loading object for fetching feedback from the server.\n- [`feedback.RefFeedbackQuery`](#class-reffeedbackquery): Object for interacting with feedback associated with a particular ref.\n\n\n\n\n---\n\n\n\n\n## class `Feedbacks`\nA collection of Feedback objects with utilities. \n\n\n\n### method `__init__`\n\n```python\n__init__(\n    show_refs: 'bool',\n    feedbacks: 'Iterable[Feedback] | None' = None\n) \u2192 None\n```\n\n\n\n\n\n\n\n\n---\n\n\n\n### method `refs`\n\n```python\nrefs() \u2192 Refs\n```\n\nReturn the unique refs associated with these feedbacks. \n\n\n---\n\n\n\n## class `FeedbackQuery`\nLazy-loading object for fetching feedback from the server. \n\n\n\n### method `__init__`\n\n```python\n__init__(\n    entity: 'str',\n    project: 'str',\n    query: 'Query',\n    offset: 'int | None' = None,\n    limit: 'int | None' = None,\n    show_refs: 'bool' = False\n)\n```\n\n\n\n\n\n\n\n\n---\n\n\n\n### method `execute`\n\n```python\nexecute() \u2192 Feedbacks\n```\n\n\n\n\n\n---\n\n\n\n### method `refresh`\n\n```python\nrefresh() \u2192 Feedbacks\n```\n\n\n\n\n\n---\n\n\n\n### method `refs`\n\n```python\nrefs() \u2192 Refs\n```\n\n\n\n\n\n\n---\n\n\n\n## class `RefFeedbackQuery`\nObject for interacting with feedback associated with a particular ref. \n\n\n\n### method `__init__`\n\n```python\n__init__(ref: 'str') \u2192 None\n```\n\n\n\n\n\n\n\n\n---\n\n\n\n### method `add`\n\n```python\nadd(\n    feedback_type: 'str',\n    payload: 'dict[str, Any] | None' = None,\n    creator: 'str | None' = None,\n    annotation_ref: 'str | None' = None,\n    **kwargs: 'dict[str, Any]'\n) \u2192 str\n```\n\nAdd feedback to the ref. \n\nfeedback_type: A string identifying the type of feedback. The \"wandb.\" prefix is reserved. creator: The name to display for the originator of the feedback. \n\n---\n\n\n\n### method `add_note`\n\n```python\nadd_note(note: 'str', creator: 'str | None' = None) \u2192 str\n```\n\n\n\n\n\n---\n\n\n\n### method `add_reaction`\n\n```python\nadd_reaction(emoji: 'str', creator: 'str | None' = None) \u2192 str\n```\n\n\n\n\n\n---\n\n\n\n### method `execute`\n\n```python\nexecute() \u2192 Feedbacks\n```\n\n\n\n\n\n---\n\n\n\n### method `purge`\n\n```python\npurge(feedback_id: 'str') \u2192 None\n```\n\n\n\n\n\n---\n\n\n\n### method `refresh`\n\n```python\nrefresh() \u2192 Feedbacks\n```\n\n\n\n\n\n---\n\n\n\n### method `refs`\n\n```python\nrefs() \u2192 Refs\n```"
  },
  {
    "title": "Weave.Trace Server Bindings.Remote Http Trace Server",
    "url": "https://weave-docs.wandb.ai/reference/python-sdk/weave/trace_server_bindings/weave.trace_server_bindings.remote_http_trace_server",
    "section": "Docs",
    "category": "Python SDK",
    "content": "# weave.trace_server_bindings.remote_http_trace_server\n\n\n\n---\n\n\n# API Overview\n\n\n\n## Classes\n\n- [`remote_http_trace_server.RemoteHTTPTraceServer`](#class-remotehttptraceserver)\n- [`remote_http_trace_server.ServerInfoRes`](#class-serverinfores)\n- [`remote_http_trace_server.StartBatchItem`](#class-startbatchitem)\n- [`remote_http_trace_server.EndBatchItem`](#class-endbatchitem)\n- [`remote_http_trace_server.Batch`](#class-batch)\n\n\n\n\n---\n\n\n\n\n## class `RemoteHTTPTraceServer`\n\n\n\n\n\n\n### method `__init__`\n\n```python\n__init__(\n    trace_server_url: str,\n    should_batch: bool = False,\n    remote_request_bytes_limit: int = 32505856\n)\n```\n\n\n\n\n\n\n\n\n---\n\n\n\n### method `actions_execute_batch`\n\n```python\nactions_execute_batch(\n    req: Union[ActionsExecuteBatchReq, dict[str, Any]]\n) \u2192 ActionsExecuteBatchRes\n```\n\n\n\n\n\n---\n\n\n\n### method `call_end`\n\n```python\ncall_end(req: Union[CallEndReq, dict[str, Any]]) \u2192 CallEndRes\n```\n\n\n\n\n\n---\n\n\n\n### method `call_read`\n\n```python\ncall_read(req: Union[CallReadReq, dict[str, Any]]) \u2192 CallReadRes\n```\n\n\n\n\n\n---\n\n\n\n### method `call_start`\n\n```python\ncall_start(req: Union[CallStartReq, dict[str, Any]]) \u2192 CallStartRes\n```\n\n\n\n\n\n---\n\n\n\n### method `call_start_batch`\n\n```python\ncall_start_batch(req: CallCreateBatchReq) \u2192 CallCreateBatchRes\n```\n\n\n\n\n\n---\n\n\n\n### method `call_update`\n\n```python\ncall_update(req: Union[CallUpdateReq, dict[str, Any]]) \u2192 CallUpdateRes\n```\n\n\n\n\n\n---\n\n\n\n### method `calls_delete`\n\n```python\ncalls_delete(req: Union[CallsDeleteReq, dict[str, Any]]) \u2192 CallsDeleteRes\n```\n\n\n\n\n\n---\n\n\n\n### method `calls_query`\n\n```python\ncalls_query(req: Union[CallsQueryReq, dict[str, Any]]) \u2192 CallsQueryRes\n```\n\n\n\n\n\n---\n\n\n\n### method `calls_query_stats`\n\n```python\ncalls_query_stats(\n    req: Union[CallsQueryStatsReq, dict[str, Any]]\n) \u2192 CallsQueryStatsRes\n```\n\n\n\n\n\n---\n\n\n\n### method `calls_query_stream`\n\n```python\ncalls_query_stream(\n    req: Union[CallsQueryReq, dict[str, Any]]\n) \u2192 Iterator[CallSchema]\n```\n\n\n\n\n\n---\n\n\n\n### method `completions_create`\n\n```python\ncompletions_create(req: CompletionsCreateReq) \u2192 CompletionsCreateRes\n```\n\n\n\n\n\n---\n\n\n\n### method `cost_create`\n\n```python\ncost_create(req: Union[CostCreateReq, dict[str, Any]]) \u2192 CostCreateRes\n```\n\n\n\n\n\n---\n\n\n\n### method `cost_purge`\n\n```python\ncost_purge(req: Union[CostPurgeReq, dict[str, Any]]) \u2192 CostPurgeRes\n```\n\n\n\n\n\n---\n\n\n\n### method `cost_query`\n\n```python\ncost_query(req: Union[CostQueryReq, dict[str, Any]]) \u2192 CostQueryRes\n```\n\n\n\n\n\n---\n\n\n\n### method `ensure_project_exists`\n\n```python\nensure_project_exists(entity: str, project: str) \u2192 EnsureProjectExistsRes\n```\n\n\n\n\n\n---\n\n\n\n### method `feedback_create`\n\n```python\nfeedback_create(\n    req: Union[FeedbackCreateReq, dict[str, Any]]\n) \u2192 FeedbackCreateRes\n```\n\n\n\n\n\n---\n\n\n\n### method `feedback_purge`\n\n```python\nfeedback_purge(req: Union[FeedbackPurgeReq, dict[str, Any]]) \u2192 FeedbackPurgeRes\n```\n\n\n\n\n\n---\n\n\n\n### method `feedback_query`\n\n```python\nfeedback_query(req: Union[FeedbackQueryReq, dict[str, Any]]) \u2192 FeedbackQueryRes\n```\n\n\n\n\n\n---\n\n\n\n### method `feedback_replace`\n\n```python\nfeedback_replace(\n    req: Union[FeedbackReplaceReq, dict[str, Any]]\n) \u2192 FeedbackReplaceRes\n```\n\n\n\n\n\n---\n\n\n\n### method `file_content_read`\n\n```python\nfile_content_read(req: FileContentReadReq) \u2192 FileContentReadRes\n```\n\n\n\n\n\n---\n\n\n\n### method `file_create`\n\n```python\nfile_create(req: FileCreateReq) \u2192 FileCreateRes\n```\n\n\n\n\n\n---\n\n\n\n### method `files_stats`\n\n```python\nfiles_stats(req: FilesStatsReq) \u2192 FilesStatsRes\n```\n\n\n\n\n\n---\n\n\n\n### classmethod `from_env`\n\n```python\nfrom_env(should_batch: bool = False) \u2192 RemoteHTTPTraceServer\n```\n\n\n\n\n\n---\n\n\n\n### method `obj_create`\n\n```python\nobj_create(req: Union[ObjCreateReq, dict[str, Any]]) \u2192 ObjCreateRes\n```\n\n\n\n\n\n---\n\n\n\n### method `obj_delete`\n\n```python\nobj_delete(req: ObjDeleteReq) \u2192 ObjDeleteRes\n```\n\n\n\n\n\n---\n\n\n\n### method `obj_read`\n\n```python\nobj_read(req: Union[ObjReadReq, dict[str, Any]]) \u2192 ObjReadRes\n```\n\n\n\n\n\n---\n\n\n\n### method `objs_query`\n\n```python\nobjs_query(req: Union[ObjQueryReq, dict[str, Any]]) \u2192 ObjQueryRes\n```\n\n\n\n\n\n---\n\n\n\n### method `op_create`\n\n```python\nop_create(req: Union[OpCreateReq, dict[str, Any]]) \u2192 OpCreateRes\n```\n\n\n\n\n\n---\n\n\n\n### method `op_read`\n\n```python\nop_read(req: Union[OpReadReq, dict[str, Any]]) \u2192 OpReadRes\n```\n\n\n\n\n\n---\n\n\n\n### method `ops_query`\n\n```python\nops_query(req: Union[OpQueryReq, dict[str, Any]]) \u2192 OpQueryRes\n```\n\n\n\n\n\n---\n\n\n\n### method `otel_export`\n\n```python\notel_export(req: OtelExportReq) \u2192 OtelExportRes\n```\n\n\n\n\n\n---\n\n\n\n### method `refs_read_batch`\n\n```python\nrefs_read_batch(req: Union[RefsReadBatchReq, dict[str, Any]]) \u2192 RefsReadBatchRes\n```\n\n\n\n\n\n---\n\n\n\n### method `server_info`\n\n```python\nserver_info() \u2192 ServerInfoRes\n```\n\n\n\n\n\n---\n\n\n\n### method `set_auth`\n\n```python\nset_auth(auth: tuple[str, str]) \u2192 None\n```\n\n\n\n\n\n---\n\n\n\n### method `table_create`\n\n```python\ntable_create(req: Union[TableCreateReq, dict[str, Any]]) \u2192 TableCreateRes\n```\n\nSimilar to `calls/batch_upsert`, we can dynamically adjust the payload size due to the property that table creation can be decomposed into a series of updates. This is useful when the table creation size is too big to be sent in a single request. We can create an empty table first, then update the table with the rows. \n\n---\n\n\n\n### method `table_query`\n\n```python\ntable_query(req: Union[TableQueryReq, dict[str, Any]]) \u2192 TableQueryRes\n```\n\n\n\n\n\n---\n\n\n\n### method `table_query_stats`\n\n```python\ntable_query_stats(\n    req: Union[TableQueryStatsReq, dict[str, Any]]\n) \u2192 TableQueryStatsRes\n```\n\n\n\n\n\n---\n\n\n\n### method `table_query_stats_batch`\n\n```python\ntable_query_stats_batch(\n    req: Union[TableQueryStatsReq, dict[str, Any]]\n) \u2192 TableQueryStatsRes\n```\n\n\n\n\n\n---\n\n\n\n### method `table_query_stream`\n\n```python\ntable_query_stream(req: TableQueryReq) \u2192 Iterator[TableRowSchema]\n```\n\n\n\n\n\n---\n\n\n\n### method `table_update`\n\n```python\ntable_update(req: TableUpdateReq) \u2192 TableUpdateRes\n```\n\nSimilar to `calls/batch_upsert`, we can dynamically adjust the payload size due to the property that table updates can be decomposed into a series of updates. \n\n\n---\n\n\n\n## class `ServerInfoRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `min_required_weave_python_version`: ``\n\n---\n\n\n\n## class `StartBatchItem`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `mode`: ``\n- `req`: ``\n\n---\n\n\n\n## class `EndBatchItem`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `mode`: ``\n- `req`: ``\n\n---\n\n\n\n## class `Batch`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `batch`: `list[typing.Union[StartBatchItem, EndBatchItem]]`"
  },
  {
    "title": "Weave.Trace Server.Trace Server Interface",
    "url": "https://weave-docs.wandb.ai/reference/python-sdk/weave/trace_server/weave.trace_server.trace_server_interface",
    "section": "Docs",
    "category": "Python SDK",
    "content": "# weave.trace_server.trace_server_interface\n\n\n\n---\n\n\n# API Overview\n\n\n\n## Classes\n\n- [`trace_server_interface.ActionsExecuteBatchReq`](#class-actionsexecutebatchreq)\n- [`trace_server_interface.ActionsExecuteBatchRes`](#class-actionsexecutebatchres)\n- [`trace_server_interface.CallBatchEndMode`](#class-callbatchendmode)\n- [`trace_server_interface.CallBatchStartMode`](#class-callbatchstartmode)\n- [`trace_server_interface.CallCreateBatchReq`](#class-callcreatebatchreq)\n- [`trace_server_interface.CallCreateBatchRes`](#class-callcreatebatchres)\n- [`trace_server_interface.CallEndReq`](#class-callendreq)\n- [`trace_server_interface.CallEndRes`](#class-callendres)\n- [`trace_server_interface.CallReadReq`](#class-callreadreq)\n- [`trace_server_interface.CallReadRes`](#class-callreadres)\n- [`trace_server_interface.CallSchema`](#class-callschema)\n- [`trace_server_interface.CallStartReq`](#class-callstartreq)\n- [`trace_server_interface.CallStartRes`](#class-callstartres)\n- [`trace_server_interface.CallUpdateReq`](#class-callupdatereq)\n- [`trace_server_interface.CallUpdateRes`](#class-callupdateres)\n- [`trace_server_interface.CallsDeleteReq`](#class-callsdeletereq)\n- [`trace_server_interface.CallsDeleteRes`](#class-callsdeleteres)\n- [`trace_server_interface.CallsFilter`](#class-callsfilter)\n- [`trace_server_interface.CallsQueryReq`](#class-callsqueryreq)\n- [`trace_server_interface.CallsQueryRes`](#class-callsqueryres)\n- [`trace_server_interface.CallsQueryStatsReq`](#class-callsquerystatsreq)\n- [`trace_server_interface.CallsQueryStatsRes`](#class-callsquerystatsres)\n- [`trace_server_interface.CompletionsCreateReq`](#class-completionscreatereq)\n- [`trace_server_interface.CompletionsCreateRequestInputs`](#class-completionscreaterequestinputs)\n- [`trace_server_interface.CompletionsCreateRes`](#class-completionscreateres)\n- [`trace_server_interface.CostCreateInput`](#class-costcreateinput)\n- [`trace_server_interface.CostCreateReq`](#class-costcreatereq)\n- [`trace_server_interface.CostCreateRes`](#class-costcreateres)\n- [`trace_server_interface.CostPurgeReq`](#class-costpurgereq)\n- [`trace_server_interface.CostPurgeRes`](#class-costpurgeres)\n- [`trace_server_interface.CostQueryOutput`](#class-costqueryoutput)\n- [`trace_server_interface.CostQueryReq`](#class-costqueryreq)\n- [`trace_server_interface.CostQueryRes`](#class-costqueryres)\n- [`trace_server_interface.EndedCallSchemaForInsert`](#class-endedcallschemaforinsert)\n- [`trace_server_interface.EnsureProjectExistsRes`](#class-ensureprojectexistsres)\n- [`trace_server_interface.ExportTracePartialSuccess`](#class-exporttracepartialsuccess)\n- [`trace_server_interface.ExtraKeysTypedDict`](#class-extrakeystypeddict)\n- [`trace_server_interface.Feedback`](#class-feedback)\n- [`trace_server_interface.FeedbackCreateReq`](#class-feedbackcreatereq)\n- [`trace_server_interface.FeedbackCreateRes`](#class-feedbackcreateres)\n- [`trace_server_interface.FeedbackDict`](#class-feedbackdict)\n- [`trace_server_interface.FeedbackPurgeReq`](#class-feedbackpurgereq)\n- [`trace_server_interface.FeedbackPurgeRes`](#class-feedbackpurgeres)\n- [`trace_server_interface.FeedbackQueryReq`](#class-feedbackqueryreq)\n- [`trace_server_interface.FeedbackQueryRes`](#class-feedbackqueryres)\n- [`trace_server_interface.FeedbackReplaceReq`](#class-feedbackreplacereq)\n- [`trace_server_interface.FeedbackReplaceRes`](#class-feedbackreplaceres)\n- [`trace_server_interface.FileContentReadReq`](#class-filecontentreadreq)\n- [`trace_server_interface.FileContentReadRes`](#class-filecontentreadres)\n- [`trace_server_interface.FileCreateReq`](#class-filecreatereq)\n- [`trace_server_interface.FileCreateRes`](#class-filecreateres)\n- [`trace_server_interface.FilesStatsReq`](#class-filesstatsreq)\n- [`trace_server_interface.FilesStatsRes`](#class-filesstatsres)\n- [`trace_server_interface.LLMCostSchema`](#class-llmcostschema)\n- [`trace_server_interface.LLMUsageSchema`](#class-llmusageschema)\n- [`trace_server_interface.ObjCreateReq`](#class-objcreatereq)\n- [`trace_server_interface.ObjCreateRes`](#class-objcreateres)\n- [`trace_server_interface.ObjDeleteReq`](#class-objdeletereq)\n- [`trace_server_interface.ObjDeleteRes`](#class-objdeleteres)\n- [`trace_server_interface.ObjQueryReq`](#class-objqueryreq)\n- [`trace_server_interface.ObjQueryRes`](#class-objqueryres)\n- [`trace_server_interface.ObjReadReq`](#class-objreadreq)\n- [`trace_server_interface.ObjReadRes`](#class-objreadres)\n- [`trace_server_interface.ObjSchema`](#class-objschema)\n- [`trace_server_interface.ObjSchemaForInsert`](#class-objschemaforinsert)\n- [`trace_server_interface.ObjectVersionFilter`](#class-objectversionfilter)\n- [`trace_server_interface.OpCreateReq`](#class-opcreatereq)\n- [`trace_server_interface.OpCreateRes`](#class-opcreateres)\n- [`trace_server_interface.OpQueryReq`](#class-opqueryreq)\n- [`trace_server_interface.OpQueryRes`](#class-opqueryres)\n- [`trace_server_interface.OpReadReq`](#class-opreadreq)\n- [`trace_server_interface.OpReadRes`](#class-opreadres)\n- [`trace_server_interface.OpVersionFilter`](#class-opversionfilter)\n- [`trace_server_interface.OtelExportReq`](#class-otelexportreq)\n- [`trace_server_interface.OtelExportRes`](#class-otelexportres)\n- [`trace_server_interface.RefsReadBatchReq`](#class-refsreadbatchreq)\n- [`trace_server_interface.RefsReadBatchRes`](#class-refsreadbatchres)\n- [`trace_server_interface.SortBy`](#class-sortby)\n- [`trace_server_interface.StartedCallSchemaForInsert`](#class-startedcallschemaforinsert)\n- [`trace_server_interface.SummaryInsertMap`](#class-summaryinsertmap)\n- [`trace_server_interface.SummaryMap`](#class-summarymap)\n- [`trace_server_interface.TableAppendSpec`](#class-tableappendspec)\n- [`trace_server_interface.TableAppendSpecPayload`](#class-tableappendspecpayload)\n- [`trace_server_interface.TableCreateReq`](#class-tablecreatereq)\n- [`trace_server_interface.TableCreateRes`](#class-tablecreateres)\n- [`trace_server_interface.TableInsertSpec`](#class-tableinsertspec)\n- [`trace_server_interface.TableInsertSpecPayload`](#class-tableinsertspecpayload)\n- [`trace_server_interface.TablePopSpec`](#class-tablepopspec)\n- [`trace_server_interface.TablePopSpecPayload`](#class-tablepopspecpayload)\n- [`trace_server_interface.TableQueryReq`](#class-tablequeryreq)\n- [`trace_server_interface.TableQueryRes`](#class-tablequeryres)\n- [`trace_server_interface.TableQueryStatsBatchReq`](#class-tablequerystatsbatchreq)\n- [`trace_server_interface.TableQueryStatsBatchRes`](#class-tablequerystatsbatchres)\n- [`trace_server_interface.TableQueryStatsReq`](#class-tablequerystatsreq)\n- [`trace_server_interface.TableQueryStatsRes`](#class-tablequerystatsres)\n- [`trace_server_interface.TableRowFilter`](#class-tablerowfilter)\n- [`trace_server_interface.TableRowSchema`](#class-tablerowschema)\n- [`trace_server_interface.TableSchemaForInsert`](#class-tableschemaforinsert)\n- [`trace_server_interface.TableStatsRow`](#class-tablestatsrow)\n- [`trace_server_interface.TableUpdateReq`](#class-tableupdatereq)\n- [`trace_server_interface.TableUpdateRes`](#class-tableupdateres)\n- [`trace_server_interface.TraceServerInterface`](#class-traceserverinterface)\n- [`trace_server_interface.TraceStatus`](#class-tracestatus): An enumeration.\n- [`trace_server_interface.WeaveSummarySchema`](#class-weavesummaryschema)\n\n\n\n\n---\n\n\n\n\n## class `ActionsExecuteBatchReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `action_ref`: ``\n- `call_ids`: `list[str]`\n- `wb_user_id`: `typing.Optional[str]`\n\n---\n\n\n\n## class `ActionsExecuteBatchRes`\n\n\n\n\n\n\n---\n\n\n\n## class `CallBatchEndMode`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `mode`: ``\n- `req`: ``\n\n---\n\n\n\n## class `CallBatchStartMode`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `mode`: ``\n- `req`: ``\n\n---\n\n\n\n## class `CallCreateBatchReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `batch`: `list[typing.Union[CallBatchStartMode, CallBatchEndMode]]`\n\n---\n\n\n\n## class `CallCreateBatchRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `res`: `list[typing.Union[CallStartRes, CallEndRes]]`\n\n---\n\n\n\n## class `CallEndReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `end`: ``\n\n---\n\n\n\n## class `CallEndRes`\n\n\n\n\n\n\n---\n\n\n\n## class `CallReadReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `id`: ``\n- `include_costs`: `typing.Optional[bool]`\n- `include_storage_size`: `typing.Optional[bool]`\n- `include_total_storage_size`: `typing.Optional[bool]`\n\n---\n\n\n\n## class `CallReadRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `call`: `typing.Optional[CallSchema]`\n\n---\n\n\n\n## class `CallSchema`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `id`: ``\n- `project_id`: ``\n- `op_name`: ``\n- `display_name`: `typing.Optional[str]`\n- `trace_id`: ``\n- `parent_id`: `typing.Optional[str]`\n- `started_at`: ``\n- `attributes`: `dict[str, typing.Any]`\n- `inputs`: `dict[str, typing.Any]`\n- `ended_at`: `typing.Optional[datetime.datetime]`\n- `exception`: `typing.Optional[str]`\n- `output`: `typing.Optional[typing.Any]`\n- `summary`: `typing.Optional[SummaryMap]`\n- `wb_user_id`: `typing.Optional[str]`\n- `wb_run_id`: `typing.Optional[str]`\n- `deleted_at`: `typing.Optional[datetime.datetime]`\n- `storage_size_bytes`: `typing.Optional[int]`\n- `total_storage_size_bytes`: `typing.Optional[int]`\n---\n\n\n\n### method `serialize_typed_dicts`\n\n```python\nserialize_typed_dicts(v: dict[str, Any]) \u2192 dict[str, Any]\n```\n\n\n\n\n\n\n---\n\n\n\n## class `CallStartReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `start`: ``\n\n---\n\n\n\n## class `CallStartRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `id`: ``\n- `trace_id`: ``\n\n---\n\n\n\n## class `CallUpdateReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `call_id`: ``\n- `display_name`: `typing.Optional[str]`\n- `wb_user_id`: `typing.Optional[str]`\n\n---\n\n\n\n## class `CallUpdateRes`\n\n\n\n\n\n\n---\n\n\n\n## class `CallsDeleteReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `call_ids`: `list[str]`\n- `wb_user_id`: `typing.Optional[str]`\n\n---\n\n\n\n## class `CallsDeleteRes`\n\n\n\n\n\n\n---\n\n\n\n## class `CallsFilter`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `op_names`: `typing.Optional[list[str]]`\n- `input_refs`: `typing.Optional[list[str]]`\n- `output_refs`: `typing.Optional[list[str]]`\n- `parent_ids`: `typing.Optional[list[str]]`\n- `trace_ids`: `typing.Optional[list[str]]`\n- `call_ids`: `typing.Optional[list[str]]`\n- `trace_roots_only`: `typing.Optional[bool]`\n- `wb_user_ids`: `typing.Optional[list[str]]`\n- `wb_run_ids`: `typing.Optional[list[str]]`\n\n---\n\n\n\n## class `CallsQueryReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `filter`: `typing.Optional[CallsFilter]`\n- `limit`: `typing.Optional[int]`\n- `offset`: `typing.Optional[int]`\n- `sort_by`: `typing.Optional[list[SortBy]]`\n- `query`: `typing.Optional[weave.trace_server.interface.query.Query]`\n- `include_costs`: `typing.Optional[bool]`\n- `include_feedback`: `typing.Optional[bool]`\n- `include_storage_size`: `typing.Optional[bool]`\n- `include_total_storage_size`: `typing.Optional[bool]`\n- `columns`: `typing.Optional[list[str]]`\n- `expand_columns`: `typing.Optional[list[str]]`\n\n---\n\n\n\n## class `CallsQueryRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `calls`: `list[CallSchema]`\n\n---\n\n\n\n## class `CallsQueryStatsReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `filter`: `typing.Optional[CallsFilter]`\n- `query`: `typing.Optional[weave.trace_server.interface.query.Query]`\n- `limit`: `typing.Optional[int]`\n- `include_total_storage_size`: `typing.Optional[bool]`\n\n---\n\n\n\n## class `CallsQueryStatsRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `count`: ``\n- `total_storage_size_bytes`: `typing.Optional[int]`\n\n---\n\n\n\n## class `CompletionsCreateReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `inputs`: ``\n- `wb_user_id`: `typing.Optional[str]`\n- `track_llm_call`: `typing.Optional[bool]`\n\n---\n\n\n\n## class `CompletionsCreateRequestInputs`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `model`: ``\n- `messages`: ``\n- `timeout`: `typing.Union[float, str, NoneType]`\n- `temperature`: `typing.Optional[float]`\n- `top_p`: `typing.Optional[float]`\n- `n`: `typing.Optional[int]`\n- `stop`: `typing.Union[str, list, NoneType]`\n- `max_completion_tokens`: `typing.Optional[int]`\n- `max_tokens`: `typing.Optional[int]`\n- `modalities`: `typing.Optional[list]`\n- `presence_penalty`: `typing.Optional[float]`\n- `frequency_penalty`: `typing.Optional[float]`\n- `logit_bias`: `typing.Optional[dict]`\n- `user`: `typing.Optional[str]`\n- `response_format`: `typing.Union[dict, type[pydantic.main.BaseModel], NoneType]`\n- `seed`: `typing.Optional[int]`\n- `tools`: `typing.Optional[list]`\n- `tool_choice`: `typing.Union[str, dict, NoneType]`\n- `logprobs`: `typing.Optional[bool]`\n- `top_logprobs`: `typing.Optional[int]`\n- `parallel_tool_calls`: `typing.Optional[bool]`\n- `extra_headers`: `typing.Optional[dict]`\n- `functions`: `typing.Optional[list]`\n- `function_call`: `typing.Optional[str]`\n- `api_version`: `typing.Optional[str]`\n\n---\n\n\n\n## class `CompletionsCreateRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `response`: `dict[str, typing.Any]`\n- `weave_call_id`: `typing.Optional[str]`\n\n---\n\n\n\n## class `CostCreateInput`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `prompt_token_cost`: ``\n- `completion_token_cost`: ``\n- `prompt_token_cost_unit`: `typing.Optional[str]`\n- `completion_token_cost_unit`: `typing.Optional[str]`\n- `effective_date`: `typing.Optional[datetime.datetime]`\n- `provider_id`: `typing.Optional[str]`\n\n---\n\n\n\n## class `CostCreateReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `costs`: `dict[str, CostCreateInput]`\n- `wb_user_id`: `typing.Optional[str]`\n\n---\n\n\n\n## class `CostCreateRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `ids`: `list[tuple[str, str]]`\n\n---\n\n\n\n## class `CostPurgeReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `query`: ``\n\n---\n\n\n\n## class `CostPurgeRes`\n\n\n\n\n\n\n---\n\n\n\n## class `CostQueryOutput`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `id`: `typing.Optional[str]`\n- `llm_id`: `typing.Optional[str]`\n- `prompt_token_cost`: `typing.Optional[float]`\n- `completion_token_cost`: `typing.Optional[float]`\n- `prompt_token_cost_unit`: `typing.Optional[str]`\n- `completion_token_cost_unit`: `typing.Optional[str]`\n- `effective_date`: `typing.Optional[datetime.datetime]`\n- `provider_id`: `typing.Optional[str]`\n\n---\n\n\n\n## class `CostQueryReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `fields`: `typing.Optional[list[str]]`\n- `query`: `typing.Optional[weave.trace_server.interface.query.Query]`\n- `sort_by`: `typing.Optional[list[SortBy]]`\n- `limit`: `typing.Optional[int]`\n- `offset`: `typing.Optional[int]`\n\n---\n\n\n\n## class `CostQueryRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `results`: `list[CostQueryOutput]`\n\n---\n\n\n\n## class `EndedCallSchemaForInsert`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `id`: ``\n- `ended_at`: ``\n- `exception`: `typing.Optional[str]`\n- `output`: `typing.Optional[typing.Any]`\n- `summary`: ``\n---\n\n\n\n### method `serialize_typed_dicts`\n\n```python\nserialize_typed_dicts(v: dict[str, Any]) \u2192 dict[str, Any]\n```\n\n\n\n\n\n\n---\n\n\n\n## class `EnsureProjectExistsRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_name`: ``\n\n---\n\n\n\n## class `ExportTracePartialSuccess`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `rejected_spans`: ``\n- `error_message`: ``\n\n---\n\n\n\n## class `ExtraKeysTypedDict`\n\n\n\n\n\n\n\n\n---\n\n\n\n## class `Feedback`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `weave_ref`: ``\n- `creator`: `typing.Optional[str]`\n- `feedback_type`: ``\n- `payload`: `dict[str, typing.Any]`\n- `annotation_ref`: `typing.Optional[str]`\n- `runnable_ref`: `typing.Optional[str]`\n- `call_ref`: `typing.Optional[str]`\n- `trigger_ref`: `typing.Optional[str]`\n- `wb_user_id`: `typing.Optional[str]`\n- `id`: ``\n- `created_at`: ``\n\n---\n\n\n\n## class `FeedbackCreateReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `weave_ref`: ``\n- `creator`: `typing.Optional[str]`\n- `feedback_type`: ``\n- `payload`: `dict[str, typing.Any]`\n- `annotation_ref`: `typing.Optional[str]`\n- `runnable_ref`: `typing.Optional[str]`\n- `call_ref`: `typing.Optional[str]`\n- `trigger_ref`: `typing.Optional[str]`\n- `wb_user_id`: `typing.Optional[str]`\n\n---\n\n\n\n## class `FeedbackCreateRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `id`: ``\n- `created_at`: ``\n- `wb_user_id`: ``\n- `payload`: `dict[str, typing.Any]`\n\n---\n\n\n\n## class `FeedbackDict`\n\n\n\n\n\n\n\n\n---\n\n\n\n## class `FeedbackPurgeReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `query`: ``\n\n---\n\n\n\n## class `FeedbackPurgeRes`\n\n\n\n\n\n\n---\n\n\n\n## class `FeedbackQueryReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `fields`: `typing.Optional[list[str]]`\n- `query`: `typing.Optional[weave.trace_server.interface.query.Query]`\n- `sort_by`: `typing.Optional[list[SortBy]]`\n- `limit`: `typing.Optional[int]`\n- `offset`: `typing.Optional[int]`\n\n---\n\n\n\n## class `FeedbackQueryRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `result`: `list[dict[str, typing.Any]]`\n\n---\n\n\n\n## class `FeedbackReplaceReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `weave_ref`: ``\n- `creator`: `typing.Optional[str]`\n- `feedback_type`: ``\n- `payload`: `dict[str, typing.Any]`\n- `annotation_ref`: `typing.Optional[str]`\n- `runnable_ref`: `typing.Optional[str]`\n- `call_ref`: `typing.Optional[str]`\n- `trigger_ref`: `typing.Optional[str]`\n- `wb_user_id`: `typing.Optional[str]`\n- `feedback_id`: ``\n\n---\n\n\n\n## class `FeedbackReplaceRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `id`: ``\n- `created_at`: ``\n- `wb_user_id`: ``\n- `payload`: `dict[str, typing.Any]`\n\n---\n\n\n\n## class `FileContentReadReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `digest`: ``\n\n---\n\n\n\n## class `FileContentReadRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `content`: ``\n\n---\n\n\n\n## class `FileCreateReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `name`: ``\n- `content`: ``\n\n---\n\n\n\n## class `FileCreateRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `digest`: ``\n\n---\n\n\n\n## class `FilesStatsReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n\n---\n\n\n\n## class `FilesStatsRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `total_size_bytes`: ``\n\n---\n\n\n\n## class `LLMCostSchema`\n\n\n\n\n\n\n\n\n---\n\n\n\n## class `LLMUsageSchema`\n\n\n\n\n\n\n\n\n---\n\n\n\n## class `ObjCreateReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `obj`: ``\n\n---\n\n\n\n## class `ObjCreateRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `digest`: ``\n\n---\n\n\n\n## class `ObjDeleteReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `object_id`: ``\n- `digests`: `typing.Optional[list[str]]`\n\n---\n\n\n\n## class `ObjDeleteRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `num_deleted`: ``\n\n---\n\n\n\n## class `ObjQueryReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `filter`: `typing.Optional[ObjectVersionFilter]`\n- `limit`: `typing.Optional[int]`\n- `offset`: `typing.Optional[int]`\n- `sort_by`: `typing.Optional[list[SortBy]]`\n- `metadata_only`: `typing.Optional[bool]`\n- `include_storage_size`: `typing.Optional[bool]`\n\n---\n\n\n\n## class `ObjQueryRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `objs`: `list[ObjSchema]`\n\n---\n\n\n\n## class `ObjReadReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `object_id`: ``\n- `digest`: ``\n- `metadata_only`: `typing.Optional[bool]`\n\n---\n\n\n\n## class `ObjReadRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `obj`: ``\n\n---\n\n\n\n## class `ObjSchema`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `object_id`: ``\n- `created_at`: ``\n- `deleted_at`: `typing.Optional[datetime.datetime]`\n- `digest`: ``\n- `version_index`: ``\n- `is_latest`: ``\n- `kind`: ``\n- `base_object_class`: `typing.Optional[str]`\n- `val`: `typing.Any`\n- `wb_user_id`: `typing.Optional[str]`\n- `size_bytes`: `typing.Optional[int]`\n\n---\n\n\n\n## class `ObjSchemaForInsert`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `object_id`: ``\n- `val`: `typing.Any`\n- `builtin_object_class`: `typing.Optional[str]`\n- `set_base_object_class`: `typing.Optional[str]`\n- `wb_user_id`: `typing.Optional[str]`\n---\n\n\n\n### method `model_post_init`\n\n```python\nmodel_post_init(_ObjSchemaForInsert__context: Any) \u2192 None\n```\n\n\n\n\n\n\n---\n\n\n\n## class `ObjectVersionFilter`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `base_object_classes`: `typing.Optional[list[str]]`\n- `object_ids`: `typing.Optional[list[str]]`\n- `is_op`: `typing.Optional[bool]`\n- `latest_only`: `typing.Optional[bool]`\n\n---\n\n\n\n## class `OpCreateReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `op_obj`: ``\n\n---\n\n\n\n## class `OpCreateRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `digest`: ``\n\n---\n\n\n\n## class `OpQueryReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `filter`: `typing.Optional[OpVersionFilter]`\n\n---\n\n\n\n## class `OpQueryRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `op_objs`: `list[ObjSchema]`\n\n---\n\n\n\n## class `OpReadReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `name`: ``\n- `digest`: ``\n\n---\n\n\n\n## class `OpReadRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `op_obj`: ``\n\n---\n\n\n\n## class `OpVersionFilter`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `op_names`: `typing.Optional[list[str]]`\n- `latest_only`: `typing.Optional[bool]`\n\n---\n\n\n\n## class `OtelExportReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `traces`: `typing.Any`\n- `wb_user_id`: `typing.Optional[str]`\n\n---\n\n\n\n## class `OtelExportRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `partial_success`: `typing.Optional[ExportTracePartialSuccess]`\n\n---\n\n\n\n## class `RefsReadBatchReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `refs`: `list[str]`\n\n---\n\n\n\n## class `RefsReadBatchRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `vals`: `list[typing.Any]`\n\n---\n\n\n\n## class `SortBy`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `field`: ``\n- `direction`: `typing.Literal['asc', 'desc']`\n\n---\n\n\n\n## class `StartedCallSchemaForInsert`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `id`: `typing.Optional[str]`\n- `op_name`: ``\n- `display_name`: `typing.Optional[str]`\n- `trace_id`: `typing.Optional[str]`\n- `parent_id`: `typing.Optional[str]`\n- `started_at`: ``\n- `attributes`: `dict[str, typing.Any]`\n- `inputs`: `dict[str, typing.Any]`\n- `wb_user_id`: `typing.Optional[str]`\n- `wb_run_id`: `typing.Optional[str]`\n\n---\n\n\n\n## class `SummaryInsertMap`\n\n\n\n\n\n\n\n\n---\n\n\n\n## class `SummaryMap`\n\n\n\n\n\n\n\n\n---\n\n\n\n## class `TableAppendSpec`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `append`: ``\n\n---\n\n\n\n## class `TableAppendSpecPayload`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `row`: `dict[str, typing.Any]`\n\n---\n\n\n\n## class `TableCreateReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `table`: ``\n\n---\n\n\n\n## class `TableCreateRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `digest`: ``\n- `row_digests`: `list[str]`\n\n---\n\n\n\n## class `TableInsertSpec`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `insert`: ``\n\n---\n\n\n\n## class `TableInsertSpecPayload`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `index`: ``\n- `row`: `dict[str, typing.Any]`\n\n---\n\n\n\n## class `TablePopSpec`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `pop`: ``\n\n---\n\n\n\n## class `TablePopSpecPayload`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `index`: ``\n\n---\n\n\n\n## class `TableQueryReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `digest`: ``\n- `filter`: `typing.Optional[TableRowFilter]`\n- `limit`: `typing.Optional[int]`\n- `offset`: `typing.Optional[int]`\n- `sort_by`: `typing.Optional[list[SortBy]]`\n\n---\n\n\n\n## class `TableQueryRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `rows`: `list[TableRowSchema]`\n\n---\n\n\n\n## class `TableQueryStatsBatchReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `digests`: `typing.Optional[list[str]]`\n- `include_storage_size`: `typing.Optional[bool]`\n\n---\n\n\n\n## class `TableQueryStatsBatchRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `tables`: `list[TableStatsRow]`\n\n---\n\n\n\n## class `TableQueryStatsReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `digest`: ``\n\n---\n\n\n\n## class `TableQueryStatsRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `count`: ``\n\n---\n\n\n\n## class `TableRowFilter`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `row_digests`: `typing.Optional[list[str]]`\n\n---\n\n\n\n## class `TableRowSchema`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `digest`: ``\n- `val`: `typing.Any`\n- `original_index`: `typing.Optional[int]`\n\n---\n\n\n\n## class `TableSchemaForInsert`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `rows`: `list[dict[str, typing.Any]]`\n\n---\n\n\n\n## class `TableStatsRow`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `count`: ``\n- `digest`: ``\n- `storage_size_bytes`: `typing.Optional[int]`\n\n---\n\n\n\n## class `TableUpdateReq`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `project_id`: ``\n- `base_digest`: ``\n- `updates`: `list[typing.Union[TableAppendSpec, TablePopSpec, TableInsertSpec]]`\n\n---\n\n\n\n## class `TableUpdateRes`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `digest`: ``\n- `updated_row_digests`: `list[str]`\n\n---\n\n\n\n## class `TraceServerInterface`\n\n\n\n\n\n\n\n---\n\n\n\n### method `actions_execute_batch`\n\n```python\nactions_execute_batch(req: ActionsExecuteBatchReq) \u2192 ActionsExecuteBatchRes\n```\n\n\n\n\n\n---\n\n\n\n### method `call_end`\n\n```python\ncall_end(req: CallEndReq) \u2192 CallEndRes\n```\n\n\n\n\n\n---\n\n\n\n### method `call_read`\n\n```python\ncall_read(req: CallReadReq) \u2192 CallReadRes\n```\n\n\n\n\n\n---\n\n\n\n### method `call_start`\n\n```python\ncall_start(req: CallStartReq) \u2192 CallStartRes\n```\n\n\n\n\n\n---\n\n\n\n### method `call_start_batch`\n\n```python\ncall_start_batch(req: CallCreateBatchReq) \u2192 CallCreateBatchRes\n```\n\n\n\n\n\n---\n\n\n\n### method `call_update`\n\n```python\ncall_update(req: CallUpdateReq) \u2192 CallUpdateRes\n```\n\n\n\n\n\n---\n\n\n\n### method `calls_delete`\n\n```python\ncalls_delete(req: CallsDeleteReq) \u2192 CallsDeleteRes\n```\n\n\n\n\n\n---\n\n\n\n### method `calls_query`\n\n```python\ncalls_query(req: CallsQueryReq) \u2192 CallsQueryRes\n```\n\n\n\n\n\n---\n\n\n\n### method `calls_query_stats`\n\n```python\ncalls_query_stats(req: CallsQueryStatsReq) \u2192 CallsQueryStatsRes\n```\n\n\n\n\n\n---\n\n\n\n### method `calls_query_stream`\n\n```python\ncalls_query_stream(req: CallsQueryReq) \u2192 Iterator[CallSchema]\n```\n\n\n\n\n\n---\n\n\n\n### method `completions_create`\n\n```python\ncompletions_create(req: CompletionsCreateReq) \u2192 CompletionsCreateRes\n```\n\n\n\n\n\n---\n\n\n\n### method `cost_create`\n\n```python\ncost_create(req: CostCreateReq) \u2192 CostCreateRes\n```\n\n\n\n\n\n---\n\n\n\n### method `cost_purge`\n\n```python\ncost_purge(req: CostPurgeReq) \u2192 CostPurgeRes\n```\n\n\n\n\n\n---\n\n\n\n### method `cost_query`\n\n```python\ncost_query(req: CostQueryReq) \u2192 CostQueryRes\n```\n\n\n\n\n\n---\n\n\n\n### method `ensure_project_exists`\n\n```python\nensure_project_exists(entity: str, project: str) \u2192 EnsureProjectExistsRes\n```\n\n\n\n\n\n---\n\n\n\n### method `feedback_create`\n\n```python\nfeedback_create(req: FeedbackCreateReq) \u2192 FeedbackCreateRes\n```\n\n\n\n\n\n---\n\n\n\n### method `feedback_purge`\n\n```python\nfeedback_purge(req: FeedbackPurgeReq) \u2192 FeedbackPurgeRes\n```\n\n\n\n\n\n---\n\n\n\n### method `feedback_query`\n\n```python\nfeedback_query(req: FeedbackQueryReq) \u2192 FeedbackQueryRes\n```\n\n\n\n\n\n---\n\n\n\n### method `feedback_replace`\n\n```python\nfeedback_replace(req: FeedbackReplaceReq) \u2192 FeedbackReplaceRes\n```\n\n\n\n\n\n---\n\n\n\n### method `file_content_read`\n\n```python\nfile_content_read(req: FileContentReadReq) \u2192 FileContentReadRes\n```\n\n\n\n\n\n---\n\n\n\n### method `file_create`\n\n```python\nfile_create(req: FileCreateReq) \u2192 FileCreateRes\n```\n\n\n\n\n\n---\n\n\n\n### method `files_stats`\n\n```python\nfiles_stats(req: FilesStatsReq) \u2192 FilesStatsRes\n```\n\n\n\n\n\n---\n\n\n\n### method `obj_create`\n\n```python\nobj_create(req: ObjCreateReq) \u2192 ObjCreateRes\n```\n\n\n\n\n\n---\n\n\n\n### method `obj_delete`\n\n```python\nobj_delete(req: ObjDeleteReq) \u2192 ObjDeleteRes\n```\n\n\n\n\n\n---\n\n\n\n### method `obj_read`\n\n```python\nobj_read(req: ObjReadReq) \u2192 ObjReadRes\n```\n\n\n\n\n\n---\n\n\n\n### method `objs_query`\n\n```python\nobjs_query(req: ObjQueryReq) \u2192 ObjQueryRes\n```\n\n\n\n\n\n---\n\n\n\n### method `op_create`\n\n```python\nop_create(req: OpCreateReq) \u2192 OpCreateRes\n```\n\n\n\n\n\n---\n\n\n\n### method `op_read`\n\n```python\nop_read(req: OpReadReq) \u2192 OpReadRes\n```\n\n\n\n\n\n---\n\n\n\n### method `ops_query`\n\n```python\nops_query(req: OpQueryReq) \u2192 OpQueryRes\n```\n\n\n\n\n\n---\n\n\n\n### method `otel_export`\n\n```python\notel_export(req: OtelExportReq) \u2192 OtelExportRes\n```\n\n\n\n\n\n---\n\n\n\n### method `refs_read_batch`\n\n```python\nrefs_read_batch(req: RefsReadBatchReq) \u2192 RefsReadBatchRes\n```\n\n\n\n\n\n---\n\n\n\n### method `table_create`\n\n```python\ntable_create(req: TableCreateReq) \u2192 TableCreateRes\n```\n\n\n\n\n\n---\n\n\n\n### method `table_query`\n\n```python\ntable_query(req: TableQueryReq) \u2192 TableQueryRes\n```\n\n\n\n\n\n---\n\n\n\n### method `table_query_stats`\n\n```python\ntable_query_stats(req: TableQueryStatsReq) \u2192 TableQueryStatsRes\n```\n\n\n\n\n\n---\n\n\n\n### method `table_query_stats_batch`\n\n```python\ntable_query_stats_batch(req: TableQueryStatsBatchReq) \u2192 TableQueryStatsBatchRes\n```\n\n\n\n\n\n---\n\n\n\n### method `table_query_stream`\n\n```python\ntable_query_stream(req: TableQueryReq) \u2192 Iterator[TableRowSchema]\n```\n\n\n\n\n\n---\n\n\n\n### method `table_update`\n\n```python\ntable_update(req: TableUpdateReq) \u2192 TableUpdateRes\n```\n\n\n\n\n\n\n---\n\n\n\n## class `TraceStatus`\nAn enumeration. \n\n\n\n\n\n---\n\n\n\n## class `WeaveSummarySchema`"
  },
  {
    "title": "Weave.Trace Server.Interface.Query",
    "url": "https://weave-docs.wandb.ai/reference/python-sdk/weave/trace_server/interface/weave.trace_server.interface.query",
    "section": "Docs",
    "category": "Python SDK",
    "content": "# weave.trace_server.interface.query\n\n\nThis file contains the interface definition for the Trace Server Query model. It\nis heavily inspired by the MongoDB query language, but is a subset of the full\nMongoDB query language. In particular, we have made the following\nsimplifications:\n\n* We only support the \"aggregation\" operators, not the \"query\" operators. This is\n    purely for simplicity and because the \"aggregation\" operators are more powerful.\n    The Mongo docs language has evolved over time and the primary query language\n    is column-oriented. However, the more expressive aggregation language can be\n    used for both direct queries, but also for column comparison and\n    calculations. We can add support for the \"query\" operators in the future if\n    needed.\n\n* We only support a subset of the operators / shorthand forms for now. We can add\n    more operators in the future as needed.\n\n    * One notable omission here is the lack of support for \"$field\" as a shorthand for\n        the \"getField\"  operator.\n\n* We have _added_ a `$contains` operator which is not in the MongoDB query\n    language. This is a simple substring match operator.\n\n\n---\n\n\n# API Overview\n\n\n\n## Classes\n\n- [`query.AndOperation`](#class-andoperation)\n- [`query.ContainsOperation`](#class-containsoperation)\n- [`query.ContainsSpec`](#class-containsspec)\n- [`query.ConvertOperation`](#class-convertoperation)\n- [`query.ConvertSpec`](#class-convertspec)\n- [`query.EqOperation`](#class-eqoperation)\n- [`query.GetFieldOperator`](#class-getfieldoperator)\n- [`query.GtOperation`](#class-gtoperation)\n- [`query.GteOperation`](#class-gteoperation)\n- [`query.InOperation`](#class-inoperation)\n- [`query.LiteralOperation`](#class-literaloperation)\n- [`query.NotOperation`](#class-notoperation)\n- [`query.OrOperation`](#class-oroperation)\n- [`query.Query`](#class-query)\n\n\n\n\n---\n\n\n\n\n## class `AndOperation`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `$and`: `list['Operand']`\n\n---\n\n\n\n## class `ContainsOperation`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `$contains`: ``\n\n---\n\n\n\n## class `ContainsSpec`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `input`: `typing.Union[LiteralOperation, GetFieldOperator, ConvertOperation, AndOperation, OrOperation, NotOperation, EqOperation, GtOperation, GteOperation, InOperation, ContainsOperation]`\n- `substr`: `typing.Union[LiteralOperation, GetFieldOperator, ConvertOperation, AndOperation, OrOperation, NotOperation, EqOperation, GtOperation, GteOperation, InOperation, ContainsOperation]`\n- `case_insensitive`: `typing.Optional[bool]`\n\n---\n\n\n\n## class `ConvertOperation`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `$convert`: ``\n\n---\n\n\n\n## class `ConvertSpec`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `input`: `typing.Union[LiteralOperation, GetFieldOperator, ConvertOperation, AndOperation, OrOperation, NotOperation, EqOperation, GtOperation, GteOperation, InOperation, ContainsOperation]`\n- `to`: `typing.Literal['double', 'string', 'int', 'bool', 'exists']`\n\n---\n\n\n\n## class `EqOperation`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `$eq`: `tuple['Operand', 'Operand']`\n\n---\n\n\n\n## class `GetFieldOperator`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `$getField`: ``\n\n---\n\n\n\n## class `GtOperation`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `$gt`: `tuple['Operand', 'Operand']`\n\n---\n\n\n\n## class `GteOperation`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `$gte`: `tuple['Operand', 'Operand']`\n\n---\n\n\n\n## class `InOperation`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `$in`: `tuple['Operand', list['Operand']]`\n\n---\n\n\n\n## class `LiteralOperation`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `$literal`: `typing.Union[str, int, float, bool, dict[str, 'LiteralOperation'], list['LiteralOperation'], NoneType]`\n\n---\n\n\n\n## class `NotOperation`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `$not`: `tuple['Operand']`\n\n---\n\n\n\n## class `OrOperation`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `$or`: `list['Operand']`\n\n---\n\n\n\n## class `Query`\n\n\n\n\n\n**Pydantic Fields:**\n\n- `$expr`: `typing.Union[AndOperation, OrOperation, NotOperation, EqOperation, GtOperation, GteOperation, InOperation, ContainsOperation]`"
  },
  {
    "title": "Comparison",
    "url": "https://weave-docs.wandb.ai/guides/tools/comparison",
    "section": "Docs",
    "category": "Tools",
    "content": "# Comparison\n\nThe Weave Comparison feature allows you to visually compare and diff code, traces, prompts, models, and model configurations.  You can compare two objects side-by-side or analyze a larger set of objects to identify differences, patterns, and trends.\n\nThis guide covers the steps to start a comparison and the available actions to tailor your comparison view, including baseline comparisons, numeric diff formatting, and more. \n\n## Access the Comparison view\n\n1. In the sidebar, select the type of object you'd like to compare (e.g. **Traces**, **Models**, etc.).\n2. Select the objects that you want to compare. The selection method varies depending on the type of object you are comparing:\n   - For **Traces**, select traces to compare by checking the checkboxes in the appropriate rows in the Traces column.\n   - For objects such as **Models**, navigate to the model Versions page and check the checkboxes next to the  versions that you want to compare.\n3. Click **Compare** to open the Comparison view. Now, you can refine your view using the [available actions](#available-actions).\n\n## Available actions\n\nIn the Comparison view, you have multiple actions available, depending on how many objects are being compared. Make sure to look at the [usage notes](#usage-notes).\n\n- [Change the diff display](#change-the-diff-display)\n- [Display side-by-side](#display-side-by-side)\n- [Display in a unified view](#display-in-a-unified-view)\n- [Set a baseline](#set-a-baseline)\n- [Remove a baseline](#remove-a-baseline)\n- [Change the comparison order](#change-the-comparison-order)\n- [Change numeric diff display format](#change-numeric-diff-display-format)\n- [Compare with baseline or previous](#compare-with-baseline-or-previous)\n- [Compare a pair from a multi-object comparison](#compare-a-pair-from-a-multi-object-comparison)\n- [Remove an object from comparison](#remove-an-object-from-comparison)\n\n### Change the diff display\n\nBy default, **Diff only** is set to off. To filter the table rows so that only changed rows are displayed, toggle **Diff only** on. \n\n### Display side-by-side \n\n> This option is only available when comparing two objects, or a [pair from a multi-object comparison](#compare-a-pair-from-a-multi-object-comparison).\n\nTo compare each object side-by-side in separate columns, select **Side-by-side**. \n\n\n\n### Display in a unified view\n\n> This option is only available when comparing two objects, or a [pair from a multi-object comparison](#compare-a-pair-from-a-multi-object-comparison).\n\nTo compare each object in a unified view, select **Unified**. \n\n\n\n### Set a baseline\n\nBy default, each object in the Comparison view is compared to the object to its left. However, you can set an object as the _baseline_, which means that all objects will be compared to the leftmost object in the view.\nTo set an object as baseline, do the following:\n\n1. In the Comparison view topbar, mouse over the object that you want to set as the baseline.\n2. Click the three dots to the right of the ID.\n   \n3. In the dropdown, select **Make baseline**. The UI refreshes so that the baseline object is furthest left in the topbar, and `Baseline` displays next to the ID.\n    \n\n### Remove a baseline\n\nTo remove an object as baseline, do the following:\n\n1. In the Comparison view topbar, mouse over the baseline object.\n2. Click the three dots to the right of the ID.\n3. In the dropdown, select **Remove baseline**. Now, `Baseline` no longer displays next to the call ID.\n\n### Change the comparison order\n\nTo change the comparison order, do the following:\n\n1. In the Comparison view topbar, mouse over the ID that you want to reorder. \n2. Click the six dots to the left of the ID.\n   \n3. Drag the ID to the left or the right, depending on which object was selected. \n4. Place the ID in the desired ordering. The UI refreshes with an updated comparison ordering.\n\n### Change numeric diff display format \n\nFor numeric values such as `completion_tokens` and `total_tokens`, you can view the diff as either an integer or a percentage. Additionally, positive numeric values can be viewed as a multiplier. To change a numeric diff's display format, do the following:\n\n1. In the Comparison table, find the numeric value that you want to update the diff display format for.\n    \n2. Click the diff value. The format automatically updates to either an integer or a percentage.\n    \n\n### Compare with baseline or previous\n\n> This option is only available when comparing 3 or more objects.\n> You can also [set](#set-a-baseline) or [remove an existing baseline by clicking the 3 dots to the right of the ID](#remove-a-baseline).\n\nTo perform a baseline comparison with 3 or more objects, do the following:\n\n1. In the right hand corner of the Comparison view, click the dropdown. Depending on your current view configuration, the dropdown is either titled **Compare with previous** or **Compare with baseline**.\n2. Depending on your current view configuration, select either **Compare with previous** or **Compare with baseline**.\n   - **Compare with baseline**: Sets the leftmost object as the baseline. The table updates so that the leftmost column is the baseline.\n   -  **Compare with previous**: No object is set as baseline.\n\n### Compare a pair from a multi-object comparison\n\n> This option is only available when comparing 3 or more objects.\n\nWhen comparing 3 or more objects, you can compare a single object to a previous object or baseline. This changes the Comparison table view so that the view is identical to a two-object comparison. To compare a pair of objects from a multi-object comparison, do the following:\n\n1. In the Comparison view topbar, find the ID that you want to compare to previous or baseline. \n2. To select the item, click the ID. The UI refreshes with a two-way comparison table.\n    \n\nTo reset the view so that the first 6 objects selected for comparison are displayed in the table, click the ID again.\n\n### Remove an object from comparison\n\n> This option is only available when comparing 3 or more objects.\n\nTo remove an object from comparison, do the following:\n\n1. In the Comparison view topbar, find the object that you want to remove from comparison.\n2. Click the three dots to the right of the ID.\n3. In the dropdown, select **Remove object from comparison**. The UI refreshes with an updated table that no longer includes the removed object.\n\n## Usage notes\n\n - The Comparison feature is only available in the UI.\n - You can compare as many objects as you'd like. However, the UI only displays a maximum of 6. To view an object in the comparison table that is not visible when comparing more than 6 objects, either [change the comparison order](#change-the-comparison-order) so that the object is one of the first 6 objects from left to right, or [pair from a multi-object comparison](#compare-a-pair-from-a-multi-object-comparison) for easy viewing."
  },
  {
    "title": "Deploy",
    "url": "https://weave-docs.wandb.ai/guides/tools/deploy",
    "section": "Docs",
    "category": "Tools",
    "content": "# Deploy\n\n## Deploy to GCP\n\n> \ud83d\udca1 **Note**: `weave deploy` requires your machine to have `gcloud` installed and configured. `weave deploy gcp` will use pre-configured configuration when not directly specified by command line arguments.\n\nGiven a Weave ref to any Weave Model you can run:\n\n```\nweave deploy gcp \n```\n\nto deploy a gcp cloud function that serves your model. The last line of the deployment will look like `Service URL: `. Visit `/docs` to interact with your model!\n\nRun\n\n```\nweave deploy gcp --help\n```\n\nto see all command line options."
  },
  {
    "title": "Playground",
    "url": "https://weave-docs.wandb.ai/guides/tools/playground",
    "section": "Docs",
    "category": "Tools",
    "content": "# Playground\n\nEvaluating LLM prompts and responses is challenging. The Weave Playground is designed to simplify the process of iterating on LLM prompts and responses, making it easier to experiment with different models and prompts. With features like prompt editing, message retrying, and model comparison, Playground helps you to quickly test and improve your LLM applications. Playground currently supports models from OpenAI, Anthropic, Google, Groq, Amazon Bedrock, and Microsoft Azure, as well as [custom providers](#add-a-custom-provider).\n\n- **Quick access:** Open the Playground from the W&B sidebar for a fresh session or from the Call page to test an existing project.\n- **Message controls:** Edit, retry, or delete messages directly within the chat.\n- **Flexible messaging:** Add new messages as either user or system inputs, and send them to the LLM.\n- **Customizable settings:** Configure your preferred LLM provider and adjust model settings.\n- **Multi-LLM support:** Switch between models, with team-level API key management.\n- **Compare models:** Compare how different models respond to prompts.\n- **Custom providers:** Test OpenAI compatible API endpoints for custom models.\n- **Saved models:** Create and configure a reusable model preset for your workflow\n\nGet started with the Playground to optimize your LLM interactions and streamline your prompt engineering process and LLM application development.\n\n- [Prerequisites](#prerequisites)\n  - [Add provider credentials and information](#add-provider-credentials-and-information)\n  - [Access the Playground](#access-the-playground)\n- [Select an LLM](#select-an-llm)\n- [Customize settings](#customize-settings)\n- [Message controls](#add-retry-edit-and-delete-messages)\n- [Compare LLMs](#compare-llms)\n- [Custom providers](#custom-providers)\n- [Saved models](#saved-models) \n\n## Prerequisites\n\nBefore you can use Playground, you must [add provider credentials](#add-provider-credentials-and-information), and [open the Playground UI](#access-the-playground).\n\n### Add provider credentials and information\n\nPlayground currently supports models from OpenAI, Anthropic, Google, Groq, Amazon Bedrock, and Microsoft Azure. To use one of the available models, add the appropriate information to your team secrets in W&B settings.\n\n- OpenAI: `OPENAI_API_KEY`\n- Anthropic: `ANTHROPIC_API_KEY`\n- Google: `GEMINI_API_KEY`\n- Groq: `GROQ_API_KEY`\n- Amazon Bedrock:\n  - `AWS_ACCESS_KEY_ID`\n  - `AWS_SECRET_ACCESS_KEY`\n  - `AWS_REGION_NAME`\n- Azure:\n  - `AZURE_API_KEY`\n  - `AZURE_API_BASE`\n  - `AZURE_API_VERSION`\n- X.AI:\n  - `XAI_API_KEY`\n- Deepseek\n  - `DEEPSEEK_API_KEY`\n\n### Access the Playground\n\nThere are two ways to access the Playground:\n\n1. _Open a fresh Playground page with a simple system prompt_: In the sidebar, select **Playground**. Playground opens in the same tab.\n2. _Open Playground for a specific call_:\n   1. In the sidebar, select the **Traces** tab. A list of traces displays.\n   2. In the list of traces, click the name of the call that you want to view. The call's details page opens.\n   3. Click **Open chat in playground**. Playground opens in a new tab.\n\n\n\n## Select an LLM\n\nYou can switch the LLM using the dropdown menu in the top left. The available models from various providers are listed below:\n\n- [Amazon Bedrock](#amazon-bedrock)\n- [Anthropic](#anthropic)\n- [Azure](#azure)\n- [Google](#google)\n- [Groq](#groq)\n- [OpenAI](#openai)\n- [X.AI](#xai)\n- [Deepseek](#deepseek)\n\n\n\n\n### [Amazon Bedrock](../integrations/bedrock.md)\n\n- ai21.j2-mid-v1\n- ai21.j2-ultra-v1\n- amazon.nova-micro-v1:0\n- amazon.nova-lite-v1:0\n- amazon.nova-pro-v1:0\n- amazon.titan-text-lite-v1\n- amazon.titan-text-express-v1\n- mistral.mistral-7b-instruct-v0:2\n- mistral.mixtral-8x7b-instruct-v0:1\n- mistral.mistral-large-2402-v1:0\n- mistral.mistral-large-2407-v1:0\n- anthropic.claude-3-sonnet-20240229-v1:0\n- anthropic.claude-3-5-sonnet-20240620-v1:0\n- anthropic.claude-3-haiku-20240307-v1:0\n- anthropic.claude-3-opus-20240229-v1:0\n- anthropic.claude-v2\n- anthropic.claude-v2:1\n- anthropic.claude-instant-v1\n- cohere.command-text-v14\n- cohere.command-light-text-v14\n- cohere.command-r-plus-v1:0\n- cohere.command-r-v1:0\n- meta.llama2-13b-chat-v1\n- meta.llama2-70b-chat-v1\n- meta.llama3-8b-instruct-v1:0\n- meta.llama3-70b-instruct-v1:0\n- meta.llama3-1-8b-instruct-v1:0\n- meta.llama3-1-70b-instruct-v1:0\n- meta.llama3-1-405b-instruct-v1:0\n\n### [Anthropic](../integrations/anthropic.md)\n\n- claude-3-7-sonnet-20250219\n- claude-3-5-sonnet-20240620\n- claude-3-5-sonnet-20241022\n- claude-3-haiku-20240307\n- claude-3-opus-20240229\n- claude-3-sonnet-20240229\n\n### [Azure](../integrations/azure.md)\n\n- azure/o1-mini\n- azure/o1-mini-2024-09-12\n- azure/o1\n- azure/o1-preview\n- azure/o1-preview-2024-09-12\n- azure/gpt-4o\n- azure/gpt-4o-2024-08-06\n- azure/gpt-4o-2024-11-20\n- azure/gpt-4o-2024-05-13\n- azure/gpt-4o-mini\n- azure/gpt-4o-mini-2024-07-18\n\n### [Google](../integrations/google.md)\n\n- gemini/gemini-2.5-pro-preview-03-25\n- gemini/gemini-2.0-pro-exp-02-05\n- gemini/gemini-2.0-flash-exp\n- gemini/gemini-2.0-flash-001\n- gemini/gemini-2.0-flash-thinking-exp\n- gemini/gemini-2.0-flash-thinking-exp-01-21\n- gemini/gemini-2.0-flash\n- gemini/gemini-2.0-flash-lite\n- gemini/gemini-2.0-flash-lite-preview-02-05\n- gemini/gemini-1.5-flash-001\n- gemini/gemini-1.5-flash-002\n- gemini/gemini-1.5-flash-8b-exp-0827\n- gemini/gemini-1.5-flash-8b-exp-0924\n- gemini/gemini-1.5-flash-latest\n- gemini/gemini-1.5-flash\n- gemini/gemini-1.5-pro-001\n- gemini/gemini-1.5-pro-002\n- gemini/gemini-1.5-pro-latest\n- gemini/gemini-1.5-pro\n\n### [Groq](../integrations/groq.md)\n\n- groq/deepseek-r1-distill-llama-70b\n- groq/llama-3.3-70b-versatile\n- groq/llama-3.3-70b-specdec\n- groq/llama-3.2-1b-preview\n- groq/llama-3.2-3b-preview\n- groq/llama-3.2-11b-vision-preview\n- groq/llama-3.2-90b-vision-preview\n- groq/llama-3.1-8b-instant\n- groq/llama3-70b-8192\n- groq/llama3-8b-8192\n- groq/gemma2-9b-it\n\n### [OpenAI](../integrations/openai.md)\n\n- gpt-4.1-mini-2025-04-14\n- gpt-4.1-mini\n- gpt-4.1-2025-04-14\n- gpt-4.1\n- gpt-4.1-nano-2025-04-14\n- gpt-4.1-nano\n- o4-mini-2025-04-16\n- o4-mini\n- gpt-4.5-preview-2025-02-27\n- gpt-4.5-preview\n- o3-2025-04-16\n- o3\n- o3-mini-2025-01-31\n- o3-mini\n- gpt-4o-mini\n- gpt-4o-2024-05-13\n- gpt-4o-2024-08-06\n- gpt-4o-mini-2024-07-18\n- gpt-4o\n- gpt-4o-2024-11-20\n- o1-mini-2024-09-12\n- o1-mini\n- o1-preview-2024-09-12\n- o1-preview\n- o1-2024-12-17\n- gpt-4-1106-preview\n- gpt-4-32k-0314\n- gpt-4-turbo-2024-04-09\n- gpt-4-turbo-preview\n- gpt-4-turbo\n- gpt-4\n- gpt-3.5-turbo-0125\n- gpt-3.5-turbo-1106\n\n### X.AI\n\n- xai/grok-3-beta\n- xai/grok-3-fast-beta\n- xai/grok-3-fast-latest\n- xai/grok-3-mini-beta\n- xai/grok-3-mini-fast-beta\n- xai/grok-3-mini-fast-latest\n- xai/grok-beta\n- xai/grok-2-1212\n- xai/grok-2\n- xai/grok-2-latest\n\n### Deepseek\n\n- deepseek/deepseek-reasoner\n- deepseek/deepseek-chat\n\n\n\n## Customize settings\n\n### Adjust LLM parameters\n\nYou can experiment with different parameter values for your selected model. To adjust parameters, do the following:\n\n1. In the upper right corner of the Playground UI, click **Chat settings** to open the parameter settings dropdown.\n2. In the dropdown, adjust parameters as desired. You can also toggle Weave call tracking on or off, and [add a function](#add-a-function).\n3. Click **Chat settings** to close the dropdown and save your changes.\n\n\n\n### Add a function\n\nYou can test how different models use functions based on input it receives from the user. To add a function for testing in Playground, do the following:\n\n1. In the upper right corner of the Playground UI, click **Chat settings** to open the parameter settings dropdown.\n2. In the dropdown, click **+ Add function**.\n3. In the pop-up, add your function information.\n4. To save your changes and close the function pop-up, click the **x** in the upper right corner.\n5. Click **Chat settings** to close the settings dropdown and save your changes.\n\n### Adjust the number of trials\n\nPlayground allows you to generate multiple outputs for the same input by setting the number of trials. The default setting is `1`. To adjust the number of trials, do the following:\n\n1. In the Playground UI, open the settings sidebar if it is not already open.\n2. Adjust the **Number of trials**.\n\n## Message controls\n\n### Retry, edit, and delete messages\n\nWith Playground, you can retry, edit, and delete messages. To use this feature, hover over the message you want to edit, retry, or delete. Three buttons display: **Delete**, **Edit**, and **Retry**.\n\n- **Delete**: Remove the message from the chat.\n- **Edit**: Modify the message content.\n- **Retry**: Delete all subsequent messages and retry the chat from the selected message.\n\n\n\n\n### Add a new message\n\nTo add a new message to the chat, do the following:\n\n1. In the chat box, select one of the available roles (**Assistant** or **User**)\n2. Click **+ Add**.\n3. To send a new message to the LLM, click the **Send** button. Alternatively, press the **Command** and **Enter** keys.\n\n\n\n## Compare LLMs\n\nPlayground allows you to compare LLMs. To perform a comparison, do the following:\n\n1. In the Playground UI, click **Compare**. A second chat opens next to the original chat.\n2. In the second chat, you can:\n   - [Select the LLM to compare](#select-an-llm)\n   - [Adjust parameters](#adjust-llm-parameters)\n   - [Add functions](#add-a-function)\n3. In the message box, enter a message that you want to test with both models and press **Send**.\n\n## Custom providers\n\n### Add a custom provider\n\nIn addition to the [supported providers](#select-an-llm), you can use the Playground to test OpenAI compatible API endpoints for custom models. Examples include:\n\n- Older versions of supported model providers\n- Local models\n\nTo add a custom provider to the Playground, do the following:\n\n1. In the upper left corner of the Playground UI, click the **Select a model** dropdown.\n2. Select **+ Add AI provider**.\n3. In the pop-up modal, enter the provider information:\n\n   - _Provider name_: For example, `openai` or `ollama`.\n   - _API key_: For example, an OpenAI API key.\n   - _Base URL_: For example, `https://api.openai.com/v1/` or a ngrok URL `https://e452-2600-1700-45f0-3e10-2d3f-796b-d6f2-8ba7.ngrok-free.app`.\n   - _Headers_ (optional): You can add multiple header keys and values.\n   - _Models_: You can add multiple models for one provider. For example, `deepseek-r1` and `qwq`.\n   - _Max tokens_ (optional): For each model, you can specify the max tokens that the model can generate in a response.\n\n4. Once you've entered your provider information, click **Add provider**.\n5. Select your new provider and available model(s) from the **Select a model** dropdown in the upper left corner of the Playground UI.\n\n> \ud83d\udea8 **Important**: Because of CORS restrictions, you can't call localhost or 127.0.0.1 URLs directly from the Playground. If you're running a local model server (such as Ollama), use a tunneling service like ngrok to expose it securely. For details, see [Use ngrok with Ollama](#use-ngrok-with-ollama).\n\nNow, you can test the custom provider model(s) using standard Playground features. You can also [edit](#edit-a-custom-provider) or [remove](#remove-a-custom-provider) the custom provider.\n\n### Edit a custom provider\n\nTo edit information for a [previously created custom provider](#add-a-custom-provider), do the following:\n\n1. In the Weave sidebar, navigate to **Overview**.\n2. From the top navigation menu, select **AI Providers**.\n3. In the **Custom providers** table, find the custom provider you want to update.\n4. In the **Last Updated** column of the entry for your custom provider, click the edit button (the pencil icon).\n5. In the pop-up modal, edit the provider information.\n6. Click **Save**.\n\n### Remove a custom provider\n\nTo remove a [previously created custom provider](#add-a-custom-provider), do the following:\n\n1. In the Weave sidebar, navigate to **Overview**.\n2. From the top navigation menu, select **AI Providers**.\n3. In the **Custom providers** table, find the custom provider you want to update.\n4. In the **Last Updated** column of the entry for your custom provider, click the delete button (the trashcan icon).\n5. In the pop-up modal, confirm that you want to delete the provider. This action cannot be undone.\n6. Click **Delete**.\n\n### Use ngrok with Ollama\n\nTo test a locally running Ollama model in the Playground, use ngrok to create a temporary public URL that bypasses CORS restrictions.\n\nTo set it up, do the following:\n\n1. [Install ngrok](https://ngrok.com/docs/getting-started/#step-1-install) for your operating system.\n2. Start your Ollama model:\n\n   ```bash\n   ollama run \n   ```\n\n3. In a separate terminal, create an ngrok tunnel with the required CORS headers:\n\n   ```bash\n   ngrok http 11434 --response-header-add \"Access-Control-Allow-Origin: *\" --host-header rewrite\n   ```\n\nAfter ngrok starts, it will display a public URL, such as `https://xxxx-xxxx.ngrok-free.app`. Use this URL as the base URL when you add Ollama as a custom provider in the Playground.\n\nThe following diagram illustrates the data flow between your local environment, the ngrok proxy, and the W&B cloud services:\n\n```mermaid\nflowchart LR\n    %% Style definitions\n    classDef clientMachine fill:#FFD95CCC,stroke:#454B52,stroke-width:2px\n    classDef proxy fill:#00CDDBCC,stroke:#454B52,stroke-width:2px\n    classDef wandbCloud fill:#DE72FFCC,stroke:#454B52,stroke-width:2px\n    classDef publicCloud fill:#FFCBADCC,stroke:#454B52,stroke-width:2px\n\n    %% Subgraphs\n    subgraph Client_Machine\n        browser[Browser]\n        llm_local[Local LLM Provider]\n    end\n\n    subgraph Proxy\n        ngrok[Ngrok Proxy]\n    end\n\n    subgraph WandB_Cloud\n        trace_server[Trace Server]\n    end\n\n    subgraph Public_Cloud\n        llm_cloud[Public LLM Provider]\n    end\n\n    %% Apply styles to subgraphs\n    class Client_Machine clientMachine\n    class Proxy proxy\n    class WandB_Cloud wandbCloud\n    class Public_Cloud publicCloud\n\n    %% Current Data Flow\n    browser -->|Sends chat request| trace_server\n    trace_server -->|Uses Public LLM| llm_cloud\n    trace_server -->|Uses Local LLM| ngrok\n    ngrok -->|Forwards to| llm_local\n    llm_cloud -->|Returns response| trace_server\n    llm_local -->|Returns response| ngrok\n    ngrok -->|Forwards to| trace_server\n    trace_server -->|Returns response| browser\n\n    %% Future Possible Connection\n    browser -.->|Future: Call local LLM directly| llm_local\n\n    %% Link styles\n    linkStyle default stroke:#454B52,stroke-width:2px\n    linkStyle 8 stroke:#454B52,stroke-width:2px,stroke-dasharray:5\n```\n\n## Saved models\n\n### Save a model\n\nYou can create and configure a reusable model preset for your workflow. Saving a model lets you quickly load it with your preferred settings, parameters, and function hooks.\n\n1. From the LLM dropdown, select a provider.\n2. From the provider list, select a model.\n3. In the upper right corner of the Playground UI, click **Chat settings** to open the chat settings window.\n4. In the chat settings window:\n   - In the **Model Name** field, enter a name for your saved model. \n   - Adjust parameters as desired. You can also toggle Weave call tracking on or off, and [add a function](#add-a-function).\n5. Click **Publish Model**. The model is saved and accesible from **Saved Models** in the LLM dropdown. You can now [use](#use-a-saved-model) and [update](#update-a-saved-model) the saved model.\n\n\n\n### Use a saved model \n\nQuickly switch to a previously [saved model](#save-a-model) to maintain consistency across experiments or sessions. This allows you to pick up right where you left off.\n\n1. From the LLM dropdown, select **Saved Models**.\n2. From the list of saved models, click the saved model you want to load. The model loads and is ready for use in the Playground.\n\n\n\n### Update a saved model\n\nEdit an existing [saved model](#save-a-model) to fine-tune parameters or refresh its configuration. This ensures your saved models evolve alongside your use cases.\n\n1. From the LLM dropdown, select **Saved Models**.\n2. From the list of saved models, click the saved model you want to update. \n3. In the upper right corner of the Playground UI, click **Chat settings** to open the chat settings window.\n4. In the chat settings window, adjust parameters as desired. You can also toggle Weave call tracking on or off, and [add a function](#add-a-function).\n5. Click **Update model**. The model is updated and accesible from **Saved Models** in the LLM dropdown."
  },
  {
    "title": "Saved Views",
    "url": "https://weave-docs.wandb.ai/guides/tools/saved-views",
    "section": "Docs",
    "category": "Tools",
    "content": "# Saved Views\n\nIn Weave, _saved views_ allow you to customize how you interact with traced function calls and evaluations. By defining a saved view, you can configure filters, sorting, and column visibility to quickly access relevant data.\n\nYou can create, modify, and save views directly in the Weave Python SDK or through the UI. The Python SDK provides fine-grained control for programmatic filtering and querying, while the UI makes it easy to explore and save different table configurations in the **Traces** and **Evals** tabs.\n\nThis guide covers:\n\n- [How to create and modify Saved Views in the Python SDK](#saved-views-in-the-python-sdk).\n- [How to create and interact with Saved Views in the Weave UI](#saved-views-in-the-ui).\n\n## Saved views in the Python SDK\n\nThe `SavedView` class in Weave provides a way to save, filter, sort, and customize views of trace and evals data. \n\n### Initialize a `SavedView`\n\nInitialize a `SavedView` instance in your Weave project:\n\n```python\nimport weave\nclient = weave.init()\n\nview = weave.SavedView()\n```\n\n### Visualize the `SavedView` as a grid\n\nUse `.to_grid()` to represent the saved view as a grid. Specify the maximum number of rows to display with `limit`.\n\n```python\nview.to_grid(limit=5)\n```\n\nDisplay the grid representation using `.show()`:\n\n```python\nview.to_grid().show()\n```\n\n### Set displayed columns\n\nUse `.set_columns()` to set the columns to be displayed in the view. Specify one or more columns to be displayed.\n\n```python\nview.set_columns(\"id\", \"op_name\")\n```\n\n### Add columns\n\nUse `.add_column()` to add one or more new columns to the view. Specify one or more columns to be added.\n\n```python\n# Add a column with the field specifier and label \"Created\"\nview.add_column(\"Created\")\n# Optionally, you can add a second argument to specify a different label name for the new column. By default, the field specifier is use for the label.\n```\n\n### Sort columns\n\nUse `.sort_by()` to sort results based on a specific column. Specify the column name to be sorted and the sort order (`asc` or `desc`).\n\n```python\nview.sort_by(\"started_at\", \"desc\")\n```\n\n### Filter by operation name\n\nIn Weave, every trace or eval is associated with an operation name.\nUse `.filter_op()` to filter the `SavedView` to only include calls where that specific operation was executed. \n\n```python\nview.filter_op(\"Evaluation.predict_and_score\")\n```\n\n\n### Filter by operator and condition\n\nUse `.add_filter()` to apply a custom filter to the view. Define the filter using one of the [supported filter operators](#filter-operators) and a condition.\n\n```python\nview.add_filter(\"output.model_latency\", \">=\", 5)\n```\n\n#### Filter operators\n\n| Operator | Description | Example |\n|----------|-------------|---------|\n| `\"contains\"` | Checks if a string contains a substring. | `view.add_filter(\"output.status\", \"contains\", \"error\")` |\n| `\"equals\"` | Checks if a string is exactly equal to a given value. | `view.add_filter(\"input.category\", \"equals\", \"Alice\")` |\n| `\"in\"` | Checks if a string is in a list of values. | `view.add_filter(\"category\", \"in\", [\"A\", \"B\", \"C\"])` |\n| `\"=\"` | Checks if a number is equal to a value. | `view.add_filter(\"output.score\", \"=\", 80)` |\n| `\"\u2260\", \"!=\"` | Checks if a number is not equal to a value. | `view.add_filter(\"metrics.loss\", \"!=\", 0.5)` |\n| `\"<\"` | Checks if a number is less than a value. | `view.add_filter(\"age\", \"<\", 30)` |\n| `\"\u2264\", \"<=\"` | Checks if a number is less than or equal to a value. | `view.add_filter(\"metric.value\", \"<=\", 100)` |\n| `\">\"` | Checks if a number is greater than a value. | `view.add_filter(\"output.score\", \">\", 90)` |\n| `\"\u2265\", \">=\"` | Checks if a number is greater than or equal to a value. | `view.add_filter(\"output.model_latency\", \">=\", 5)` |\n| `\"is\"` | Checks if a boolean field is `True` or `False`. | `view.add_filter(\"is_active\", \"is\", True)` |\n| `\"after\"` | Checks if a date is after a given timestamp. | `view.add_filter(\"started_at\", \"after\", \"2024-01-01\")` |\n| `\"before\"` | Checks if a date is before a given timestamp. | `view.add_filter(\"ended_at\", \"before\", \"2024-12-31\")` |\n| `\"is empty\"` | Checks if a field is empty (`None` or `\"\"`). | `view.add_filter(\"comments\", \"is empty\", None)` |\n| `\"is not empty\"` | Checks if a field is not empty. | `view.add_filter(\"attachments\", \"is not empty\", None)` |\n\n### Remove filters\n\nUse `.remove_filter()` to remove a specific filter from the view by index or field name.\n\n```python\nview.remove_filter(\"output.model_latency\")\n```\n\nUse `.remove_filters()` to remove all filters.\n\n```python\nview.remove_filters()\n```\n\n### Save the `SavedView`\n\nUse `.save()` to publish the saved view to Weave.\n\n```python\nview.save()\n```\n\n### Retrieve function calls\n\nUse `.get_calls()` to retrieve function calls that match the filters in the saved view. You can specify optional parameters such as `limit` and `offset`.\n\n```python\ncalls = view.get_calls(limit=10)\n```\n\n## Saved views in the UI \n\nYou can create, load, rename, and edit saved views in the Weave UI. For fine-grained control, use the [Python SDK](#saved-views-in-the-python-sdk).\n\n### Create a saved view\n\n1. Navigate to your **Traces** or **Evals** tab.\n2. Adjust any of the following variables in your table configuration:\n   - Filters\n   - Sort order\n   - Page size\n   - Column visibility\n   - Column pinning\n3. Save the view using one of two options:\n   - In the upper right-hand corner, click **Save view**. \n   - Click the hamburger menu to the left of **Save view**. In the dropdown menu, click **+ Save as new view**.\n\n### Load a saved view\n\n1. Navigate to your **Traces** or **Evals** tab.\n2. Click the hamburger menu to the left of the tab title. A dropdown menu showing all saved views displays. \n3. Click the view that you want to access. The saved view displays in the **Traces** or **Evals** tab. \n\n### Rename a saved view\n\n1. Follow the steps described in [Load a saved view](#load-a-saved-view).\n2. In the upper lefthand corner of the **Traces** or **Evals** tab, click the view name.\n3. Enter a new name for the view.\n4. To save the new view name, press **Enter**.\n\n### Edit a saved view\n\n1. Follow the steps described in [Load a saved view](#load-a-saved-view).\n2. Adjust your table configuration.\n3. In the upper right-hand corner, click **Save view**. \n\n### Delete a saved view \n\n> \ud83d\udea8 **Important**: You can delete a view if you believe it is no longer useful to you and your team. This cannot be undone.\n\n1. Navigate to your **Traces** or **Evals** tab.\n2. [Load the view](#load-a-saved-view) that you want to delete.\n3. Click the hamburger menu to the left of **Save view**. \n4. In the dropdown menu, click **Delete view**.\n5. In the pop-up modal, confirm by clicking **Delete view**. Alternatively, click **Cancel** to stop deletion.\n\n### Return to the default view\n\n1. Navigate to your **Traces** or **Evals** tab.\n2. Click the hamburger menu to the right of the **Traces** or **Evals** tab. A dropdown menu showing all saved views displays. \n3. At the bottom on the menu, click **Traces** or **Evals**. The default view displays."
  },
  {
    "title": "Index",
    "url": "https://weave-docs.wandb.ai/guides/tools/index",
    "section": "Docs",
    "category": "Tools",
    "content": "# Tools & Utilities\n\nWeave is developing a set of tools and utilities to help with your workflow and deployment process for AI applications. These are currently in early alpha stages and subject to change. Here's an overview of what we're working on:\n\n## Serve (experimental)\n\n[Serve](/guides/tools/serve) is a feature to expose your Weave ops and models as API endpoints. We're exploring possibilities such as:\n\n- Creating web services for your Weave components\n- Integrating Weave components into existing applications\n- Providing a way to test models in a more production-like setting\n\n## Deploy (experimental)\n\n[Deploy](/guides/tools/deploy) is another alpha-stage utility we're developing to help with deploying Weave ops and models. Some potential features we're considering include:\n\n- Pushing models to cloud platforms\n- Managing different deployment environments\n- Exploring ways to automate parts of the deployment process\n\nPlease note that these tools are still in very early stages of development. They may not be fully functional, could change significantly, or might be discontinued. We recommend using them for experimental purposes only at this time."
  },
  {
    "title": "Serve",
    "url": "https://weave-docs.wandb.ai/guides/tools/serve",
    "section": "Docs",
    "category": "Tools",
    "content": "# Serve\n\nGiven a Weave ref to any Weave Model you can run:\n\n```\nweave serve \n```\n\nto run a FastAPI server for that model. Visit [http://0.0.0.0:9996/docs](http://0.0.0.0:9996/docs) to query the model interactively.\n\n## Install FastAPI\n\n```bash\npip install fastapi uvicorn\n```\n\n## Serve Model\n\nIn a terminal, call:\n\n```bash\nweave serve \n```\n\nGet your model ref by navigating to the model and copying it from the UI. It should look like:\n`weave:///your_entity/project-name/YourModel:`\n\nTo use it, navigate to the Swagger UI link, click the predict endpoint and then click \"Try it out!\"."
  },
  {
    "title": "Weave Self Managed",
    "url": "https://weave-docs.wandb.ai/guides/platform/weave-self-managed",
    "section": "Docs",
    "category": "Platform",
    "content": "# W&B Weave Self-Managed\n\n> \ud83d\udea8 **Important**: Weave on self-managed infrastructure is currently in Private Preview.  \n\nFor production environments, W&B strongly recommends using [W&B Dedicated Cloud](https://docs.wandb.ai/guides/hosting/hosting-options/dedicated_cloud), where Weave is Generally Available.  \n\nTo deploy a production-grade, self-managed instance, contact `support@wandb.com`.  \n\nThis guide explains how to deploy all the components required to run W&B Weave in a self-managed environment.\n\nA key component of a self-managed Weave deployment is [ClickHouseDB](https://clickhouse.com/), which the Weave application backend relies on.\n\nAlthough the deployment process sets up a fully functional ClickHouseDB instance, you may need to take additional steps to ensure reliability and high availability for a production-ready environment.\n\n## Requirements\n\n- W&B Platform installed. For more information, see the [Self-Managed Deployment Guide](https://docs.wandb.ai/guides/hosting/hosting-options/self-managed/).\n- [Bitnami's ClickHouse Helm Chart](https://github.com/bitnami/charts/tree/main/bitnami/clickhouse).\n- An S3 bucket pre-configured for ClickHouse storage. For configuration details, see [Provide S3 Credentials](#provide-s3-credentials).\n- Kubernetes Cluster Nodes with the following specifications:\n  - CPU: 8 cores  \n  - RAM: 64 GB  \n  - Disk: 200GB+\n- A Weave-enabled license from W&B. To request a license, please contact `support@wandb.com`.\n\n> \ud83c\udf1f **Tip**: For a detailed reference architecture, see [https://docs.wandb.ai/guides/hosting/self-managed/ref-arch/](https://docs.wandb.ai/guides/hosting/self-managed/ref-arch/#models-and-weave).\n\n## 1. Configure ClickHouse\n\nThe ClickHouse deployment in this document uses the [Bitnami ClickHouse](https://bitnami.com/stack/clickhouse) package.\n\nThe Bitnami Helm chart provides good support for basic ClickHouse functionalities, particularly the use of [ClickHouse Keeper](https://clickhouse.com/docs/en/guides/sre/keeper/clickhouse-keeper).\n\nTo configure Clickhouse, complete the following steps:\n\n1. [Configure the Helm repository](#configure-helm-repository)\n2. [Create Helm Configuration](#create-helm-configuration)\n3. [Provide S3 credentials](#provide-s3-credentials)\n\n### Configure Helm repository\n\n1. Add the Bitnami Helm repository:\n\n   `helm repo add bitnami https://charts.bitnami.com/bitnami` \n\n2. Update the repository:\n\n   `helm repo update`\n\n### Create Helm Configuration\n\nThe most critical part of the Helm configuration is the ClickHouse configuration, which is provided in XML format. Below is an example `values.yaml` file with customizable parameters to suit your needs.\nTo make the configuration process easier, we have added comments in the relevant sections using the format ``.\n\nModify the following parameters:\n\n- `clusterName`\n- `auth.username`\n- `auth.password`\n- S3 bucket-related configurations\n\nW&B recommends keeping the `clusterName` value in `values.yaml` set to `weave_cluster`.  This is the expected cluster name when W&B Weave runs the database migration. If you need to use a different name, see the [Setting `clusterName`](#setting-clustername) section for more information.\n\n```yaml\n## @param clusterName ClickHouse cluster name\nclusterName: weave_cluster\n\n## @param shards Number of ClickHouse shards to deploy\nshards: 1\n\n## @param replicaCount Number of ClickHouse replicas per shard to deploy\n## if keeper enable, same as keeper count, keeper cluster by shards.\nreplicaCount: 3\n\npersistence:\n  enabled: true\n  size: 30G # this size must be larger than cache size.\n\n## ClickHouse resource requests and limits\nresources:\n  requests:\n    cpu: 0.5\n    memory: 500Mi\n  limits:\n    cpu: 3.0\n    memory: 6Gi\n\n## Authentication\nauth:\n  username: weave_admin\n  password: \"weave_123\"\n  existingSecret: \"\"\n  existingSecretKey: \"\"\n\n## @param logLevel Logging level\nlogLevel: information\n\n## @section ClickHouse keeper configuration parameters\nkeeper:\n  enabled: true\n\n## @param extraEnvVars Array with extra environment variables to add to ClickHouse nodes\n##\nextraEnvVars:\n  - name: S3_ENDPOINT\n    value: \"https://s3.us-east-1.amazonaws.com/bucketname/$(CLICKHOUSE_REPLICA_ID)\"\n\n\n## @param defaultConfigurationOverrides [string] Default configuration overrides (evaluated as a template)\ndefaultConfigurationOverrides: |\n  \n    \n    \n      \n      \n    \n    \n    \n      {{ .Values.logLevel }}\n    \n    {{- if or (ne (int .Values.shards) 1) (ne (int .Values.replicaCount) 1)}}\n    \n      \n        {{- $shards := $.Values.shards | int }}\n        {{- range $shard, $e := until $shards }}\n        \n          true\n          {{- $replicas := $.Values.replicaCount | int }}\n          {{- range $i, $_e := until $replicas }}\n          \n            {{ printf \"%s-shard%d-%d.%s.%s.svc.%s\" (include \"common.names.fullname\" $ ) $shard $i (include \"clickhouse.headlessServiceName\" $) (include \"common.names.namespace\" $) $.Values.clusterDomain }}\n            {{ $.Values.service.ports.tcp }}\n          \n          {{- end }}\n        \n        {{- end }}\n      \n    \n    {{- end }}\n    {{- if .Values.keeper.enabled }}\n    \n      {{ $.Values.containerPorts.keeper }}\n      {{- if .Values.tls.enabled }}\n      {{ $.Values.containerPorts.keeperSecure }}\n      {{- end }}\n      \n      /bitnami/clickhouse/keeper/coordination/log\n      /bitnami/clickhouse/keeper/coordination/snapshots\n      \n        10000\n        30000\n        trace\n      \n      \n        {{- $nodes := .Values.replicaCount | int }}\n        {{- range $node, $e := until $nodes }}\n        \n          {{ $node | int }}\n          \n          {{ $.Values.service.ports.keeperInter }}\n        \n        {{- end }}\n      \n    \n    {{- end }}\n    {{- if or .Values.keeper.enabled .Values.zookeeper.enabled .Values.externalZookeeper.servers }}\n    \n      {{- if or .Values.keeper.enabled }}\n      {{- $nodes := .Values.replicaCount | int }}\n      {{- range $node, $e := until $nodes }}\n      \n        \n        {{ $.Values.service.ports.keeper }}\n      \n      {{- end }}\n      {{- else if .Values.zookeeper.enabled }}\n      {{- $nodes := .Values.zookeeper.replicaCount | int }}\n      {{- range $node, $e := until $nodes }}\n      \n        \n        {{ $.Values.zookeeper.service.ports.client }}\n      \n      {{- end }}\n      {{- else if .Values.externalZookeeper.servers }}\n      {{- range $node :=.Values.externalZookeeper.servers }}\n      \n        {{ $node }}\n        {{ $.Values.externalZookeeper.port }}\n      \n      {{- end }}\n      {{- end }}\n    \n    {{- end }}\n    {{- if .Values.metrics.enabled }}\n    \n      /metrics\n      \n      true\n      true\n      true\n    \n    {{- end }}\n    0.0.0.0\n    ::\n    1\n    \n      \n        \n          s3\n          \n\n          \n          xxx\n          xxx\n          \n\n         /var/lib/clickhouse/disks/s3_disk/\n        \n        \n  \t      cache\n          s3_disk\n          /var/lib/clickhouse/s3_disk_cache/cache/\n          \n          20Gi\n          1\n          1 \n        \n      \n      \n        \n          \n            \n              s3_disk_cache\n            \n          \n        \n      \n    \n    \n      s3_main\n    \n  \n\n## @section Zookeeper subchart parameters\nzookeeper:\n  enabled: false\n```\n\n### S3 endpoint configuration\n\nThe bucket endpoint must be set as an environment variable to ensure each ClickHouse replica read and writes data in it's folder in the bucket.\n\n```\nextraEnvVars:\n  - name: S3_ENDPOINT\n    value: \"https://s3.us-east-1.amazonaws.com/bucketname/$(CLICKHOUSE_REPLICA_ID)\"\n```\n\n> \ud83d\udea8 **Important**: Do not remove the `$(CLICKHOUSE_REPLICA_ID)` from the bucket endpoint configuration. It will ensure each ClickHouse replica is writing and reading data from it's folder in the bucket.\n\n### Provide S3 credentials\n\nYou can specify credentials for accessing an S3 bucket by either hardcoding the configuration, or having ClickHouse fetch the data from environment variables or an EC2 instance.\n\n#### Hardcode the configuration   \n   \nDirectly include the credentials in the storage configuration:\n\n```plaintext\ns3\n\nxxx\nxxx\n```\n\n#### Use environment variables or EC2 Metadata\n\nInstead of hardcoding credentials, you can enable ClickHouse to fetch them dynamically from environment variables or Amazon EC2 instance metadata.\n\n```plaintext\ntrue\n```  \n\nYou can find more details on this at [ClickHouse: Separation of Storage and Compute](https://clickhouse.com/docs/en/guides/separation-storage-compute).\n\n## 2. Install and deploy ClickHouse\n\nWith the repositories set up and the `values.yaml` file prepared, the next step is to install ClickHouse.\n\n```bash\nhelm install clickhouse bitnami/clickhouse -f values.yaml --version 8.0.10\n```\n\n> \ud83d\udea8 **Important**: Ensure you're using the version `8.0.10`. The latest chart version (`9.0.0`) doesn't work with the configuration proposed in this document.\n\n## 3. Confirm ClickHouse deployment\n\nConfirm that ClickHouse is deployed using the following command:\n\n```bash\nkubectl get pods\n```\n\nYou should see the following pods:\n\n```bash\nNAME                                 READY   STATUS    RESTARTS   AGE\nclickhouse-shard0-0                  1/1     Running   0          9m59s\nclickhouse-shard0-1                  1/1     Running   0          10m\nclickhouse-shard0-2                  1/1     Running   0          10m\n```\n\n## 4. Deploy Weave\n\nWeave is already available for automatic deployment via [W&B Operator](https://docs.wandb.ai/guides/hosting/operator/#wb-kubernetes-operator). With the W&B Platform installed, complete the following steps:\n\n1. Edit the [CR instance](https://docs.wandb.ai/guides/hosting/operator/#complete-example) used to deploy the platform.\n2. Add the Weave configuration.\n\n## 5. Gather information\n\n1. Use Kubernetes service details to configure Weave tracing:\n\n  - **Endpoint**: `-headless..svc.cluster.local`\n    - Replace `` with your Helm release name\n    - Replace `` with your `NAMESPACE`\n    - Get the service details: `kubectl get svc -n `\n  - **Username**: Set in the `values.yaml`\n  - **Password**: Set in the `values.yaml`\n\n2. With this information, update the W&B Platform Custom Resource(CR) by adding the following configuration:\n\n    ```yaml\n    apiVersion: apps.wandb.com/v1\n    kind: WeightsAndBiases\n    metadata:\n      labels:\n        app.kubernetes.io/name: weightsandbiases\n        app.kubernetes.io/instance: wandb\n      name: wandb\n      namespace: default\n    spec:\n      values:\n        global:\n        [...]\n          clickhouse:\n            host: -headless..svc.cluster.local\n            port: 8123\n            password: \n            user: \n            database: wandb_weave\n            # `replicated` must be set to `true` if replicating data across multiple nodes\n            # This is in preview, use the env var `WF_CLICKHOUSE_REPLICATED`\n            replicated: true\n\n          weave-trace:\n            enabled: true\n        [...]\n        weave-trace:\n          install: true\n          extraEnv:\n            WF_CLICKHOUSE_REPLICATED: \"true\"\n        [...]\n    ```\n\n> \ud83d\udea8 **Important**: When using more than one replica (W&B recommend a least 3 replicas), ensure to have the following environment variable set for Weave Traces.\n```\nextraEnv:\n  WF_CLICKHOUSE_REPLICATED: \"true\"\n```\nThis has the same effect of `replicated: true` which in preview.\n\n\n3. Set the `clusterName` in `values.yaml` to `weave_cluster`. If it is not, the database migration will fail.  \n\n    Alternatively, ff you use a different cluster name, set the `WF_CLICKHOUSE_REPLICATED_CLUSTER` environment variable in `weave-trace.extraEnv` to match the chosen name, as shown in the example below.\n\n    ```yaml\n    [...]\n      clickhouse:\n        host: -headless..svc.cluster.local\n        port: 8123\n        password: \n        user: \n        database: wandb_weave\n        # `replicated` must be set to `true` if replicating data across multiple nodes\n        # This is in preview, use the env var `WF_CLICKHOUSE_REPLICATED`\n        replicated: true\n\n      weave-trace:\n        enabled: true\n    [...]\n    weave-trace:\n      install: true\n      extraEnv:\n        WF_CLICKHOUSE_REPLICATED: \"true\"\n        WF_CLICKHOUSE_REPLICATED_CLUSTER: \"different_cluster_name\"\n    [...]\n    ```\n\n    The final configuration will look like the following example:\n\n    ```yaml\n    apiVersion: apps.wandb.com/v1\n    kind: WeightsAndBiases\n    metadata:\n      labels:\n        app.kubernetes.io/name: weightsandbiases\n        app.kubernetes.io/instance: wandb\n      name: wandb\n      namespace: default\n    spec:\n      values:\n        global:\n          license: eyJhbGnUzaHgyQjQyQWhEU3...ZieKQ2x5GGfw\n          host: https://wandb.example.com\n\n          bucket:\n            name: abc-wandb-moving-pipefish\n            provider: gcs\n\n          mysql:\n            database: wandb_local\n            host: 10.218.0.2\n            name: wandb_local\n            password: 8wtX6cJHizAZvYScjDzZcUarK4zZGjpV\n            port: 3306\n            user: wandb\n\n          clickhouse:\n            host: -headless..svc.cluster.local\n            port: 8123\n            password: \n            user: \n            database: wandb_weave\n            # This option must be true if replicating data across multiple nodes\n            replicated: true\n\n          weave-trace:\n            enabled: true\n    \n        ingress:\n          annotations:\n            ingress.gcp.kubernetes.io/pre-shared-cert: abc-wandb-cert-creative-puma\n            kubernetes.io/ingress.class: gce\n            kubernetes.io/ingress.global-static-ip-name: abc-wandb-operator-address\n\n        weave-trace:\n          install: true\n          extraEnv:\n            WF_CLICKHOUSE_REPLICATED: \"true\"\n    ```\n\n4. With the Custom Resource (CR) prepared, apply the new configuration:\n\n    ```bash\n    kubectl apply -f wandb.yaml\n    ```\n\n## 6. Access Weave\n\nOnce the deployment is running, accessing the W&B endpoint configured in the `host` option should display the Weave licensing status as enabled."
  },
  {
    "title": "Index",
    "url": "https://weave-docs.wandb.ai/guides/platform/index",
    "section": "Docs",
    "category": "Platform",
    "content": "# Platform & Security\n\nWeave is available on the following deployment options:\n\n- **[W&B SaaS Cloud](https://docs.wandb.ai/guides/hosting/hosting-options/saas_cloud):** A multi-tenant, fully-managed platform deployed in W&B's Google Cloud Platform (GCP) account in a North America region.\n- **[W&B Dedicated Cloud](https://docs.wandb.ai/guides/hosting/hosting-options/dedicated_cloud):** Generally available on AWS and in preview on GCP and Azure. \n- **[Self-managed instances](./weave-self-managed.md):** For teams that prefer to host Weave independently, guidance is available from your W&B team to evaluate deployment options.\n\n## Identity and Access Management\n\nUse the identity and access management capabilities for secure authentication and effective authorization in your [W&B Organization](https://docs.wandb.ai/guides/hosting/iam/org_team_struct#organization). The following capabilities are available for Weave users depending on your deployment option and [pricing plan](https://wandb.ai/site/pricing/):\n\n- **Authenticate using Single-Sign On (SSO):** Options include public identity providers like Google and Github, as well as enterprise providers such as Okta, Azure Active Directory, and others, [using OIDC](https://docs.wandb.ai/guides/technical-faq/general#does-wb-support-sso-for-saas).\n- **[Team-based logical separation](https://docs.wandb.ai/guides/models/app/settings-page/teams/):** Each team may correspond to a business unit, department, or project team within your organization.\n- **Use W&B projects to organize initiatives:** Organize initiatives within teams and configure the required [visibility scope](https://docs.wandb.ai/guides/hosting/restricted-projects), including the `restricted` scope for sensitive collaborations.\n- **Role-based access control:** Configure access at the [team](https://docs.wandb.ai/guides/hosting/iam/manage-organization#assign-or-update-a-team-members-role) or [project](https://docs.wandb.ai/guides/hosting/iam/restricted-projects#project-level-roles) level to ensure users access data on a need-to-know basis.\n- **Scoped service accounts:** Automate Gen AI workflows using service accounts scoped to your organization or team.\n- **[SCIM API and Python SDK](https://docs.wandb.ai/guides/hosting/iam/automate_iam):** Manage users and teams efficiently with SCIM API and Python SDK.\n\n## Data Security\n\n- **SaaS Cloud:** Data for all Weave users is stored in a shared Clickhouse Cloud cluster, encrypted using cloud-native encryption. Shared compute services process the data, ensuring isolation through a security context comprising your W&B organization, team, and project.\n\n- **Dedicated Cloud:** Data is stored in a unique Clickhouse Cloud cluster in the cloud and region of your choice. A unique compute environment processes the data, with the following additional protections:\n  - **[IP allowlisting](https://docs.wandb.ai/guides/hosting/data-security/ip-allowlisting):** Authorize access to your instance from specific IP addresses. This is an optional capability.\n  - **[Private connectivity](https://docs.wandb.ai/guides/hosting/data-security/private-connectivity):** Route data securely through the cloud provider's private network. This is an optional capability.\n  - **[Data encryption](https://docs.wandb.ai/guides/hosting/data-security/data-encryption):** W&B encrypts data at rest using a unique W&B-managed encryption key.\n  - **Clickhouse cluster security:** W&B connects to the unique Clickhouse Cloud cluster for your Dedicated Cloud instance over the cloud provider's private network. W&B also encrypts the cluster using a unique W&B-managed encryption key, while leveraging Clickhouse's file level encryption.\n\n> \ud83d\udea8 **Important**: [The W&B Platform secure storage connector or BYOB](https://docs.wandb.ai/guides/hosting/data-security/secure-storage-connector) is not available for Weave.\n\n## Maintenance \n\nIf you're using Weave on SaaS Cloud or Dedicated Cloud, you avoid the overhead and costs of provisioning, operating, and maintaining the W&B platform, as it is fully managed for you.\n\n## Compliance\n\n> \ud83c\udf1f **Tip**: To request SOC 2 reports and other security and compliance documents, refer to the [W&B Security Portal](https://security.wandb.ai/) or contact your W&B team for more information.\n\nSecurity controls for both SaaS Cloud and Dedicated Cloud are periodically audited internally and externally. Both platforms are SOC 2 Type II compliant. Additionally, Dedicated Cloud is HIPAA-compliant for organizations managing PHI data while building Generative AI applications."
  },
  {
    "title": "Smolagents",
    "url": "https://weave-docs.wandb.ai/guides/integrations/smolagents",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Smolagents\n\n> \ud83d\udea8 **Important**: All code samples shown on this page are in Python.\n\nThis page explains how to integrate [Smolagents](https://huggingface.co/docs/smolagents/en/index) with W&B Weave to track and analyze your agentic applications. You'll learn how to log model inferences, monitor function calls, and organize experiments using Weave's tracing and versioning capabilities. By following the examples provided, you can capture valuable insights, debug your applications efficiently, and compare different model configurations\u2014all within the Weave web interface.\n\n## Overview\n\nSmolagents is a simple framework that offers minimal abstractions for building powerful agentic applications. It supports multiple LLM providers, such as OpenAI, Hugging Face Transformers, and Anthropic.\n\nWeave automatically captures traces for [Smolagents](https://huggingface.co/docs/smolagents/en/index). To start tracking, call `weave.init()` and use the library as usual.\n\n## Prerequisites\n\n1. Before you can use Smolagents with Weave, install the required libraries or upgrade to the latest versions. The following command installs or upgrades `smolagents`, `openai`, and `weave`, and suppresses output:\n\n    ```python\n    pip install -U smolagents openai weave -qqq\n    ```\n\n2. Smolagents supports multiple LLM providers, such as OpenAI, Hugging Face Transformers, and Anthropic. Set the API key for your chosen provider by setting the corresponding environment variable:\n\n    ```python\n    import os\n    import getpass\n\n    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n    ```\n\n## Basic tracing\n\nStoring traces of language model applications in a central location is essential during development and production. These traces help with debugging and serve as valuable datasets for improving your application.\n\nWeave automatically captures traces for [Smolagents](https://huggingface.co/docs/smolagents/en/index). To start tracking, initialize Weave by calling `weave.init()`, then use the library as usual.\n\nThe following example demonstrates how to log inference calls to a tool-using LLM agent with Weave. In this scenario:\n\n- You define a language model (OpenAI's `gpt-4o`) using Smolagents' `OpenAIServerModel`.\n- You configure a search tool (`DuckDuckGoSearchTool`) that the agent can invoke when needed.\n- You construct a `ToolCallingAgent`, passing in the tool and model.\n- You run a query through the agent that triggers the search tool.\n- Weave logs each function and model invocation, making them available for inspection via its web interface.\n\n```python\nimport weave\nfrom smolagents import DuckDuckGoSearchTool, OpenAIServerModel, ToolCallingAgent\n\n# Initialize Weave\nweave.init(project_name=\"smolagents\")\n\n# Define your LLM provider supported by Smolagents\nmodel = OpenAIServerModel(model_id=\"gpt-4o\")\n\n# Define a DuckDuckGo web search tool based on your query\nsearch_tool = DuckDuckGoSearchTool()\n\n# Define a tool-calling agent\nagent = ToolCallingAgent(tools=[search_tool], model=model)\nanswer = agent.run(\n    \"Get me just the title of the page at url 'https://wandb.ai/geekyrakshit/story-illustration/reports/Building-a-GenAI-assisted-automatic-story-illustrator--Vmlldzo5MTYxNTkw'?\"\n)\n```\n\nOnce you run the code sample, navigate to your Weave project dashboard to view the traces.\n\n\n\n## Tracing custom tools\n\nYou can declare custom tools for your agentic workflows by decorating a function with `@tool` from `smolagents` or by inheriting from the `smolagents.Tool` class.\n\nWeave automatically tracks custom tool calls for your Smolagents workflows. The following example shows how to log a custom Smolagents tool call with Weave:\n\n- A custom `get_weather` function is defined and decorated with `@tool` from Smolagents, enabling the agent to invoke it as part of its reasoning process.\n- The function accepts a location and an optional flag for Celsius output.\n- A language model is instantiated using `OpenAIServerModel`.\n- A `ToolCallingAgent` is created with the custom tool and model.\n- When the agent runs the query, it selects and invokes the `get_weather` tool.\n- Weave logs both the model inference and the custom tool invocation, including arguments and return values.\n\n```python\nfrom typing import Optional\n\nimport weave\nfrom smolagents import OpenAIServerModel, ToolCallingAgent, tool\n\nweave.init(project_name=\"smolagents\")\n\n@tool\ndef get_weather(location: str, celsius: Optional[bool] = False) -> str:\n    \"\"\"\n    Get the weather in the next few days for a given location.\n    Args:\n        location: The location.\n        celsius: Whether to use Celsius for temperature.\n    \"\"\"\n    return f\"The weather in {location} is sunny with temperatures around 7\u00b0C.\"\n\nmodel = OpenAIServerModel(model_id=\"gpt-4o\")\nagent = ToolCallingAgent(tools=[get_weather], model=model)\nanswer = agent.run(\"What is the weather in Tokyo?\")\n```\n\nOnce you run the code sample, navigate to your Weave project dashboard to view the traces."
  },
  {
    "title": "Huggingface",
    "url": "https://weave-docs.wandb.ai/guides/integrations/huggingface",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Hugging Face Hub\n\n> \ud83d\udea8 **Important**: All code samples shown on this page are in Python.\n\nThis page explains how to integrate [Hugging Face Hub](https://hf.co/) with W&B Weave to track and analyze your machine learning applications. You'll learn how to log model inferences, monitor function calls, and organize experiments using Weave's tracing and versioning capabilities. By following the examples provided, you can capture valuable insights, debug your applications efficiently, and compare different model configurations\u2014all within the Weave web interface.\n\n:::tip[Try Hugging Face Hub with Weave in Google Colab]\nDo you want to experiment with Hugging Face Hub and Weave without any of the set up? You can try the code samples shown here as a Jupyter Notebook on Google Colab.\n\n\n  \n\n:::\n\n## Overview\n\n[Hugging Face Hub](https://hf.co/) is a machine learning platform for creators and collaborators, offering a vast collection of pre-trained models and datasets for various projects.\n\nThe `huggingface_hub` Python library provides a unified interface to run inference across multiple services for models hosted on the Hub. You can invoke these models using the [`InferenceClient`](https://huggingface.co/docs/huggingface_hub/en/package_reference/inference_client).\n\nWeave will automatically capture traces for [`InferenceClient`](https://huggingface.co/docs/huggingface_hub/en/package_reference/inference_client). To start tracking, calling `weave.init()` and use the library as normal.\n\n## Prerequisites\n\n1. Before you can use `huggingface_hub` with Weave, you must install the necessary libraries, or upgrade to the latest versions. The following command installs or upgrades `huggingface_hub` and `weave` to the latest version if it's already installed, and reduces installation output.\n\n    ```python\n    pip install -U huggingface_hub weave -qqq\n    ```\n\n2. To use inference with a model on the Hugging Face Hub, set your [User Access Token](https://huggingface.co/docs/hub/security-tokens). You can either set the token from your [Hugging Face Hub Settings page](https://huggingface.co/settings/tokens) or programmatically. The following code sample prompts the user to enter their `HUGGINGFACE_TOKEN` and sets the token as an environment variable.\n\n    ```python\n    import os\n    import getpass\n\n    os.environ[\"HUGGINGFACE_TOKEN\"] = getpass.getpass(\"Enter your Hugging Face Hub Token: \")\n    ```\n\n## Basic tracing\n\nStoring traces of language model applications in a central location is essential during development and production. These traces help with debugging and serve as valuable datasets for improving your application.\n\nWeave automatically captures traces for the [`InferenceClient`](https://huggingface.co/docs/huggingface_hub/en/package_reference/inference_client). To start tracking, initialize Weave by calling `weave.init()`, then use the library as usual.\n\nThe following example demonstrates how to log inference calls to the Hugging Face Hub using Weave:\n\n```python\nimport weave\nfrom huggingface_hub import InferenceClient\n\n# Initialize Weave\nweave.init(project_name=\"quickstart-huggingface\")\n\n# Initialize Hugging Face Inference Client\nhuggingface_client = InferenceClient(\n    api_key=os.environ.get(\"HUGGINGFACE_TOKEN\")\n)\n\n# Make a chat completion inference call to the Hugging Face Hub with the Llama-3.2-11B-Vision-Instruct model\nimage_url = \"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\"\nresponse = huggingface_client.chat_completion(\n    model=\"meta-llama/Llama-3.2-11B-Vision-Instruct\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n                {\"type\": \"text\", \"text\": \"Describe this image in one sentence.\"},\n            ],\n        }\n    ],\n    max_tokens=500,\n    seed=42,\n)\n```\n\nAfter the code shown above runs, Weave tracks and logs all LLM calls made with the Hugging Face Inference Client. You can view these traces in the Weave web interface.\n\n\n\nWeave logs each inference call, providing details about inputs, outputs, and metadata.\n\n\n\nWeave also renders the call as a chat view in the UI, displaying the entire chat history with the model.\n\n## Trace a function\n\nTo gain deeper insights into how data flows through your application, you can use `@weave.op` to track function calls. This captures inputs, outputs, and execution logic, helping with debugging and performance analysis.\n\nBy nesting multiple ops, you can build a structured tree of tracked functions. Weave also automatically versions your code, preserving intermediate states as you experiment, even before committing changes to Git.\n\nTo start tracking, decorate the functions that you want to track with `@weave.op`.\n\nIn the following example, Weave tracks three functions: `generate_image`, `check_image_correctness`, and `generate_image_and_check_correctness`. These functions generate an image and validate whether it matches a given prompt.\n\n```python\nimport base64\nfrom PIL import Image\n\n\ndef encode_image(pil_image):\n    import io\n    buffer = io.BytesIO()\n    pil_image.save(buffer, format=\"JPEG\")\n    buffer.seek(0)\n    encoded_image = base64.b64encode(buffer.read()).decode(\"utf-8\")\n    return f\"data:image/jpeg;base64,{encoded_image}\"\n\n\n@weave.op\ndef generate_image(prompt: str):\n    return huggingface_client.text_to_image(\n        prompt=prompt,\n        model=\"black-forest-labs/FLUX.1-schnell\",\n        num_inference_steps=4,\n    )\n\n\n@weave.op\ndef check_image_correctness(image: Image.Image, image_generation_prompt: str):\n    return huggingface_client.chat_completion(\n        model=\"meta-llama/Llama-3.2-11B-Vision-Instruct\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"image_url\", \"image_url\": {\"url\": encode_image(image)}},\n                    {\n                        \"type\": \"text\",\n                        \"text\": f\"Is this image correct for the prompt: {image_generation_prompt}? Answer with only one word: yes or no\",\n                    },\n                ],\n            }\n        ],\n        max_tokens=500,\n        seed=42,\n    ).choices[0].message.content\n\n\n@weave.op\ndef generate_image_and_check_correctness(prompt: str):\n    image = generate_image(prompt)\n    return {\n        \"image\": image,\n        \"is_correct\": check_image_correctness(image, prompt),\n    }\n\n\nresponse = generate_image_and_check_correctness(\"A cute puppy\")\n```\n\nWeave now logs all function calls wrapped with `@weave.op`, allowing you to analyze execution details in the Weave UI.\n\n \n\nWeave also captures and visualizes function execution, helping you to understand data flow and logic within your application.\n\n## Use `Model`s for experimentation\n\nManaging LLM experiments can be challenging when multiple components are involved. The Weave [`Model`](../core-types/models.md) class helps capture and organize experimental details, such as system prompts and model configurations, allowing you to easily compare different iterations.\n\nIn addition to versioning code and capturing inputs/outputs, a `Model` stores structured parameters that control application behavior. This makes it easier to track which configurations produced the best results. You can also integrate a Weave `Model` with Weave [Serve](../tools/serve.md) and [Evaluations](../evaluation/scorers.md) for further insights.\n\nThe example below demonstrates defines a `CityVisitRecommender` model for travel recommendations. Each modification to its parameters generates a new version, making experimentation easy.\n\n```python\nimport rich\n\n\nclass CityVisitRecommender(weave.Model):\n    model: str\n    temperature: float = 0.7\n    max_tokens: int = 500\n    seed: int = 42\n\n    @weave.op()\n    def predict(self, city: str) -> str:\n        return huggingface_client.chat_completion(\n            model=self.model,\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": \"You are a helpful assistant meant to suggest places to visit in a city\",\n                },\n                {\"role\": \"user\", \"content\": city},\n            ],\n            max_tokens=self.max_tokens,\n            temperature=self.temperature,\n            seed=self.seed,\n        ).choices[0].message.content\n\n\ncity_visit_recommender = CityVisitRecommender(\n    model=\"meta-llama/Llama-3.2-11B-Vision-Instruct\",\n    temperature=0.7,\n    max_tokens=500,\n    seed=42,\n)\nrich.print(city_visit_recommender.predict(\"New York City\"))\nrich.print(city_visit_recommender.predict(\"Paris\"))\n```\n\nWeave automatically logs models and tracks different versions, making it easy to analyze performance and experiment history."
  },
  {
    "title": "Local Models",
    "url": "https://weave-docs.wandb.ai/guides/integrations/local_models",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Local Models\n\nMany developers download and run open source models like LLama-3, Mixtral, Gemma, Phi and more locally. There are quite a few ways of running these models locally and Weave supports a few of them out of the box, as long as they support OpenAI SDK compatibility.\n\n## Wrap local model functions with `@weave.op()`\n\nYou can easily integrate Weave with any LLM yourself simply by initializing Weave with `weave.init('')` and then wrapping the calls to your LLMs with `weave.op()`. See our guide on [tracing](/guides/tracking/tracing) for more details.\n\n## Updating your OpenAI SDK code to use local models\n\nAll of the frameworks of services that support OpenAI SDK compatibility require a few minor changes.\n\nFirst and most important, is the `base_url` change during the `openai.OpenAI()` initialization.\n\n```python\nclient = openai.OpenAI(\n    base_url=\"http://localhost:1234\",\n)\n```\n\nIn the case of local models, the `api_key` can be any string but it should be overridden, as otherwise OpenAI will try to use it from environment variables and show you an error.\n\n## OpenAI SDK supported Local Model runners\n\nHere's a list of apps that allows you to download and run models from Hugging Face on your computer, that support OpenAI SDK compatibility.\n\n1. Nomic [GPT4All](https://www.nomic.ai/gpt4all) - support via Local Server in settings ([FAQ](https://docs.gpt4all.io/gpt4all_help/faq.html))\n1. [LMStudio](https://lmstudio.ai/) - Local Server OpenAI SDK support [docs](https://lmstudio.ai/docs/local-server)\n1. [Ollama](https://ollama.com/) - [Experimental Support](https://github.com/ollama/ollama/blob/main/docs/openai.md) for OpenAI SDK\n1. llama.cpp via [llama-cpp-python](https://llama-cpp-python.readthedocs.io/en/latest/server/) python package\n1. [llamafile](https://github.com/Mozilla-Ocho/llamafile#other-example-llamafiles) - `http://localhost:8080/v1` automatically supports OpenAI SDK on Llamafile run"
  },
  {
    "title": "Dspy",
    "url": "https://weave-docs.wandb.ai/guides/integrations/dspy",
    "section": "Docs",
    "category": "Integrations",
    "content": "# DSPy\n\n\n  \n\n\n[DSPy](https://dspy-docs.vercel.app/) is a framework for algorithmically optimizing LM prompts and weights, especially when LMs are used one or more times within a pipeline. Weave automatically tracks and logs calls made using DSPy modules and functions.\n\n## Tracing\n\nIt\u2019s important to store traces of language model applications in a central location, both during development and in production. These traces can be useful for debugging, and as a dataset that will help you improve your application.\n\nWeave will automatically capture traces for [DSPy](https://dspy-docs.vercel.app/). To start tracking, calling `weave.init(project_name=\"\")` and use the library as normal.\n\n```python\nimport os\nimport dspy\nimport weave\n\nos.environ[\"OPENAI_API_KEY\"] = \"\"\n\nweave.init(project_name=\"\")\n\nlm = dspy.LM('openai/gpt-4o-mini')\ndspy.configure(lm=lm)\nclassify = dspy.Predict(\"sentence -> sentiment\")\nclassify(sentence=\"it's a charming and often affecting journey.\")\n```\n\n[](https://wandb.ai/geekyrakshit/dspy-project/weave/calls)\n\nWeave logs all LM calls in your DSPy program, providing details about inputs, outputs, and metadata.\n\n## Track your own DSPy Modules and Signatures\n\nA `Module` is the building block with learnable parameters for DSPy programs that abstracts a prompting technique. A `Signature` is a declarative specification of input/output behavior of a DSPy Module. Weave automatically tracks all in-built and cutom Signatures and Modules in your DSPy programs.\n\n```python\nimport os\nimport dspy\nimport weave\n\nos.environ[\"OPENAI_API_KEY\"] = \"\"\n\nweave.init(project_name=\"\")\n\nclass Outline(dspy.Signature):\n    \"\"\"Outline a thorough overview of a topic.\"\"\"\n\n    topic: str = dspy.InputField()\n    title: str = dspy.OutputField()\n    sections: list[str] = dspy.OutputField()\n    section_subheadings: dict[str, list[str]] = dspy.OutputField(\n        desc=\"mapping from section headings to subheadings\"\n    )\n\n\nclass DraftSection(dspy.Signature):\n    \"\"\"Draft a top-level section of an article.\"\"\"\n\n    topic: str = dspy.InputField()\n    section_heading: str = dspy.InputField()\n    section_subheadings: list[str] = dspy.InputField()\n    content: str = dspy.OutputField(desc=\"markdown-formatted section\")\n\n\nclass DraftArticle(dspy.Module):\n    def __init__(self):\n        self.build_outline = dspy.ChainOfThought(Outline)\n        self.draft_section = dspy.ChainOfThought(DraftSection)\n\n    def forward(self, topic):\n        outline = self.build_outline(topic=topic)\n        sections = []\n        for heading, subheadings in outline.section_subheadings.items():\n            section, subheadings = (\n                f\"## {heading}\",\n                [f\"### {subheading}\" for subheading in subheadings],\n            )\n            section = self.draft_section(\n                topic=outline.title,\n                section_heading=section,\n                section_subheadings=subheadings,\n            )\n            sections.append(section.content)\n        return dspy.Prediction(title=outline.title, sections=sections)\n\n\ndraft_article = DraftArticle()\narticle = draft_article(topic=\"World Cup 2002\")\n```\n\n[](https://wandb.ai/geekyrakshit/dspy-project/weave/calls)\n\n\n## Optimization and Evaluation of your DSPy Program\n\nWeave also automatically captures traces for DSPy optimizers and Evaluation calls which you can use to improve and evaulate your DSPy program's performance on a development set.\n\n\n```python\nimport os\nimport dspy\nimport weave\n\nos.environ[\"OPENAI_API_KEY\"] = \"\"\nweave.init(project_name=\"\")\n\ndef accuracy_metric(answer, output, trace=None):\n    predicted_answer = output[\"answer\"].lower()\n    return answer[\"answer\"].lower() == predicted_answer\n\nmodule = dspy.ChainOfThought(\"question -> answer: str, explanation: str\")\noptimizer = dspy.BootstrapFewShot(metric=accuracy_metric)\noptimized_module = optimizer.compile(\n    module, trainset=SAMPLE_EVAL_DATASET, valset=SAMPLE_EVAL_DATASET\n)\n```\n\n[](https://wandb.ai/geekyrakshit/dspy-project/weave/calls)"
  },
  {
    "title": "Anthropic",
    "url": "https://weave-docs.wandb.ai/guides/integrations/anthropic",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Anthropic\n\n\n  \n\n\nWeave automatically tracks and logs LLM calls made via the [Anthropic Python library](https://github.com/anthropics/anthropic-sdk-python), after `weave.init()` is called.\n\n> \ud83d\udca1 **Note**: Do you want to experiment with Anthropic models on Weave without any set up? Try the [LLM Playground](../tools/playground.md).\n\n## Traces\n\nIt\u2019s important to store traces of LLM applications in a central database, both during development and in production. You\u2019ll use these traces for debugging, and as a dataset that will help you improve your application.\n\nWeave will automatically capture traces for [anthropic-sdk-python](https://github.com/anthropics/anthropic-sdk-python). You can use the library as usual, start by calling `weave.init()`:\n\n```python\nimport weave    \n# use the anthropic library as usual\nimport os\nfrom anthropic import Anthropic\nweave.init(\"anthropic_project\")\n\nclient = Anthropic(\n    api_key=os.environ.get(\"ANTHROPIC_API_KEY\"),\n)\n\nmessage = client.messages.create(\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Tell me a joke about a dog\",\n        }\n    ],\n    model=\"claude-3-opus-20240229\",\n)\nprint(message.content)\n```\n\n\nWeave will now track and log all LLM calls made through the Anthropic library. You can view the traces in the Weave web interface.\n\n[](https://wandb.ai/capecape/anthropic_project/weave/calls)\n\n> \ud83d\udca1 **Note**: We patch the anthropic `Messages.create` method for you to keep track of your LLM calls.\n\n\nWeave will now track and log all LLM calls made through Anthropic. You can view the logs and insights in the Weave web interface.\n\n## Wrapping with your own ops\n\nWeave ops make results *reproducible* by automatically versioning code as you experiment, and they capture their inputs and outputs. Simply create a function decorated with [`@weave.op()`](https://wandb.github.io/weave/guides/tracking/ops) that calls into [`Anthropic.messages.create`](https://docs.anthropic.com/en/api/messages-examples) and Weave will track the inputs and outputs for you. Let's see how we can do this in nested example:\n\n```python\nimport weave\nimport os\nfrom anthropic import Anthropic\nweave.init(\"anthropic_project\")\nclient = Anthropic(\n    api_key=os.environ.get(\"ANTHROPIC_API_KEY\"),\n)\n@weave.op()\ndef call_anthropic(user_input:str, model:str) -> str:\n    message = client.messages.create(\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": user_input,\n        }\n        ],\n        model=model,\n    )\n    return message.content[0].text\n@weave.op()\ndef generate_joke(topic: str) -> str:\n    return call_anthropic(f\"Tell me a joke about {topic}\", model=\"claude-3-haiku-20240307\")\n\nprint(generate_joke(\"chickens\"))\nprint(generate_joke(\"cars\"))\n```\n\n[](https://wandb.github.io/weave/guides/tracking/ops)\n\n## Create a `Model` for easier experimentation\n\nOrganizing experimentation is difficult when there are many moving pieces. By using the [`Model`](/guides/core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app. \n\nIn addition to versioning code and capturing inputs/outputs, [`Model`](/guides/core-types/models)s capture structured parameters that control your application\u2019s behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and [`Evaluation`](/guides/core-types/evaluations)s.\n\nIn the example below, you can experiment with `model` and `temperature`. Every time you change one of these, you'll get a new _version_ of `JokerModel`. \n\n```python\nimport weave    \n# use the anthropic library as usual\nimport os\nfrom anthropic import Anthropic\nweave.init('joker-anthropic')\n\nclass JokerModel(weave.Model): # Change to `weave.Model`\n  model: str\n  temperature: float\n  \n  @weave.op()\n  def predict(self, topic): # Change to `predict`\n    client = Anthropic()\n    message = client.messages.create(\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": f\"Tell me a joke about {topic}\",\n        }\n        ],\n        model=self.model,\n        temperature=self.temperature\n    )\n    return message.content[0].text\n\n\njoker = JokerModel(\n    model=\"claude-3-haiku-20240307\",\n    temperature = 0.1)\nresult = joker.predict(\"Chickens and Robots\")\nprint(result)\n```\n\n[](https://wandb.ai/capecape/anthropic_project/weave/calls)\n\n## Tools (function calling)\n\nAnthropic provides [tools](https://docs.anthropic.com/en/docs/tool-use) interface for calling functions. Weave will automatically track those functions calls.\n\n```python\nmessage = client.messages.create(\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"What's the weather like in San Francisco?\",\n        }\n    ],\n    tools=[\n        {\n            \"name\": \"get_weather\",\n            \"description\": \"Get the current weather in a given location\",\n            \"input_schema\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"location\": {\n                        \"type\": \"string\",\n                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n                    }\n                },\n                \"required\": [\"location\"],\n            },\n        },\n    ],\n    model=model,\n)\n\nprint(message)\n```\n\nWe automatically capture the tools you used on the prompt and keep them versioned.\n\n[](https://wandb.ai/capecape/anthropic_project/weave/calls)"
  },
  {
    "title": "Groq",
    "url": "https://weave-docs.wandb.ai/guides/integrations/groq",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Groq\n\n\n  \n\n\n> \ud83d\udca1 **Note**: Do you want to experiment with Groq models on Weave without any set up? Try the [LLM Playground](../tools/playground.md).\n\n[Groq](https://groq.com/) is the AI infrastructure company that delivers fast AI inference. The LPU\u2122 Inference Engine by Groq is a hardware and software platform that delivers exceptional compute speed, quality, and energy efficiency. Weave automatically tracks and logs calls made using Groq chat completion calls.\n\n## Tracing\n\nIt\u2019s important to store traces of language model applications in a central location, both during development and in production. These traces can be useful for debugging, and as a dataset that will help you improve your application.\n\nWeave will automatically capture traces for [Groq](https://groq.com/). To start tracking, calling `weave.init(project_name=\"\")` and use the library as normal.\n\n```python\nimport os\nimport weave\nfrom groq import Groq\n\nweave.init(project_name=\"groq-project\")\n\nclient = Groq(\n    api_key=os.environ.get(\"GROQ_API_KEY\"),\n)\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Explain the importance of fast language models\",\n        }\n    ],\n    model=\"llama3-8b-8192\",\n)\n```\n\n|  |\n|---|\n| Weave will now track and log all LLM calls made through the Groq library. You can view the traces in the Weave web interface. |\n\n## Track your own ops\n\nWrapping a function with `@weave.op` starts capturing inputs, outputs and app logic so you can debug how data flows through your app. You can deeply nest ops and build a tree of functions that you want to track. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git.\n\nSimply create a function decorated with [`@weave.op`](/guides/tracking/ops).\n\nIn the example below, we have the function `recommend_places_to_visit` which is a function wrapped with `@weave.op` that recommends places to visit in a city.\n\n```python\nimport os\nimport weave\nfrom groq import Groq\n\n\nweave.init(project_name=\"groq-test\")\n\nclient = Groq(\n    api_key=os.environ.get(\"GROQ_API_KEY\"),\n)\n\n@weave.op()\ndef recommend_places_to_visit(city: str, model: str=\"llama3-8b-8192\"):\n    chat_completion = client.chat.completions.create(\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a helpful assistant meant to suggest places to visit in a city\",\n            },\n            {\n                \"role\": \"user\",\n                \"content\": city,\n            }\n        ],\n        model=\"llama3-8b-8192\",\n    )\n    return chat_completion.choices[0].message.content\n\n\nrecommend_places_to_visit(\"New York\")\nrecommend_places_to_visit(\"Paris\")\nrecommend_places_to_visit(\"Kolkata\")\n```\n\n|  |\n|---|\n| Decorating the `recommend_places_to_visit` function with `@weave.op` traces its inputs, outputs, and all internal LM calls made inside the function.  |\n\n## Create a `Model` for easier experimentation\n\nOrganizing experimentation is difficult when there are many moving pieces. By using the [`Model`](../core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app. \n\nIn addition to versioning code and capturing inputs/outputs, [`Model`](../core-types/models)s capture structured parameters that control your application\u2019s behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and [`Evaluation`](../core-types/evaluations.md)s.\n\nIn the example below, you can experiment with `GroqCityVisitRecommender`. Every time you change one of these, you'll get a new _version_ of `GroqCityVisitRecommender`.\n\n```python\nimport os\nfrom groq import Groq\nimport weave\n\n\nclass GroqCityVisitRecommender(weave.Model):\n    model: str\n    groq_client: Groq\n\n    @weave.op()\n    def predict(self, city: str) -> str:\n        system_message = {\n            \"role\": \"system\",\n            \"content\": \"\"\"\nYou are a helpful assistant meant to suggest places to visit in a city\n\"\"\",\n        }\n        user_message = {\"role\": \"user\", \"content\": city}\n        chat_completion = self.groq_client.chat.completions.create(\n            messages=[system_message, user_message],\n            model=self.model,\n        )\n        return chat_completion.choices[0].message.content\n\n\nweave.init(project_name=\"groq-test\")\ncity_recommender = GroqCityVisitRecommender(\n    model=\"llama3-8b-8192\", groq_client=Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n)\nprint(city_recommender.predict(\"New York\"))\nprint(city_recommender.predict(\"San Francisco\"))\nprint(city_recommender.predict(\"Los Angeles\"))\n```\n\n|  |\n|---|\n| Tracing and versioning your calls using a [`Model`](../core-types/models) |\n\n### Serving a Weave Model\n\nGiven a weave reference to any `weave.Model` object, you can spin up a fastapi server and [serve](https://wandb.github.io/weave/guides/tools/serve) it.\n\n| [](https://wandb.ai/geekyrakshit/groq-test/weave/objects/GroqCityVisitRecommender/versions/6O1xPTJ9yFx8uuCjJAlI7KgcVYxXKn7JxfmVD9AQT5Q) |\n|---|\n| You can find the weave reference of any WeaveModel by navigating to the model and copying it from the UI. |\n\nYou can serve your model by using the following command in the terminal:\n\n```shell\nweave serve weave:///your_entity/project-name/YourModel:\n```"
  },
  {
    "title": "Litellm",
    "url": "https://weave-docs.wandb.ai/guides/integrations/litellm",
    "section": "Docs",
    "category": "Integrations",
    "content": "# LiteLLM\n\n\n  \n\n\nWeave automatically tracks and logs LLM calls made via LiteLLM, after `weave.init()` is called.\n\n## Traces\n\nIt's important to store traces of LLM applications in a central database, both during development and in production. You'll use these traces for debugging, and as a dataset that will help you improve your application.\n\n> **Note:** When using LiteLLM, make sure to import the library using `import litellm` and call the completion function with `litellm.completion` instead of `from litellm import completion`. This ensures that all functions and parameters are correctly referenced.\n\nWeave will automatically capture traces for LiteLLM. You can use the library as usual, start by calling `weave.init()`:\n\n```python\nimport litellm\nimport weave\nweave.init(\"weave_litellm_integration\")\n\nopenai_response = litellm.completion(\n    model=\"gpt-3.5-turbo\", \n    messages=[{\"role\": \"user\", \"content\": \"Translate 'Hello, how are you?' to French\"}],\n    max_tokens=1024\n)\nprint(openai_response.choices[0].message.content)\n\nclaude_response = litellm.completion(\n    model=\"claude-3-5-sonnet-20240620\", \n    messages=[{\"role\": \"user\", \"content\": \"Translate 'Hello, how are you?' to French\"}],\n    max_tokens=1024\n)\nprint(claude_response.choices[0].message.content)\n```\n\nWeave will now track and log all LLM calls made through LiteLLM. You can view the traces in the Weave web interface.\n\n## Wrapping with your own ops\n\nWeave ops make results reproducible by automatically versioning code as you experiment, and they capture their inputs and outputs. Simply create a function decorated with `@weave.op()` that calls into LiteLLM's completion function and Weave will track the inputs and outputs for you. Here's an example:\n\n```python\nimport litellm\nimport weave\nweave.init(\"weave_litellm_integration\")\n@weave.op()\ndef translate(text: str, target_language: str, model: str) -> str:\n    response = litellm.completion(\n        model=model,\n        messages=[{\"role\": \"user\", \"content\": f\"Translate '{text}' to {target_language}\"}],\n        max_tokens=1024\n    )\n    return response.choices[0].message.content\n\nprint(translate(\"Hello, how are you?\", \"French\", \"gpt-3.5-turbo\"))\nprint(translate(\"Hello, how are you?\", \"Spanish\", \"claude-3-5-sonnet-20240620\"))\n```\n\n## Create a `Model` for easier experimentation\n\nOrganizing experimentation is difficult when there are many moving pieces. By using the `Model` class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app.\n\nIn addition to versioning code and capturing inputs/outputs, Models capture structured parameters that control your application's behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and Evaluations.\n\nIn the example below, you can experiment with different models and temperatures:\n\n```python\nimport litellm\nimport weave\nweave.init('weave_litellm_integration')\nclass TranslatorModel(weave.Model):\n    model: str\n    temperature: float\n    @weave.op()\n    def predict(self, text: str, target_language: str):\n        response = litellm.completion(\n            model=self.model,\n            messages=[\n                {\"role\": \"system\", \"content\": f\"You are a translator. Translate the given text to {target_language}.\"},\n                {\"role\": \"user\", \"content\": text}\n            ],\n            max_tokens=1024,\n            temperature=self.temperature\n        )\n        return response.choices[0].message.content\n\n# Create instances with different models\ngpt_translator = TranslatorModel(model=\"gpt-3.5-turbo\", temperature=0.3)\nclaude_translator = TranslatorModel(model=\"claude-3-5-sonnet-20240620\", temperature=0.1)\n\n# Use different models for translation\nenglish_text = \"Hello, how are you today?\"\n\nprint(\"GPT-3.5 Translation to French:\")\nprint(gpt_translator.predict(english_text, \"French\"))\n\nprint(\"\\nClaude-3.5 Sonnet Translation to Spanish:\")\nprint(claude_translator.predict(english_text, \"Spanish\"))\n```\n\n## Function Calling\n\nLiteLLM supports function calling for compatible models. Weave will automatically track these function calls.\n\n```python\nimport litellm\nimport weave\nweave.init(\"weave_litellm_integration\")\n\nresponse = litellm.completion(\n    model=\"gpt-3.5-turbo\",\n    messages=[{\"role\": \"user\", \"content\": \"Translate 'Hello, how are you?' to French\"}],\n    functions=[\n        {\n            \"name\": \"translate\",\n            \"description\": \"Translate text to a specified language\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"text\": {\n                        \"type\": \"string\",\n                        \"description\": \"The text to translate\",\n                    },\n                    \"target_language\": {\n                        \"type\": \"string\",\n                        \"description\": \"The language to translate to\",\n                    }\n                },\n                \"required\": [\"text\", \"target_language\"],\n            },\n        },\n    ],\n)\n\nprint(response)\n```\n\nWe automatically capture the functions you used in the prompt and keep them versioned.\n\n[](https://wandb.ai/a-sh0ts/weave_litellm_integration/weave/calls)"
  },
  {
    "title": "Mcp",
    "url": "https://weave-docs.wandb.ai/guides/integrations/mcp",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Model Context Protocol (MCP) and Weave\n\n\n  \n\n\nThe Model Context Protocol (MCP) is a standardized communication protocol that enables AI applications to exchange information with large language models (LLMs). Similar to universal connectors that transformed hardware compatibility, MCP provides an interface for LLMs to access various data sources and interact with external tools, all without requiring custom integrations for each new service.\n\nThe Weave integration lets you trace activity between your MCP client and MCP server. It gives you detailed visibility into tool calls, resource access, and prompt generation across MCP-based systems.\n\n## How it works\n\n> \ud83d\udea8 **Important**: Currently, the integration captures client-side and server-side operations separately, but does not provide end-to-end visibility into their interaction. There's an ongoing proposal to add OpenTelemetry trace support to MCP to enable end-to-end observability. For more information, see [GitHub discussion #269](https://github.com/modelcontextprotocol/modelcontextprotocol/discussions/269).\n\nThe Weave integration automatically traces key components of the Model Context Protocol (MCP) by patching core methods with the [`weave.op()`](../tracking/ops.md) decorator. Specifically, it patches methods in the [`mcp.server.fastmcp.FastMCP`](https://github.com/modelcontextprotocol/python-sdk/blob/b4c7db6a50a5c88bae1db5c1f7fba44d16eebc6e/src/mcp/server/fastmcp/server.py#L109) and [`mcp.ClientSession`](https://github.com/modelcontextprotocol/python-sdk/blob/b4c7db6a50a5c88bae1db5c1f7fba44d16eebc6e/src/mcp/client/session.py#L84) classes.\n\nThrough this integration, Weave traces the following MCP components:\n\n- [Tools](https://modelcontextprotocol.io/docs/concepts/tools)\n- [Resources](https://modelcontextprotocol.io/docs/concepts/resources)\n- [Prompts](https://modelcontextprotocol.io/docs/concepts/prompts)\n\n[](https://wandb.ai/ayut/mcp_example/weave/traces?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fayut%2Fmcp_example%2Fop%2Frun_client%3A*%22%5D%7D&peekPath=%2Fayut%2Fmcp_example%2Fcalls%2F01966bbe-cc5e-7012-b45f-bf10617d8c1e%3FhideTraceTree%3D0)\n\n\n## Use the integration\n\nThe Weave integration works with both the MCP server and client. Once installed, you can enable tracing with just two additional lines of code\u2014one to import `weave`, and another to initialize it.\n\n### Prerequisites\n\nBefore you begin, install the required packages:\n\n```bash\npip install -qq \"mcp[cli]\" weave\n```\n\n### Configuration\n\nThe MCP integration can be configured through environment variables:\n\n- `MCP_TRACE_LIST_OPERATIONS`: Set to `true` to trace list operations (`list_tools`, `list_resources`, and `list_prompts`) on both server and client sides.\n\n### Server-side integration\n\nTo trace an MCP server, add two lines to your existing `FastMCP` setup: one to import Weave and one to initialize the client. Once added, tool, resource, and prompt operations will be automatically traced.\n\n```python\n# Import Weave (required for tracing)\nimport weave\nfrom mcp.server.fastmcp import FastMCP\n\n# Initialize Weave with your project name\nweave_client = weave.init(\"my-project\")\n\n# Set up the MCP server\nmcp = FastMCP(\"Demo\")\n\n# Define a tool (this call will be traced)\n@mcp.tool()\ndef add(a: int, b: int) -> int:\n    \"\"\"Add two numbers.\"\"\"\n    return a + b\n\n# Define a resource (this call will be traced)\n@mcp.resource(\"greeting://{name}\")\ndef get_greeting(name: str) -> str:\n    \"\"\"Return a personalized greeting.\"\"\"\n    return f\"Hello, {name}!\"\n\n# Define a prompt (this call will be traced)\n@mcp.prompt()\ndef review_code(code: str) -> str:\n    \"\"\"Return a prompt for reviewing code.\"\"\"\n    return f\"Please review this code:\\n\\n{code}\"\n\n# Start the server\nmcp.run(transport=\"stdio\")\n```\n\n### Client-side integration\n\nOn the client side, tracing also requires just two changes: import Weave and initialize it. All tool calls, resource accesses, and prompt requests will be traced automatically.\n\n```python\n# Import Weave (required for tracing)\nimport weave\nfrom mcp import ClientSession, StdioServerParameters\nfrom mcp.client.stdio import stdio_client\n\n# Initialize Weave with your project name\nweave_client = weave.init(\"my-project\")\n\n# Set up and run the MCP client\nasync with stdio_client(server_params) as (read, write):\n    async with ClientSession(read, write) as session:\n        # Initialize the session\n        await session.initialize()\n        \n        # Call a tool (this will be traced)\n        result = await session.call_tool(\"add\", arguments={\"a\": 1, \"b\": 2})\n        \n        # Read a resource (this will be traced)\n        resource = await session.read_resource(\"greeting://user\")\n        \n        # Get a prompt (this will be traced)\n        prompt = await session.get_prompt(\"review_code\", arguments={\"code\": \"print('Hello')\"})\n```\n\n## Tutorial: `mcp_demo` example\n\nThe [`mcp_example`](https://github.com/wandb/weave/tree/master/examples/mcp_demo) demonstrates an integration between the Model Context Protocol (MCP) and Weave for tracing. It showcases how to instrument both the client and server components to capture detailed traces of their interactions. \n\n### Run the example\n\n1. Clone the `weave` repository and navigate to the `mcp_demo` example:\n\n   ```bash\n   git clone https://github.com/wandb/weave\n   cd weave/examples/mcp_demo\n   ```\n\n   The example includes two main files:\n\n    - `example_server.py`: A demo MCP server built with `FastMCP`. It defines tools, resources, and prompts.\n    - `example_client.py`: A client that connects to the server and interacts with its components.\n\n2. Install the required dependencies manually:\n\n   ```bash\n   pip install mcp[cli] weave\n   ```\n\n3. Run the demo:\n\n   ```bash\n   python example_client.py example_server.py\n   ```\n\n   This command launches both the client and server. The client starts an interactive CLI where you can test various features.\n\n### Client CLI commands\n\nThe client interface supports the following commands:\n\n| Command               | Description                             |\n|-----------------------|-----------------------------------------|\n| `tools`              | List available tools                     |\n| `resources`          | List available resources                 |\n| `prompts`            | List available prompts                   |\n| `add  `        | Add two numbers                          |\n| `bmi  ` | Calculate Body Mass Index             |\n| `weather `     | Get weather data for a city              |\n| `greeting `    | Get a personalized greeting              |\n| `user `          | Retrieve a user profile                  |\n| `config`             | Fetch app configuration                 |\n| `code-review ` | Generate a code review prompt            |\n| `debug `      | Generate a debugging prompt              |\n| `demo`               | Run a full demo of all available features. This will run each feature in sequence and produce a full trace timeline of interactions in the Weave UI. |\n| `q`                  | Quit the session                         |\n\n### Understanding the example\n\nThe `example_server.py` server defines the following:\n\n- _Tools_: Functions such as `add()`, `calculate_bmi()`, `fetch_weather()`\n- _Resources_: Endpoints like `greeting://{name}`, `config://app`, `users://{id}/profile`\n- _Prompts_: Templates like `review_code()` and `debug_error()`\n\nAll server-side operations are automatically traced by Weave when you initialize the client with `weave.init()`.\n\nThe `example_client.py` client demonstrates how to:\n\n- Connect to an MCP server\n- Discover available tools, resources, and prompts\n- Call tools with parameters\n- Read from resource URIs\n- Generate prompts with arguments\n- Show usage of [`weave.op()`](../tracking/ops.md) with custom methods/functions.\n\nWeave traces all client-side calls to provide a complete view of interactions between the client and server.\n\n## FAQ\n\n### Why is MCP tracing needed?\n\nAs an LLM application developer, you fall into one of three categories:\n\n- _MCP server-side developer_: You want to expose multiple tools, resources, and prompts to the MCP client. You expose your existing application's tools, resources, etc., or you have built agents or have multiple agents orchestrated by an orchestrator agent. \n\n- _MCP client-side developer_: You want to plug your client-side application into multiple MCP servers. A core part of your client-side logic is making LLM calls to decide which tool to call or which resource to fetch.\n\n- _MCP server and client developer_: You are developing both the server and the client.\n\nIf you fall into either of the first two categories, you want to know when each tool is called, what the execution flow looks like, the token count, and latency of different components in your server or client-side logic. \n\nIf you are developing both the server and client, the ability to see a unified trace timeline can help you quickly iterate through both server and client-side logic.\n\nIn any case, an observability layer allows you to:\n\n- Quickly iterate through your application\n- Audit the workflow or execution logic\n- Identify bottlenecks"
  },
  {
    "title": "Openai",
    "url": "https://weave-docs.wandb.ai/guides/integrations/openai",
    "section": "Docs",
    "category": "Integrations",
    "content": "# OpenAI\n\n\n  \n\n\n> \ud83d\udca1 **Note**: Do you want to experiment with OpenAI models on Weave without any set up? Try the [LLM Playground](../tools/playground.md).\n\n## Tracing\n\nIt\u2019s important to store traces of LLM applications in a central database, both during development and in production. You\u2019ll use these traces for debugging and to help build a dataset of tricky examples to evaluate against while improving your application.\n\n\n  \n    Weave can automatically capture traces for the [openai python library](https://platform.openai.com/docs/libraries/python-library).\n\n    Start capturing by calling `weave.init()` with a project name your choice.\n\n    ```python\n    from openai import OpenAI\n    import weave\n    client = OpenAI()\n    weave.init('emoji-bot')\n\n    response = client.chat.completions.create(\n      model=\"gpt-4\",\n      messages=[\n        {\n          \"role\": \"system\",\n          \"content\": \"You are AGI. You will be provided with a message, and your task is to respond using emojis only.\"\n        },\n        {\n          \"role\": \"user\",\n          \"content\": \"How are you?\"\n        }\n      ],\n      temperature=0.8,\n      max_tokens=64,\n      top_p=1\n    )\n    ```\n\n  \n  \n    Weave can automatically capture traces for the [openai typescript library](https://platform.openai.com/docs/libraries/node-js-library).\n\n    Start capturing by calling `await weave.init()` with a project name your choice, and then wrapping your OpenAI client with `weave.wrapOpenAI`.\n\n    ```typescript\n        \n    // highlight-next-line\n    const client = await weave.init('emoji-bot');\n    // highlight-next-line\n    const openai = weave.wrapOpenAI(new OpenAI());\n\n    const response = await openai.chat.completions.create({\n      model: 'gpt-4',\n      messages: [\n        {\n          role: 'system',\n          content:\n            'You are AGI. You will be provided with a message, and your task is to respond using emojis only.',\n        },\n        {\n          role: 'user',\n          content: 'How are you?',\n        },\n      ],\n      temperature: 0.8,\n      max_tokens: 64,\n      top_p: 1,\n    });\n    ```\n\n  \n\n\n[](https://wandb.ai/_scott/emoji-bot/weave/calls)\n\n## Track your own ops\n\n\n  \nWrapping a function with `@weave.op` starts capturing inputs, outputs and app logic so you can debug how data flows through your app. You can deeply nest ops and build a tree of functions that you want to track. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git.\n\nSimply create a function decorated with [`@weave.op`](/guides/tracking/ops) that calls into [openai python library](https://platform.openai.com/docs/reference/python-sdk?lang=python).\n\nIn the example below, we have 2 functions wrapped with op. This helps us see how intermediate steps, like the retrieval step in a RAG app, are affecting how our app behaves.\n\n    ```python\n    import weave\n    from openai import OpenAI\n    import requests, random\n    PROMPT=\"\"\"Emulate the Pokedex from early Pok\u00e9mon episodes. State the name of the Pokemon and then describe it.\n            Your tone is informative yet sassy, blending factual details with a touch of dry humor. Be concise, no more than 3 sentences. \"\"\"\n    POKEMON = ['pikachu', 'charmander', 'squirtle', 'bulbasaur', 'jigglypuff', 'meowth', 'eevee']\n    client = OpenAI()\n    @weave.op\n    def get_pokemon_data(pokemon_name):\n        # This is a step within your application, like the retrieval step within a RAG app\n        url = f\"https://pokeapi.co/api/v2/pokemon/{pokemon_name}\"\n        response = requests.get(url)\n        if response.status_code == 200:\n            data = response.json()\n            name = data[\"name\"]\n            types = [t[\"type\"][\"name\"] for t in data[\"types\"]]\n            species_url = data[\"species\"][\"url\"]\n            species_response = requests.get(species_url)\n            evolved_from = \"Unknown\"\n            if species_response.status_code == 200:\n                species_data = species_response.json()\n                if species_data[\"evolves_from_species\"]:\n                    evolved_from = species_data[\"evolves_from_species\"][\"name\"]\n            return {\"name\": name, \"types\": types, \"evolved_from\": evolved_from}\n        else:\n            return None\n    @weave.op\n    def pokedex(name: str, prompt: str) -> str:\n        # This is your root op that calls out to other ops\n        data = get_pokemon_data(name)\n        if not data: return \"Error: Unable to fetch data\"\n        response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\"role\": \"system\",\"content\": prompt},\n                {\"role\": \"user\", \"content\": str(data)}\n            ],\n            temperature=0.7,\n            max_tokens=100,\n            top_p=1\n        )\n        return response.choices[0].message.content\n    weave.init('pokedex-openai')\n    # Get data for a specific Pok\u00e9mon\n    pokemon_data = pokedex(random.choice(POKEMON), PROMPT)\n    ```\n\nNavigate to Weave and you can click `get_pokemon_data` in the UI to see the inputs & outputs of that step.\n\n\nWrapping a function with `weave.op` starts capturing inputs, outputs and app logic so you can debug how data flows through your app. You can deeply nest ops and build a tree of functions that you want to track. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git.\n\n    Simply create a function wrapped with [`weave.op`](/guides/tracking/ops) that calls into [openai typescript library](https://platform.openai.com/docs/libraries/node-js-library).\n\n    In the example below, we have 2 functions wrapped with op. This helps us see how intermediate steps, like the retrieval step within a RAG app, are affecting how our app behaves.\n\n    ```typescript\n        // highlight-next-line\n    \n    const PROMPT = `Emulate the Pokedex from early Pok\u00e9mon episodes. State the name of the Pokemon and then describe it.\n            Your tone is informative yet sassy, blending factual details with a touch of dry humor. Be concise, no more than 3 sentences.`;\n    const POKEMON = [\n      'pikachu',\n      'charmander',\n      'squirtle',\n      'bulbasaur',\n      'jigglypuff',\n      'meowth',\n      'eevee',\n    ];\n\n    const openai = weave.wrapOpenAI(new OpenAI());\n\n    interface PokemonData {\n      name: string;\n      types: string[];\n      evolved_from: string;\n    }\n\n    // highlight-next-line\n    const getPokemonData = weave.op(async function getPokemonData(\n      pokemonName: string\n    ): Promise {\n      try {\n        const url = `https://pokeapi.co/api/v2/pokemon/${pokemonName}`;\n        const response = await fetch(url);\n\n        if (response.ok) {\n          const data = await response.json();\n          const name = data.name;\n          const types = data.types.map((t: any) => t.type.name);\n\n          const speciesResponse = await fetch(data.species.url);\n          let evolved_from = 'Unknown';\n\n          if (speciesResponse.ok) {\n            const speciesData = await speciesResponse.json();\n            if (speciesData.evolves_from_species) {\n              evolved_from = speciesData.evolves_from_species.name;\n            }\n          }\n\n          return {name, types, evolved_from};\n        }\n        return null;\n      } catch (error) {\n        return null;\n      }\n    });\n\n    // highlight-next-line\n    const pokedex = weave.op(async function pokedex(\n      name: string,\n      prompt: string\n    ): Promise {\n      const data = await getPokemonData(name);\n      if (!data) return 'Error: Unable to fetch data';\n\n      const response = await openai.chat.completions.create({\n        model: 'gpt-3.5-turbo',\n        messages: [\n          {role: 'system', content: prompt},\n          {role: 'user', content: JSON.stringify(data)},\n        ],\n        temperature: 0.7,\n        max_tokens: 100,\n        top_p: 1,\n      });\n\n      return response.choices[0].message.content || '';\n    });\n\n    async function main() {\n      await weave.init('pokedex-openai');\n      const randomPokemon = POKEMON[Math.floor(Math.random() * POKEMON.length)];\n      const pokemonData = await pokedex(randomPokemon, PROMPT);\n      console.log(pokemonData);\n    }\n\n    main();\n    ```\n\n  \n\n\n[](https://wandb.ai/_scott/pokedex-openai/weave)\n\n## Create a `Model` for easier experimentation\n\n\n  \n    Organizing experimentation is difficult when there are many moving pieces. By using the [`Model`](/guides/core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app.\n\n    In addition to versioning code and capturing inputs/outputs, [`Model`](/guides/core-types/models)s capture structured parameters that control your application\u2019s behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and [`Evaluation`](/guides/core-types/evaluations)s.\n\n    In the example below, you can experiment with `model` and `system_message`. Every time you change one of these, you'll get a new _version_ of `GrammarCorrectorModel`.\n\n    ```python\n    import weave\n    from openai import OpenAI\n\n    weave.init('grammar-openai')\n\n    class GrammarCorrectorModel(weave.Model): # Change to `weave.Model`\n      model: str\n      system_message: str\n\n      @weave.op()\n      def predict(self, user_input): # Change to `predict`\n        client = OpenAI()\n        response = client.chat.completions.create(\n          model=self.model,\n          messages=[\n              {\n                  \"role\": \"system\",\n                  \"content\": self.system_message\n              },\n              {\n                  \"role\": \"user\",\n                  \"content\": user_input\n              }\n              ],\n              temperature=0,\n        )\n        return response.choices[0].message.content\n\n\n    corrector = GrammarCorrectorModel(\n        model=\"gpt-3.5-turbo-1106\",\n        system_message = \"You are a grammar checker, correct the following user input.\")\n    result = corrector.predict(\"That was so easy, it was a piece of pie!\")\n    print(result)\n    ```\n\n    [](https://wandb.ai/_scott/grammar-openai/weave/calls)\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n## Usage Info\n\nThe OpenAI calls return usage info as a default when `stream=False`. Weave will track this usage info and log it to weave to render token counts and cost of the call.\n\nIn case you set `stream=True`, we will automatically patch the call execution with `stream_options={\"include_usage\": True}` argument. This will return the usage info in the last chunk to be rendered in the UI. As a user, the stream iterator will not contain this info.\n\nIf you explicitly set `stream=True` and `stream_options={\"include_usage\": True}`, the returned stream object will contain the usage info. If you don't want to track the usage info you need to explicitly set `stream_options={\"include_usage\": False}`.\n\n## Support for deprecated function calling\n\nOpenAI deprecated the `functions` argument in favor of `tool_calls`. Since frameworks like Langchain, LlamaIndex, etc., still support this argument our OpenAI weave integration will trace if you pass list of function schemas to `functions` argument."
  },
  {
    "title": "Bedrock",
    "url": "https://weave-docs.wandb.ai/guides/integrations/bedrock",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Amazon Bedrock\n\nWeave automatically tracks and logs LLM calls made via Amazon Bedrock, AWS's fully managed service that offers foundation models from leading AI companies through a unified API.\n\nThere are multiple ways to log LLM calls to Weave from Amazon Bedrock. You can use `weave.op` to create reusable operations for tracking any calls to a Bedrock model. Optionally, if you're using Anthropic models, you can use Weave\u2019s built-in integration with Anthropic. \n\n> \ud83c\udf1f **Tip**: For the latest tutorials, visit [Weights & Biases on Amazon Web Services](https://wandb.ai/site/partners/aws/).\n\n## Traces\n\nWeave will automatically capture traces for Bedrock API calls. You can use the Bedrock client as usual after initializing Weave and patching the client:\n\n```python\nimport weave\nimport boto3\nimport json\nfrom weave.integrations.bedrock.bedrock_sdk import patch_client\n\nweave.init(\"my_bedrock_app\")\n\n# Create and patch the Bedrock client\nclient = boto3.client(\"bedrock-runtime\")\npatch_client(client)\n\n# Use the client as usual\nresponse = client.invoke_model(\n    modelId=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    body=json.dumps({\n        \"anthropic_version\": \"bedrock-2023-05-31\",\n        \"max_tokens\": 100,\n        \"messages\": [\n            {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n        ]\n    }),\n    contentType='application/json',\n    accept='application/json'\n)\nresponse_dict = json.loads(response.get('body').read())\nprint(response_dict[\"content\"][0][\"text\"])\n```\n\nof using the `converse` API:\n\n```python\nmessages = [{\"role\": \"user\", \"content\": [{\"text\": \"What is the capital of France?\"}]}]\n\nresponse = client.converse(\n    modelId=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    system=[{\"text\": \"You are a helpful AI assistant.\"}],\n    messages=messages,\n    inferenceConfig={\"maxTokens\": 100},\n)\nprint(response[\"output\"][\"message\"][\"content\"][0][\"text\"])\n\n```\n\n## Wrapping with your own ops\n\nYou can create reusable operations using the `@weave.op()` decorator. Here's an example showing both the `invoke_model` and `converse` APIs:\n\n```python\n@weave.op\ndef call_model_invoke(\n    model_id: str,\n    prompt: str,\n    max_tokens: int = 100,\n    temperature: float = 0.7\n) -> dict:\n    body = json.dumps({\n        \"anthropic_version\": \"bedrock-2023-05-31\",\n        \"max_tokens\": max_tokens,\n        \"temperature\": temperature,\n        \"messages\": [\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    })\n\n    response = client.invoke_model(\n        modelId=model_id,\n        body=body,\n        contentType='application/json',\n        accept='application/json'\n    )\n    return json.loads(response.get('body').read())\n\n@weave.op\ndef call_model_converse(\n    model_id: str,\n    messages: str,\n    system_message: str,\n    max_tokens: int = 100,\n) -> dict:\n    response = client.converse(\n        modelId=model_id,\n        system=[{\"text\": system_message}],\n        messages=messages,\n        inferenceConfig={\"maxTokens\": max_tokens},\n    )\n    return response\n```\n\n\n\n## Create a `Model` for easier experimentation\n\nYou can create a Weave Model to better organize your experiments and capture parameters. Here's an example using the `converse` API:\n\n```python\nclass BedrockLLM(weave.Model):\n    model_id: str\n    max_tokens: int = 100\n    system_message: str = \"You are a helpful AI assistant.\"\n\n    @weave.op\n    def predict(self, prompt: str) -> str:\n        \"Generate a response using Bedrock's converse API\"\n        \n        messages = [{\n            \"role\": \"user\",\n            \"content\": [{\"text\": prompt}]\n        }]\n\n        response = client.converse(\n            modelId=self.model_id,\n            system=[{\"text\": self.system_message}],\n            messages=messages,\n            inferenceConfig={\"maxTokens\": self.max_tokens},\n        )\n        return response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n\n# Create and use the model\nmodel = BedrockLLM(\n    model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    max_tokens=100,\n    system_message=\"You are an expert software engineer that knows a lot of programming. You prefer short answers.\"\n)\nresult = model.predict(\"What is the best way to handle errors in Python?\")\nprint(result)\n```\n\nThis approach allows you to version your experiments and easily track different configurations of your Bedrock-based application.\n\n## Learn more\n\nLearn more about using Amazon Bedrock with Weave\n\n### Try Bedrock in the Weave Playground\n\nDo you want to experiment with Amazon Bedrock models in the Weave UI without any set up? Try the [LLM Playground](../tools/playground.md).\n\n### Report: Compare LLMs on Bedrock for text summarization with Weave\n\nThe [Compare LLMs on Bedrock for text summarization with Weave](https://wandb.ai/byyoung3/ML_NEWS3/reports/Compare-LLMs-on-Amazon-Bedrock-for-text-summarization-with-W-B-Weave--VmlldzoxMDI1MTIzNw) report explains how to use Bedrock in combination with Weave to evaluate and compare LLMs for summarization tasks, code samples included."
  },
  {
    "title": "Openai Agents",
    "url": "https://weave-docs.wandb.ai/guides/integrations/openai_agents",
    "section": "Docs",
    "category": "Integrations",
    "content": "# OpenAI Agents SDK\n\nThe [OpenAI Agents Python SDK](https://github.com/openai/openai-agents-python) is a lightweight and powerful framework for building multi-agent workflows. You can use W&B Weave with the OpenAI Agents SDK to track and monitor your agentic applications.\n\n## Installation\n\nInstall the required dependencies using `pip`: \n\n```bash\npip install weave openai-agents\n```\n\n## Get started\n\nTo use the OpenAI Agents SDK with Weave, you'll need to:\n\n- Initialize Weave with your project name\n- Add the Weave tracing processor to your agents\n- Create and run your agents as usual\n\nIn the following codes sample, an OpenAI Agent is created and integrated with Weave for traceability. First, a Weave project is initialized and the `WeaveTracingProcessor` is set up to capture execution traces. A `Weather` data model is created to represent weather information. The `get_weather` function is decorated as a tool the agent can use and returns a sample weather report. An agent named `Hello world` is configured with basic instructions and access to the weather tool. The main function asynchronously runs the agent with a sample input (`What's the weather in Tokyo?`) and outputs the final response.\n\n```python\nfrom pydantic import BaseModel\nfrom agents import Agent, Runner, function_tool, set_trace_processors\nimport agents\nimport weave\nfrom weave.integrations.openai_agents.openai_agents import WeaveTracingProcessor\nimport asyncio\n\nweave.init(\"openai-agents\")\nset_trace_processors([WeaveTracingProcessor()])\n\nclass Weather(BaseModel):\n    city: str\n    temperature_range: str\n    conditions: str\n\n@function_tool\ndef get_weather(city: str) -> Weather:\n    return Weather(city=city, temperature_range=\"14-20C\", conditions=\"Sunny with wind.\")\n\nagent = Agent(\n    name=\"Hello world\",\n    instructions=\"You are a helpful agent.\",\n    tools=[get_weather]\n)\n\nasync def main():\n    result = await Runner.run(agent, input=\"What's the weather in Tokyo?\")    \n    print(result.final_output)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n## View traces\n\nWhen the above code sample is run, a link to the Weave dashboard is generated. To see what happened during your agent execution, follow the link to see your agent traces."
  },
  {
    "title": "Nvidia Nim",
    "url": "https://weave-docs.wandb.ai/guides/integrations/nvidia_nim",
    "section": "Docs",
    "category": "Integrations",
    "content": "# NVIDIA NIM\n\nWeave automatically tracks and logs LLM calls made via the [ChatNVIDIA](https://python.langchain.com/docs/integrations/chat/nvidia_ai_endpoints/) library, after `weave.init()` is called.\n\n> \ud83c\udf1f **Tip**: For the latest tutorials, visit [Weights & Biases on NVIDIA](https://wandb.ai/site/partners/nvidia).\n\n## Tracing\n\nIt\u2019s important to store traces of LLM applications in a central database, both during development and in production. You\u2019ll use these traces for debugging and to help build a dataset of tricky examples to evaluate against while improving your application.\n\n\n  \n    Weave can automatically capture traces for the [ChatNVIDIA python library](https://python.langchain.com/docs/integrations/chat/nvidia_ai_endpoints/).\n\n    Start capturing by calling `weave.init()` with a project name your choice.\n\n    ```python\n    from langchain_nvidia_ai_endpoints import ChatNVIDIA\n    import weave\n    client = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\", temperature=0.8, max_tokens=64, top_p=1)\n    weave.init('emoji-bot')\n\n    messages=[\n        {\n          \"role\": \"system\",\n          \"content\": \"You are AGI. You will be provided with a message, and your task is to respond using emojis only.\"\n        }]\n\n    response = client.invoke(messages)\n    ```\n\n  \n  \n      ```plaintext\n      This feature is not available in TypeScript yet since this library is only in Python.\n      ```\n  \n\n\n\n\n## Track your own ops\n\n\n  \nWrapping a function with `@weave.op` starts capturing inputs, outputs and app logic so you can debug how data flows through your app. You can deeply nest ops and build a tree of functions that you want to track. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git.\n\nSimply create a function decorated with [`@weave.op`](/guides/tracking/ops) that calls into [ChatNVIDIA python library](https://python.langchain.com/docs/integrations/chat/nvidia_ai_endpoints/).\n\nIn the example below, we have 2 functions wrapped with op. This helps us see how intermediate steps, like the retrieval step in a RAG app, are affecting how our app behaves.\n\n    ```python\n    import weave\n    from langchain_nvidia_ai_endpoints import ChatNVIDIA\n    import requests, random\n    PROMPT=\"\"\"Emulate the Pokedex from early Pok\u00e9mon episodes. State the name of the Pokemon and then describe it.\n            Your tone is informative yet sassy, blending factual details with a touch of dry humor. Be concise, no more than 3 sentences. \"\"\"\n    POKEMON = ['pikachu', 'charmander', 'squirtle', 'bulbasaur', 'jigglypuff', 'meowth', 'eevee']\n    client = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\", temperature=0.7, max_tokens=100, top_p=1)\n    @weave.op\n    def get_pokemon_data(pokemon_name):\n        # This is a step within your application, like the retrieval step within a RAG app\n        url = f\"https://pokeapi.co/api/v2/pokemon/{pokemon_name}\"\n        response = requests.get(url)\n        if response.status_code == 200:\n            data = response.json()\n            name = data[\"name\"]\n            types = [t[\"type\"][\"name\"] for t in data[\"types\"]]\n            species_url = data[\"species\"][\"url\"]\n            species_response = requests.get(species_url)\n            evolved_from = \"Unknown\"\n            if species_response.status_code == 200:\n                species_data = species_response.json()\n                if species_data[\"evolves_from_species\"]:\n                    evolved_from = species_data[\"evolves_from_species\"][\"name\"]\n            return {\"name\": name, \"types\": types, \"evolved_from\": evolved_from}\n        else:\n            return None\n    @weave.op\n    def pokedex(name: str, prompt: str) -> str:\n        # This is your root op that calls out to other ops\n        data = get_pokemon_data(name)\n        if not data: return \"Error: Unable to fetch data\"\n\n        messages=[\n                {\"role\": \"system\",\"content\": prompt},\n                {\"role\": \"user\", \"content\": str(data)}\n            ]\n\n        response = client.invoke(messages)\n        return response.content\n    weave.init('pokedex-nvidia')\n    # Get data for a specific Pok\u00e9mon\n    pokemon_data = pokedex(random.choice(POKEMON), PROMPT)\n    ```\n\nNavigate to Weave and you can click `get_pokemon_data` in the UI to see the inputs & outputs of that step.\n\n\n    ```plaintext\n    This feature is not available in TypeScript yet since this library is only in Python.\n    ```\n\n\n\n\n\n## Create a `Model` for easier experimentation\n\n\n  \n    Organizing experimentation is difficult when there are many moving pieces. By using the [`Model`](/guides/core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app.\n\n    In addition to versioning code and capturing inputs/outputs, [`Model`](/guides/core-types/models)s capture structured parameters that control your application\u2019s behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and [`Evaluation`](/guides/core-types/evaluations)s.\n\n    In the example below, you can experiment with `model` and `system_message`. Every time you change one of these, you'll get a new _version_ of `GrammarCorrectorModel`.\n\n    ```python\n    import weave\n    from langchain_nvidia_ai_endpoints import ChatNVIDIA\n\n    weave.init('grammar-nvidia')\n\n    class GrammarCorrectorModel(weave.Model): # Change to `weave.Model`\n      system_message: str\n\n      @weave.op()\n      def predict(self, user_input): # Change to `predict`\n        client = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\", temperature=0, max_tokens=100, top_p=1)\n\n        messages=[\n              {\n                  \"role\": \"system\",\n                  \"content\": self.system_message\n              },\n              {\n                  \"role\": \"user\",\n                  \"content\": user_input\n              }\n              ]\n\n        response = client.invoke(messages)\n        return response.content\n\n\n    corrector = GrammarCorrectorModel(\n        system_message = \"You are a grammar checker, correct the following user input.\")\n    result = corrector.predict(\"That was so easy, it was a piece of pie!\")\n    print(result)\n    ```\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet since this library is only in Python.\n    ```\n  \n\n\n\n\n## Usage Info\n\nThe ChatNVIDIA integration supports `invoke`, `stream` and their async variants. It also supports tool use. \nAs ChatNVIDIA is meant to be used with many types of models, it does not have function calling support."
  },
  {
    "title": "Langchain",
    "url": "https://weave-docs.wandb.ai/guides/integrations/langchain",
    "section": "Docs",
    "category": "Integrations",
    "content": "# LangChain\n\n\n  \n\n\nWeave is designed to make tracking and logging all calls made through the [LangChain Python library](https://github.com/langchain-ai/langchain) effortless.\n\nWhen working with LLMs, debugging is inevitable. Whether a model call fails, an output is misformatted, or nested model calls create confusion, pinpointing issues can be challenging. LangChain applications often consist of multiple steps and LLM call invocations, making it crucial to understand the inner workings of your chains and agents.\n\nWeave simplifies this process by automatically capturing traces for your [LangChain](https://python.langchain.com/v0.2/docs/introduction/) applications. This enables you to monitor and analyze your application's performance, making it easier to debug and optimize your LLM workflows.\n\n\n## Getting Started\n\nTo get started, simply call `weave.init()` at the beginning of your script. The argument in weave.init() is a project name that will help you organize your traces.\n\n```python\nimport weave\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI\n\n# Initialize Weave with your project name\nweave.init(\"langchain_demo\")\n\nllm = ChatOpenAI()\nprompt = PromptTemplate.from_template(\"1 + {number} = \")\n\nllm_chain = prompt | llm\n\noutput = llm_chain.invoke({\"number\": 2})\n\nprint(output)\n```\n\n## Tracking Call Metadata\n\nTo track metadata from your LangChain calls, you can use the [`weave.attributes`](https://weave-docs.wandb.ai/reference/python-sdk/weave/#function-attributes) context manager. This context manager allows you to set custom metadata for a specific block of code, such as a chain or a single request.\n\n```python\nimport weave\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI\n\n# Initialize Weave with your project name\nweave.init(\"langchain_demo\")\n\nllm = ChatOpenAI()\nprompt = PromptTemplate.from_template(\"1 + {number} = \")\n\nllm_chain = prompt | llm\nwith weave.attributes({\"my_awesome_attribute\": \"value\"}):\n    output = llm_chain.invoke()\n\nprint(output)\n```\nWeave automatically tracks the metadat against the trace of the LangChain call. You can view the metadata in the Weave web interface as shown below:\n\n[](https://wandb.ai/parambharat/langchain_demo/weave/traces?cols=%7B%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D)\n\n## Traces\n\nStoring traces of LLM applications in a central database is crucial during both development and production. These traces are essential for debugging and improving your application by providing a valuable dataset.\n\nWeave automatically captures traces for your LangChain applications. It will track and log all calls made through the LangChain library, including prompt templates, chains, LLM calls, tools, and agent steps. You can view the traces in the Weave web interface.\n\n[](https://wandb.ai/parambharat/langchain_demo/weave/calls)\n\n## Manually Tracing Calls\n\nIn addition to automatic tracing, you can manually trace calls using the `WeaveTracer` callback or the `weave_tracing_enabled` context manager. These methods are akin to using request callbacks in individual parts of a LangChain application.\n\n**Note:** Weave traces Langchain Runnables by default and this is enabled when you call `weave.init()`. You can disable this behaviour by setting the environment variable `WEAVE_TRACE_LANGCHAIN` to `\"false\"` before calling `weave.init()`. This allows you to control the tracing behaviour of specific chains or even individual requests in your application.\n\n### Using `WeaveTracer`\n\nYou can pass the `WeaveTracer` callback to individual LangChain components to trace specific requests.\n\n```python\nimport os\n\nos.environ[\"WEAVE_TRACE_LANGCHAIN\"] = \"false\" # <- explicitly disable global tracing.\n\nfrom weave.integrations.langchain import WeaveTracer\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI\nimport weave\n\n# Initialize Weave with your project name\nweave.init(\"langchain_demo\")  # <-- we don't enable tracing here because the env var is explicitly set to `false`\nweave_tracer = WeaveTracer()\nconfig = {\"callbacks\": [weave_tracer]}\n\nllm = ChatOpenAI()\nprompt = PromptTemplate.from_template(\"1 + {number} = \")\n\nllm_chain = prompt | llm\noutput = llm_chain.invoke({\"number\": 2}, config=config) # <-- this enables tracing only for this chain invoke.\n\nllm_chain.invoke({\"number\": 4})  # <-- this will not have tracing enabled for langchain calls but openai calls will still be traced\n```\n\n### Using `weave_tracing_enabled` Context Manager\n\nAlternatively, you can use the `weave_tracing_enabled` context manager to enable tracing for specific blocks of code.\n\n```python\nimport os\n\nos.environ[\"WEAVE_TRACE_LANGCHAIN\"] = \"false\" # <- explicitly disable global tracing.\n\nfrom weave.integrations.langchain import weave_tracing_enabled\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI\nimport weave\n\n# Initialize Weave with your project name\nweave.init(\"langchain_demo\")  # <-- we don't enable tracing here because the env var is explicitly set to `false`\n\nllm = ChatOpenAI()\nprompt = PromptTemplate.from_template(\"1 + {number} = \")\n\nllm_chain = prompt | llm\nwith weave_tracing_enabled():  # <-- this enables tracing only for this chain invoke.\n    output = llm_chain.invoke({\"number\": 2})\n\n\nllm_chain.invoke({\"number\": 4})  # <-- this will not have tracing enabled for langchain calls but openai calls will still be traced\n```\n\n## Configuration\n\nUpon calling `weave.init`, tracing is enabled by setting the environment variable `WEAVE_TRACE_LANGCHAIN` to `\"true\"`. This allows Weave to automatically capture traces for your LangChain applications. If you wish to disable this behavior, set the environment variable to `\"false\"`.\n\n## Relation to LangChain Callbacks\n\n### Auto Logging\n\nThe automatic logging provided by `weave.init()` is similar to passing a constructor callback to every component in a LangChain application. This means that all interactions, including prompt templates, chains, LLM calls, tools, and agent steps, are tracked globally across your entire application.\n\n### Manual Logging\n\nThe manual logging methods (`WeaveTracer` and `weave_tracing_enabled`) are similar to using request callbacks in individual parts of a LangChain application. These methods provide finer control over which parts of your application are traced:\n\n- **Constructor Callbacks:** Applied to the entire chain or component, logging all interactions consistently.\n- **Request Callbacks:** Applied to specific requests, allowing detailed tracing of particular invocations.\n\nBy integrating Weave with LangChain, you can ensure comprehensive logging and monitoring of your LLM applications, facilitating easier debugging and performance optimization.\n\nFor more detailed information, refer to the [LangChain documentation](https://python.langchain.com/v0.2/docs/how_to/debugging/#tracing).\n\n## Models and Evaluations\n\nOrganizing and evaluating LLMs in applications for various use cases is challenging with multiple components, such as prompts, model configurations, and inference parameters. Using the [`weave.Model`](/guides/core-types/models), you can capture and organize experimental details like system prompts or the models you use, making it easier to compare different iterations.\n\nThe following example demonstrates wrapping a Langchain chain in a `WeaveModel`:\n\n```python\nimport json\nimport asyncio\n\nimport weave\n\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI\n\n# Initialize Weave with your project name\nweave.init(\"langchain_demo\")\nclass ExtractFruitsModel(weave.Model):\n    model_name: str\n    prompt_template: str\n    @weave.op()\n    async def predict(self, sentence: str) -> dict:\n        llm = ChatOpenAI(model=self.model_name, temperature=0.0)\n        prompt = PromptTemplate.from_template(self.prompt_template)\n\n        llm_chain = prompt | llm\n        response = llm_chain.invoke({\"sentence\": sentence})\n        result = response.content\n\n        if result is None:\n            raise ValueError(\"No response from model\")\n        parsed = json.loads(result)\n        return parsed\n\nmodel = ExtractFruitsModel(\n    model_name=\"gpt-3.5-turbo-1106\",\n    prompt_template='Extract fields (\"fruit\": , \"color\": , \"flavor\": ) from the following text, as json: {sentence}',\n)\nsentence = \"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.\"\n\nprediction = asyncio.run(model.predict(sentence))\n\n# if you're in a Jupyter Notebook, run:\n# prediction = await model.predict(sentence)\n\nprint(prediction)\n```\nThis code creates a model that can be visualized in the Weave UI:\n\n[](https://wandb.ai/parambharat/langchain_demo/weave/object-versions?filter=%7B%22baseObjectClass%22%3A%22Model%22%7D&peekPath=%2Fparambharat%2Flangchain_demo%2Fobjects%2FExtractFruitsModel%2Fversions%2FBeoL6WuCH8wgjy6HfmuBMyKzArETg1oAFpYaXZSq1hw%3F%26)\n\n\nYou can also use Weave Models with `serve`, and [`Evaluations`](/guides/core-types/evaluations).\n\n### Evaluations\nEvaluations help you measure the performance of your models. By using the [`weave.Evaluation`](/guides/core-types/evaluations) class, you can capture how well your model performs on specific tasks or datasets, making it easier to compare different models and iterations of your application. The following example demonstrates how to evaluate the model we created:\n\n\n```python\n\nfrom weave.scorers import MultiTaskBinaryClassificationF1\n\nsentences = [\n    \"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.\",\n    \"Pounits are a bright green color and are more savory than sweet.\",\n    \"Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\",\n]\nlabels = [\n    {\"fruit\": \"neoskizzles\", \"color\": \"purple\", \"flavor\": \"candy\"},\n    {\"fruit\": \"pounits\", \"color\": \"bright green\", \"flavor\": \"savory\"},\n    {\"fruit\": \"glowls\", \"color\": \"pale orange\", \"flavor\": \"sour and bitter\"},\n]\nexamples = [\n    {\"id\": \"0\", \"sentence\": sentences[0], \"target\": labels[0]},\n    {\"id\": \"1\", \"sentence\": sentences[1], \"target\": labels[1]},\n    {\"id\": \"2\", \"sentence\": sentences[2], \"target\": labels[2]},\n]\n\n@weave.op()\ndef fruit_name_score(target: dict, output: dict) -> dict:\n    return {\"correct\": target[\"fruit\"] == output[\"fruit\"]}\n\n\nevaluation = weave.Evaluation(\n    dataset=examples,\n    scorers=[\n        MultiTaskBinaryClassificationF1(class_names=[\"fruit\", \"color\", \"flavor\"]),\n        fruit_name_score,\n    ],\n)\nscores = asyncio.run(evaluation.evaluate(model)))\n# if you're in a Jupyter Notebook, run:\n# scores = await evaluation.evaluate(model)\n\nprint(scores)\n```\n\nThis code generates an evaluation trace that can be visualized in the Weave UI:\n\n[](https://wandb.ai/parambharat/langchain_demo/weave/calls?filter=%7B%22traceRootsOnly%22%3Atrue%7D&peekPath=%2Fparambharat%2Flangchain_demo%2Fcalls%2F44c3f26c-d9d3-423e-b434-651ea5174be3)\n\nBy integrating Weave with Langchain, you can ensure comprehensive logging and monitoring of your LLM applications, facilitating easier debugging and performance optimization.\n\n\n## Known Issues\n\n- **Tracing Async Calls** - A bug in the implementation of the `AsyncCallbackManager` in Langchain results in async calls not being traced in the correct order. We have filed a [PR](https://github.com/langchain-ai/langchain/pull/23909) to fix this. Therefore, the order of calls in the trace may not be accurate when using `ainvoke`, `astream` and `abatch` methods in Langchain Runnables."
  },
  {
    "title": "Pydantic Ai",
    "url": "https://weave-docs.wandb.ai/guides/integrations/pydantic_ai",
    "section": "Docs",
    "category": "Integrations",
    "content": "# PydanticAI\n\nYou can trace [PydanticAI](https://ai.pydantic.dev/) agent and tool calls in Weave using [OpenTelemetry (OTEL)](https://opentelemetry.io/). PydanticAI is a Python agent framework built by the Pydantic team to make it easy and type-safe to build production-grade applications with Generative AI. It uses OTEL for tracing all agent and tool calls.\n\n> \ud83c\udf1f **Tip**: For more information on OTEL tracing in Weave, see [Send OTEL Traces to Weave](../tracking/otel.md).\n\nThis guide shows you how to trace PydanticAI agent and tool calls using OTEL and visualize those traces in Weave. You\u2019ll learn how to install the required dependencies, configure an OTEL tracer to send data to Weave, and instrument your PydanticAI agents and tools. You\u2019ll also see how to enable tracing by default across all agents in your application.\n\n## Prerequisites\n\nBefore you begin, install the required OTEL dependencies:\n\n```bash\npip install opentelemetry-sdk OTELemetry-exporter-otlp-proto-http\n```\nThen, [configure OTEL tracing in Weave](#configure-otel-tracing-in-weave).\n\n### Configure OTEL tracing in Weave\n\nTo send traces from PydanticAI to Weave, configure OTEL with a `TracerProvider` and an `OTLPSpanExporter`. Set the exporter to the [correct endpoint and HTTP headers for authentication and project identification](#required-configuration).\n\n> \ud83d\udea8 **Important**: It is recommended that you store sensitive environment variables like your API key and project info in an environment file (e.g., `.env`), and load them using `os.environ`. This keeps your credentials secure and out of your codebase.\n\n### Required configuration\n\n- **Endpoint:** `https://trace.wandb.ai/otel/v1/traces`\n- **Headers:**\n  - `Authorization`: Basic auth using your W&B API key\n  - `project_id`: Your W&B entity/project name (e.g., `myteam/myproject`)\n\n### Example set up\n\nThe following code snippet demonstrates how to configure an OTLP span exporter and tracer provider to send OTEL traces from a PydanticAI application to Weave. \n\n```python\nimport base64\nimport os\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk import trace as trace_sdk\nfrom opentelemetry.sdk.trace.export import SimpleSpanProcessor\n\n# Load sensitive values from environment variables\nWANDB_BASE_URL = \"https://trace.wandb.ai\"\nPROJECT_ID = os.environ.get(\"WANDB_PROJECT_ID\")  # Your W&B entity/project name e.g. \"myteam/myproject\"\nWANDB_API_KEY = os.environ.get(\"WANDB_API_KEY\")  # Your W&B API key\n\nOTEL_EXPORTER_OTLP_ENDPOINT = f\"{WANDB_BASE_URL}/otel/v1/traces\"\nAUTH = base64.b64encode(f\"api:{WANDB_API_KEY}\".encode()).decode()\n\nOTEL_EXPORTER_OTLP_HEADERS = {\n    \"Authorization\": f\"Basic {AUTH}\",\n    \"project_id\": PROJECT_ID,\n}\n\n# Create the OTLP span exporter with endpoint and headers\nexporter = OTLPSpanExporter(\n    endpoint=OTEL_EXPORTER_OTLP_ENDPOINT,\n    headers=OTEL_EXPORTER_OTLP_HEADERS,\n)\n\n# Create a tracer provider and add the exporter\ntracer_provider = trace_sdk.TracerProvider()\ntracer_provider.add_span_processor(SimpleSpanProcessor(exporter))\n```\n\n## Trace PydanticAI Agents with OTEL\n\nTo trace your PydanticAI agents and send trace data to Weave, pass an `InstrumentationSettings` object configured with your tracer provider to the `Agent constructor`. This ensures that all agent and tool calls are traced according to your OTEL configuration.\n\nThe following example shows how to create a simple agent with tracing enabled. The key step is setting the instrument argument when initializing the agent:\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.instrumented import InstrumentationSettings\n\n# Create a PydanticAI agent with OTEL tracing\nagent = Agent(\n    \"openai:gpt-4o\",\n    instrument=InstrumentationSettings(tracer_provider=tracer_provider),\n)\n\nresult = agent.run_sync(\"What is the capital of France?\")\nprint(result.output)\n```\n\nAll calls to the agent are traced and sent to Weave.\n\n \n\n## Trace PydanticAI Tools with OTEL\n\nWeave can trace any PydanticAI operations that are instrumented with OTEL, including both agent and tool calls. This means that when your agent invokes a tool (e.g. a function decorated with `@agent.tool_plain`), the entire interaction is captured and visualized in Weave, including tool inputs, outputs, and the model's reasoning.\n\nThe following example shows how to create an agent with a system prompt and a tool. Tracing is enabled automatically for both the agent and the tool:\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.instrumented import InstrumentationSettings\n\n# Create a PydanticAI agent with a system prompt and OTEL tracing\nagent = Agent(\n    \"openai:gpt-4o\",\n    system_prompt=(\n        \"You are a helpful assistant that can multiply numbers. \"\n        \"When asked to multiply numbers, use the multiply tool.\"\n    ),\n    instrument=InstrumentationSettings(tracer_provider=tracer_provider),\n)\n\n# Define a tool\n@agent.tool_plain\ndef multiply(a: int, b: int) -> int:\n    \"\"\"Multiply two numbers.\"\"\"\n    return a * b\n\n# Ask the agent to use the tool\nresult = agent.run_sync(\"What is 7 multiplied by 8?\")\nprint(result.output)\n```\n\n \n\nBoth the agent call and the tool call are traced in Weave, allowing you to inspect the full reasoning and execution path of your application.\n\n## Instrument all agents by default\n\nTo apply OTEL tracing to all PydanticAI agents in your application, use the `Agent.instrument_all()` method. This sets a default `InstrumentationSettings` instance for any agent that doesn\u2019t explicitly specify the `instrument` parameter.\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.instrumented import InstrumentationSettings\n\n# Set up default instrumentation for all agents\nAgent.instrument_all(InstrumentationSettings(tracer_provider=tracer_provider))\n\n# Now, any new agent will use this instrumentation by default\nagent1 = Agent(\"openai:gpt-4o\")\nagent2 = Agent(\"openai:gpt-4o\", system_prompt=\"Be helpful.\")\n\nresult = agent1.run_sync(\"What is the capital of France?\")\nprint(result.output)\n```\n\nThis is useful for larger applications where you want consistent tracing across all agents without repeating configuration. For more details, see the [PydanticAI OTEL docs](https://ai.pydantic.dev/logfire/#using-logfire).\n\n## Learn more\n\n- [Weave documentation: Send OTEL traces to Weave](../tracking/otel.md)\n- [Official OTEL documentation](https://opentelemetry.io/)\n- [Official PydanticAI documentation](https://ai.pydantic.dev/)\n- [PydanticAI GitHub repository](https://github.com/pydantic/pydantic-ai)"
  },
  {
    "title": "Cohere",
    "url": "https://weave-docs.wandb.ai/guides/integrations/cohere",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Cohere\n\n\n  \n\n\nWeave automatically tracks and logs LLM calls made via the [Cohere Python library](https://github.com/cohere-ai/cohere-python) after `weave.init()` is called.\n\n## Traces\n\nIt's important to store traces of LLM applications in a central database, both during development and in production. You'll use these traces for debugging, and as a dataset that will help you improve your application.\n\nWeave will automatically capture traces for [cohere-python](https://github.com/cohere-ai/cohere-python). You can use the library as usual, start by calling `weave.init()`:\n\n```python\nimport cohere\nimport os\nimport weave\n\n# Use the Cohere library as usual\nco = cohere.Client(api_key=os.environ[\"COHERE_API_KEY\"])\nweave.init(\"cohere_project\")\n\nresponse = co.chat(\n    message=\"How is the weather in Boston?\",\n    # perform web search before answering the question. You can also use your own custom connector.\n    connectors=[{\"id\": \"web-search\"}],\n)\nprint(response.text)\n```\nA powerful feature of cohere models is using [connectors](https://docs.cohere.com/docs/overview-rag-connectors#using-connectors-to-create-grounded-generations) enabling you to make requests to other API on the endpoint side. The response will then contain the generated text with citation elements that link to the documents returned from the connector. \n\n[](https://wandb.ai/capecape/cohere_dev/weave/calls)\n\n> \ud83d\udca1 **Note**: We patch the Cohere `Client.chat`, `AsyncClient.chat`, `Client.chat_stream`, and `AsyncClient.chat_stream` methods for you to keep track of your LLM calls.\n\n## Wrapping with your own ops\n\nWeave ops make results *reproducible* by automatically versioning code as you experiment, and they capture their inputs and outputs. Simply create a function decorated with [`@weave.op()`](/guides/tracking/ops) that calls into Cohere's chat methods, and Weave will track the inputs and outputs for you. Here's an example:\n\n```python\nimport cohere\nimport os\nimport weave\n\nco = cohere.Client(api_key=os.environ[\"COHERE_API_KEY\"])\n\nweave.init(\"cohere_project\")\n@weave.op()\ndef weather(location: str, model: str) -> str:\n    response = co.chat(\n        model=model,\n        message=f\"How is the weather in {location}?\",\n        # perform web search before answering the question. You can also use your own custom connector.\n        connectors=[{\"id\": \"web-search\"}],\n    )\n    return response.text\n\nprint(weather(\"Boston\", \"command\"))\n```\n\n[](https://wandb.ai/capecape/cohere_dev/weave/calls)\n\n## Create a `Model` for easier experimentation\n\nOrganizing experimentation is difficult when there are many moving pieces. By using the [`Model`](/guides/core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app.\n\nIn addition to versioning code and capturing inputs/outputs, [`Model`](/guides/core-types/models)s capture structured parameters that control your application's behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and [`Evaluation`](/guides/core-types/evaluations)s.\n\nIn the example below, you can experiment with `model` and `temperature`. Every time you change one of these, you'll get a new _version_ of `WeatherModel`.\n\n```python\nimport weave\nimport cohere\nimport os\n\nweave.init('weather-cohere')\n\nclass WeatherModel(weave.Model):\n    model: str\n    temperature: float\n  \n    @weave.op()\n    def predict(self, location: str) -> str:\n        co = cohere.Client(api_key=os.environ[\"COHERE_API_KEY\"])\n        response = co.chat(\n            message=f\"How is the weather in {location}?\",\n            model=self.model,\n            temperature=self.temperature,\n            connectors=[{\"id\": \"web-search\"}]\n        )\n        return response.text\n\nweather_model = WeatherModel(\n    model=\"command\",\n    temperature=0.7\n)\nresult = weather_model.predict(\"Boston\")\nprint(result)\n```\n\n[](https://wandb.ai/capecape/cohere_dev/weave/models)"
  },
  {
    "title": "Mistral",
    "url": "https://weave-docs.wandb.ai/guides/integrations/mistral",
    "section": "Docs",
    "category": "Integrations",
    "content": "# MistralAI\n\n\n  \n\n\nWeave automatically tracks and logs LLM calls made via the [MistralAI Python library](https://github.com/mistralai/client-python). \n\n> We support the new Mistral v1.0 SDK, check the migration guide [here](https://github.com/mistralai/client-python/blob/main/MIGRATION.md)\n\n## Traces\n\nIt\u2019s important to store traces of LLM applications in a central database, both during development and in production. You\u2019ll use these traces for debugging, and as a dataset that will help you improve your application.\n\nWeave will automatically capture traces for [mistralai](https://github.com/mistralai/client-python). You can use the library as usual, start by calling `weave.init()`:\n\n```python\nimport weave\nweave.init(\"cheese_recommender\")\n\n# then use mistralai library as usual\nimport os\nfrom mistralai import Mistral\n\napi_key = os.environ[\"MISTRAL_API_KEY\"]\nmodel = \"mistral-large-latest\"\n\nclient = Mistral(api_key=api_key)\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"What is the best French cheese?\",\n    },\n]\n\nchat_response = client.chat.complete(\n    model=model,\n    messages=messages,\n)\n```\n\nWeave will now track and log all LLM calls made through the MistralAI library. You can view the traces in the Weave web interface.\n\n[](https://wandb.ai/capecape/mistralai_project/weave/calls)\n\n## Wrapping with your own ops\n\nWeave ops make results *reproducible* by automatically versioning code as you experiment, and they capture their inputs and outputs. Simply create a function decorated with [`@weave.op()`](/guides/tracking/ops) that calls into [`mistralai.client.MistralClient.chat()`](https://docs.mistral.ai/capabilities/completion/) and Weave will track the inputs and outputs for you. Let's see how we can do this for our cheese recommender:\n\n```python\n@weave.op()\ndef cheese_recommender(region:str, model:str) -> str:\n    \"Recommend the best cheese in a given region\"\n    \n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": f\"What is the best cheese in {region}?\",\n        },\n    ]\n\n    chat_response = client.chat.complete(\n        model=model,\n        messages=messages,\n    )\n    return chat_response.choices[0].message.content\n\ncheese_recommender(region=\"France\", model=\"mistral-large-latest\")\ncheese_recommender(region=\"Spain\", model=\"mistral-large-latest\")\ncheese_recommender(region=\"Netherlands\", model=\"mistral-large-latest\")\n```\n\n[](https://wandb.ai/capecape/mistralai_project/weave/calls)\n\n## Create a `Model` for easier experimentation\n\nOrganizing experimentation is difficult when there are many moving pieces. By using the [`Model`](/guides/core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app. \n\nIn addition to versioning code and capturing inputs/outputs, [`Model`](/guides/core-types/models)s capture structured parameters that control your application\u2019s behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and [`Evaluation`](/guides/core-types/evaluations)s.\n\nIn the example below, you can experiment with `model` and `country`. Every time you change one of these, you'll get a new _version_ of `CheeseRecommender`. \n\n```python\nimport weave\nfrom mistralai import Mistral\n\nweave.init(\"mistralai_project\")\n\nclass CheeseRecommender(weave.Model): # Change to `weave.Model`\n    model: str\n    temperature: float\n\n    @weave.op()\n    def predict(self, region:str) -> str: # Change to `predict`\n        \"Recommend the best cheese in a given region\"\n        \n        client = Mistral(api_key=api_key)\n\n        messages = [\n            {\n                \"role\": \"user\",\n                \"content\": f\"What is the best cheese in {region}?\",\n            },\n        ]\n\n        chat_response = client.chat.complete(\n            model=model,\n            messages=messages,\n            temperature=self.temperature\n        )\n        return chat_response.choices[0].message.content\n\ncheese_model = CheeseRecommender(\n    model=\"mistral-medium-latest\",\n    temperature=0.0\n    )\nresult = cheese_model.predict(region=\"France\")\nprint(result)\n```\n\n[](https://wandb.ai/capecape/mistralai_project/weave/models)"
  },
  {
    "title": "Index",
    "url": "https://weave-docs.wandb.ai/guides/integrations/index",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Integrations\n\n:::success[Automatic Tracking]\nIn most cases, all you need to do is call `weave.init()` at the top of your script or program in order for Weave to automatically patch and track any of these libraries!\n:::\n\nWeave provides automatic logging integrations for popular LLM providers and orchestration frameworks. These integrations allow you to seamlessly trace calls made through various libraries, enhancing your ability to monitor and analyze your AI applications.\n\n## LLM Providers\n\nLLM providers are the vendors that offer access to large language models for generating predictions. Weave integrates with these providers to log and trace the interactions with their APIs:\n\n- **[Amazon Bedrock](/guides/integrations/bedrock)**\n- **[Anthropic](/guides/integrations/anthropic)**\n- **[Cerebras](/guides/integrations/cerebras)**\n- **[Cohere](/guides/integrations/cohere)**\n- **[Google](/guides/integrations/google)**\n- **[Groq](/guides/integrations/groq)**\n- **[Hugging Face Hub](/guides/integrations/huggingface)**\n- **[LiteLLM](/guides/integrations/litellm)**\n- **[Microsoft Azure](/guides/integrations/azure)**\n- **[MistralAI](/guides/integrations/mistral)**\n- **[NVIDIA NIM](/guides/integrations/nvidia_nim)**\n- **[OpenAI](/guides/integrations/openai)**\n- **[Open Router](/guides/integrations/openrouter)**\n- **[Together AI](/guides/integrations/together_ai)**\n\n**[Local Models](/guides/integrations/local_models)**: For when you're running models on your own infrastructure.\n\n## Frameworks\n\nFrameworks help orchestrate the actual execution pipelines in AI applications. They provide tools and abstractions for building complex workflows. Weave integrates with these frameworks to trace the entire pipeline:\n\n- **[OpenAI Agents SDK](/guides/integrations/openai_agents)**\n- **[LangChain](/guides/integrations/langchain)**\n- **[LlamaIndex](/guides/integrations/llamaindex)**\n- **[DSPy](/guides/integrations/dspy)**\n- **[Instructor](/guides/integrations/instructor)**\n- **[CrewAI](/guides/integrations/crewai)**\n- **[Smolagents](/guides/integrations/smolagents)**\n- **[PydanticAI](/guides/integrations/pydantic_ai)**\n\n## Protocols\n\nWeave integrates with standardized protocols that enable communication between AI applications and their supporting services:\n\n- **[Model Context Protocol (MCP)](/guides/integrations/mcp)**\n\nChoose an integration from the lists above to learn more about how to use Weave with your preferred LLM provider, framework, or protocol. Whether you're directly accessing LLM APIs, building complex pipelines, or using standardized protocols, Weave provides the tools to trace and analyze your AI applications effectively."
  },
  {
    "title": "Cerebras",
    "url": "https://weave-docs.wandb.ai/guides/integrations/cerebras",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Cerebras\n\nWeave automatically tracks and logs LLM calls made via the [Cerebras Cloud SDK](https://inference-docs.cerebras.ai/introduction).\n\n## Traces\n\nTracking LLM calls is crucial for debugging and performance monitoring. Weave helps you do this by automatically capturing traces for the Cerebras Cloud SDK.\n\nHere's an example of how to use Weave with Cerebras:\n\n```python\nimport os\nimport weave\nfrom cerebras.cloud.sdk import Cerebras\n\n# Initialise the weave project\nweave.init(\"cerebras_speedster\")\n\n# Use the Cerebras SDK as usual\napi_key = os.environ[\"CEREBRAS_API_KEY\"]\nmodel = \"llama3.1-8b\"  # Cerebras model\n\nclient = Cerebras(api_key=api_key)\n\nresponse = client.chat.completions.create(\n    model=model,\n    messages=[{\"role\": \"user\", \"content\": \"What's the fastest land animal?\"}],\n)\n\nprint(response.choices[0].message.content)\n```\n\nWeave will now track and log all LLM calls made through the Cerebras SDK. You can view the traces in the Weave web interface, including details like token usage and response time.\n\n[](https://wandb.ai/capecape/cerebras_speedster/weave/traces)\n\n## Wrapping with your own ops\n\nWeave ops offer a powerful way to enhance reproducibility and traceability in your experiments. By automatically versioning your code and capturing inputs and outputs. Here's an example of how you can leverage Weave ops with the Cerebras SDK:\n\n```python\nimport os\nimport weave\nfrom cerebras.cloud.sdk import Cerebras\n\n# Initialise the weave project\nweave.init(\"cerebras_speedster\")\n\nclient = Cerebras(api_key=os.environ[\"CEREBRAS_API_KEY\"])\n\n# Weave will track the inputs, outputs and code of this function\n@weave.op\ndef animal_speedster(animal: str, model: str) -> str:\n    \"Find out how fast an animal can run\"\n    \n    response = client.chat.completions.create(\n        model=model,\n        messages=[{\"role\": \"user\", \"content\": f\"How fast can a {animal} run?\"}],\n    )\n    return response.choices[0].message.content\n\nanimal_speedster(\"cheetah\", \"llama3.1-8b\")\nanimal_speedster(\"ostrich\", \"llama3.1-8b\")\nanimal_speedster(\"human\", \"llama3.1-8b\")\n```\n\n## Create a `Model` for easier experimentation\n\nThe [Model](/guides/core-types/models) class in Weave helps you organize and compare different iterations of your app. This is particularly useful when experimenting with Cerebras models. Here's an example:\n\n\n```python\nimport os\nimport weave\nfrom cerebras.cloud.sdk import Cerebras\n\n# Initialise the weave project\nweave.init(\"cerebras_speedster\")\n\nclient = Cerebras(api_key=os.environ[\"CEREBRAS_API_KEY\"])\n\nclass AnimalSpeedModel(weave.Model):\n    model: str\n    temperature: float\n\n    @weave.op\n    def predict(self, animal: str) -> str:\n        \"Predict the top speed of an animal\"        \n\n        response = client.chat.completions.create(\n            model=self.model,\n            messages=[{\"role\": \"user\", \"content\": f\"What's the top speed of a {animal}?\"}],\n            temperature=self.temperature\n        )\n        return response.choices[0].message.content\n\nspeed_model = AnimalSpeedModel(\n    model=\"llama3.1-8b\",\n    temperature=0.7\n)\nresult = speed_model.predict(animal=\"cheetah\")\nprint(result)\n```\n\nWith this setup, you can easily experiment with different models and parameters, all while keeping track of your Cerebras-powered inferences!\n\n[](https://wandb.ai/capecape/cerebras_speedster/weave/traces)"
  },
  {
    "title": "Instructor",
    "url": "https://weave-docs.wandb.ai/guides/integrations/instructor",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Instructor\n\n\n  \n\n\n[Instructor](https://python.useinstructor.com/) is a lightweight library that makes it easy to get structured data like JSON from LLMs.\n\n## Tracing\n\nIt\u2019s important to store traces of language model applications in a central location, both during development and in production. These traces can be useful for debugging, and as a dataset that will help you improve your application.\n\nWeave will automatically capture traces for [Instructor](https://python.useinstructor.com/). To start tracking, calling `weave.init(project_name=\"\")` and use the library as normal.\n\n```python\nimport instructor\nimport weave\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n\n\n# Define your desired output structure\nclass UserInfo(BaseModel):\n    user_name: str\n    age: int\n\n# Initialize Weave\nweave.init(project_name=\"instructor-test\")\n\n# Patch the OpenAI client\nclient = instructor.from_openai(OpenAI())\n\n# Extract structured data from natural language\nuser_info = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=UserInfo,\n    messages=[{\"role\": \"user\", \"content\": \"John Doe is 30 years old.\"}],\n)\n```\n\n|                                                                         |\n|-----------------------------------------------------------------------------------------------------------------------|\n| Weave will now track and log all LLM calls made using Instructor. You can view the traces in the Weave web interface. |\n\n## Track your own ops\n\nWrapping a function with `@weave.op` starts capturing inputs, outputs and app logic so you can debug how data flows through your app. You can deeply nest ops and build a tree of functions that you want to track. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git.\n\nSimply create a function decorated with [`@weave.op`](/guides/tracking/ops).\n\nIn the example below, we have the function `extract_person` which is the metric function wrapped with `@weave.op`. This helps us see how intermediate steps, such as OpenAI chat completion call.\n\n```python\nimport instructor\nimport weave\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\n\n# Define your desired output structure\nclass Person(BaseModel):\n    person_name: str\n    age: int\n\n\n# Initialize Weave\nweave.init(project_name=\"instructor-test\")\n\n# Patch the OpenAI client\nlm_client = instructor.from_openai(OpenAI())\n\n\n# Extract structured data from natural language\n@weave.op()\ndef extract_person(text: str) -> Person:\n    return lm_client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\"role\": \"user\", \"content\": text},\n        ],\n        response_model=Person,\n    )\n\n\nperson = extract_person(\"My name is John and I am 20 years old\")\n```\n\n|  |\n|---|\n| Decorating the `extract_person` function with `@weave.op` traces its inputs, outputs, and all internal LM calls made inside the function. Weave also automatically tracks and versions the structured objects generated by Instructor. |\n\n## Create a `Model` for easier experimentation\n\nOrganizing experimentation is difficult when there are many moving pieces. By using the [`Model`](../core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app. \n\nIn addition to versioning code and capturing inputs/outputs, [`Model`](../core-types/models)s capture structured parameters that control your application\u2019s behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve` (see below), and [`Evaluation`](../core-types/evaluations.md)s.\n\nIn the example below, you can experiment with `PersonExtractor`. Every time you change one of these, you'll get a new _version_ of `PersonExtractor`.\n\n```python\nimport asyncio\nfrom typing import List, Iterable\n\nimport instructor\nimport weave\nfrom openai import AsyncOpenAI\nfrom pydantic import BaseModel\n\n\n# Define your desired output structure\nclass Person(BaseModel):\n    person_name: str\n    age: int\n\n\n# Initialize Weave\nweave.init(project_name=\"instructor-test\")\n\n# Patch the OpenAI client\nlm_client = instructor.from_openai(AsyncOpenAI())\n\n\nclass PersonExtractor(weave.Model):\n    openai_model: str\n    max_retries: int\n\n    @weave.op()\n    async def predict(self, text: str) -> List[Person]:\n        model = await lm_client.chat.completions.create(\n            model=self.openai_model,\n            response_model=Iterable[Person],\n            max_retries=self.max_retries,\n            stream=True,\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": \"You are a perfect entity extraction system\",\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Extract `{text}`\",\n                },\n            ],\n        )\n        return [m async for m in model]\n\n\nmodel = PersonExtractor(openai_model=\"gpt-4\", max_retries=2)\nasyncio.run(model.predict(\"John is 30 years old\"))\n```\n\n|  |\n|---------------------------------------------------------------------------|\n| Tracing and versioning your calls using a [`Model`](../core-types/models) |\n\n## Serving a Weave Model\n\nGiven a weave reference a `weave.Model` object, you can spin up a fastapi server and [`serve`](https://wandb.github.io/weave/guides/tools/serve) it.\n\n| [](https://wandb.ai/geekyrakshit/instructor-test/weave/objects/PersonExtractor/versions/xXpMsJvaiTOjKafz1TnHC8wMgH5ZAAwYOaBMvHuLArI) |\n|----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| You can find the weave reference of any `weave.Model` by navigating to the model and copying it from the UI.                                                      |\n\nYou can serve your model by using the following command in the terminal:\n\n```shell\nweave serve weave:///your_entity/project-name/YourModel:\n```"
  },
  {
    "title": "Google",
    "url": "https://weave-docs.wandb.ai/guides/integrations/google",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Google\n\n\n  \n\n\n> \ud83c\udf1f **Tip**: For the latest tutorials, visit [Weights & Biases on Google Cloud](https://wandb.ai/site/partners/googlecloud/).\n\n> \ud83d\udca1 **Note**: Do you want to experiment with Google AI models on Weave without any set up? Try the [LLM Playground](../tools/playground.md).\n\nThis page describes how to use W&B Weave with the Google Vertex AI API and the Google Gemini API.\n\nYou can use Weave to evaluate, monitor, and iterate on your Google GenAI applications. Weave automatically captures traces for the:\n\n1. [Google GenAI SDK](https://github.com/googleapis/python-genai), which is accessible via Python SDK, Node.js SDK, Go SDK, and REST.\n2. [Google Vertex AI API](https://cloud.google.com/vertex-ai/docs), which provides access to Google\u2019s Gemini models and [various partner models](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/use-partner-models).\n\n> \ud83d\udca1 **Note**: We also have support for the deprecated [Google AI Python SDK for the Gemini API](https://github.com/google-gemini/deprecated-generative-ai-python). Note that this support is deprecated as well and will be removed in a future version.\n\n## Get started\n\nWeave will automatically capture traces for [Google GenAI SDK](https://github.com/googleapis/python-genai). To start tracking, calling `weave.init(project_name=\"\")` and use the library as normal.\n\n```python\nimport os\nfrom google import genai\nimport weave\n\nweave.init(project_name=\"google-genai\")\n\ngoogle_client = genai.Client(api_key=os.getenv(\"GOOGLE_GENAI_KEY\"))\nresponse = google_client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=\"What's the capital of France?\",\n)\n```\n\n[](https://wandb.ai/geekyrakshit/google-genai/weave/traces)\n\nWeave will also automatically capture traces for [Vertex APIs](https://github.com/googleapis/python-aiplatform/tree/main/vertexai/generative_models). To start tracking, calling `weave.init(project_name=\"\")` and use the library as normal.\n\n```python\nimport vertexai\nimport weave\nfrom vertexai.generative_models import GenerativeModel\n\nweave.init(project_name=\"vertex-ai-test\")\nvertexai.init(project=\"\", location=\"\")\nmodel = GenerativeModel(\"gemini-1.5-flash-002\")\nresponse = model.generate_content(\n    \"What's a good name for a flower shop specialising in selling dried flower bouquets?\"\n)\n```\n\n## Track your own ops\n\nWrapping a function with `@weave.op` starts capturing inputs, outputs and app logic so you can debug how data flows through your app. You can deeply nest ops and build a tree of functions that you want to track. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git.\n\nSimply create a function decorated with [`@weave.op`](/guides/tracking/ops).\n\nIn the example below, we have the function `recommend_places_to_visit` which is a function wrapped with `@weave.op` that recommends places to visit in a city.\n\n```python\nimport os\nfrom google import genai\nimport weave\n\nweave.init(project_name=\"google-genai\")\ngoogle_client = genai.Client(api_key=os.getenv(\"GOOGLE_GENAI_KEY\"))\n\n\n@weave.op()\ndef recommend_places_to_visit(city: str, model: str = \"gemini-1.5-flash\"):\n    response = google_client.models.generate_content(\n        model=model,\n        contents=\"You are a helpful assistant meant to suggest all budget-friendly places to visit in a city\",\n    )\n    return response.text\n\n\nrecommend_places_to_visit(\"New York\")\nrecommend_places_to_visit(\"Paris\")\nrecommend_places_to_visit(\"Kolkata\")\n```\n\n[](https://wandb.ai/geekyrakshit/google-genai/weave/traces)\n\n## Create a `Model` for easier experimentation\n\nOrganizing experimentation is difficult when there are many moving pieces. By using the [`Model`](../core-types/models) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app. \n\nIn addition to versioning code and capturing inputs/outputs, [`Model`](../core-types/models)s capture structured parameters that control your application\u2019s behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and [`Evaluation`](../core-types/evaluations.md)s.\n\nIn the example below, you can experiment with `CityVisitRecommender`. Every time you change one of these, you'll get a new _version_ of `CityVisitRecommender`.\n\n```python\nimport os\nfrom google import genai\nimport weave\n\nweave.init(project_name=\"google-genai\")\ngoogle_client = genai.Client(api_key=os.getenv(\"GOOGLE_GENAI_KEY\"))\n\n\nclass CityVisitRecommender(weave.Model):\n    model: str\n\n    @weave.op()\n    def predict(self, city: str) -> str:\n        response = google_client.models.generate_content(\n            model=self.model,\n            contents=\"You are a helpful assistant meant to suggest all budget-friendly places to visit in a city\",\n        )\n        return response.text\n\n\ncity_recommender = CityVisitRecommender(model=\"gemini-1.5-flash\")\nprint(city_recommender.predict(\"New York\"))\nprint(city_recommender.predict(\"San Francisco\"))\nprint(city_recommender.predict(\"Los Angeles\"))\n```"
  },
  {
    "title": "Together Ai",
    "url": "https://weave-docs.wandb.ai/guides/integrations/together_ai",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Together AI\n\nTogether AI is a platform for building and finetuning generative AI models, focusing on Open Source LLMs, and allowing customers to fine-tune and host their own models.\n\n:::info\n\nFull Weave `together` python package support is currently in development\n\n:::\n\nWhile full Weave support for the `together` python package is currently in development, Together supports the OpenAI SDK compatibility ([docs](https://docs.together.ai/docs/openai-api-compatibility)) which Weave automatically detects and integrates with.\n\nTo switch to using the Together API, simply switch out the API key to your [Together API](https://docs.together.ai/docs/get-started#access-your-api-key) key, `base_url` to `https://api.together.xyz/v1`, and model to one of their [chat models](https://docs.together.ai/docs/inference-models#chat-models).\n\n```python\nimport os\nimport openai\nimport weave\nweave.init('together-weave')\n\nsystem_content = \"You are a travel agent. Be descriptive and helpful.\"\nuser_content = \"Tell me about San Francisco\"\nclient = openai.OpenAI(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n    base_url=\"https://api.together.xyz/v1\",\n)\nchat_completion = client.chat.completions.create(\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n    messages=[\n        {\"role\": \"system\", \"content\": system_content},\n        {\"role\": \"user\", \"content\": user_content},\n    ],\n    temperature=0.7,\n    max_tokens=1024,\n)\nresponse = chat_completion.choices[0].message.content\nprint(\"Together response:\\n\", response)\n```\n\nWhile this is a simple example to get started, see our [OpenAI](/guides/integrations/openai#track-your-own-ops) guide for more details on how to integrate Weave with your own functions for more complex use cases."
  },
  {
    "title": "Llamaindex",
    "url": "https://weave-docs.wandb.ai/guides/integrations/llamaindex",
    "section": "Docs",
    "category": "Integrations",
    "content": "# LlamaIndex\n\nWeave is designed to simplify the tracking and logging of all calls made through the [LlamaIndex Python library](https://github.com/run-llama/llama_index).\n\nWhen working with LLMs, debugging is inevitable. Whether a model call fails, an output is misformatted, or nested model calls create confusion, pinpointing issues can be challenging. [LlamaIndex](https://docs.llamaindex.ai/en/stable/) applications often consist of multiple steps and LLM call invocations, making it crucial to understand the inner workings of your chains and agents.\n\nWeave simplifies this process by automatically capturing traces for your LlamaIndex applications. This enables you to monitor and analyze your application's performance, making it easier to debug and optimize your LLM workflows. Weave also helps with your evaluation workflows.\n\n## Getting Started\n\nTo get started, simply call `weave.init()` at the beginning of your script. The argument in `weave.init()` is a project name that will help you organize your traces.\n\n```python\nimport weave\nfrom llama_index.core.chat_engine import SimpleChatEngine\n\n# Initialize Weave with your project name\nweave.init(\"llamaindex_demo\")\n\nchat_engine = SimpleChatEngine.from_defaults()\nresponse = chat_engine.chat(\n    \"Say something profound and romantic about fourth of July\"\n)\nprint(response)\n```\n\nIn the example above, we are creating a simple LlamaIndex chat engine which under the hood is making an OpenAI call. Check out the trace below:\n\n[](https://wandb.ai/wandbot/test-llamaindex-weave/weave/calls/b6b5d898-2df8-4e14-b553-66ce84661e74)\n\n## Tracing\n\nLlamaIndex is known for its ease of connecting data with LLM. A simple RAG application requires an embedding step, retrieval step and a response synthesis step. With the increasing complexity, it becomes important to store traces of individual steps in a central database during both development and production.\n\nThese traces are essential for debugging and improving your application. Weave automatically tracks all calls made through the LlamaIndex library, including prompt templates, LLM calls, tools, and agent steps. You can view the traces in the Weave web interface.\n\nBelow is an example of a simple RAG pipeline from LlamaIndex's [Starter Tutorial (OpenAI)](https://docs.llamaindex.ai/en/stable/getting_started/starter_example/):\n\n```python\nimport weave\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n\n# Initialize Weave with your project name\nweave.init(\"llamaindex_demo\")\n\n# Assuming you have a `.txt` file in the `data` directory\ndocuments = SimpleDirectoryReader(\"data\").load_data()\nindex = VectorStoreIndex.from_documents(documents)\n\nquery_engine = index.as_query_engine()\nresponse = query_engine.query(\"What did the author do growing up?\")\nprint(response)\n```\n\nThe trace timeline not only captures the \"events\" but it also capture the execution time, cost and token counts where applicable. Drill down the trace to see the inputs and outputs of each step.\n\n[](https://wandb.ai/wandbot/test-llamaindex-weave/weave/calls?filter=%7B%22traceRootsOnly%22%3Atrue%7D&peekPath=%2Fwandbot%2Ftest-llamaindex-weave%2Fcalls%2F6ac53407-1bb7-4c38-b5a3-c302bd877a11%3Ftracetree%3D1)\n\n## One-click observability \ud83d\udd2d\n\nLlamaIndex provides [one-click observability \ud83d\udd2d](https://docs.llamaindex.ai/en/stable/module_guides/observability/) to allow you to build principled LLM applications in a production setting.\n\nOur integration leverages this capability of LlamaIndex and automatically sets [`WeaveCallbackHandler()`](https://github.com/wandb/weave/blob/master/weave/integrations/llamaindex/llamaindex.py) to `llama_index.core.global_handler`. Thus as a user of LlamaIndex and Weave all you need to do is initialize a Weave run - `weave.init()`\n\n## Create a `Model` for easier experimentation\n\nOrganizing and evaluating LLMs in applications for various use cases is challenging with multiple components, such as prompts, model configurations, and inference parameters. Using the [`weave.Model`](/guides/core-types/models), you can capture and organize experimental details like system prompts or the models you use, making it easier to compare different iterations.\n\nThe following example demonstrates building a LlamaIndex query engine in a `WeaveModel`, using data that can be found in the [weave/data](https://github.com/wandb/weave/tree/master/data) folder:\n\n```python\nimport weave\n\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader\nfrom llama_index.core.node_parser import SentenceSplitter\nfrom llama_index.llms.openai import OpenAI\nfrom llama_index.core import PromptTemplate\n\n\nPROMPT_TEMPLATE = \"\"\"\nYou are given with relevant information about Paul Graham. Answer the user query only based on the information provided. Don't make up stuff.\n\nUser Query: {query_str}\nContext: {context_str}\nAnswer:\n\"\"\"\nclass SimpleRAGPipeline(weave.Model):\n    chat_llm: str = \"gpt-4\"\n    temperature: float = 0.1\n    similarity_top_k: int = 2\n    chunk_size: int = 256\n    chunk_overlap: int = 20\n    prompt_template: str = PROMPT_TEMPLATE\n\n    def get_llm(self):\n        return OpenAI(temperature=self.temperature, model=self.chat_llm)\n\n    def get_template(self):\n        return PromptTemplate(self.prompt_template)\n\n    def load_documents_and_chunk(self, data):\n        documents = SimpleDirectoryReader(data).load_data()\n        splitter = SentenceSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n        )\n        nodes = splitter.get_nodes_from_documents(documents)\n        return nodes\n\n    def get_query_engine(self, data):\n        nodes = self.load_documents_and_chunk(data)\n        index = VectorStoreIndex(nodes)\n\n        llm = self.get_llm()\n        prompt_template = self.get_template()\n\n        return index.as_query_engine(\n            similarity_top_k=self.similarity_top_k,\n            llm=llm,\n            text_qa_template=prompt_template,\n        )\n    @weave.op()\n    def predict(self, query: str):\n        query_engine = self.get_query_engine(\n            # This data can be found in the weave repo under data/paul_graham\n            \"data/paul_graham\",\n        )\n        response = query_engine.query(query)\n        return {\"response\": response.response}\nweave.init(\"test-llamaindex-weave\")\n\nrag_pipeline = SimpleRAGPipeline()\nresponse = rag_pipeline.predict(\"What did the author do growing up?\")\nprint(response)\n```\n\nThis `SimpleRAGPipeline` class subclassed from `weave.Model` organizes the important parameters for this RAG pipeline. Decorating the `query` method with `weave.op()` allows for tracing.\n\n[](https://wandb.ai/wandbot/test-llamaindex-weave/weave/calls?filter=%7B%22traceRootsOnly%22%3Atrue%7D&peekPath=%2Fwandbot%2Ftest-llamaindex-weave%2Fcalls%2Fa82afbf4-29a5-43cd-8c51-603350abeafd%3Ftracetree%3D1)\n\n## Doing Evaluation with `weave.Evaluation`\n\nEvaluations help you measure the performance of your applications. By using the [`weave.Evaluation`](/guides/core-types/evaluations) class, you can capture how well your model performs on specific tasks or datasets, making it easier to compare different models and iterations of your application. The following example demonstrates how to evaluate the model we created:\n\n```python\nimport asyncio\nfrom llama_index.core.evaluation import CorrectnessEvaluator\n\neval_examples = [\n    {\n        \"id\": \"0\",\n        \"query\": \"What programming language did Paul Graham learn to teach himself AI when he was in college?\",\n        \"ground_truth\": \"Paul Graham learned Lisp to teach himself AI when he was in college.\",\n    },\n    {\n        \"id\": \"1\",\n        \"query\": \"What was the name of the startup Paul Graham co-founded that was eventually acquired by Yahoo?\",\n        \"ground_truth\": \"The startup Paul Graham co-founded that was eventually acquired by Yahoo was called Viaweb.\",\n    },\n    {\n        \"id\": \"2\",\n        \"query\": \"What is the capital city of France?\",\n        \"ground_truth\": \"I cannot answer this question because no information was provided in the text.\",\n    },\n]\n\nllm_judge = OpenAI(model=\"gpt-4\", temperature=0.0)\nevaluator = CorrectnessEvaluator(llm=llm_judge)\n@weave.op()\ndef correctness_evaluator(query: str, ground_truth: str, output: dict):\n    result = evaluator.evaluate(\n        query=query, reference=ground_truth, response=output[\"response\"]\n    )\n    return {\"correctness\": float(result.score)}\nevaluation = weave.Evaluation(dataset=eval_examples, scorers=[correctness_evaluator])\n\nrag_pipeline = SimpleRAGPipeline()\nasyncio.run(evaluation.evaluate(rag_pipeline))\n```\n\nThis evaluation builds on the example in the earlier section. Evaluating using `weave.Evaluation` requires an evaluation dataset, a scorer function and a `weave.Model`. Here are a few nuances about the three key components:\n\n- Make sure that the keys of the evaluation sample dicts matches the arguments of the scorer function and of the `weave.Model`'s `predict` method.\n- The `weave.Model` should have a method with the name `predict` or `infer` or `forward`. Decorate this method with `weave.op()` for tracing.\n- The scorer function should be decorated with `weave.op()` and should have `output` as named argument.\n\n[](https://wandb.ai/wandbot/llamaindex-weave/weave/calls?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fwandbot%2Fllamaindex-weave%2Fop%2FEvaluation.predict_and_score%3ANmwfShfFmgAhDGLXrF6Xn02T9MIAsCXBUcifCjyKpOM%22%5D%2C%22parentId%22%3A%2233491e66-b580-47fa-9d43-0cd6f1dc572a%22%7D&peekPath=%2Fwandbot%2Fllamaindex-weave%2Fcalls%2F33491e66-b580-47fa-9d43-0cd6f1dc572a%3Ftracetree%3D1)\n\nBy integrating Weave with LlamaIndex, you can ensure comprehensive logging and monitoring of your LLM applications, facilitating easier debugging and performance optimization using evaluation."
  },
  {
    "title": "Notdiamond",
    "url": "https://weave-docs.wandb.ai/guides/integrations/notdiamond",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Not Diamond \u00ac\u25c7\n\nWhen building complex LLM workflows users may need to prompt different models according to accuracy,\ncost, or call latency. Users can use [Not Diamond][nd] to route prompts in these workflows to the\nright model for their needs, helping maximize accuracy while saving on model costs.\n\n## Getting started\n\nMake sure you have [created an account][account] and [generated an API key][keys], then add your API\nkey to your env as `NOTDIAMOND_API_KEY`.\n\n]\n\nFrom here, you can\n\n- try the [quickstart guide],\n- [build a custom router][custom router] with W&B Weave and Not Diamond, or\n- [chat with Not Diamond][chat] to see routing in action\n\n## Tracing\n\nWeave integrates with [Not Diamond's Python library][python] to [automatically log API calls][ops].\nYou only need to run `weave.init()` at the start of your workflow, then continue using the routed\nprovider as usual:\n\n```python\nfrom notdiamond import NotDiamond\n\nimport weave\nweave.init('notdiamond-quickstart')\n\nclient = NotDiamond()\nsession_id, provider = client.chat.completions.model_select(\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Concisely explain merge sort.\"}\n    ],\n    model=['openai/gpt-4o', 'anthropic/claude-3-5-sonnet-20240620']\n)\n\nprint(\"LLM called: \", provider.provider)  # openai, anthropic, etc\nprint(\"Provider model: \", provider.model) # gpt-4o, claude-3-5-sonnet-20240620, etc\n```\n\n## Custom routing\n\nYou can also train your own [custom router] on [Evaluations][evals], allowing Not Diamond to route prompts\naccording to eval performance for specialized use cases.\n\nStart by training a custom router:\n\n```python\nfrom weave.flow.eval import EvaluationResults\nfrom weave.integrations.notdiamond.custom_router import train_router\n\n# Build an Evaluation on gpt-4o and Claude 3.5 Sonnet\nevaluation = weave.Evaluation(...)\ngpt_4o = weave.Model(...)\nsonnet = weave.Model(...)\n\nmodel_evals = {\n    'openai/gpt-4o': evaluation.get_eval_results(gpt_4o),\n    'anthropic/claude-3-5-sonnet-20240620': evaluation.get_eval_results(sonnet),\n}\npreference_id = train_router(\n    model_evals=model_evals,\n    prompt_column=\"prompt\",\n    response_column=\"actual\",\n    language=\"en\",\n    maximize=True,\n)\n```\n\nBy reusing this preference ID in any `model_select` request, you can route your prompts\nto maximize performance and minimize cost on your evaluation data:\n\n```python\nfrom notdiamond import NotDiamond\nclient = NotDiamond()\n\nimport weave\nweave.init('notdiamond-quickstart')\n\nsession_id, provider = client.chat.completions.model_select(\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Concisely explain merge sort.\"}\n    ],\n    model=['openai/gpt-4o', 'anthropic/claude-3-5-sonnet-20240620'],\n\n    # passing this preference ID reuses your custom router\n    preference_id=preference_id\n)\n\nprint(\"LLM called: \", provider.provider)  # openai, anthropic, etc\nprint(\"Provider model: \", provider.model) # gpt-4o, claude-3-5-sonnet-20240620, etc\n```\n\n## Additional support\n\nVisit the [docs] or [send us a message][support] for further support.\n\n[account]: https://app.notdiamond.ai\n[chat]: https://chat.notdiamond.ai\n[custom router]: https://docs.notdiamond.ai/docs/router-training-quickstart\n[docs]: https://docs.notdiamond.ai\n[evals]: ../../guides/core-types/evaluations.md\n[keys]: https://app.notdiamond.ai/keys\n[nd]: https://www.notdiamond.ai/\n[ops]: ../../guides/tracking/ops.md\n[python]: https://github.com/Not-Diamond/notdiamond-python\n[quickstart guide]: https://docs.notdiamond.ai/docs/quickstart\n[support]: mailto:support@notdiamond.ai"
  },
  {
    "title": "Openrouter",
    "url": "https://weave-docs.wandb.ai/guides/integrations/openrouter",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Open Router\n\nOpenrouter.ai is a unified interface for many LLMs, supporting both foundational models like OpenAI GPT-4, Anthropic Claude, Google Gemini but also open source models like LLama-3, Mixtral and [many more](https://openrouter.ai/models), some models are even offered for free. \n\nOpen Router offers a Rest API and an OpenAI SDK compatibility ([docs](https://docs.together.ai/docs/openai-api-compatibility)) which Weave automatically detects and integrates with (see Open Router [quick start](https://openrouter.ai/docs/quick-start) for more details).\n\nTo get switch your OpenAI SDK code to Open Router, simply switch out the API key to your [Open Router API](https://openrouter.ai/docs/api-keys) key, `base_url` to `https://openrouter.ai/api/v1`, and model to one of their many [chat models](https://openrouter.ai/docs/models).\n\n```python\nimport os\nimport openai\nimport weave\nweave.init('together-weave')\n\nsystem_content = \"You are a travel agent. Be descriptive and helpful.\"\nuser_content = \"Tell me about San Francisco\"\nclient = openai.OpenAI(\n    api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n    base_url=\"https://openrouter.ai/api/v1\",\n)\nchat_completion = client.chat.completions.create(\n    extra_headers={\n    \"HTTP-Referer\": $YOUR_SITE_URL, # Optional, for including your app on openrouter.ai rankings.\n    \"X-Title\": $YOUR_APP_NAME, # Optional. Shows in rankings on openrouter.ai.\n    },\n    model=\"meta-llama/llama-3.1-8b-instruct:free\",\n    messages=[\n        {\"role\": \"system\", \"content\": system_content},\n        {\"role\": \"user\", \"content\": user_content},\n    ],\n    temperature=0.7,\n    max_tokens=1024,\n)\nresponse = chat_completion.choices[0].message.content\nprint(\"Model response:\\n\", response)\n```\n\nWhile this is a simple example to get started, see our [OpenAI](/guides/integrations/openai#track-your-own-ops) guide for more details on how to integrate Weave with your own functions for more complex use cases."
  },
  {
    "title": "Crewai",
    "url": "https://weave-docs.wandb.ai/guides/integrations/crewai",
    "section": "Docs",
    "category": "Integrations",
    "content": "# CrewAI\n\n\n  \n\n\nCrewAI is a lean, lightning-fast Python framework built entirely from scratch\u2014completely independent of LangChain or other agent frameworks. CrewAI empowers developers with both high-level simplicity ([Crews](https://docs.crewai.com/guides/crews/first-crew)) and precise low-level control ([Flows](https://docs.crewai.com/guides/flows/first-flow)), ideal for creating autonomous AI agents tailored to any scenario. Learn more about [CrewAI here](https://docs.crewai.com/introduction).\n\n\nWhen working with AI agents, debugging and monitoring their interactions is crucial. CrewAI applications often consist of multiple agents working together, making it essential to understand how they collaborate and communicate. Weave simplifies this process by automatically capturing traces for your CrewAI applications, enabling you to monitor and analyze your agents' performance and interactions.\n\nThe integration supports both Crews and Flows.\n\n## Getting Started with Crew\n\nYou need to install CrewAI ([more details](https://docs.crewai.com/installation)) and weave to run this example:\n\n```\npip install crewai weave\n```\n\nNow we will create a CrewAI Crew and trace the execution using Weave. To get started, simply call `weave.init()` at the beginning of your script. The argument in weave.init() is a project name where the traces will be logged.\n\n```python\nimport weave\nfrom crewai import Agent, Task, Crew, LLM, Process\n\n# Initialize Weave with your project name\nweave.init(project_name=\"crewai_demo\")\n\n# Create an LLM with a temperature of 0 to ensure deterministic outputs\nllm = LLM(model=\"gpt-4o-mini\", temperature=0)\n\n# Create agents\nresearcher = Agent(\n    role='Research Analyst',\n    goal='Find and analyze the best investment opportunities',\n    backstory='Expert in financial analysis and market research',\n    llm=llm,\n    verbose=True,\n    allow_delegation=False,\n)\n\nwriter = Agent(\n    role='Report Writer',\n    goal='Write clear and concise investment reports',\n    backstory='Experienced in creating detailed financial reports',\n    llm=llm,\n    verbose=True,\n    allow_delegation=False,\n)\n\n# Create tasks\nresearch_task = Task(\n    description='Deep research on the {topic}',\n    expected_output='Comprehensive market data including key players, market size, and growth trends.',\n    agent=researcher\n)\n\nwriting_task = Task(\n    description='Write a detailed report based on the research',\n    expected_output='The report should be easy to read and understand. Use bullet points where applicable.',\n    agent=writer\n)\n\n# Create a crew\ncrew = Crew(\n    agents=[researcher, writer],\n    tasks=[research_task, writing_task],\n    verbose=True,\n    process=Process.sequential,\n)\n\n# Run the crew\nresult = crew.kickoff(inputs={\"topic\": \"AI in material science\"})\nprint(result)\n```\n\nWeave will track and log all calls made through the CrewAI library, including agent interactions, task executions, and LLM calls. You can view the traces in the Weave web interface.\n\n[](https://wandb.ai/ayut/crewai_demo/weave/traces?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fayut%2Fcrewai_demo%2Fop%2Fcrewai.Crew.kickoff%3A*%22%5D%7D&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c7ac-bd52-7390-95a7-309370e9e058%3FhideTraceTree%3D0&cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D)\n\n> \ud83d\udca1 **Note**: CrewAI provides several methods for better control over the kickoff process: `kickoff()`, `kickoff_for_each()`, `kickoff_async()`, and `kickoff_for_each_async()`. The integration supports logging traces from all these methods.\n\n## Track Tools\n\nCrewAI tools empower agents with capabilities ranging from web searching and data analysis to collaboration and delegating tasks among coworkers. The integration can trace them as well. \n\nWe will improve the quality of the generated report in the above example by giving it access to a tool that can search the internet and return the most relevant results.\n\nLet us first install the extra dependency.\n\n```\npip install 'crewai[tools]'\n```\n\nIn this example, we are using the `SerperDevTool` to enable our 'Research Analyst' agent to search relevant information on the internet. Learn more about this tool and API requirements [here](https://docs.crewai.com/tools/serperdevtool).\n\n```python\n# .... existing imports ....\nfrom crewai_tools import SerperDevTool\n\n# We provide the agent with the tool.\nresearcher = Agent(\n    role='Research Analyst',\n    goal='Find and analyze the best investment opportunities',\n    backstory='Expert in financial analysis and market research',\n    llm=llm,\n    verbose=True,\n    allow_delegation=False,\n    tools=[SerperDevTool()],\n)\n\n# .... existing code ....\n```\n\nRunning this Crew with an agent with access to internet produces better and more relevant result. We automatically trace the tool usage as shown in the image below.\n\n[](https://wandb.ai/ayut/crewai_demo/weave/traces?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fayut%2Fcrewai_demo%2Fop%2Fcrewai.Crew.kickoff%3A*%22%5D%7D&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c7c7-0213-7f42-b130-caa93a79316c%3FdescendentCallId%3D0195c7c7-0a16-7f11-8cfd-9dedf1d03b3b&cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D)\n\n> \ud83d\udca1 **Note**: The integration automatically patches all the tools available in the [`crewAI-tools`](https://github.com/crewAIInc/crewAI-tools) repository. \n\n## Getting Started with Flow\n\n```python\nimport weave\n# Initialize Weave with your project name\nweave.init(\"crewai_demo\")\n\nfrom crewai.flow.flow import Flow, listen, router, start\nfrom litellm import completion\n\n\nclass CustomerFeedbackFlow(Flow):\n    model = \"gpt-4o-mini\"\n\n    @start()\n    def fetch_feedback(self):\n        print(\"Fetching customer feedback\")\n        # In a real-world scenario, this could be replaced by an API call.\n        # For this example, we simulate customer feedback.\n        feedback = (\n            \"I had a terrible experience with the product. \"\n            \"It broke after one use and customer service was unhelpful.\"\n        )\n        self.state[\"feedback\"] = feedback\n        return feedback\n\n    @router(fetch_feedback)\n    def analyze_feedback(self, feedback):\n        # Use the language model to analyze sentiment\n        prompt = (\n            f\"Analyze the sentiment of this customer feedback and \"\n            \"return only 'positive' or 'negative':\\n\\n\"\n            f\"Feedback: {feedback}\"\n        )\n        response = completion(\n            model=self.model,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n        )\n        sentiment = response[\"choices\"][0][\"message\"][\"content\"].strip().lower()\n        # If the response is ambiguous, default to negative\n        if sentiment not in [\"positive\", \"negative\"]:\n            sentiment = \"negative\"\n        return sentiment\n\n    @listen(\"positive\")\n    def handle_positive_feedback(self):\n        # Generate a thank you message for positive feedback\n        prompt = \"Generate a thank you message for a customer who provided positive feedback.\"\n        response = completion(\n            model=self.model,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n        )\n        thank_you_message = response[\"choices\"][0][\"message\"][\"content\"].strip()\n        self.state[\"response\"] = thank_you_message\n        return thank_you_message\n\n    @listen(\"negative\")\n    def handle_negative_feedback(self):\n        # Generate an apology message with a promise to improve service for negative feedback\n        prompt = (\n            \"Generate an apology message to a customer who provided negative feedback and offer assistance or a solution.\"\n        )\n        response = completion(\n            model=self.model,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n        )\n        apology_message = response[\"choices\"][0][\"message\"][\"content\"].strip()\n        self.state[\"response\"] = apology_message\n        return apology_message\n\n# Instantiate and kickoff the flow\nflow = CustomerFeedbackFlow()\nresult = flow.kickoff()\nprint(result)\n```\n\n[](https://wandb.ai/ayut/crewai_demo/weave/traces?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fayut%2Fcrewai_demo%2Fop%2Fcrewai.Flow.kickoff%3A*%22%5D%7D&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c7e3-7a63-7283-bef4-9e0eb2f0eab1&cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D)\n\n> \ud83d\udca1 **Note**: The integration automatically patches the `Flow.kickoff` entry point and all the available decorators -- `@start`, `@listen`, `@router`, `@or_` and `@and_`.\n\n\n## Crew Guardrail - Track your own ops\n\nTask guardrails provide a way to validate and transform task outputs before they are passed to the next task. We can use a simple python function to validate the agent's execution on-the-fly.\n\nWrapping this function with `@weave.op` starts capturing inputs, outputs and app logic so you can debug how data is validated through your agents. This also starts automatically versioning code as you experiment to capture ad-hoc details that haven't been committed to git.\n\nLet's take the example of research analyst and writer. We add a guardrail to validate the length of the generated report.\n\n```python\n# .... existing imports and weave initialization ....\n\n# Decorate your guardrail function with `@weave.op()`\n@weave.op(name=\"guardrail-validate_blog_content\")\ndef validate_blog_content(result: TaskOutput) -> Tuple[bool, Any]:\n    # Get raw string result\n    result = result.raw\n\n    \"\"\"Validate blog content meets requirements.\"\"\"\n    try:\n        # Check word count\n        word_count = len(result.split())\n\n        if word_count > 200:\n            return (False, {\n                \"error\": \"Blog content exceeds 200 words\",\n                \"code\": \"WORD_COUNT_ERROR\",\n                \"context\": {\"word_count\": word_count}\n            })\n\n        # Additional validation logic here\n        return (True, result.strip())\n    except Exception as e:\n        return (False, {\n            \"error\": \"Unexpected error during validation\",\n            \"code\": \"SYSTEM_ERROR\"\n        })\n\n\n# .... existing agents and research analyst task ....\n\nwriting_task = Task(\n    description='Write a detailed report based on the research under 200 words',\n    expected_output='The report should be easy to read and understand. Use bullet points where applicable.',\n    agent=writer,\n    guardrail=validate_blog_content,\n)\n\n# .... existing code to run crew ....\n```\n\nBy simply decorating the guardrail function with `@weave.op` we are able to keep track of the input and output to this function along with execution time, token information if an LLM is used under the hood, code version and more.\n\n[](https://wandb.ai/ayut/crewai_demo/weave/traces?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fayut%2Fcrewai_demo%2Fop%2Fcrewai.Crew.kickoff%3A*%22%5D%7D&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c838-38cb-71a2-8a15-651ecddf9d89%3FdescendentCallId%3D0195c838-8632-7173-846d-f230e7272c20&cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D)\n\n## Conclusion\n\nDo let us know what we should improve about this integration. Please open an issue if you encounter one [here](https://github.com/wandb/weave/issues/new/choose).\n\nLearn more about how to build powerful multiagent systems using CrewAI through their [many examples](https://github.com/crewAIInc/crewAI-examples) and [documentation](https://docs.crewai.com/introduction)."
  },
  {
    "title": "Azure",
    "url": "https://weave-docs.wandb.ai/guides/integrations/azure",
    "section": "Docs",
    "category": "Integrations",
    "content": "# Microsoft Azure\n\nWeights & Biases (W&B) Weave integrates with Microsoft Azure OpenAI services, helping teams to optimize their Azure AI applications. Using W&B, you can \n\n> \ud83c\udf1f **Tip**: For the latest tutorials, visit [Weights & Biases on Microsoft Azure](https://wandb.ai/site/partners/azure).\n\n## Getting started\n\nTo get started using Azure with Weave, simply decorate the function(s) you want to track with `weave.op`.\n\n```python\n@weave.op()\ndef call_azure_chat(model_id: str, messages: list, max_tokens: int = 1000, temperature: float = 0.5):\n    response = client.chat.completions.create(\n        model=model_id,\n        messages=messages,\n        max_tokens=max_tokens,\n        temperature=temperature\n    )\n    return {\"status\": \"success\", \"response\": response.choices[0].message.content}\n\n```\n\n## Learn more\n\nLearn more about advanced Azure with Weave topics using the resources below.\n\n### Use the Azure AI Model Inference API with Weave\n\nLearn how to use the [Azure AI Model Inference API] with Weave to gain insights into Azure models in [this guide](https://wandb.ai/byyoung3/ML-NEWS2/reports/A-guide-to-using-the-Azure-AI-model-inference-API--Vmlldzo4OTY1MjEy#tutorial:-implementing-azure-ai-model-inference-api-with-w&b-weave-).\n\n### Trace Azure OpenAI models with Weave\n\nLearn how to trace Azure OpenAI models using Weave in [this guide](https://wandb.ai/a-sh0ts/azure-weave-cookbook/reports/How-to-use-Azure-OpenAI-and-Azure-AI-Studio-with-W-B-Weave--Vmlldzo4MTI0NDgy)."
  },
  {
    "title": "Builtin Scorers",
    "url": "https://weave-docs.wandb.ai/guides/evaluation/builtin_scorers",
    "section": "Docs",
    "category": "Evaluation",
    "content": "# Builtin Scorers\n\n\n  \n    **Installation**\n\n    To use Weave's predefined scorers you need to install some additional dependencies:\n\n    ```bash\n    pip install weave[scorers]\n    ```\n\n    **LLM-evaluators**\n    Update Feb 2025: The pre-defined scorers that leverage LLMs now automatically integrate with litellm.\n    You no longer need to pass an LLM client; just set the `model_id`. \n    See the supported models [here](https://docs.litellm.ai/docs/providers).\n\n    ## `HallucinationFreeScorer`\n\n    This scorer checks if your AI system's output includes any hallucinations based on the input data.\n\n    ```python\n    from weave.scorers import HallucinationFreeScorer\n\n    scorer = HallucinationFreeScorer()\n    ```\n\n    **Customization:**\n\n    - Customize the `system_prompt` and `user_prompt` fields of the scorer to define what \"hallucination\" means for you.\n\n    **Notes:**\n\n    - The `score` method expects an input column named `context`. If your dataset uses a different name, use the `column_map` attribute to map `context` to the dataset column.\n\n    Here you have an example in the context of an evaluation:\n\n    ```python\n    import asyncio\n    import weave\n    from weave.scorers import HallucinationFreeScorer\n\n    # Initialize scorer with a column mapping if needed.\n    hallucination_scorer = HallucinationFreeScorer(\n        model_id=\"openai/gpt-4o\", # or any other model supported by litellm\n        column_map={\"context\": \"input\", \"output\": \"other_col\"}\n    )\n\n    # Create dataset\n    dataset = [\n        {\"input\": \"John likes various types of cheese.\"},\n        {\"input\": \"Pepe likes various types of cheese.\"},\n    ]\n\n    @weave.op\n    def model(input: str) -> str:\n        return \"The person's favorite cheese is cheddar.\"\n\n    # Run evaluation\n    evaluation = weave.Evaluation(\n        dataset=dataset,\n        scorers=[hallucination_scorer],\n    )\n    result = asyncio.run(evaluation.evaluate(model))\n    print(result)\n    # Example output:\n    # {'HallucinationFreeScorer': {'has_hallucination': {'true_count': 2, 'true_fraction': 1.0}}, 'model_latency': {'mean': ...}}\n    ```\n\n    ---\n\n    ## `SummarizationScorer`\n\n    Use an LLM to compare a summary to the original text and evaluate the quality of the summary.\n\n    ```python\n    from weave.scorers import SummarizationScorer\n\n    scorer = SummarizationScorer(\n        model_id=\"openai/gpt-4o\"  # or any other model supported by litellm\n    )\n    ```\n\n    **How It Works:**\n\n    This scorer evaluates summaries in two ways:\n\n    1. **Entity Density:** Checks the ratio of unique entities (like names, places, or things) mentioned in the summary to the total word count in the summary in order to estimate the \"information density\" of the summary. Uses an LLM to extract the entities. Similar to how entity density is used in the Chain of Density paper, https://arxiv.org/abs/2309.04269\n    2. **Quality Grading:** An LLM evaluator grades the summary as `poor`, `ok`, or `excellent`. These grades are then mapped to scores (0.0 for poor, 0.5 for ok, and 1.0 for excellent) for aggregate performance evaluation.\n\n    **Customization:**\n\n    - Adjust `summarization_evaluation_system_prompt` and `summarization_evaluation_prompt` to tailor the evaluation process.\n\n    **Notes:**\n\n    - The scorer uses litellm internally.\n    - The `score` method expects the original text (the one being summarized) to be present in the `input` column. Use `column_map` if your dataset uses a different name.\n\n    Here you have an example usage in the context of an evaluation:\n\n    ```python\n    import asyncio\n    import weave\n    from weave.scorers import SummarizationScorer\n\n    class SummarizationModel(weave.Model):\n        @weave.op()\n        async def predict(self, input: str) -> str:\n            return \"This is a summary of the input text.\"\n\n    # Initialize scorer\n    summarization_scorer = SummarizationScorer(\n        model_id=\"openai/gpt-4o\"  # or any other model supported by litellm\n    )\n    # Create dataset\n    dataset = [\n        {\"input\": \"The quick brown fox jumps over the lazy dog.\"},\n        {\"input\": \"Artificial Intelligence is revolutionizing various industries.\"}\n    ]\n    # Run evaluation\n    evaluation = weave.Evaluation(dataset=dataset, scorers=[summarization_scorer])\n    results = asyncio.run(evaluation.evaluate(SummarizationModel()))\n    print(results)\n    # Example output:\n    # {'SummarizationScorer': {'is_entity_dense': {'true_count': 0, 'true_fraction': 0.0}, 'summarization_eval_score': {'mean': 0.0}, 'entity_density': {'mean': 0.0}}, 'model_latency': {'mean': ...}}\n    ```\n\n    ---\n\n    ## `OpenAIModerationScorer`\n\n    The `OpenAIModerationScorer` uses OpenAI's Moderation API to check if the AI system's output contains disallowed content, such as hate speech or explicit material.\n\n    ```python\n    from weave.scorers import OpenAIModerationScorer\n\n    scorer = OpenAIModerationScorer()\n    ```\n\n    **How It Works:**\n\n    - Sends the AI's output to the OpenAI Moderation endpoint and returns a structured response indicating if the content is flagged.\n\n    **Notes:**\n    Here is an example in the context of an evaluation:\n\n    ```python\n    import asyncio\n    import weave\n    from weave.scorers import OpenAIModerationScorer\n\n    class MyModel(weave.Model):\n        @weave.op\n        async def predict(self, input: str) -> str:\n            return input\n\n    # Initialize scorer\n    moderation_scorer = OpenAIModerationScorer()\n\n    # Create dataset\n    dataset = [\n        {\"input\": \"I love puppies and kittens!\"},\n        {\"input\": \"I hate everyone and want to hurt them.\"}\n    ]\n\n    # Run evaluation\n    evaluation = weave.Evaluation(dataset=dataset, scorers=[moderation_scorer])\n    results = asyncio.run(evaluation.evaluate(MyModel()))\n    print(results)\n    # Example output:\n    # {'OpenAIModerationScorer': {'flagged': {'true_count': 1, 'true_fraction': 0.5}, 'categories': {'violence': {'true_count': 1, 'true_fraction': 1.0}}}, 'model_latency': {'mean': ...}}\n    ```\n\n    ---\n\n    ## `EmbeddingSimilarityScorer`\n\n    The `EmbeddingSimilarityScorer` computes the cosine similarity between the embeddings of the AI system's output and a target text from your dataset. It is useful for measuring how similar the AI's output is to a reference text.\n\n    ```python\n    from weave.scorers import EmbeddingSimilarityScorer\n\n    similarity_scorer = EmbeddingSimilarityScorer(\n        model_id=\"openai/text-embedding-3-small\",  # or any other model supported by litellm\n        threshold=0.4  # the cosine similarity threshold\n    )\n    ```\n\n    Note: You can use `column_map` to map the `target` column to a different name.\n\n    **Parameters:**\n\n    - `threshold` (float): The minimum cosine similarity score (between -1 and 1) needed to consider the two texts similar (defaults to `0.5`).\n\n    Here is an example usage in the context of an evaluation:\n\n    ```python\n    import asyncio\n    import weave\n    from weave.scorers import EmbeddingSimilarityScorer\n\n    # Initialize scorer\n    similarity_scorer = EmbeddingSimilarityScorer(\n        model_id=\"openai/text-embedding-3-small\",  # or any other model supported by litellm\n        threshold=0.7\n    )\n    # Create dataset\n    dataset = [\n        {\n            \"input\": \"He's name is John\",\n            \"target\": \"John likes various types of cheese.\",\n        },\n        {\n            \"input\": \"He's name is Pepe.\",\n            \"target\": \"Pepe likes various types of cheese.\",\n        },\n    ]\n    # Define model\n    @weave.op\n    def model(input: str) -> str:\n        return \"John likes various types of cheese.\"\n\n    # Run evaluation\n    evaluation = weave.Evaluation(\n        dataset=dataset,\n        scorers=[similarity_scorer],\n    )\n    result = asyncio.run(evaluation.evaluate(model))\n    print(result)\n    # Example output:\n    # {'EmbeddingSimilarityScorer': {'is_similar': {'true_count': 1, 'true_fraction': 0.5}, 'similarity_score': {'mean': 0.844851403}}, 'model_latency': {'mean': ...}}\n    ```\n\n    ---\n\n    ## `ValidJSONScorer`\n\n    The `ValidJSONScorer` checks whether the AI system's output is valid JSON. This scorer is useful when you expect the output to be in JSON format and need to verify its validity.\n\n    ```python\n    from weave.scorers import ValidJSONScorer\n\n    json_scorer = ValidJSONScorer()\n    ```\n\n    Here is an example in the context of an evaluation:\n\n    ```python\n    import asyncio\n    import weave\n    from weave.scorers import ValidJSONScorer\n\n    class JSONModel(weave.Model):\n        @weave.op()\n        async def predict(self, input: str) -> str:\n            # This is a placeholder.\n            # In a real scenario, this would generate JSON.\n            return '{\"key\": \"value\"}'\n\n    model = JSONModel()\n    json_scorer = ValidJSONScorer()\n\n    dataset = [\n        {\"input\": \"Generate a JSON object with a key and value\"},\n        {\"input\": \"Create an invalid JSON\"}\n    ]\n\n    evaluation = weave.Evaluation(dataset=dataset, scorers=[json_scorer])\n    results = asyncio.run(evaluation.evaluate(model))\n    print(results)\n    # Example output:\n    # {'ValidJSONScorer': {'json_valid': {'true_count': 2, 'true_fraction': 1.0}}, 'model_latency': {'mean': ...}}\n    ```\n\n    ---\n\n    ## `ValidXMLScorer`\n\n    The `ValidXMLScorer` checks whether the AI system's output is valid XML. It is useful when expecting XML-formatted outputs.\n\n    ```python\n    from weave.scorers import ValidXMLScorer\n\n    xml_scorer = ValidXMLScorer()\n    ```\n\n    Here is an example in the context of an evaluation:\n\n    ```python\n    import asyncio\n    import weave\n    from weave.scorers import ValidXMLScorer\n\n    class XMLModel(weave.Model):\n        @weave.op()\n        async def predict(self, input: str) -> str:\n            # This is a placeholder. In a real scenario, this would generate XML.\n            return 'value'\n\n    model = XMLModel()\n    xml_scorer = ValidXMLScorer()\n\n    dataset = [\n        {\"input\": \"Generate a valid XML with a root element\"},\n        {\"input\": \"Create an invalid XML\"}\n    ]\n\n    evaluation = weave.Evaluation(dataset=dataset, scorers=[xml_scorer])\n    results = asyncio.run(evaluation.evaluate(model))\n    print(results)\n    # Example output:\n    # {'ValidXMLScorer': {'xml_valid': {'true_count': 2, 'true_fraction': 1.0}}, 'model_latency': {'mean': ...}}\n    ```\n\n    ---\n\n    ## `PydanticScorer`\n\n    The `PydanticScorer` validates the AI system's output against a Pydantic model to ensure it adheres to a specified schema or data structure.\n\n    ```python\n    from weave.scorers import PydanticScorer\n    from pydantic import BaseModel\n\n    class FinancialReport(BaseModel):\n        revenue: int\n        year: str\n\n    pydantic_scorer = PydanticScorer(model=FinancialReport)\n    ```\n\n    ---\n\n    ## RAGAS - `ContextEntityRecallScorer`\n\n    The `ContextEntityRecallScorer` estimates context recall by extracting entities from both the AI system's output and the provided context, then computing the recall score. It is based on the [RAGAS](https://github.com/explodinggradients/ragas) evaluation library.\n\n    ```python\n    from weave.scorers import ContextEntityRecallScorer\n\n    entity_recall_scorer = ContextEntityRecallScorer(\n        model_id=\"openai/gpt-4o\"\n    )\n    ```\n\n    **How It Works:**\n\n    - Uses an LLM to extract unique entities from the output and context and calculates recall.\n    - **Recall** indicates the proportion of important entities from the context that are captured in the output.\n    - Returns a dictionary with the recall score.\n\n    **Notes:**\n\n    - Expects a `context` column in your dataset. Use the `column_map` attribute if the column name is different.\n\n    ---\n\n    ## RAGAS - `ContextRelevancyScorer`\n\n    The `ContextRelevancyScorer` evaluates the relevancy of the provided context to the AI system's output. It is based on the [RAGAS](https://github.com/explodinggradients/ragas) evaluation library.\n\n    ```python\n    from weave.scorers import ContextRelevancyScorer\n\n    relevancy_scorer = ContextRelevancyScorer(\n        model_id=\"openai/gpt-4o\",  # or any other model supported by litellm\n        relevancy_prompt=\"\"\"\n    Given the following question and context, rate the relevancy of the context to the question on a scale from 0 to 1.\n\n    Question: {question}\n    Context: {context}\n    Relevancy Score (0-1):\n    \"\"\"\n    )\n    ```\n\n    **How It Works:**\n\n    - Uses an LLM to rate the relevancy of the context to the output on a scale from 0 to 1.\n    - Returns a dictionary with the `relevancy_score`.\n\n    **Notes:**\n\n    - Expects a `context` column in your dataset. Use `column_map` if a different name is used.\n    - Customize the `relevancy_prompt` to define how relevancy is assessed.\n\n    Here is an example usage in the context of an evaluation:\n\n    ```python\n    import asyncio\n    from textwrap import dedent\n    import weave\n    from weave.scorers import ContextEntityRecallScorer, ContextRelevancyScorer\n\n    class RAGModel(weave.Model):\n        @weave.op()\n        async def predict(self, question: str) -> str:\n            \"Retrieve relevant context\"\n            return \"Paris is the capital of France.\"\n\n    # Define prompts\n    relevancy_prompt: str = dedent(\"\"\"\n        Given the following question and context, rate the relevancy of the context to the question on a scale from 0 to 1.\n\n        Question: {question}\n        Context: {context}\n        Relevancy Score (0-1):\n        \"\"\")\n    # Initialize scorers\n    entity_recall_scorer = ContextEntityRecallScorer()\n    relevancy_scorer = ContextRelevancyScorer(relevancy_prompt=relevancy_prompt)\n    # Create dataset\n    dataset = [\n        {\n            \"question\": \"What is the capital of France?\",\n            \"context\": \"Paris is the capital city of France.\"\n        },\n        {\n            \"question\": \"Who wrote Romeo and Juliet?\",\n            \"context\": \"William Shakespeare wrote many famous plays.\"\n        }\n    ]\n    # Run evaluation\n    evaluation = weave.Evaluation(\n        dataset=dataset,\n        scorers=[entity_recall_scorer, relevancy_scorer]\n    )\n    results = asyncio.run(evaluation.evaluate(RAGModel()))\n    print(results)\n    # Example output:\n    # {'ContextEntityRecallScorer': {'recall': {'mean': ...}}, \n    # 'ContextRelevancyScorer': {'relevancy_score': {'mean': ...}}, \n    # 'model_latency': {'mean': ...}}\n    ```\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n**Note:** The built-in scorers were calibrated using OpenAI models (e.g. `openai/gpt-4o`, `openai/text-embedding-3-small`). If you wish to experiment with other providers, you can simply update the `model_id`. For example, to use an Anthropic model:\n\n```python\nfrom weave.scorers import SummarizationScorer\n\n# Switch to Anthropic's Claude model\nsummarization_scorer = SummarizationScorer(\n    model_id=\"anthropic/claude-3-5-sonnet-20240620\"\n)\n```"
  },
  {
    "title": "Guardrails And Monitors",
    "url": "https://weave-docs.wandb.ai/guides/evaluation/guardrails_and_monitors",
    "section": "Docs",
    "category": "Evaluation",
    "content": "# Online Evaluation: Guardrails and Monitors\n\n\n\n## Introduction\n\nBuilding production LLM applications? Two questions likely keep you up at night:\n1. How do you ensure your LLMs generate safe, appropriate content?\n2. How do you measure and improve output quality over time?\n\nWeave's unified scoring system answers both questions through a simple yet powerful framework. Whether you need active safety controls (guardrails) or passive quality monitoring, this guide will show you how to implement robust evaluation systems for your LLM applications.\n\nThe foundation of Weave's evaluation system is the [**Scorer**](./scorers.md) - a component that evaluates your function's inputs and outputs to measure quality, safety, or any other metric you care about. Scorers are versatile and can be used in two ways:\n\n- **As Guardrails**: Block or modify unsafe content before it reaches users\n- **As Monitors**: Track quality metrics over time to identify trends and improvements\n\n:::note Terminology\nThroughout this guide, we'll refer to functions decorated with `@weave.op` as \"ops\". These are regular Python functions that have been enhanced with Weave's tracking capabilities.\n:::\n\n#### Ready-to-Use Scorers\nWhile this guide shows you how to create custom scorers, Weave comes with a variety of [predefined scorers](./builtin_scorers.mdx) that you can use right away, including:\n- [Hallucination detection](./builtin_scorers.mdx#hallucinationfreescorer)\n- [Summarization quality](./builtin_scorers.mdx#summarizationscorer)\n- [Embedding similarity](./builtin_scorers.mdx#embeddingsimilarityscorer)\n- [Relevancy evaluation](./builtin_scorers.mdx#ragas---contextrelevancyscorer)\n- And more!\n\n### Guardrails vs. Monitors: When to Use Each\n\nWhile scorers power both guardrails and monitors, they serve different purposes:\n\n| Aspect | Guardrails | Monitors |\n|--------|------------|----------|\n| **Purpose** | Active intervention to prevent issues | Passive observation for analysis |\n| **Timing** | Real-time, before output reaches users | Can be asynchronous or batched |\n| **Performance** | Must be fast (affects response time) | Can be slower, run in background |\n| **Sampling** | Usually every request | Often sampled (e.g., 10% of calls) |\n| **Control Flow** | Can block/modify outputs | No impact on application flow |\n| **Resource Usage** | Must be efficient | Can use more resources if needed |\n\nFor example, a toxicity scorer could be used:\n- \ud83d\udee1\ufe0f **As a Guardrail**: Block toxic content immediately\n- \ud83d\udcca **As a Monitor**: Track toxicity levels over time\n\n> \ud83d\udca1 **Note**: Every scorer result is automatically stored in Weave's database. This means your guardrails double as monitors without any extra work! You can always analyze historical scorer results, regardless of how they were originally used.\n\n### Using the `.call()` Method\n\nTo use scorers with Weave ops, you'll need access to both the operation's result and its tracking information. The `.call()` method provides both:\n\n```python\n# Instead of calling the op directly:\nresult = generate_text(input)  # Primary way to call the op but doesn't give access to the Call object\n\n# Use the .call() method to get both result and Call object:\nresult, call = generate_text.call(input)  # Now you can use the call object with scorers\n```\n\n:::tip Why Use `.call()`?\nThe Call object is essential for associating the score with the call in the database. While you can directly call the scoring function, this would not be associated with the call, and therefore not searchable, filterable, or exportable for later analysis.\n\nFor more details about Call objects, see the [Calls guide section on Call objects](../tracking/tracing.mdx#getting-a-handle-to-the-call-object-during-execution).\n:::\n\n## Getting Started with Scorers\n\n### Basic Example\n\nHere's a simple example showing how to use `.call()` with a scorer:\n\n```python\nimport weave\nfrom weave import Scorer\n\nclass LengthScorer(Scorer):\n    @weave.op\n    def score(self, output: str) -> dict:\n        \"\"\"A simple scorer that checks output length.\"\"\"\n        return {\n            \"length\": len(output),\n            \"is_short\": len(output) < 100\n        }\n\n@weave.op\ndef generate_text(prompt: str) -> str:\n    return \"Hello, world!\"\n\n# Get both result and Call object\nresult, call = generate_text.call(\"Say hello\")\n\n# Now you can apply scorers\nawait call.apply_scorer(LengthScorer())\n```\n\n## Using Scorers as Guardrails {#using-scorers-as-guardrails}\n\nGuardrails act as safety checks that run before allowing LLM output to reach users. Here's a practical example:\n\n```python\nimport weave\nfrom weave import Scorer\n\n@weave.op\ndef generate_text(prompt: str) -> str:\n    \"\"\"Generate text using an LLM.\"\"\"\n    # Your LLM generation logic here\n    return \"Generated response...\"\n\nclass ToxicityScorer(Scorer):\n    @weave.op\n    def score(self, output: str) -> dict:\n        \"\"\"\n        Evaluate content for toxic language.\n        \"\"\"\n        # Your toxicity detection logic here\n        return {\n            \"flagged\": False,  # True if content is toxic\n            \"reason\": None     # Optional explanation if flagged\n        }\n\nasync def generate_safe_response(prompt: str) -> str:\n    # Get result and Call object\n    result, call = generate_text.call(prompt)\n    \n    # Check safety\n    safety = await call.apply_scorer(ToxicityScorer())\n    if safety.result[\"flagged\"]:\n        return f\"I cannot generate that content: {safety.result['reason']}\"\n    \n    return result\n```\n\n:::note Scorer Timing\nWhen applying scorers:\n- The main operation (`generate_text`) completes and is marked as finished in the UI\n- Scorers run asynchronously after the main operation\n- Scorer results are attached to the call once they complete\n- You can view scorer results in the UI or query them via the API\n:::\n\n## Using Scorers as Monitors {#using-scorers-as-monitors}\n\nMonitors help track quality metrics over time without blocking operations. This is useful for:\n- Identifying quality trends\n- Detecting model drift\n- Gathering data for model improvements\n\n```python\nimport weave\nfrom weave import Scorer\nfrom weave.scorers import ValidJSONScorer, ValidXMLScorer\n\nimport random\n\n@weave.op\ndef generate_text(prompt: str) -> str:\n    \"\"\"Generate text using an LLM.\"\"\"\n    return \"Generated response...\"\n\nasync def generate_with_monitoring(prompt: str) -> str:\n    # Get both the result and tracking information\n    result, call = generate_text.call(prompt)\n    \n    # Sample monitoring (only monitor 10% of calls)\n    if random.random() < 0.1:\n        # Monitor multiple aspects asynchronously\n        await call.apply_scorer(ValidJSONScorer())\n        await call.apply_scorer(ValidXMLScorer())\n    \n    return result\n```\n\n## AWS Bedrock Guardrails\n\nThe `BedrockGuardrailScorer` uses AWS Bedrock's guardrail feature to detect and filter content based on configured policies. It calls the `apply_guardrail` API to apply the guardrail to the content.\n\nTo use the `BedrockGuardrailScorer`, you need the following:\n- An AWS account with Bedrock access\n- An AWS account with access to Bedrock\n- A configured guardrail in the AWS Bedrock console\n- The `boto3` Python package\n\n> \ud83c\udf1f **Tip**: You don't need to create your own Bedrock client\u2014Weave creates it for you.  To specify a region, pass the `bedrock_runtime_kwargs` parameter to the scorer.\n\nFor more details on creating a guardrail, see the [Bedrock guardrails notebook](https://github.com/aws-samples/amazon-bedrock-samples/blob/main/responsible_ai/bedrock-guardrails/guardrails-api.ipynb).\n```python\nimport weave\nimport boto3\nfrom weave.scorers.bedrock_guardrails import BedrockGuardrailScorer\n\n# Initialize Weave\nweave.init(\"my_app\")\n\n# Create a guardrail scorer\nguardrail_scorer = BedrockGuardrailScorer(\n    guardrail_id=\"your-guardrail-id\",  # Replace \"your-guardrail-id\" with your guardrail ID\n    guardrail_version=\"DRAFT\",          # Use guardrail_version to use a specific guardrail version\n    source=\"INPUT\",                             # Can be \"INPUT\" or \"OUTPUT\"\n    bedrock_runtime_kwargs={\"region_name\": \"us-east-1\"}  # AWS region\n)\n\n@weave.op\ndef generate_text(prompt: str) -> str:\n    # Add your text generation logic here\n    return \"Generated text...\"\n\n# Use the guardrail as a safety check\nasync def generate_safe_text(prompt: str) -> str:\n    result, call = generate_text.call(prompt)\n    \n    # Apply the guardrail\n    score = await call.apply_scorer(guardrail_scorer)\n    \n    # Check if the content passed the guardrail\n    if not score.result.passed:\n        # Use the modified output if available\n        if score.result.metadata.get(\"modified_output\"):\n            return score.result.metadata[\"modified_output\"]\n        return \"I cannot generate that content due to content policy restrictions.\"\n    \n    return result\n```\n\n\n## Implementation Details\n\n### The Scorer Interface\n\nA scorer is a class that inherits from `Scorer` and implements a `score` method. The method receives:\n- `output`: The result from your function\n- Any input parameters matching your function's parameters\n\nHere's a comprehensive example:\n\n```python\n@weave.op\ndef generate_styled_text(prompt: str, style: str, temperature: float) -> str:\n    \"\"\"Generate text in a specific style.\"\"\"\n    return \"Generated text in requested style...\"\n\nclass StyleScorer(Scorer):\n    @weave.op\n    def score(self, output: str, prompt: str, style: str) -> dict:\n        \"\"\"\n        Evaluate if the output matches the requested style.\n        \n        Args:\n            output: The generated text (automatically provided)\n            prompt: Original prompt (matched from function input)\n            style: Requested style (matched from function input)\n        \"\"\"\n        return {\n            \"style_match\": 0.9,  # How well it matches requested style\n            \"prompt_relevance\": 0.8  # How relevant to the prompt\n        }\n\n# Example usage\nasync def generate_and_score():\n    # Generate text with style\n    result, call = generate_styled_text.call(\n        prompt=\"Write a story\",\n        style=\"noir\",\n        temperature=0.7\n    )\n    \n    # Score the result\n    score = await call.apply_scorer(StyleScorer())\n    print(f\"Style match score: {score.result['style_match']}\")\n```\n\n### Score Parameters\n\n#### Parameter Matching Rules\n- The `output` parameter is special and always contains the function's result\n- Other parameters must match the function's parameter names exactly\n- Scorers can use any subset of the function's parameters\n- Parameter types should match the function's type hints\n\n#### Handling Parameter Name Mismatches\n\nSometimes your scorer's parameter names might not match your function's parameter names exactly. For example:\n\n```python\n@weave.op\ndef generate_text(user_input: str):  # Uses 'user_input'\n    return process(user_input)\n\nclass QualityScorer(Scorer):\n    @weave.op\n    def score(self, output: str, prompt: str):  # Expects 'prompt'\n        \"\"\"Evaluate response quality.\"\"\"\n        return {\"quality_score\": evaluate_quality(prompt, output)}\n\nresult, call = generate_text.call(user_input=\"Say hello\")\n\n# Map 'prompt' parameter to 'user_input'\nscorer = QualityScorer(column_map={\"prompt\": \"user_input\"})\nawait call.apply_scorer(scorer)\n```\n\nCommon use cases for `column_map`:\n- Different naming conventions between functions and scorers\n- Reusing scorers across different functions\n- Using third-party scorers with your function names\n\n\n#### Adding Additional Parameters\n\nSometimes scorers need extra parameters that aren't part of your function. You can provide these using `additional_scorer_kwargs`:\n\n```python\nclass ReferenceScorer(Scorer):\n    @weave.op\n    def score(self, output: str, reference_answer: str):\n        \"\"\"Compare output to a reference answer.\"\"\"\n        similarity = compute_similarity(output, reference_answer)\n        return {\"matches_reference\": similarity > 0.8}\n\n# Provide the reference answer as an additional parameter\nawait call.apply_scorer(\n    ReferenceScorer(),\n    additional_scorer_kwargs={\n        \"reference_answer\": \"The Earth orbits around the Sun.\"\n    }\n)\n```\n\nThis is useful when your scorer needs context or configuration that isn't part of the original function call.\n\n\n### Using Scorers: Two Approaches\n\n1. **With Weave's Op System** (Recommended)\n```python\nresult, call = generate_text.call(input)\nscore = await call.apply_scorer(MyScorer())\n```\n\n2. **Direct Usage** (Quick Experiments)\n```python\nscorer = MyScorer()\nscore = scorer.score(output=\"some text\")\n```\n\n**When to use each:**\n- \ud83d\udc49 Use the op system for production, tracking, and analysis\n- \ud83d\udc49 Use direct scoring for quick experiments or one-off evaluations\n\n**Tradeoffs of Direct Usage:**\n- \u2705 Simpler for quick tests\n- \u2705 No Op required\n- \u274c No association with the LLM/Op call\n\n### Score Analysis\n\n\nFor detailed information about querying calls and their scorer results, see our [Score Analysis Guide](./scorers.md#score-analysis) and our [Data Access Guide](/guides/tracking/tracing#querying--exporting-calls).\n\n\n## Production Best Practices\n\n### 1. Set Appropriate Sampling Rates\n```python\n@weave.op\ndef generate_text(prompt: str) -> str:\n    return generate_response(prompt)\n\nasync def generate_with_sampling(prompt: str) -> str:\n    result, call = generate_text.call(prompt)\n    \n    # Only monitor 10% of calls\n    if random.random() < 0.1:\n        await call.apply_scorer(ToxicityScorer())\n        await call.apply_scorer(QualityScorer())\n    \n    return result\n```\n\n### 2. Monitor Multiple Aspects\n```python\nasync def evaluate_comprehensively(call):\n    await call.apply_scorer(ToxicityScorer())\n    await call.apply_scorer(QualityScorer())\n    await call.apply_scorer(LatencyScorer())\n```\n### 3. Analyze and Improve\n- Review trends in the Weave Dashboard\n- Look for patterns in low-scoring outputs\n- Use insights to improve your LLM system\n- Set up alerts for concerning patterns (coming soon)\n\n### 4. Access Historical Data\nScorer results are stored with their associated calls and can be accessed through:\n- The Call object's `feedback` field\n- The Weave Dashboard\n- Our query APIs\n\n### 5. Initialize Guards Efficiently\n\nFor optimal performance, especially with locally-run models, initialize your guards outside of the main function. This pattern is particularly important when:\n- Your scorers load ML models\n- You're using local LLMs where latency is critical\n- Your scorers maintain network connections\n- You have high-traffic applications\n\nSee the Complete Example section below for a demonstration of this pattern.\n\n:::caution Performance Tips\nFor Guardrails:\n- Keep logic simple and fast\n- Consider caching common results\n- Avoid heavy external API calls\n- Initialize guards outside of your main functions to avoid repeated initialization costs\n\nFor Monitors:\n- Use sampling to reduce load\n- Can use more complex logic\n- Can make external API calls\n:::\n\n## Complete Example\n\nHere's a comprehensive example that brings together all the concepts we've covered:\n\n```python\nimport weave\nfrom weave import Scorer\nimport asyncio\nimport random\nfrom typing import Optional\n\nclass ToxicityScorer(Scorer):\n    def __init__(self):\n        # Initialize any expensive resources here\n        self.model = load_toxicity_model()\n    \n    @weave.op\n    async def score(self, output: str) -> dict:\n        \"\"\"Check content for toxic language.\"\"\"\n        try:\n            result = await self.model.evaluate(output)\n            return {\n                \"flagged\": result.is_toxic,\n                \"reason\": result.explanation if result.is_toxic else None\n            }\n        except Exception as e:\n            # Log error and default to conservative behavior\n            print(f\"Toxicity check failed: {e}\")\n            return {\"flagged\": True, \"reason\": \"Safety check unavailable\"}\n\nclass QualityScorer(Scorer):\n    @weave.op\n    async def score(self, output: str, prompt: str) -> dict:\n        \"\"\"Evaluate response quality and relevance.\"\"\"\n        return {\n            \"coherence\": evaluate_coherence(output),\n            \"relevance\": evaluate_relevance(output, prompt),\n            \"grammar\": evaluate_grammar(output)\n        }\n\n# Initialize scorers at module level (optional optimization)\ntoxicity_guard = ToxicityScorer()\nquality_monitor = QualityScorer()\nrelevance_monitor = RelevanceScorer()\n\n@weave.op\ndef generate_text(\n    prompt: str,\n    style: Optional[str] = None,\n    temperature: float = 0.7\n) -> str:\n    \"\"\"Generate an LLM response.\"\"\"\n    # Your LLM generation logic here\n    return \"Generated response...\"\n\nasync def generate_safe_response(\n    prompt: str,\n    style: Optional[str] = None,\n    temperature: float = 0.7\n) -> str:\n    \"\"\"Generate a response with safety checks and quality monitoring.\"\"\"\n    try:\n        # Generate initial response\n        result, call = generate_text.call(\n            prompt=prompt,\n            style=style,\n            temperature=temperature\n        )\n\n        # Apply safety check (guardrail)\n        safety = await call.apply_scorer(toxicity_guard)\n        if safety.result[\"flagged\"]:\n            return f\"I cannot generate that content: {safety.result['reason']}\"\n\n        # Sample quality monitoring (10% of requests)\n        if random.random() < 0.1:\n            # Run quality checks in parallel\n            await asyncio.gather(\n                call.apply_scorer(quality_monitor),\n                call.apply_scorer(relevance_monitor)\n            )\n        \n        return result\n\n    except Exception as e:\n        # Log error and return user-friendly message\n        print(f\"Generation failed: {e}\")\n        return \"I'm sorry, I encountered an error. Please try again.\"\n\n# Example usage\nasync def main():\n    # Basic usage\n    response = await generate_safe_response(\"Tell me a story\")\n    print(f\"Basic response: {response}\")\n    \n    # Advanced usage with all parameters\n    response = await generate_safe_response(\n        prompt=\"Tell me a story\",\n        style=\"noir\",\n        temperature=0.8\n    )\n    print(f\"Styled response: {response}\")\n\n```\n\nThis example demonstrates:\n- Proper scorer initialization and error handling\n- Combined use of guardrails and monitors\n- Async operation with parallel scoring\n- Production-ready error handling and logging\n\n## Next Steps\n\n- Explore [Available Scorers](./scorers.md)\n- Learn about [Weave Ops](../../guides/tracking/ops.md)"
  },
  {
    "title": "Scorers",
    "url": "https://weave-docs.wandb.ai/guides/evaluation/scorers",
    "section": "Docs",
    "category": "Evaluation",
    "content": "# Scoring Overview\n\nIn Weave, Scorers are used to evaluate AI outputs and return evaluation metrics. They take the AI's output, analyze it, and return a dictionary of results. Scorers can use your input data as reference if needed and can also output extra information, such as explanations or reasonings from the evaluation.\n\n\n  \n    Scorers are passed to a `weave.Evaluation` object during evaluation. There are two types of Scorers in weave:\n\n    1. **Function-based Scorers:** Simple Python functions decorated with `@weave.op`.\n    2. **Class-based Scorers:** Python classes that inherit from `weave.Scorer` for more complex evaluations.\n\n    Scorers must return a dictionary and can return multiple metrics, nested metrics and non-numeric values such as text returned from a LLM-evaluator about its reasoning.\n\n  \n  \n    Scorers are special ops passed to a `weave.Evaluation` object during evaluation.\n  \n\n\n## Create your own Scorers\n\n:::tip[Ready-to-Use Scorers]\nWhile this guide shows you how to create custom scorers, Weave comes with a variety of [predefined scorers](./builtin_scorers.mdx) and [local SLM scorers](./weave_local_scorers.md) that you can use right away, including:\n- [Hallucination detection](./builtin_scorers.mdx#hallucinationfreescorer)\n- [Summarization quality](./builtin_scorers.mdx#summarizationscorer)\n- [Embedding similarity](./builtin_scorers.mdx#embeddingsimilarityscorer)\n- [Toxicity detection (local)](./weave_local_scorers.md#weavetoxicityscorerv1)\n- [Context Relevance scoring (local)](./weave_local_scorers.md#weavecontextrelevancescorerv1)\n- And more!\n:::\n\n### Function-based Scorers\n\n\n  \n    These are functions decorated with `@weave.op` that return a dictionary. They're great for simple evaluations like:\n\n    ```python\n    import weave\n\n    @weave.op\n    def evaluate_uppercase(text: str) -> dict:\n        return {\"text_is_uppercase\": text.isupper()}\n\n    my_eval = weave.Evaluation(\n        dataset=[{\"text\": \"HELLO WORLD\"}],\n        scorers=[evaluate_uppercase]\n    )\n    ```\n\n    When the evaluation is run, `evaluate_uppercase` checks if the text is all uppercase.\n\n  \n  \n    These are functions wrapped with `weave.op` that accept an object with `modelOutput` and optionally `datasetRow`.  They're great for simple evaluations like:\n    ```typescript\n    import * as weave from 'weave'\n\n    const evaluateUppercase = weave.op(\n        ({modelOutput}) => modelOutput.toUpperCase() === modelOutput,\n        {name: 'textIsUppercase'}\n    );\n\n\n    const myEval = new weave.Evaluation({\n        dataset: [{text: 'HELLO WORLD'}],\n        scorers: [evaluateUppercase],\n    })\n    ```\n\n  \n\n\n### Class-based Scorers\n\n\n  \n    For more advanced evaluations, especially when you need to keep track of additional scorer metadata, try different prompts for your LLM-evaluators, or make multiple function calls, you can use the `Scorer` class.\n\n    **Requirements:**\n\n    1. Inherit from `weave.Scorer`.\n    2. Define a `score` method decorated with `@weave.op`.\n    3. The `score` method must return a dictionary.\n\n    Example:\n\n    ```python\n    import weave\n    from openai import OpenAI\n    from weave import Scorer\n\n    llm_client = OpenAI()\n\n    #highlight-next-line\n    class SummarizationScorer(Scorer):\n        model_id: str = \"gpt-4o\"\n        system_prompt: str = \"Evaluate whether the summary is good.\"\n\n        @weave.op\n        def some_complicated_preprocessing(self, text: str) -> str:\n            processed_text = \"Original text: \\n\" + text + \"\\n\"\n            return processed_text\n\n        @weave.op\n        def call_llm(self, summary: str, processed_text: str) -> dict:\n            res = llm_client.chat.completions.create(\n                messages=[\n                    {\"role\": \"system\", \"content\": self.system_prompt},\n                    {\"role\": \"user\", \"content\": (\n                        f\"Analyse how good the summary is compared to the original text.\"\n                        f\"Summary: {summary}\\n{processed_text}\"\n                    )}])\n            return {\"summary_quality\": res}\n\n        @weave.op\n        def score(self, output: str, text: str) -> dict:\n            \"\"\"Score the summary quality.\n\n            Args:\n                output: The summary generated by an AI system\n                text: The original text being summarized\n            \"\"\"\n            processed_text = self.some_complicated_preprocessing(text)\n            eval_result = self.call_llm(summary=output, processed_text=processed_text)\n            return {\"summary_quality\": eval_result}\n\n    evaluation = weave.Evaluation(\n        dataset=[{\"text\": \"The quick brown fox jumps over the lazy dog.\"}],\n        scorers=[summarization_scorer])\n    ```\n\n    This class evaluates how good a summary is by comparing it to the original text.\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n## How Scorers Work\n\n### Scorer Keyword Arguments\n\n\n  \n    Scorers can access both the output from your AI system and the input data from the dataset row.\n\n    - **Input:** If you would like your scorer to use data from your dataset row, such as a \"label\" or \"target\" column then you can easily make this available to the scorer by adding a `label` or `target` keyword argument to your scorer definition.\n\n    For example if you wanted to use a column called \"label\" from your dataset then your scorer function (or `score` class method) would have a parameter list like this:\n\n    ```python\n    @weave.op\n    def my_custom_scorer(output: str, label: int) -> dict:\n        ...\n    ```\n\n    When a weave `Evaluation` is run, the output of the AI system is passed to the `output` parameter. The `Evaluation` also automatically tries to match any additional scorer argument names to your dataset columns. If customizing your scorer arguments or dataset columns is not feasible, you can use column mapping - see below for more.\n\n    - **Output:** Include an `output` parameter in your scorer function's signature to access the AI system's output.\n\n    ### Mapping Column Names with `column_map`\n\n    Sometimes, the `score` methods' argument names don't match the column names in your dataset. You can fix this using a `column_map`.\n\n    If you're using a class-based scorer, pass a dictionary to the `column_map` attribute of `Scorer` when you initialise your scorer class. This dictionary maps your `score` method's argument names to the dataset's column names, in the order: `{scorer_keyword_argument: dataset_column_name}`.\n\n    Example:\n\n    ```python\n    import weave\n    from weave import Scorer\n\n    # A dataset with news articles to be summarised\n    dataset = [\n        {\"news_article\": \"The news today was great...\", \"date\": \"2030-04-20\", \"source\": \"Bright Sky Network\"},\n        ...\n    ]\n\n    # Scorer class\n    class SummarizationScorer(Scorer):\n\n        @weave.op\n        def score(self, output, text) -> dict:\n            \"\"\"\n                output: output summary from a LLM summarization system\n                text: the text being summarised\n            \"\"\"\n            ...  # evaluate the quality of the summary\n\n    # create a scorer with a column mapping the `text` argument to the `news_article` data column\n    scorer = SummarizationScorer(column_map={\"text\" : \"news_article\"})\n    ```\n\n    Now, the `text` argument in the `score` method will receive data from the `news_article` dataset column.\n\n    **Notes:**\n\n    - Another equivalent option to map your columns is to subclass the `Scorer` and overload the `score` method mapping the columns explicitly.\n\n    ```python\n    import weave\n    from weave import Scorer\n\n    class MySummarizationScorer(SummarizationScorer):\n\n        @weave.op\n        def score(self, output: str, news_article: str) -> dict:  # Added type hints\n            # overload the score method and map columns manually\n            return super().score(output=output, text=news_article)\n    ```\n\n  \n  \n    Scorers can access both the output from your AI system and the contents of the dataset row.\n\n    You can easily access relevant columns from the dataset row by adding a `datasetRow` keyword argument to your scorer definition.\n\n    ```typescript\n    const myScorer = weave.op(\n        ({modelOutput, datasetRow}) => {\n            return modelOutput * 2 === datasetRow.expectedOutputTimesTwo;\n        },\n        {name: 'myScorer'}\n    );\n    ```\n\n    ### Mapping Column Names with `columnMapping`\n    > \ud83d\udea8 **Important**:     In TypeScript, this feature is currently on the `Evaluation` object, not individual scorers.\n\n    :::\n\n    Sometimes your `datasetRow` keys will not exactly match the scorer's naming scheme, but they are semantically similar. You can map the columns using the `Evaluation`'s `columnMapping` option.\n\n    The mapping is always from the scorer's perspective, i.e. `{scorer_key: dataset_column_name}`.\n\n    Example:\n\n    ```typescript\n    const myScorer = weave.op(\n        ({modelOutput, datasetRow}) => {\n            return modelOutput * 2 === datasetRow.expectedOutputTimesTwo;\n        },\n        {name: 'myScorer'}\n    );\n\n    const myEval = new weave.Evaluation({\n        dataset: [{expected: 2}],\n        scorers: [myScorer],\n        columnMapping: {expectedOutputTimesTwo: 'expected'}\n    });\n    ```\n\n  \n\n\n### Final summarization of the scorer\n\n\n  \n    During evaluation, the scorer will be computed for each row of your dataset. To provide a final score for the evaluation we provide an `auto_summarize` depending on the returning type of the output.\n    - Averages are computed for numerical columns\n    - Count and fraction for boolean columns\n    - Other column types are ignored\n\n    You can override the `summarize` method on the `Scorer` class and provide your own way of computing the final scores. The `summarize` function expects:\n\n    - A single parameter `score_rows`: This is a list of dictionaries, where each dictionary contains the scores returned by the `score` method for a single row of your dataset.\n    - It should return a dictionary containing the summarized scores.\n\n    **Why this is useful?**\n\n    When you need to score all rows before deciding on the final value of the score for the dataset.\n\n    ```python\n    class MyBinaryScorer(Scorer):\n        \"\"\"\n        Returns True if the full output matches the target, False if not\n        \"\"\"\n\n        @weave.op\n        def score(self, output, target):\n            return {\"match\": output == target}\n\n        def summarize(self, score_rows: list) -> dict:\n            full_match = all(row[\"match\"] for row in score_rows)\n            return {\"full_match\": full_match}\n    ```\n\n    > In this example, the default `auto_summarize` would have returned the count and proportion of True.\n\n    If you want to learn more, check the implementation of [CorrectnessLLMJudge](/tutorial-rag#optional-defining-a-scorer-class).\n\n  \n  \n    During evaluation, the scorer will be computed for each row of your dataset.  To provide a final score, we use an internal `summarizeResults` function that aggregates depending on the output type.\n    - Averages are computed for numerical columns\n    - Count and fraction for boolean columns\n    - Other column types are ignored\n\n    We don't currently support custom summarization.\n\n  \n\n\n### Applying Scorers to a Call\n\nTo apply scorers to your Weave ops, you'll need to use the `.call()` method which provides access to both the operation's result and its tracking information. This allows you to associate scorer results with specific calls in Weave's database.\n\nFor more information on how to use the `.call()` method, see the [Calling Ops](../tracking/tracing#calling-ops#getting-a-handle-to-the-call-object-during-execution) guide.\n\n\n  \n    Here's a basic example:\n\n    ```python\n    # Get both result and Call object\n    result, call = generate_text.call(\"Say hello\")\n\n    # Apply a scorer\n    score = await call.apply_scorer(MyScorer())\n    ```\n\n    You can also apply multiple scorers to the same call:\n\n    ```python\n    # Apply multiple scorers in parallel\n    await asyncio.gather(\n        call.apply_scorer(quality_scorer),\n        call.apply_scorer(toxicity_scorer)\n    )\n    ```\n\n    **Notes:**\n    - Scorer results are automatically stored in Weave's database\n    - Scorers run asynchronously after the main operation completes\n    - You can view scorer results in the UI or query them via the API\n\n    For more detailed information about using scorers as guardrails or monitors, including production best practices and complete examples, see our [Guardrails and Monitors guide](./guardrails_and_monitors.md).\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet. Stay tuned!\n    ```\n  \n\n\n### Use `preprocess_model_input` \n\nYou can use the `preprocess_model_input` parameter to modify dataset examples before they reach your model during evaluation. \nimportant\nThe `preprocess_model_input` function only transforms inputs before they are passed to the model\u2019s prediction function.\n\nScorer functions always receive the original dataset examples, without any preprocessing applied.\n:::\n\nFor usage information and an example, see [Using `preprocess_model_input` to format dataset rows before evaluating](../core-types/evaluations.md#using-preprocess_model_input-to-format-dataset-rows-before-evaluating).\n\n## Score Analysis\n\nIn this section, we'll show you how to analyze the scores for a single call, multiple calls, and all calls scored by a specific scorer.\n\n### Analyze a single Call's Scores\n\n#### Single Call API\n\nTo retrieve the calls for a single call, you can use the `get_call` method.\n\n```python\nclient = weave.init(\"my-project\")\n\n# Get a single call\ncall = client.get_call(\"call-uuid-here\")\n\n# Get the feedback for the call which contains the scores\nfeedback = list(call.feedback)\n```\n\n\n#### Single Call UI\n\n\n\nScores for an individual call are displayed in the call details page under the \"Scores\" tab.\n\n\n### Analyze multiple Calls' Scores\n\n#### Multiple Calls API\n\nTo retrieve the calls for multiple calls, you can use the `get_calls` method.\n\n```python\nclient = weave.init(\"my-project\")\n\n# Get multiple calls - use whatever filters you want and include feedback\ncalls = client.get_calls(..., include_feedback=True)\n\n# Iterate over the calls and access the feedback which contains the scores\nfor call in calls:\n    feedback = list(call.feedback)\n```\n\n#### Multiple Calls UI\n\n\n\nScores for multiple calls are displayed in the traces table under the \"Scores\" column.\n\n### Analyze all Calls scored by a specific Scorer\n\n#### All Calls by Scorer API\n\nTo retrieve all calls scored by a specific scorer, you can use the `get_calls` method.\n\n```python\nclient = weave.init(\"my-project\")\n\n# To get all the calls scored by any version of a scorer, use the scorer name (typically the class name)\ncalls = client.get_calls(scored_by=[\"MyScorer\"], include_feedback=True)\n\n# To get all the calls scored by a specific version of a scorer, use the entire ref\n# Refs can be obtained from the scorer object or via the UI.\ncalls = client.get_calls(scored_by=[myScorer.ref.uri()], include_feedback=True)\n\n# Iterate over the calls and access the feedback which contains the scores\nfor call in calls:\n    feedback = list(call.feedback)\n```\n\n\n#### All Calls by Scorer UI\n\nFinally, if you would like to see all the calls scored by a Scorer, navigate to the Scorers Tab in the UI and select \"Programmatic Scorer\" tab. Click your Scorer to open the Scorer details page.\n\n\n\nNext, click the `View Traces` button under `Scores` to view all the calls scored by your Scorer.\n\n\n\nThis will default to the selected version of the Scorer. You can remove the version filter to see all the calls scored by any version of the Scorer."
  },
  {
    "title": "Weave Local Scorers",
    "url": "https://weave-docs.wandb.ai/guides/evaluation/weave_local_scorers",
    "section": "Docs",
    "category": "Evaluation",
    "content": "# Weave Local Scorers\n\n\n\n\n\nWeave's local scorers are a suite of small language models that run locally on your machine with minimal latency. These models evaluate the safety and quality of your AI system\u2019s inputs, context, and outputs.\n\nSome of these models are fine-tuned by Weights & Biases, while others are state-of-the-art open-source models trained by the community. Weights & Biases (W&B) Reports were used for training and evaluation. You can find the full details in this [list of W&B Reports](https://wandb.ai/c-metrics/weave-scorers/reports/Weave-Scorers-v1--VmlldzoxMDQ0MDE1OA).\n\nThe model weights are publicly available in W&B Artifacts, and are automatically downloaded when you instantiate the scorer class. The artifact paths can be found here if you'd like to download them yourself: `weave.scorers.default_models`\n\nThe object returned by these scorers contains a `passed` boolean attribute indicating whether the input text is safe or high quality, as well as a `metadata` attribute that contains more detail such as the raw score from the model.\n\n> \ud83c\udf1f **Tip**: While local scorers can be run on CPUs and GPUs, use GPUs for best performance.  \n\n\n  \n\n    ## Prerequisites\n\n    Before you can use Weave local scorers, install additional dependencies:\n\n    ```bash\n    pip install weave[scorers]\n    ```\n\n    ## Select a scorer\n\n    The following local scorers are available. Select a scorer based on your use case.\n\n    | Scorer                           | Scenario                                                                                                                                                                      |\n    |----------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n    | [WeaveToxicityScorerV1](#weavetoxicityscorerv1)                  | Identify toxic or harmful content in your AI system's inputs and outputs, including hate speech or threats.                                                       |\n    | [WeaveBiasScorerV1](#weavebiasscorerv1)                          | Detect biased or stereotypical content in your AI system's inputs and outputs. Ideal for reducing harmful biases in generated text.                               |\n    | [WeaveHallucinationScorerV1](#weavehallucinationscorerv1)       | Identify whether your RAG system generates hallucinations in its output based on the input and context provided.                                                  |\n    | [WeaveContextRelevanceScorerV1](#weavecontextrelevancescorerv1) | Measure whether the AI system's output is relevant to the input and context provided.                                                                             |\n    | [WeaveCoherenceScorerV1](#weavecoherencescorerv1)                | Evaluate the coherence and logical structure of the AI system's output.                                                                                           |\n    | [WeaveFluencyScorerV1](#weavefluencyscorerv1)                    | Measure whether the AI system's output is fluent.                                                                                                                  |\n    | [WeaveTrustScorerV1](#weavetrustscorerv1)                        | An aggregate scorer that leverages the toxicity, hallucination, context relevance, fluency, and coherence scorers.                                                |\n    | [PresidioScorer](#presidioscorer)                                | Detect Personally Identifiable Information (PII) in your AI system's inputs and outputs using the Presidio library from Microsoft.                                |\n\n    ## `WeaveBiasScorerV1`\n\n    This scorer assesses gender and race/origin bias along two dimensions:\n        \n        - Race and Origin: Racism and bias against a country or region of origin, immigration status, ethnicity, etc.\n        - Gender and Sexuality: Sexism, misogyny, homophobia, transphobia, sexual harassment, etc.\n\n    `WeaveBiasScorerV1` uses a fine-tuned [deberta-small-long-nli](https://huggingface.co/tasksource/deberta-small-long-nli) model. For more details on the model, dataset, and calibration process, see the [WeaveBiasScorerV1 W&B Report](https://wandb.ai/c-metrics/bias-benchmark/reports/Bias-Scorer--VmlldzoxMDM2MTgzNw).\n\n    ### Usage notes \n\n    - The `score` method expects a string to be passed to the `output` parameter. \n    - A higher score means that there is a stronger prediction of bias in the text.\n    - The `threshold` parameter is set but can also be overridden on initialization.\n    \n    ### Usage example\n\n    ```python\n    import weave\n    from weave.scorers import WeaveBiasScorerV1\n\n    bias_scorer = WeaveBiasScorerV1()\n    result = bias_scorer.score(output=\"Martian men are terrible at cleaning\")\n\n    print(f\"The text is biased: {not result.passed}\")\n    print(result)\n    ```\n\n    ---\n\n    ## `WeaveToxicityScorerV1`\n\n    This scorer assesses the input text for toxicity along five dimensions:\n    \n        - Race and Origin: Racism and bias against a country or region of origin, immigration status, ethnicity, etc.\n        - Gender and Sexuality: Sexism, misogyny, homophobia, transphobia, sexual harassment, etc.\n        - Religious: Bias or stereotypes against someone's religion.\n        - Ability: Bias related to someone's physical, mental, or intellectual ability or disability.\n        - Violence and Abuse: Overly graphic descriptions of violence, threats of violence, or incitement of violence.\n    \n    The `WeaveToxicityScorerV1` uses the open source [Celadon](https://huggingface.co/PleIAs/celadon) model from PleIAs. For more information, see the [WeaveToxicityScorerV1 W&B Report](https://wandb.ai/c-metrics/toxicity-benchmark/reports/Toxicity-Scorer--VmlldzoxMDMyNjc0NQ).\n\n    ### Usage notes\n\n    - The `score` method expects a string to be passed to the `output` parameter. \n    - The model returns scores from `0` to `3` across five different categories: \n      - If the sum of these scores is above `total_threshold` (default value `5`), the input is flagged as toxic. \n      - If any single category has a score higher than `category_threshold` (default `2`), the input is flagged as toxic.\n    - To make filtering more aggressive, override `category_threshold` or `total_threshold` during initialization.\n\n    ### Usage example\n\n    ```python\n    import weave\n    from weave.scorers import WeaveToxicityScorerV1\n\n    toxicity_scorer = WeaveToxicityScorerV1()\n    result = toxicity_scorer.score(output=\"people from the south pole of Mars are the worst\")\n\n    print(f\"Input is toxic: {not result.passed}\")\n    print(result)\n    ```\n\n    ---\n\n    ## `WeaveHallucinationScorerV1`\n\n    This scorer checks if your AI system's output contains any hallucinations based on the input data.\n\n    The `WeaveHallucinationScorerV1` uses the open source [HHEM 2.1 model](https://huggingface.co/vectara/hallucination_evaluation_model) from Vectara. For more information, see the [WeaveHallucinationScorerV1 W&B Report](https://wandb.ai/c-metrics/hallucination/reports/Hallucination-Scorer--VmlldzoxMDM3NDA3MA).\n\n    ### Usage notes\n\n    - The `score` method expects values to be passed to the `query` and `output` parameters.  \n    - The context should be passed to the `output` parameter (as a string or list of strings).  \n    - A higher output score means a stronger prediction of hallucination in the output.\n    - The `threshold` parameter is set but can be overridden on initialization.\n\n    ### Usage example \n\n    ```python\n    import weave\n    from weave.scorers import WeaveHallucinationScorerV1\n\n    hallucination_scorer = WeaveHallucinationScorerV1()\n\n    result = hallucination_scorer.score(\n        query=\"What is the capital of Antarctica?\",\n        context=\"People in Antarctica love the penguins.\",\n        output=\"While Antarctica is known for its sea life, penguins aren't liked there.\"\n    )\n\n    print(f\"Output is hallucinated: {not result.passed}\")\n    print(result)\n    ```\n\n    ---\n\n    ## `WeaveContextRelevanceScorerV1`\n\n    This scorer is designed to be used when evaluating RAG systems. It scores the relevance of the context to the query.\n\n    The `WeaveContextRelevanceScorerV1` uses a fine-tuned [deberta-small-long-nli](https://huggingface.co/tasksource/deberta-small-long-nli) model from tasksource. For more details, see the [WeaveContextRelevanceScorerV1 W&B Report](https://wandb.ai/c-metrics/context-relevance-scorer/reports/Context-Relevance-Scorer--VmlldzoxMDYxNjEyNA).\n\n    ### Usage notes\n\n    - The `score` method expects values for `query` and `output`.  \n    - The context should be passed to the `output` parameter (string or list of strings).\n    - A higher score means a stronger prediction that the context is relevant to the query.\n    - You can pass `verbose=True` to the `score` method to get per-chunk scores.\n\n    ### Usage example\n\n    ```python\n    import weave\n    from weave.scorers import WeaveContextRelevanceScorerV1\n\n    context_relevance_scorer = WeaveContextRelevanceScorerV1()\n\n    result = context_relevance_scorer.score(\n        query=\"What is the capital of Antarctica?\",\n        output=\"The Antarctic has the happiest penguins.\"  # context is passed to the output parameter\n    )\n\n    print(f\"Output is relevant: {result.passed}\")\n    print(result)\n    ```\n\n    ## `WeaveCoherenceScorerV1`\n\n    This scorer checks whether the input text is coherent.\n\n    The `WeaveCoherenceScorerV1` uses a fine-tuned [deberta-small-long-nli](https://huggingface.co/tasksource/deberta-small-long-nli) model from tasksource. For more information, see the [WeaveCoherenceScorerV1 W&B Report](https://wandb.ai/c-metrics/coherence_scorer/reports/Coherence-Scorer--VmlldzoxMDI5MjA1MA).\n\n    ### Usage notes\n\n    - The `score` method expects text to be passed to the `query` and `output` parameters.\n    - A higher output score means a stronger prediction of coherence.\n\n    ### Usage example \n\n    ```python\n    import weave\n    from weave.scorers import WeaveCoherenceScorerV1\n\n    coherence_scorer = WeaveCoherenceScorerV1()\n\n    result = coherence_scorer.score(\n        query=\"What is the capital of Antarctica?\",\n        output=\"but why not monkey up day\"\n    )\n\n    print(f\"Output is coherent: {result.passed}\")\n    print(result)\n    ```\n\n    ---\n\n    ## `WeaveFluencyScorerV1`\n\n    This scorer checks whether the input text is fluent\u2014that is, easy to read and understand, similar to natural human language. It evaluates grammar, syntax, and overall readability.\n\n    The `WeaveFluencyScorerV1` uses a fine-tuned [ModernBERT-base](https://huggingface.co/answerdotai/ModernBERT-base) model from AnswerDotAI. For more information, see the [WeaveFluencyScorerV1 W&B Report](https://wandb.ai/c-metrics/fluency-eval/reports/Fluency-Scorer--VmlldzoxMTA3NzE2Ng).\n\n    ### Usage notes\n\n    - The `score` method expects text to be passed to the `output` parameter.\n    - A higher output score indicates higher fluency.\n\n    ### Usage example \n\n    ```python\n    import weave\n    from weave.scorers import WeaveFluencyScorerV1\n\n    fluency_scorer = WeaveFluencyScorerV1()\n\n    result = fluency_scorer.score(\n        output=\"The cat did stretching lazily into warmth of sunlight.\"\n    )\n\n    print(f\"Output is fluent: {result.passed}\")\n    print(result)\n    ```\n\n    ---\n\n    ## `WeaveTrustScorerV1`\n\n    The `WeaveTrustScorerV1` is a composite scorer for RAG systems that evaluates the trustworthiness of model outputs by grouping other scorers into two categories: Critical and Advisory. Based on the composite score, it returns a trust level:\n\n    - `high`: No issues detected  \n    - `medium`: Only Advisory issues detected  \n    - `low`: Critical issues detected or input is empty  \n\n    Any input that fails a Critical scorer results in a `low` trust level. Failing an Advisory scorer results in `medium`.\n\n    - **Critical:**\n        - `WeaveToxicityScorerV1`\n        - `WeaveHallucinationScorerV1`\n        - `WeaveContextRelevanceScorerV1`\n\n    - **Advisory:**\n        - `WeaveFluencyScorerV1`\n        - `WeaveCoherenceScorerV1`\n\n    ### Usage notes\n\n    - This scorer is designed for evaluating RAG pipelines.  \n    - It requires `query`, `context`, and `output` keys for correct scoring.\n\n    ### Usage example\n\n    ```python\n    import weave\n    from weave.scorers import WeaveTrustScorerV1\n\n    trust_scorer = WeaveTrustScorerV1()\n\n    def print_trust_scorer_result(result):\n        print()\n        print(f\"Output is trustworthy: {result.passed}\")\n        print(f\"Trust level: {result.metadata['trust_level']}\")\n        if not result.passed:\n            print(\"Triggered scorers:\")\n            for scorer_name, scorer_data in result.metadata['raw_outputs'].items():\n                if not scorer_data.passed:\n                    print(f\"  - {scorer_name} did not pass\")\n        print()\n        print(f\"WeaveToxicityScorerV1 scores: {result.metadata['scores']['WeaveToxicityScorerV1']}\")\n        print(f\"WeaveHallucinationScorerV1 scores: {result.metadata['scores']['WeaveHallucinationScorerV1']}\")\n        print(f\"WeaveContextRelevanceScorerV1 score: {result.metadata['scores']['WeaveContextRelevanceScorerV1']}\")\n        print(f\"WeaveCoherenceScorerV1 score: {result.metadata['scores']['WeaveCoherenceScorerV1']}\")\n        print(f\"WeaveFluencyScorerV1: {result.metadata['scores']['WeaveFluencyScorerV1']}\")\n        print()\n\n    result = trust_scorer.score(\n        query=\"What is the capital of Antarctica?\",\n        context=\"People in Antarctica love the penguins.\",\n        output=\"The cat stretched lazily in the warm sunlight.\"\n    )\n\n    print_trust_scorer_result(result)\n    print(result)\n    ```\n\n    ---\n\n    ## `PresidioScorer`\n\n    This scorer uses the [Presidio library](https://github.com/microsoft/presidio) to detect Personally Identifiable Information (PII) in your AI system's inputs and outputs.\n\n    ### Usage notes\n\n    - To specify specific entity types, such as emails or phone numbers, pass a list of Presidio entities to the `selected_entities` parameter. Otherwise, Presidio will detect all entity types in its default entities list.\n    - To detect specific entity types, such as emails or phone numbers, pass a list to the `selected_entities` parameter.\n    - You can pass custom recognizers via the `custom_recognizers` parameter as a list of `presidio.EntityRecognizer` instances.\n    - To handle non-English input, use the `language` parameter to specify the language.\n\n    ### Usage example\n\n    ```python\n    import weave\n    from weave.scorers import PresidioScorer\n\n    presidio_scorer = PresidioScorer()\n\n    result = presidio_scorer.score(\n        output=\"Mary Jane is a software engineer at XYZ company and her email is mary.jane@xyz.com.\"\n    )\n\n    print(f\"Output contains PII: {not result.passed}\")\n    print(result)\n    ```\n\n  \n  \n    Weave local scorers are not available in TypeScript yet. Stay tuned!\n\n    To use Weave scorers in TypeScript, see [function-based scorers](scorers#function-based-scorers)."
  },
  {
    "title": "Evaluation Logger",
    "url": "https://weave-docs.wandb.ai/guides/evaluation/evaluation_logger",
    "section": "Docs",
    "category": "Evaluation",
    "content": "# `EvaluationLogger`\n\nThe `EvaluationLogger` provides a flexible, incremental way to log evaluation data directly from your Python code. You don't need deep knowledge of Weave's internal data types; simply instantiate a logger and use its methods (`log_prediction`, `log_score`, `log_summary`) to record evaluation steps.\n\nThis approach is particularly helpful in complex workflows where the entire dataset or all scorers might not be defined upfront.\n\nIn contrast to the standard `Evaluation` object, which requires a predefined `Dataset` and list of `Scorer` objects, the `EvaluationLogger` allows you to log individual predictions and their associated scores incrementally as they become available.\n\n:::info Prefer a more structured evaluation?\n\nIf you prefer a more opinionated evaluation framework with predefined datasets and scorers, see [Weave's standard Evaluation framework](../core-types/evaluations.md). \n\nThe `EvaluationLogger` offers flexibility while the standard framework offers structure and guidance.\n:::\n\n## Basic workflow\n\n1. _Initialize the logger:_ Create an instance of `EvaluationLogger`, optionally providing metadata about the `model` and `dataset`. Defaults will be used if omitted.\n2. _Log predictions:_ Call `log_prediction` for each input/output pair from your system.\n3. _Log scores:_ Use the returned `ScoreLogger` to `log_score` for the prediction. Multiple scores per prediction are supported.\n4. _Finish prediction:_ Always call `finish()` after logging scores for a prediction to finalize it.\n5. _Log summary:_ After all predictions are processed, call `log_summary` to aggregate scores and add optional custom metrics.\n\n> \ud83d\udea8 **Important**: After calling `finish()` on a prediction, no more scores can be logged for it.\n\nFor a Python code demonstrating the described workflow, see the [Basic example](#basic-example).\n\n## Basic example\nThe following example shows how to use `EvaluationLogger` to log predictions and scores inline with your existing Python code.\n\nThe `user_model` model function is defined and applied to a list of inputs. For each example:\n\n- The input and output are logged using `log_prediction`.\n- A simple correctness score (`correctness_score`) is logged via `log_score`.\n- `finish()` finalizes logging for that prediction.\nFinally, `log_summary` records any aggregate metrics and triggers automatic score summarization in Weave.\n\n```python\nimport weave\nfrom openai import OpenAI\nfrom weave.flow.eval_imperative import EvaluationLogger\n\n# Initialize the logger (model/dataset names are optional metadata)\neval_logger = EvaluationLogger(\n    model=\"my_model\",\n    dataset=\"my_dataset\"\n)\n\n# Example input data (this can be any data structure you want)\neval_samples = [\n    {'inputs': {'a': 1, 'b': 2}, 'expected': 3},\n    {'inputs': {'a': 2, 'b': 3}, 'expected': 5},\n    {'inputs': {'a': 3, 'b': 4}, 'expected': 7},\n]\n\n# Example model logic.  This does not have to be decorated with @weave.op,\n# but if you do, it will be traced and logged.\n@weave.op\ndef user_model(a: int, b: int) -> int:\n    oai = OpenAI()\n    _ = oai.chat.completions.create(messages=[{\"role\": \"user\", \"content\": f\"What is {a}+{b}?\"}], model=\"gpt-4o-mini\")\n    return a + b\n\n# Iterate through examples, predict, and log\nfor sample in eval_samples:\n    inputs = sample[\"inputs\"]\n    model_output = user_model(**inputs) # Pass inputs as kwargs\n\n    # Log the prediction input and output\n    pred_logger = eval_logger.log_prediction(\n        inputs=inputs,\n        output=model_output\n    )\n\n    # Calculate and log a score for this prediction\n    expected = sample[\"expected\"]\n    correctness_score = model_output == expected\n    pred_logger.log_score(\n        scorer=\"correctness\", # Simple string name for the scorer\n        score=correctness_score\n    )\n\n    # Finish logging for this specific prediction\n    pred_logger.finish()\n\n# Log a final summary for the entire evaluation.\n# Weave auto-aggregates the 'correctness' scores logged above.\nsummary_stats = {\"subjective_overall_score\": 0.8}\neval_logger.log_summary(summary_stats)\n\nprint(\"Evaluation logging complete. View results in the Weave UI.\")\n```\n\n## Advanced usage\n\n### Get outputs before logging\n\nYou can first compute your model outputs, then separately log predictions and scores. This allows for better separation of evaluation and logging logic.\n\n```python\nev = EvaluationLogger(model=\"example_model\", dataset=\"example_dataset\")\n\noutputs = [your_output_generator(**inputs) for inputs in your_dataset]\npreds = [ev.log_prediction(inputs, output) for inputs, output in zip(your_dataset, outputs)]\nfor pred in preds:\n    pred.log_score(scorer=\"greater_than_5_scorer\", score=output > 5)\n    pred.log_score(scorer=\"greater_than_7_scorer\", score=output > 7)\n\nev.log_summary()\n```\n\n### Log rich media\n\nInputs, outputs, and scores can include rich media such as images, videos, audio, or structured tables. Simply pass a dict or media object into the `log_prediction` or `log_score` methods:\n\n```python\nimport io\nimport wave\nimport struct\nfrom PIL import Image\nimport random\nfrom typing import Any\nimport weave\n\ndef generate_random_audio_wave_read(duration=2, sample_rate=44100):\n    n_samples = duration * sample_rate\n    amplitude = 32767  # 16-bit max amplitude\n\n    buffer = io.BytesIO()\n\n    # Write wave data to the buffer\n    with wave.open(buffer, 'wb') as wf:\n        wf.setnchannels(1)\n        wf.setsampwidth(2)  # 16-bit\n        wf.setframerate(sample_rate)\n\n        for _ in range(n_samples):\n            sample = random.randint(-amplitude, amplitude)\n            wf.writeframes(struct.pack('<h', sample))\n\n    # Rewind the buffer to the beginning so we can read from it\n    buffer.seek(0)\n\n    # Return a Wave_read object\n    return wave.open(buffer, 'rb')\n\nrich_media_dataset = [\n    {\n        'image': Image.new(\n            \"RGB\",\n            (100, 100),\n            color=(\n                random.randint(0, 255),\n                random.randint(0, 255),\n                random.randint(0, 255),\n            ),\n        ),\n        \"audio\": generate_random_audio_wave_read(),\n    }\n    for _ in range(5)\n]\n\n@weave.op\ndef your_output_generator(image: Image.Image, audio) -> dict[str, Any]:\n    return {\n        \"result\": random.randint(0, 10),\n        \"image\": image,\n        \"audio\": audio,\n    }\n\nev = EvaluationLogger(model=\"example_model\", dataset=\"example_dataset\")\n\nfor inputs in rich_media_dataset:\n    output = your_output_generator(**inputs)\n    pred = ev.log_prediction(inputs, output)\n    pred.log_score(scorer=\"greater_than_5_scorer\", score=output[\"result\"] > 5)\n    pred.log_score(scorer=\"greater_than_7_scorer\", score=output[\"result\"] > 7)\n\nev.log_summary()\n```\n\n### Log and compare multiple evaluations\n\nWith `EvaluationLogger`, you can log and compare multiple evaluations.\n\n1. Run the code sample shown below.\n2. In the Weave UI, navigate to the `Evals` tab.\n3. Select the evals that you want to compare.\n4. Click the **Compare** button. In the Compare view, you can:\n   - Choose which Evals to add or remove\n   - Choose which metrics to show or hide\n   - Page through specific examples to see how different models performed for the same input on a given dataset\n   \n   For more information on comparisons, see [Comparisons](../tools/comparison.md)\n\n```python\nimport weave\n\nmodels = [\n    \"model1\",\n    \"model2\",\n     {\"name\": \"model3\", \"metadata\": {\"coolness\": 9001}}\n]\n\nfor model in models:\n    ev = EvaluationLogger(model=model, dataset=\"example_dataset\")\n    for inputs in your_dataset:\n        output = your_output_generator(**inputs)\n        pred = ev.log_prediction(inputs=inputs, output=output)\n        pred.log_score(scorer=\"greater_than_3_scorer\", score=output > 3)\n        pred.log_score(scorer=\"greater_than_5_scorer\", score=output > 5)\n        pred.log_score(scorer=\"greater_than_7_scorer\", score=output > 7)\n        pred.finish()\n\n    ev.log_summary()\n```\n\n\n\n\n\n## Usage tips\n\n- Call `finish()` promptly after each prediction.\n- Use `log_summary` to capture metrics not tied to single predictions (e.g., overall latency).\n- Rich media logging is great for qualitative analysis."
  },
  {
    "title": "Costs",
    "url": "https://weave-docs.wandb.ai/guides/tracking/costs",
    "section": "Docs",
    "category": "Tracking",
    "content": "# Costs\n\n## Adding a custom cost\n\n\n  \n    You can add a custom cost by using the [`add_cost`](/reference/python-sdk/weave/trace/weave.trace.weave_client#method-add_cost) method.\n    The three required fields are `llm_id`, `prompt_token_cost`, and `completion_token_cost`.\n    `llm_id` is the name of the LLM (e.g. `gpt-4o`). `prompt_token_cost` and `completion_token_cost` are cost per token for the LLM (if the LLM prices were specified inper million tokens, make sure to convert the value).\n    You can also set `effective_date` to a datetime, to make the cost effective at a specific date, this defaults to the current date.\n\n    ```python\n    import weave\n    from datetime import datetime\n\n    client = weave.init(\"my_custom_cost_model\")\n\n    client.add_cost(\n        llm_id=\"your_model_name\",\n        prompt_token_cost=0.01,\n        completion_token_cost=0.02\n    )\n\n    client.add_costs(\n        llm_id=\"your_model_name\",\n        prompt_token_cost=10,\n        completion_token_cost=20,\n        # If for example I want to raise the price of the model after a certain date\n        effective_date=datetime(2025, 4, 22),\n    )\n    ```\n\n  \n  \n\n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n\n  \n\n\n## Querying for costs\n\n\n  \n    You can query for costs by using the [`query_costs`](/reference/python-sdk/weave/trace/weave.trace.weave_client#method-query_costs) method.\n    There are a few ways to query for costs, you can pass in a singular cost id, or a list of LLM model names.\n\n    ```python\n    import weave\n\n    client = weave.init(\"my_custom_cost_model\")\n\n    costs = client.query_costs(llm_ids=[\"your_model_name\"])\n\n    cost = client.query_costs(costs[0].id)\n    ```\n\n  \n  \n\n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n\n  \n\n\n## Purging a custom cost\n\n\n  \n    You can purge a custom cost by using the [`purge_costs`](/reference/python-sdk/weave/trace/weave.trace.weave_client#method-purge_costs) method. You pass in a list of cost ids, and the costs with those ids are purged.\n\n    ```python\n    import weave\n\n    client = weave.init(\"my_custom_cost_model\")\n\n    costs = client.query_costs(llm_ids=[\"your_model_name\"])\n    client.purge_costs([cost.id for cost in costs])\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n## Calculating costs for a Project\n\n\n  \n    You can calculate costs for a project by using our `calls_query` and adding `include_costs=True` with a little bit of setup.\n\n    ```python\n    import weave\n\n    weave.init(\"project_costs\")\n    @weave.op()\n    def get_costs_for_project(project_name: str):\n        total_cost = 0\n        requests = 0\n\n        client = weave.init(project_name)\n        # Fetch all the calls in the project\n        calls = list(\n            client.get_calls(filter={\"trace_roots_only\": True}, include_costs=True)\n        )\n\n        for call in calls:\n            # If the call has costs, we add them to the total cost\n            if call.summary[\"weave\"] is not None and call.summary[\"weave\"].get(\"costs\", None) is not None:\n                for k, cost in call.summary[\"weave\"][\"costs\"].items():\n                    requests += cost[\"requests\"]\n                    total_cost += cost[\"prompt_tokens_total_cost\"]\n                    total_cost += cost[\"completion_tokens_total_cost\"]\n\n        # We return the total cost, requests, and calls\n        return {\n            \"total_cost\": total_cost,\n            \"requests\": requests,\n            \"calls\": len(calls),\n        }\n\n    # Since we decorated our function with @weave.op(),\n    # our totals are stored in weave for historic cost total calculations\n    get_costs_for_project(\"my_custom_cost_model\")\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n## Setting up a custom model with custom costs\n\nTry our cookbook for a [Setting up costs with a custom model](/reference/gen_notebooks/custom_model_cost) or Open in Colab"
  },
  {
    "title": "Ops",
    "url": "https://weave-docs.wandb.ai/guides/tracking/ops",
    "section": "Docs",
    "category": "Tracking",
    "content": "# Ops\n\nA Weave op is a versioned function that automatically logs all calls.\n\n\n  \n    To create an op, decorate a python function with `weave.op()`\n\n    ```python showLineNumbers\n    import weave\n\n    @weave.op()\n    def track_me(v):\n        return v + 5\n\n    weave.init('intro-example')\n    track_me(15)\n    ```\n\n    Calling an op will create a new op version if the code has changed from the last call, and log the inputs and outputs of the function.\n\n    :::note\n    Functions decorated with `@weave.op()` will behave normally (without code versioning and tracking), if you don't call `weave.init('your-project-name')` before calling them.\n    :::\n\n    Ops can be [served](/guides/tools/serve) or [deployed](/guides/tools/deploy) using the Weave toolbelt.\n\n  \n  \n    To create an op, wrap a typescript function with `weave.op`\n\n    ```typescript showLineNumbers\n    import * as weave from 'weave'\n\n    function trackMe(v: number) {\n        return v + 5\n    }\n\n    const trackMeOp = weave.op(trackMe)\n    trackMeOp(15)\n\n\n    // You can also do this inline, which may be more convenient\n    const trackMeInline = weave.op((v: number) => v + 5)\n    trackMeInline(15)\n    ```\n\n  \n\n\n## Customize display names\n\n\n  \n    You can customize the op's display name by setting the `name` parameter in the `@weave.op` decorator:\n\n    ```python\n    @weave.op(name=\"custom_name\")\n    def func():\n        ...\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n## Customize logged inputs and outputs\n\n\n  \n    If you want to change the data that is logged to weave without modifying the original function (e.g. to hide sensitive data), you can pass `postprocess_inputs` and `postprocess_output` to the op decorator.\n\n    `postprocess_inputs` takes in a dict where the keys are the argument names and the values are the argument values, and returns a dict with the transformed inputs.\n\n    `postprocess_output` takes in any value which would normally be returned by the function and returns the transformed output.\n\n    ```py\n    from dataclasses import dataclass\n    from typing import Any\n    import weave\n\n    @dataclass\n    class CustomObject:\n        x: int\n        secret_password: str\n\n    def postprocess_inputs(inputs: dict[str, Any]) -> dict[str, Any]:\n        return {k:v for k,v in inputs.items() if k != \"hide_me\"}\n\n    def postprocess_output(output: CustomObject) -> CustomObject:\n        return CustomObject(x=output.x, secret_password=\"REDACTED\")\n\n    @weave.op(\n        postprocess_inputs=postprocess_inputs,\n        postprocess_output=postprocess_output,\n    )\n    def func(a: int, hide_me: str) -> CustomObject:\n        return CustomObject(x=a, secret_password=hide_me)\n\n    weave.init('hide-data-example') # \ud83d\udc1d\n    func(a=1, hide_me=\"password123\")\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n## Control sampling rate\n\n\n  \n    You can control how frequently an op's calls are traced by setting the `tracing_sample_rate` parameter in the `@weave.op` decorator. This is useful for high-frequency ops where you only need to trace a subset of calls.\n\n     Note that sampling rates are only applied to root calls. If an op has a sample rate, but is called by another op first, then that sampling rate will be ignored.\n\n    ```python\n    @weave.op(tracing_sample_rate=0.1)  # Only trace ~10% of calls\n    def high_frequency_op(x: int) -> int:\n        return x + 1\n\n    @weave.op(tracing_sample_rate=1.0)  # Always trace (default)\n    def always_traced_op(x: int) -> int:\n        return x + 1\n    ```\n\n    When an op's call is not sampled:\n    - The function executes normally\n    - No trace data is sent to Weave\n    - Child ops are also not traced for that call\n\n    The sampling rate must be between 0.0 and 1.0 inclusive.\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet. Stay tuned!\n    ```\n  \n\n\n## Control call link output\n\nIf you want to suppress the printing of call links during logging, you can set the `WEAVE_PRINT_CALL_LINK` environment variable to `false`. This can be useful if you want to reduce output verbosity and reduce clutter in your logs.\n\n```bash\nexport WEAVE_PRINT_CALL_LINK=false\n```\n\n## Deleting an op\n\n\n  \n    To delete a version of an op, call `.delete()` on the op ref.\n\n    ```python\n    weave.init('intro-example')\n    my_op_ref = weave.ref('track_me:v1')\n    my_op_ref.delete()\n    ```\n\n    Trying to access a deleted op will result in an error.\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```"
  },
  {
    "title": "Faqs",
    "url": "https://weave-docs.wandb.ai/guides/tracking/faqs",
    "section": "Docs",
    "category": "Tracking",
    "content": "# FAQs\n\nThe following page provides answers to common questions about Weave tracing.\n\n## What information does Weave capture for a function?\n\nA function can be designated as a Weave [Op](/guides/tracking/ops) either manually through a decorator or automatically as part of an enabled integration. When an Op executes, Weave captures detailed information to support your analysis. Weave provides you with fine grained control over what is logged in case you would like something different than the default; see below for configuration examples.\n\n- **Code capture** - Weave captures a representation of the Op's source code. This includes inline comments as well as recursively capturing the value of variables or the source of non-Op functions that were called. Code capture allows you to see what your function was doing even if the change was not saved to your source control system. Code capture is used as part of Op versioning, allowing you to understand the evaluation of your code over time. If code capture is disabled, a hash value will be used instead.\n\n- **Function name, inputs, and outputs** - The name of the function will be captured but can be [overridden](/guides/tracking/tracing/#call-display-name). A JSON-based representation of the inputs and outputs will be captured. For inputs, argument name will be capture in addition to value. Weave lets you [customize the logging](/guides/tracking/ops#customize-logged-inputs-and-outputs) of inputs and outputs - you can specify a function to add/remove/modify what is logged.\n\n- **Op call hierarchy** - When an Op is called within the context of another Op executing, this relationship is captured, even in cases\n  where there is an intermediate non-Op function executing. This relationship between Op calls is used to provide a \"Trace tree\".\n\n- **Execution status and exceptions** - Weave tracks whether a function is executing, finished, or errored. If an exception occurs during execution the error message and a stack track is recorded.\n\n- **System information** - Weave may capture information about which operating system the client is running on including detailed version information.\n\n- **Client information** - Weave may capture information about the Weave client itself, such as the programming language in use and detailed version information for that language and the Weave client library.\n\n- **Timing** - The execution start and end time is captured and also used for latency calculations.\n\n- **Token usage** - In some [integrations](/guides/integrations/) LLM token usage counts may be automatically logged.\n\n- **User and run context** - Logging is associated with a W&B user account. That will be captured along with any wandb Run context.\n\n- **Derived information** - Weave may compute derived information from the raw information logged, for example a cost estimate may be calculated based on token usage and knowledge of the model used. Weave also aggregates some information over calls.\n\n- **Additional information you choose** - You can choose to log [custom metadata with `weave.attributes`](/guides/core-types/models#track-production-calls) as part of your call or attach [feedback](/guides/tracking/feedback#add-feedback-to-a-call) to a call.\n\n## How can I disable code capture?\n\nYou can disable code capture during Weave client initialization: `weave.init(\"entity/project\", settings={\"capture_code\": False})`.\nYou can also use the [environment variable](/guides/core-types/env-vars) `WEAVE_CAPTURE_CODE=false`.\n\n## How can I disable system information capture?\n\nYou can disable system information capture during Weave client initialization: `weave.init(\"entity/project\", settings={\"capture_system_info\": False})`.\n\n## How can I disable client information capture?\n\nYou can disable client information capture during Weave client initialization: `weave.init(\"entity/project\", settings={\"capture_client_info\": False})`.\n\n## How do I render Python datetime values in the UI?\n\nUse Python\u2019s `datetime.datetime` (with timezone info), and publish the object using `weave.publish(...)`. Weave recognizes this type and renders it as a timestamp.\n\n## How do I render Markdown in the UI?\n\nWrap your string with `weave.Markdown(...)` before saving, and use `weave.publish(...)` to store it. Weave uses the object\u2019s type to determine rendering, and `weave.Markdown` maps to a known UI renderer.  The value will be shown as a formatted Markdown object in the UI.\n\n## Will Weave affect my function's execution speed?\n\nThe overhead of Weave logging is typically negligible compared to making a call to an LLM.\nTo minimize Weave's impact on the speed of your Op's execution, its network activity happens on a background thread.\nWhen your program is exiting it may appear to pause while any remaining enqueued data is logged.\n\n## How is Weave data ingestion calculated?\n\nWe define ingested bytes as bytes that we receive, process, and store on your behalf. This includes trace metadata, LLM inputs/outputs, and any other information you explicitly log to Weave, but does not include communication overhead (e.g., HTTP headers) or any other data that is not placed in long-term storage. We count bytes as \"ingested\" only once at the time they are received and stored.\n\n## What is pairwise evaluation and how do I do it?\n\nWhen [scoring](../evaluation/scorers.md) models in a Weave [evaluation](../core-types/evaluations.md), absolute value metrics (e.g. `9/10` for Model A and `8/10` for Model B) are typically harder to assign than relative ones (e.g. Model A performs better than Model B). _Pairwise evaluation_ allows you to compare the outputs of two models by ranking them relative to each other. This approach is particularly useful when you want to determine which model performs better for subjective tasks such as text generation, summarization, or question answering. With pairwise evaluation, you can obtain a relative preference ranking that reveals which model is best for specific inputs.\n\n> \ud83d\udea8 **Important**: This approach is a workaround and may change in future releases. We are actively working on a more robust API to support pairwise evaluations. Stay tuned for updates!\n\nThe following code sample demonstrates how to implement a pairwise evaluation in Weave by creating a [class-based scorer](../evaluation/scorers.md#class-based-scorers) called `PreferenceScorer`. The `PreferenceScorer` compares two models, `ModelA` and `ModelB`, and returns a relative score of the model outputs based on explicit hints in the input text.\n\n```python\nfrom weave import Model, Evaluation, Scorer, Dataset\nfrom weave.flow.model import ApplyModelError, apply_model_async\n\nclass ModelA(Model):\n    @weave.op\n    def predict(self, input_text: str):\n        if \"Prefer model A\" in input_text:\n            return {\"response\": \"This is a great answer from Model A\"}\n        return {\"response\": \"Meh, whatever\"}\n\nclass ModelB(Model):\n    @weave.op\n    def predict(self, input_text: str):\n        if \"Prefer model B\" in input_text:\n            return {\"response\": \"This is a thoughtful answer from Model B\"}\n        return {\"response\": \"I don't know\"}\n\nclass PreferenceScorer(Scorer):\n    @weave.op\n    async def _get_other_model_output(self, example: dict) -> Any:\n        \"\"\"Get output from the other model for comparison.\n        Args:\n            example: The input example data to run through the other model\n        Returns:\n            The output from the other model\n        \"\"\"\n\n        other_model_result = await apply_model_async(\n            self.other_model,\n            example,\n            None,\n        )\n\n        if isinstance(other_model_result, ApplyModelError):\n            return None\n\n        return other_model_result.model_output\n\n    @weave.op\n    async def score(self, output: dict, input_text: str) -> dict:\n        \"\"\"Compare the output of the primary model with the other model.\n        Args:\n            output (dict): The output from the primary model.\n            input_text (str): The input text used to generate the outputs.\n        Returns:\n            dict: A flat dictionary containing the comparison result and reason.\n        \"\"\"\n        other_output = await self._get_other_model_output(\n            {\"input_text\": input_text}\n        )\n        if other_output is None:\n            return {\"primary_is_better\": False, \"reason\": \"Other model failed\"}\n\n        if \"Prefer model A\" in input_text:\n            primary_is_better = True\n            reason = \"Model A gave a great answer\"\n        else:\n            primary_is_better = False\n            reason = \"Model B is preferred for this type of question\"\n\n        return {\"primary_is_better\": primary_is_better, \"reason\": reason}\n\ndataset = Dataset(\n    rows=[\n        {\"input_text\": \"Prefer model A: Question 1\"},  # Model A wins\n        {\"input_text\": \"Prefer model A: Question 2\"},  # Model A wins\n        {\"input_text\": \"Prefer model B: Question 3\"},  # Model B wins\n        {\"input_text\": \"Prefer model B: Question 4\"},  # Model B wins\n    ]\n)\n\nmodel_a = ModelA()\nmodel_b = ModelB()\npref_scorer = PreferenceScorer(other_model=model_b)\nevaluation = Evaluation(dataset=dataset, scorers=[pref_scorer])\nevaluation.evaluate(model_a)\n```"
  },
  {
    "title": "Otel",
    "url": "https://weave-docs.wandb.ai/guides/tracking/otel",
    "section": "Docs",
    "category": "Tracking",
    "content": "# Send OpenTelemetry Traces\n\n## Overview\nWeave supports ingestion of OpenTelemetry compatible trace data through a dedicated endpoint. This endpoint allows you to send OTLP (OpenTelemetry Protocol) formatted trace data directly to your Weave project.\n\n## Endpoint details\n\n**Path**: `/otel/v1/traces`\n**Method**: POST\n**Content-Type**: `application/x-protobuf`\n\n## Authentication\nStandard W&B authentication is used. You must have write permissions to the project where you're sending trace data.\n\n## Required Headers\n- `project_id: /`\n- `Authorization=Basic `\n\n## Examples:\n\nYou must modify the following fields before you can run the code samples below:\n1. `WANDB_API_KEY`: You can get this from [https://wandb.ai/authorize](https://wandb.ai/authorize).\n2. Entity: You can only log traces to the project under an entity that you have access to. You can find your entity name by visiting your W&N dashboard at [https://wandb.ai/home], and checking the **Teams** field in the left sidebar.\n3. Project Name: Choose a fun name!\n4. `OPENAI_API_KEY`: You can obtain this from the [OpenAI dashboard](https://platform.openai.com/api-keys).\n\n### OpenInference Instrumentation:\n\nThis example shows how to use the OpenAI instrumentation. There are many more available which you can find in the official repository: https://github.com/Arize-ai/openinference\n\nFirst, install the required dependencies:\n\n```bash\npip install openai openinference-instrumentation-openai opentelemetry-exporter-otlp-proto-http\n```\n\nNext, paste the following code into a python file such as `openinference_example.py`\n\n```python\nimport base64\nimport openai\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk import trace as trace_sdk\nfrom opentelemetry.sdk.trace.export import ConsoleSpanExporter, SimpleSpanProcessor\nfrom openinference.instrumentation.openai import OpenAIInstrumentor\n\nOPENAI_API_KEY=\"YOUR_OPENAI_API_KEY\"\nWANDB_BASE_URL = \"https://trace.wandb.ai\"\nPROJECT_ID = \"/\"\n\nOTEL_EXPORTER_OTLP_ENDPOINT = f\"{WANDB_BASE_URL}/otel/v1/traces\"\n\n# Can be found at https://wandb.ai/authorize\nWANDB_API_KEY = \"\"\nAUTH = base64.b64encode(f\"api:{WANDB_API_KEY}\".encode()).decode()\n\nOTEL_EXPORTER_OTLP_HEADERS = {\n    \"Authorization\": f\"Basic {AUTH}\",\n    \"project_id\": PROJECT_ID,\n}\n\ntracer_provider = trace_sdk.TracerProvider()\n\n# Configure the OTLP exporter\nexporter = OTLPSpanExporter(\n    endpoint=OTEL_EXPORTER_OTLP_ENDPOINT,\n    headers=OTEL_EXPORTER_OTLP_HEADERS,\n)\n\n# Add the exporter to the tracer provider\ntracer_provider.add_span_processor(SimpleSpanProcessor(exporter))\n\n# Optionally, print the spans to the console.\ntracer_provider.add_span_processor(SimpleSpanProcessor(ConsoleSpanExporter()))\n\nOpenAIInstrumentor().instrument(tracer_provider=tracer_provider)\n\ndef main():\n    client = openai.OpenAI(api_key=OPENAI_API_KEY)\n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[{\"role\": \"user\", \"content\": \"Describe OTEL in a single sentence.\"}],\n        max_tokens=20,\n        stream=True,\n        stream_options={\"include_usage\": True},\n    )\n    for chunk in response:\n        if chunk.choices and (content := chunk.choices[0].delta.content):\n            print(content, end=\"\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\nFinally, once you have set the fields specified above to their correct values, run the code:\n\n```bash\npython openinference_example.py\n```\n\n### OpenLLMetry Instrumentation:\n\nThe following example shows how to use the OpenAI instrumentation. Additional examples are available at [https://github.com/traceloop/openllmetry/tree/main/packages](https://github.com/traceloop/openllmetry/tree/main/packages).\n\nFirst install the required dependencies:\n\n```bash\npip install openai opentelemetry-instrumentation-openai opentelemetry-exporter-otlp-proto-http\n```\n\nNext, paste the following code into a python file such as `openllmetry_example.py`. Note that this is the same code as above, except the `OpenAIInstrumentor` is imported from `opentelemetry.instrumentation.openai` instead of `openinference.instrumentation.openai`\n\n```python\nimport base64\nimport openai\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk import trace as trace_sdk\nfrom opentelemetry.sdk.trace.export import ConsoleSpanExporter, SimpleSpanProcessor\nfrom opentelemetry.instrumentation.openai import OpenAIInstrumentor\n\nOPENAI_API_KEY=\"YOUR_OPENAI_API_KEY\"\nWANDB_BASE_URL = \"https://trace.wandb.ai\"\nPROJECT_ID = \"/\"\n\nOTEL_EXPORTER_OTLP_ENDPOINT = f\"{WANDB_BASE_URL}/otel/v1/traces\"\n\n# Can be found at https://wandb.ai/authorize\nWANDB_API_KEY = \"\"\nAUTH = base64.b64encode(f\"api:{WANDB_API_KEY}\".encode()).decode()\n\nOTEL_EXPORTER_OTLP_HEADERS = {\n    \"Authorization\": f\"Basic {AUTH}\",\n    \"project_id\": PROJECT_ID,\n}\n\ntracer_provider = trace_sdk.TracerProvider()\n\n# Configure the OTLP exporter\nexporter = OTLPSpanExporter(\n    endpoint=OTEL_EXPORTER_OTLP_ENDPOINT,\n    headers=OTEL_EXPORTER_OTLP_HEADERS,\n)\n\n# Add the exporter to the tracer provider\ntracer_provider.add_span_processor(SimpleSpanProcessor(exporter))\n\n# Optionally, print the spans to the console.\ntracer_provider.add_span_processor(SimpleSpanProcessor(ConsoleSpanExporter()))\n\nOpenAIInstrumentor().instrument(tracer_provider=tracer_provider)\n\ndef main():\n    client = openai.OpenAI(api_key=OPENAI_API_KEY)\n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[{\"role\": \"user\", \"content\": \"Describe OTEL in a single sentence.\"}],\n        max_tokens=20,\n        stream=True,\n        stream_options={\"include_usage\": True},\n    )\n    for chunk in response:\n        if chunk.choices and (content := chunk.choices[0].delta.content):\n            print(content, end=\"\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\nFinally, once you have set the fields specified above to their correct values, run the code:\n\n```bash\npython openllmetry_example.py\n```\n\n### Without Instrumentation\n\nIf you would prefer to use OTEL directly instead of an instrumentation package, you may do so. Span attributes will be parsed according to the OpenTelemetry semantic conventions described at [https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-spans/](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-spans/).\n\nFirst, install the required dependencies:\n\n```bash\npip install openai opentelemetry-sdk opentelemetry-api opentelemetry-exporter-otlp-proto-http\n```\n\nNext, paste the following code into a python file such as `opentelemetry_example.py`\n\n```python\nimport json\nimport base64\nimport openai\nfrom opentelemetry import trace\nfrom opentelemetry.sdk import trace as trace_sdk\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk.trace.export import ConsoleSpanExporter, SimpleSpanProcessor\n\nOPENAI_API_KEY = \"YOUR_OPENAI_API_KEY\"\nWANDB_BASE_URL = \"https://trace.wandb.ai\"\nPROJECT_ID = \"/\"\n\nOTEL_EXPORTER_OTLP_ENDPOINT = f\"{WANDB_BASE_URL}/otel/v1/traces\"\n\n# Can be found at https://wandb.ai/authorize\nWANDB_API_KEY = \"\"\nAUTH = base64.b64encode(f\"api:{WANDB_API_KEY}\".encode()).decode()\n\nOTEL_EXPORTER_OTLP_HEADERS = {\n    \"Authorization\": f\"Basic {AUTH}\",\n    \"project_id\": PROJECT_ID,\n}\n\ntracer_provider = trace_sdk.TracerProvider()\n\n# Configure the OTLP exporter\nexporter = OTLPSpanExporter(\n    endpoint=OTEL_EXPORTER_OTLP_ENDPOINT,\n    headers=OTEL_EXPORTER_OTLP_HEADERS,\n)\n\n# Add the exporter to the tracer provider\ntracer_provider.add_span_processor(SimpleSpanProcessor(exporter))\n\n# Optionally, print the spans to the console.\ntracer_provider.add_span_processor(SimpleSpanProcessor(ConsoleSpanExporter()))\n\ntrace.set_tracer_provider(tracer_provider)\n# Creates a tracer from the global tracer provider\ntracer = trace.get_tracer(__name__)\ntracer.start_span('name=standard-span')\n\ndef my_function():\n    with tracer.start_as_current_span(\"outer_span\") as outer_span:\n        client = openai.OpenAI()\n        input_messages=[{\"role\": \"user\", \"content\": \"Describe OTEL in a single sentence.\"}]\n        # This will only appear in the side panel\n        outer_span.set_attribute(\"input.value\", json.dumps(input_messages))\n        # This follows conventions and will appear in the dashboard\n        outer_span.set_attribute(\"gen_ai.system\", 'openai')\n        response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=input_messages,\n            max_tokens=20,\n            stream=True,\n            stream_options={\"include_usage\": True},\n        )\n        out = \"\"\n        for chunk in response:\n            if chunk.choices and (content := chunk.choices[0].delta.content):\n                out += content\n        # This will only appear in the side panel\n        outer_span.set_attribute(\"output.value\", json.dumps({\"content\": out}))\n\nif __name__ == \"__main__\":\n    my_function()\n```\n\nFinally, once you have set the fields specified above to their correct values, run the code:\n\n```bash\npython opentelemetry_example.py\n```\n\nThe span attribute prefixes `gen_ai` and `openinference` are used to determine which convention to use, if any, when interpreting the trace. If neither key is detected, then all span attributes are visible in the trace view. The full span is available in the side panel when you select a trace."
  },
  {
    "title": "Video",
    "url": "https://weave-docs.wandb.ai/guides/tracking/video",
    "section": "Docs",
    "category": "Tracking",
    "content": "# Video Support\n\nWeave automatically logs videos using [`moviepy`](https://zulko.github.io/moviepy/). This allows you to pass video inputs and outputs to traced functions, and Weave will automatically handle uploading and storing video data.\n\n> \ud83d\udca1 **Note**: Video support is currently only available in Python.\n\n## Supported video types\n\nWeave recognizes `moviepy` video clip objects, such as:\n\n- A `VideoFileClip` loaded from a video file\n- In-memory clips like `ImageClip`, `ColorClip`, and `TextClip`\n\n### Direct upload of file-based clips\n\nIf your clip is a `VideoFileClip` and has a valid filename with a supported extension, Weave will upload the file directly.\n\n**Supported file extensions:**\n\n- `.mp4`\n- `.webm`\n- `.gif`\n\n### In-memory clip support\n\nIf the video object is in memory (no file on disk), Weave will encode it as an `.mp4` file and handle the upload automatically. This applies to clips of the following type:\n\n- `ImageClip`\n- `ColorClip`\n- `TextClip`\n\n## Example: Trace a video function\n\nThe following code sample demonstrates how to trace a video processing function in Weave. The code sample:\n\n1. Initializes a Weave project `video-test`.\n2. Defines a `get_video` function tracked as a `weave.op` that extracts a 1 second subclip of the loaded `VideoFileClip` as a `VideoClip`.\n3. Uploads and tracks the clip in Weave.\n4. Automatically generates a dummy MP4 video if none is found.\n\nBefore you can use the code sample, complete the prerequisites:\n\n1. Install `weave` and `moviepy==1.0.3`.\n2. Create a W&B account.\n\n> \ud83d\udea8 **Important**: To avoid thread-safety issues, always pass the path to `VideoFileClip` objects instead of creating them outside the Weave `op`.\n\n```python\nimport os\nimport weave\nfrom moviepy import VideoFileClip, ColorClip, VideoClip\n\n# Update to your project name, or create a new project named 'video-test'\nweave.init('video-test')\n\n@weave.op\ndef get_video(clip: VideoFileClip) -> VideoClip:\n    \"\"\"Process a video by path rather than by passing the clip directly.\n\n    This ensures that the VideoFileClip is created and managed within the\n    Weave op's thread context, avoiding thread-safety issues.\n    \"\"\"\n    new_clip = clip.subclip(0, 1)\n    return new_clip\n\nif __name__ == \"__main__\":\n    os.makedirs(\"videos\", exist_ok=True)\n\n    # Update the path to point to your MP4 file\n    video_path = './videos/example.mp4'\n\n    # Generate a dummy video if it doesn't exist\n    # Dummy video contents: A red square that displays for 5 seconds\n    if not os.path.isfile(video_path):\n        print(\"No video found. Creating dummy video...\")\n        dummy_clip = ColorClip(size=(640, 480), color=(255, 0, 0), duration=5)\n        dummy_clip.write_videofile(video_path, fps=24)\n\n    clip = VideoFileClip(video_path, has_mask=False, audio=True)\n    get_video(clip) \n```\n\nWhen the code sample runs successfully, you can view your video by clicking the link in the **Traces** table of your project."
  },
  {
    "title": "Objects",
    "url": "https://weave-docs.wandb.ai/guides/tracking/objects",
    "section": "Docs",
    "category": "Tracking",
    "content": "# Objects\n\n## Publishing an object\n\nWeave's serialization layer saves and versions objects.\n\n\n  \n\n    ```python\n    import weave\n    # Initialize tracking to the project 'intro-example'\n    weave.init('intro-example')\n    # Save a list, giving it the name 'cat-names'\n    weave.publish(['felix', 'jimbo', 'billie'], 'cat-names')\n    ```\n\n  \n  \n    Publishing in TypeScript is still early, so not all objects are fully supported yet.\n\n    ```typescript\n    import * as weave from 'weave'\n\n    // Initialize tracking to the project 'intro-example'\n    const client = await weave.init('intro-example')\n\n    // Save an array, giving it the name 'cat-names'\n    client.publish(['felix', 'jimbo', 'billie'], 'cat-names')\n    ```\n\n  \n\n\nSaving an object with a name will create the first version of that object if it doesn't exist.\n\n## Getting an object back\n\n\n  \n    `weave.publish` returns a Ref. You can call `.get()` on any Ref to get the object back.\n\n    You can construct a ref and then fetch the object back.\n\n    ```python\n    weave.init('intro-example')\n    cat_names = weave.ref('cat-names').get()\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n## Deleting an object\n\n\n  \n    To delete a version of an object, call `.delete()` on the object ref.\n\n    ```python\n    weave.init('intro-example')\n    cat_names_ref = weave.ref('cat-names:v1')\n    cat_names_ref.delete()\n    ```\n\n    Trying to access a deleted object will result in an error. Resolving an object that has a reference to a deleted object will return a `DeletedRef` object in place of the deleted object.\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n## Ref styles\n\nA fully qualified weave object ref uri looks like this:\n\n```\nweave://///object/:\n```\n\n- _entity_: wandb entity (username or team)\n- _project_: wandb project\n- _object_name_: object name\n- _object_version_: either a version hash, a string like v0, v1..., or an alias like \":latest\". All objects have the \":latest\" alias.\n\nRefs can be constructed with a few different styles\n\n- `weave.ref()`: requires `weave.init()` to have been called. Refers to the \":latest\" version\n- `weave.ref(:)`: requires `weave.init()` to have been called.\n- `weave.ref()`: can be constructed without calling weave.init"
  },
  {
    "title": "Trace Tree",
    "url": "https://weave-docs.wandb.ai/guides/tracking/trace-tree",
    "section": "Docs",
    "category": "Tracking",
    "content": "# Navigate the Trace View\n\nThe Weave Trace view is designed to help you make sense of complex execution paths in your LLM and agentic apps. Whether you're debugging an agentic app with dozens of nested calls, or tracking the flow of a single model prediction, the Trace view provides a clear breakdown, while also providing alternate ways to view and understand your application flow.\n\nThis guide describes how to move through the trace stack, filter and search for ops, switch between visual representations, and more.\n\n## Get started\n\nTo enter the Trace view:\n1. Navigate to the **Traces** tab.\n2. Click on any trace to open the Trace view. The Trace view pops out and displays a hierarchical breakdown of the trace execution.\n\n## Traces page overview\n\nThe Traces page is composed of three core panels:\n\n- _Left sidebar_: A sortable, paginated list of all trace runs for the project.\n- _Center panel_: Interactive [trace view](#trace-view-navigation) showing the stack and ops hierarchy for a selected trace. \n- _Right panel_: Detailed view for a selected op (Call, Code, Feedback, Scores, Summary, Use).\n\n\n\n## Trace view navigation\n\n- _Breadcrumbs_: At the top of the center panel, navigate up and down the trace stack via the breadcrumb trail.\n- _Stack arrows_: Use the `\u2191` and `\u2193` buttons to move up and down the stack.\n- _Double-click_: Double-click on an op to focus the view exclusively on that substack.\n- _\"Jump to Top\" Button_: Return to the root of the trace stack.\n\n### Filter and search\n\n- _Filter an op by name_: Use the input bar above the trace tree to search for ops of a specific type (e.g., `tool`, `openai.response.create`).\n- _Filter persistence_: Selecting ops across traces retains the sub-path context for easier comparison.\n\n\n\n### Scrubbers and contextual navigation\n\nThe panel below the tree includes multiple scrubbers for navigating across calls:\n\n- **Timeline**: Chronological order of events.\n- **Peers**: Ops sharing the same type.\n- **Siblings**: Ops with the same parent.\n- **Stack**: Traverse up/down the call stack.\n\nTo view the available scrubbers, click the **^** button at the bottom of the panel.\n\nEach scrubber has a slider and **>** jump buttons to move step-by-step.\n\n\n\n### Alternate trace tree views\n\nYou can switch between multiple visual representations of the trace tree depending on your needs. To switch to an alternate trace view, click one of available options (default trace view, code composition, flame graph, graph view) in the upper right corner \n\n#### Traces (default)\n\nThe default view showing, stack hierarchy, cost per op, execution time, and status indicators.\n\n#### Code view\n\nIn the code view, boxes represent ops and their nested calls. This is helpful for visualizing flow of function calls. In this view, you can click on a box to drill into that op and filter the call path.\n\n\n\n#### Flame graph\n\nThe flame graph view provides a timeline-based visualization of execution depth and duration. This is helpful for when trying to understand performance diagnostics over time. You can click into frames to isolate sub-traces.\n\n\n\n#### Graph view\n\nThe graph view shows hierarchical relationships between ops. This is useful for understanding parent/child relationships.\n\n## Usage tips and tricks\n\n- Use the **\"Filter by op name\u201d** search bar at the top of the trace tree view to quickly isolate relevant tool or LLM calls.\n- Switch between views based on your debugging need. Use **Code View** for call logic, **Flame Graph** for to understand performance over time, and **Graph View** to understand structure."
  },
  {
    "title": "Index",
    "url": "https://weave-docs.wandb.ai/guides/tracking/index",
    "section": "Docs",
    "category": "Tracking",
    "content": "# Tracing\n\nWeave provides powerful tracing capabilities to track and version objects and function calls in your applications. This comprehensive system enables better monitoring, debugging, and iterative development of AI-powered applications, allowing you to \"track insights between commits.\"\n\n## Key Tracing Features\n\nWeave's tracing functionality comprises three main components:\n\n### Calls\n\n[Calls](/guides/tracking/tracing) trace function calls, inputs, and outputs, enabling you to:\n\n- Analyze data flow through your application\n- Debug complex interactions between components\n- Optimize application performance based on call patterns\n\n### Ops\n\n[Ops](/guides/tracking/ops) are automatically versioned and tracked functions (which produce Calls) that allow you to:\n\n- Monitor function performance and behavior\n- Maintain a record of function modifications\n- Ensure experiment reproducibility\n\n### Objects\n\n[Objects](/guides/tracking/objects) form Weave's extensible serialization layer, automatically versioning runtime objects (often the inputs and outputs of Calls). This feature allows you to:\n\n- Track changes in data structures over time\n- Maintain a clear history of object modifications\n- Easily revert to previous versions when needed\n\nBy leveraging these tracing capabilities, you can gain deeper insights into your application's behavior, streamline your development process, and build more robust AI-powered systems.\n\n## FAQs\n\nFor answers to common questions about Weave tracing, see the [FAQs page](./faqs.md)"
  },
  {
    "title": "Tracing",
    "url": "https://weave-docs.wandb.ai/guides/tracking/tracing",
    "section": "Docs",
    "category": "Tracking",
    "content": "import { DesktopWindow } from '../../../src/components/DesktopImage'\n\n\n# Tracing Basics\n\n<DesktopWindow \n  images={[\n    TracingCallsMacroImage,\n    BasicCallImage,\n    TracingCallsFilterImage,\n  ]}\n  alt=\"Screenshot of Weave Calls\"\n  title=\"Weave Calls\"\n/>\n\n:::info[Calls]\nCalls are the fundamental building block in Weave. They represent a single execution of a function, including:\n- Inputs (arguments)\n- Outputs (return value) \n- Metadata (duration, exceptions, LLM usage, etc.)\n\nCalls are similar to spans in the [OpenTelemetry](https://opentelemetry.io) data model. A Call can:\n- Belong to a Trace (a collection of calls in the same execution context)\n- Have parent and child Calls, forming a tree structure\n:::\n\n## Creating Calls\n\nThere are three main ways to create Calls in Weave:\n\n### 1. Automatic tracking of LLM libraries\n\n\n\n  \n    Weave automatically tracks [calls to common LLM libraries](../integrations/index.md) like `openai`, `anthropic`, `cohere`, and `mistral`. Simply call [`weave.init('project_name')`](../../reference/python-sdk/weave/index.md#function-init) at the start of your program:\n\n    > \ud83c\udf1f **Tip**:     You can control Weave's default tracking behavior [using the `autopatch_settings` argument in `weave.init`](#configure-autopatching).\n    :::\n\n    ```python showLineNumbers\n    import weave\n\n    from openai import OpenAI\n    client = OpenAI()\n\n    # Initialize Weave Tracing\n    weave.init('intro-example')\n\n    response = client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": \"How are you?\"\n            }\n        ],\n        temperature=0.8,\n        max_tokens=64,\n        top_p=1,\n    )\n    ```\n\n  \n  \n    Weave automatically tracks [calls to common LLM libraries](../integrations/index.md) like `openai`. Simply call [`await weave.init('project_name')`](../../reference/typescript-sdk/weave/functions/init.md) and wrap your OpenAI client with [`weave.wrapOpenAI`](../../reference/typescript-sdk/weave/functions/wrapOpenAI.md) at the start of your program:\n\n    ```typescript showLineNumbers\n    import OpenAI from 'openai'\n    import * as weave from 'weave'\n\n    const client = weave.wrapOpenAI(new OpenAI())\n\n    // Initialize Weave Tracing\n    await weave.init('intro-example')\n\n    const response = await client.chat.completions.create({\n      model: 'gpt-4',\n      messages: [\n        {\n          role: 'user',\n          content: 'How are you?',\n        },\n      ],\n      temperature: 0.8,\n      max_tokens: 64,\n      top_p: 1,\n    });\n    ```\n\n  \n\n\n### 2. Decorating and wrapping functions\n\nHowever, often LLM applications have additional logic (such as pre/post processing, prompts, etc.) that you want to track.\n\n\n  \n    Weave allows you to manually track these calls using the [`@weave.op`](../../reference/python-sdk/weave/index.md#function-op) decorator. For example:\n\n    ```python showLineNumbers\n    import weave\n\n    # Initialize Weave Tracing\n    weave.init('intro-example')\n\n    # Decorate your function\n    @weave.op\n    def my_function(name: str):\n        return f\"Hello, {name}!\"\n\n    # Call your function -- Weave will automatically track inputs and outputs\n    print(my_function(\"World\"))\n    ```\n\n    You can also track [methods on classes](#4-track-class-and-object-methods).\n\n  \n  \n    Weave allows you to manually track these calls by wrapping your function with [`weave.op`](../../reference/typescript-sdk/weave/functions/op.md). For example:\n\n    ```typescript showLineNumbers\n    import * as weave from 'weave'\n\n    await weave.init('intro-example')\n\n    function myFunction(name: string) {\n        return `Hello, ${name}!`\n    }\n\n    const myFunctionOp = weave.op(myFunction)\n    ```\n\n    You can also define the wrapping inline:\n\n    ```typescript\n    const myFunctionOp = weave.op((name: string) => `Hello, ${name}!`)\n    ```\n\n    This works for both functions as well as methods on classes:\n\n    ```typescript\n    class MyClass {\n        constructor() {\n            this.myMethod = weave.op(this.myMethod)\n        }\n\n        myMethod(name: string) {\n            return `Hello, ${name}!`\n        }\n    }\n    ```\n  \n\n\n\n#### Getting a handle to the call object during execution\n\n\n  \n    Sometimes it is useful to get a handle to the `Call` object itself. You can do this by calling the `op.call` method, which returns both the result and the `Call` object. For example:\n\n    ```python showLineNumbers\n    result, call = my_function.call(\"World\")\n    ```\n\n    Then, `call` can be used to set / update / fetch additional properties (most commonly used to get the ID of the call to be used for feedback).\n\n    > \ud83d\udca1 **Note**:     If your op is a method on a class, you need to pass the instance as the first argument to the op (see example below).\n    :::\n\n    ```python showLineNumbers\n    # Notice that we pass the `instance` as the first argument.\n    print(instance.my_method.call(instance, \"World\"))\n    ```\n\n\n    ```python showLineNumbers\n    import weave\n\n    # Initialize Weave Tracing\n    weave.init(\"intro-example\")\n\n    class MyClass:\n        # Decorate your method\n        @weave.op\n        def my_method(self, name: str):\n            return f\"Hello, {name}!\"\n\n    instance = MyClass()\n\n    # Call your method -- Weave will automatically track inputs and outputs\n    instance.my_method.call(instance, \"World\")\n    ```\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n\n\n#### Call display name\n\n\n  \n    Sometimes you may want to override the display name of a call. You can achieve this in one of four ways:\n\n    1. Change the display name at the time of calling the op:\n\n    ```python showLineNumbers\n    result = my_function(\"World\", __weave={\"display_name\": \"My Custom Display Name\"})\n    ```\n\n    :::note\n\n    Using the `__weave` dictionary sets the call display name which will take precedence over the Op display name.\n\n    :::\n\n    2. Change the display name on a per-call basis. This uses the [`Op.call`](../../reference/python-sdk/weave/trace/weave.trace.op.md#function-call) method to return a `Call` object, which you can then use to set the display name using [`Call.set_display_name`](../../reference/python-sdk/weave/trace/weave.trace.weave_client.md#method-set_display_name).\n    ```python showLineNumbers\n    result, call = my_function.call(\"World\")\n    call.set_display_name(\"My Custom Display Name\")\n    ```\n\n    3. Change the display name for all Calls of a given Op:\n\n    ```python showLineNumbers\n    @weave.op(call_display_name=\"My Custom Display Name\")\n    def my_function(name: str):\n        return f\"Hello, {name}!\"\n    ```\n\n    4. The `call_display_name` can also be a function that takes in a `Call` object and returns a string.  The `Call` object will be passed automatically when the function is called, so you can use it to dynamically generate names based on the function's name, call inputs, fields, etc.\n\n    1. One common use case is just appending a timestamp to the function's name.\n\n        ```py\n        from datetime import datetime\n\n        @weave.op(call_display_name=lambda call: f\"{call.func_name}__{datetime.now()}\")\n        def func():\n            return ...\n        ```\n\n    2. You can also log custom metadata using `.attributes`\n\n        ```py\n        def custom_attribute_name(call):\n            model = call.attributes[\"model\"]\n            revision = call.attributes[\"revision\"]\n            now = call.attributes[\"date\"]\n\n            return f\"{model}__{revision}__{now}\"\n\n        @weave.op(call_display_name=custom_attribute_name)\n        def func():\n            return ...\n\n        with weave.attributes(\n            {\n                \"model\": \"finetuned-llama-3.1-8b\",\n                \"revision\": \"v0.1.2\",\n                \"date\": \"2024-08-01\",\n            }\n        ):\n            func()  # the display name will be \"finetuned-llama-3.1-8b__v0.1.2__2024-08-01\"\n\n\n            with weave.attributes(\n                {\n                    \"model\": \"finetuned-gpt-4o\",\n                    \"revision\": \"v0.1.3\",\n                    \"date\": \"2024-08-02\",\n                }\n            ):\n                func()  # the display name will be \"finetuned-gpt-4o__v0.1.3__2024-08-02\"\n        ```\n\n\n    **Technical Note:** \"Calls\" are produced by \"Ops\". An Op is a function or method that is decorated with `@weave.op`. \n    By default, the Op's name is the function name, and the associated calls will have the same display name. The above example shows how to override the display name for all Calls of a given Op.  Sometimes, users wish to override the name of the Op itself. This can be achieved in one of two ways:\n\n    1. Set the `name` property of the Op before any calls are logged\n    ```python showLineNumbers\n    my_function.name = \"My Custom Op Name\"\n    ```\n\n    2. Set the `name` option on the op decorator\n    ```python showLineNumbers\n    @weave.op(name=\"My Custom Op Name)\n    ```\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n\n\n\n\n#### Attributes\n\n\n  \n    When calling tracked functions, you can add additional metadata to the call by using [`weave.attributes`](../../reference/python-sdk/weave/index.md#function-attributes) context manager. In the example below, we add an `env` attribute to the call specified as `'production'`.\n\n    ```python showLineNumbers\n    # ... continued from above ...\n\n    # Add additional attributes to the call\n    with weave.attributes({'env': 'production'}):\n        print(my_function.call(\"World\"))\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n### 3. Manual Call tracking\n\nYou can also manually create Calls using the API directly.\n\n\n    \n\n        ```python showLineNumbers\n        import weave\n\n        # Initialize Weave Tracing\n        client = weave.init('intro-example')\n\n        def my_function(name: str):\n            # Start a call\n            call = client.create_call(op=\"my_function\", inputs={\"name\": name})\n\n            # ... your function code ...\n\n            # End a call\n            client.finish_call(call, output=\"Hello, World!\")\n\n        # Call your function\n        print(my_function(\"World\"))\n        ```\n\n    \n    \n\n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n\n    \n\n    \n    * Start a call: [POST `/call/start`](../../reference/service-api/call-start-call-start-post.api.mdx)\n    * End a call: [POST `/call/end`](../../reference/service-api/call-end-call-end-post.api.mdx)\n    ```bash\n    curl -L 'https://trace.wandb.ai/call/start' \\\n    -H 'Content-Type: application/json' \\\n    -H 'Accept: application/json' \\\n    -d '{\n        \"start\": {\n            \"project_id\": \"string\",\n            \"id\": \"string\",\n            \"op_name\": \"string\",\n            \"display_name\": \"string\",\n            \"trace_id\": \"string\",\n            \"parent_id\": \"string\",\n            \"started_at\": \"2024-09-08T20:07:34.849Z\",\n            \"attributes\": {},\n            \"inputs\": {},\n            \"wb_run_id\": \"string\"\n        }\n    }\n    ```\n    \n\n\n### 4. Track class and object methods\n\nYou can also track class and object methods.\n\n\n    \n    Track any method on a class using `weave.op`.\n\n    ```python showLineNumbers\n    import weave\n\n    # Initialize Weave Tracing\n    weave.init(\"intro-example\")\n\n    class MyClass:\n        # Decorate your method\n        @weave.op\n        def my_method(self, name: str):\n            return f\"Hello, {name}!\"\n\n    instance = MyClass()\n\n    # Call your method -- Weave will automatically track inputs and outputs\n    print(instance.my_method(\"World\"))\n    ```\n\n    \n    \n\n    :::important\n    **Using decorators in TypeScript**\n\n    To use the `@weave.op` decorator with your TypeScript code, make sure your environment is properly configured:\n\n    - **TypeScript v5.0 or newer**: Decorators are supported out of the box and no additional configuration is required.\n    - **TypeScript older than v5.0**: Enable experimental support for decorators. For more details, see the [official TypeScript documentation on decorators](https://www.typescriptlang.org/docs/handbook/decorators.html).\n    :::\n    \n    #### Decorate a class method\n\n    Use `@weave.op` to trace instance methods.\n\n    ```typescript\n    class Foo {\n        @weave.op\n        async predict(prompt: string) {\n            return \"bar\"\n        }\n    }\n    ```\n\n    #### Decorate a static class method\n\n    Apply `@weave.op` to static methods to monitor utility functions within a class.\n\n    ```typescript\n    class MathOps {\n        @weave.op\n        static square(n: number): number {\n            return n * n;\n        }\n    }\n    ```\n\n    \n\n\n\n## Viewing Calls\n\n    \n    To view a call in the web app:\n    1. Navigate to your project's \"Traces\" tab\n    2. Find the call you want to view in the list\n    3. Click on the call to open its details page\n    \n    The details page will show the call's inputs, outputs, runtime, and any additional metadata.\n    \n    \n    \n    \n    To view a call using the Python API, you can use the [`get_call`](../../reference/python-sdk/weave/trace/weave.trace.weave_client#method-get_call) method:\n\n    ```python\n    import weave\n\n    # Initialize the client\n    client = weave.init(\"your-project-name\")\n\n    # Get a specific call by its ID\n    call = client.get_call(\"call-uuid-here\")\n\n    print(call)\n    ```\n\n    \n    \n    ```typescript showLineNumbers\n    import * as weave from 'weave'\n\n    // Initialize the client\n    const client = await weave.init('intro-example')\n\n    // Get a specific call by its ID\n    const call = await client.getCall('call-uuid-here')\n\n    console.log(call)\n    ```\n    \n\n    \n    To view a call using the Service API, you can make a request to the [`/call/read`](../../reference/service-api/call-read-call-read-post.api.mdx) endpoint.\n\n    ```bash\n    curl -L 'https://trace.wandb.ai/call/read' \\\n    -H 'Content-Type: application/json' \\\n    -H 'Accept: application/json' \\\n    -d '{\n        \"project_id\": \"string\",\n        \"id\": \"string\",\n    }'\n    ```\n    \n\n\n\n## Updating Calls\n\nCalls are mostly immutable once created, however, there are a few mutations which are supported:\n* [Set Display Name](#set-display-name)\n* [Add Feedback](#add-feedback)\n* [Delete a Call](#delete-a-call)\n\nAll of these mutations can be performed from the UI by navigating to the call detail page:\n\n\n\n### Set display name\n\n\n    \n    In order to set the display name of a call, you can use the [`Call.set_display_name`](../../reference/python-sdk/weave/trace/weave.trace.weave_client.md#method-set_display_name) method.\n\n    ```python showLineNumbers\n    import weave\n\n    # Initialize the client\n    client = weave.init(\"your-project-name\")\n\n    # Get a specific call by its ID\n    call = client.get_call(\"call-uuid-here\")\n\n    # Set the display name of the call\n    call.set_display_name(\"My Custom Display Name\")\n    ```\n    \n    \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n    \n    \n    To set the display name of a call using the Service API, you can make a request to the [`/call/update`](../../reference/service-api/call-update-call-update-post.api.mdx) endpoint.\n\n    ```bash\n    curl -L 'https://trace.wandb.ai/call/update' \\\n    -H 'Content-Type: application/json' \\\n    -H 'Accept: application/json' \\\n    -d '{\n        \"project_id\": \"string\",\n        \"call_id\": \"string\",\n        \"display_name\": \"string\",\n    }'\n    ```\n    \n\n\n### Add feedback \n\nPlease see the [Feedback Documentation](./feedback.md) for more details.\n\n### Delete a Call\n\n\n    \n    To delete a Call using the Python API, you can use the [`Call.delete`](../../reference/python-sdk/weave/trace/weave.trace.weave_client.md#method-delete) method.\n\n    ```python showLineNumbers\n    import weave\n\n    # Initialize the client\n    client = weave.init(\"your-project-name\")\n\n    # Get a specific call by its ID\n    call = client.get_call(\"call-uuid-here\")\n    \n    # Delete the call\n    call.delete()\n    ```\n\n    \n    \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n    \n    \n    To delete a call using the Service API, you can make a request to the [`/calls/delete`](../../reference/service-api/calls-delete-calls-delete-post.api.mdx) endpoint.\n\n    ```bash\n    curl -L 'https://trace.wandb.ai/calls/delete' \\\n    -H 'Content-Type: application/json' \\\n    -H 'Accept: application/json' \\\n    -d '{\n        \"project_id\": \"string\",\n        \"call_ids\": [\n            \"string\"\n        ],\n    }'\n    ```\n    \n\n\n### Delete multiple Calls\n\n\n    \n    To delete batches of Calls using the Python API, pass a list of Call IDs to `delete_calls()`.\n\n    :::important\n    - The maximum amount of Calls that can be deleted is `1000`.\n    - Deleting a Call also deletes all of its children.\n    :::\n\n    ```python showLineNumbers\n    import weave\n\n    # Initialize the client\n    client = weave.init(\"my-project\")\n\n    # Get all calls from client \n    all_calls = client.get_calls()\n\n    # Get list of first 1000 Call objects\n    first_1000_calls = all_calls[:1000]\n\n    # Get list of first 1000 Call IDs\n    first_1000_calls_ids = [c.id for c in first_1000_calls]\n\n    # Delete first 1000 Call objects by ID\n    client.delete_calls(call_ids=first_1000_calls_ids)\n    ```\n\n    \n    \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n    \n\n\n## Querying and exporting Calls\n\n<DesktopWindow \n  images={[\n    TracingCallsFilterImage,\n  ]}\n  alt=\"Screenshot of many calls\"\n  title=\"Weave Calls\"\n/>\n\nThe `/calls` page of your project (\"Traces\" tab) contains a table view of all the Calls in your project. From there, you can:\n* Sort\n* Filter\n* Export\n\n\n\nThe Export Modal (shown above) allows you to export your data in a number of formats, as well as shows the Python & CURL equivalents for the selected calls!\nThe easiest way to get started is to construct a view in the UI, then learn more about the export API via the generated code snippets.\n\n\n\n    \n    To fetch calls using the Python API, you can use the [`client.get_calls`](../../reference/python-sdk/weave/trace/weave.trace.weave_client.md#method-get_calls) method:\n\n    ```python\n    import weave\n\n    # Initialize the client\n    client = weave.init(\"your-project-name\")\n\n    # Fetch calls\n    calls = client.get_calls(filter=...)\n    ```\n\n    \n    \n    To fetch calls using the TypeScript API, you can use the [`client.getCalls`](../../reference/typescript-sdk/weave/classes/WeaveClient#getcalls) method.\n    ```typescript\n    import * as weave from 'weave'\n\n    // Initialize the client\n    const client = await weave.init('intro-example')\n\n    // Fetch calls\n    const calls = await client.getCalls(filter=...)\n    ```\n    \n    \n    The most powerful query layer is at the Service API. To fetch calls using the Service API, you can make a request to the [`/calls/stream_query`](../../reference/service-api/calls-query-stream-calls-stream-query-post.api.mdx) endpoint.\n\n    ```bash\n    curl -L 'https://trace.wandb.ai/calls/stream_query' \\\n    -H 'Content-Type: application/json' \\\n    -H 'Accept: application/json' \\\n    -d '{\n    \"project_id\": \"string\",\n    \"filter\": {\n        \"op_names\": [\n            \"string\"\n        ],\n        \"input_refs\": [\n            \"string\"\n        ],\n        \"output_refs\": [\n            \"string\"\n        ],\n        \"parent_ids\": [\n            \"string\"\n        ],\n        \"trace_ids\": [\n            \"string\"\n        ],\n        \"call_ids\": [\n            \"string\"\n        ],\n        \"trace_roots_only\": true,\n        \"wb_user_ids\": [\n            \"string\"\n        ],\n        \"wb_run_ids\": [\n            \"string\"\n        ]\n    },\n    \"limit\": 100,\n    \"offset\": 0,\n    \"sort_by\": [\n        {\n        \"field\": \"string\",\n        \"direction\": \"asc\"\n        }\n    ],\n    \"query\": {\n        \"$expr\": {}\n    },\n    \"include_costs\": true,\n    \"include_feedback\": true,\n    \"columns\": [\n        \"string\"\n    ],\n    \"expand_columns\": [\n        \"string\"\n    ]\n    }'\n    ```\n    \n\n\n{/* ## Compare calls\ninfo[Comming Soon] */}\n\n### Call schema\n\nPlease see the [schema](../../reference/python-sdk/weave/trace_server/weave.trace_server.trace_server_interface#class-callschema) for a complete list of fields.\n\n\n| Property | Type | Description |\n|----------|------|-------------|\n| id | string (uuid) | Unique identifier for the call |\n| project_id | string (optional) | Associated project identifier |\n| op_name | string | Name of the operation (can be a reference) |\n| display_name | string (optional) | User-friendly name for the call |\n| trace_id | string (uuid) | Identifier for the trace this call belongs to |\n| parent_id | string (uuid) | Identifier of the parent call |\n| started_at | datetime | Timestamp when the call started |\n| attributes | Dict[str, Any] | User-defined metadata about the call |\n| inputs | Dict[str, Any] | Input parameters for the call |\n| ended_at | datetime (optional) | Timestamp when the call ended |\n| exception | string (optional) | Error message if the call failed |\n| output | Any (optional) | Result of the call |\n| summary | Optional[SummaryMap] | Post-execution summary information |\n| wb_user_id | Optional[str] | Associated Weights & Biases user ID |\n| wb_run_id | Optional[str] | Associated Weights & Biases run ID |\n| deleted_at | datetime (optional) | Timestamp of call deletion, if applicable |\n\nThe table above outlines the key properties of a Call in Weave. Each property plays a crucial role in tracking and managing function calls:\n\n- The `id`, `trace_id`, and `parent_id` fields help in organizing and relating calls within the system.\n- Timing information (`started_at`, `ended_at`) allows for performance analysis.\n- The `attributes` and `inputs` fields provide context for the call, while `output` and `summary` capture the results.\n- Integration with Weights & Biases is facilitated through `wb_user_id` and `wb_run_id`.\n\nThis comprehensive set of properties enables detailed tracking and analysis of function calls throughout your project.\n\n\nCalculated Fields:\n    * Cost\n    * Duration\n    * Status\n\n## Saved views \n\nYou can save your Trace table configurations, filters, and sorts as _saved views_ for quick access to your preferred setup. You can configure and access saved views via the UI and the Python SDK. For more information, see [Saved Views](/guides/tools/saved-views.md).\n\n## View a W&B run in the Traces table\n\nWith Weave, you can trace function calls in your code and link them directly to the [W&B runs](https://docs.wandb.ai/guides/runs/) in which they were executed. \nWhen you trace a function with @weave.op() and call it inside a wandb.init() context, Weave automatically associates the trace with the W&B run. \nLinks to any associated runs are shown in the Traces table.\n\n### Python example\n\nThe following Python code shows how traced operations are linked to W&B\nruns when executed inside a `wandb.init()` context. These traces appear in the\nWeave UI and are associated with the corresponding run.\n\n```python \nimport wandb\nimport weave\n\ndef example_wandb(projname):\n    # Split projname into entity and project\n    entity, project = projname.split(\"/\", 1)\n\n    # Initialize Weave context for tracing\n    weave.init(projname)\n\n    # Define a traceable operation\n    @weave.op()\n    def say(message: str) -> str:\n        return f\"I said: {message}\"\n\n    # First W&B run\n    with wandb.init(\n        entity=entity,\n        project=project,\n        notes=\"Experiment 1\",\n        tags=[\"baseline\", \"paper1\"],\n    ) as run:\n        say(\"Hello, world!\")\n        say(\"How are you!\")\n        run.log({\"messages\": 2})\n\n    # Second W&B run\n    with wandb.init(\n        entity=entity,\n        project=project,\n        notes=\"Experiment 2\",\n        tags=[\"baseline\", \"paper1\"],\n    ) as run:\n        say(\"Hello, world from experiment 2!\")\n        say(\"How are you!\")\n        run.log({\"messages\": 2})\n\n\nif __name__ == \"__main__\":\n    # Replace this with your actual W&B username/project\n    example_wandb(\"your-username/your-project\")\n```\n\nTo use the code sample:\n\n1. In the terminal, install dependencies:\n\n   ```bash\n   pip install wandb weave\n   ```\n\n2. Log in to W&B:\n\n   ```bash\n   wandb login\n   ```\n\n3. In the script, replace `your-username/your-project` with your actual W&B entity/project.\n4. Run the script:\n\n   ```bash\n   python weave_trace_with_wandb.py\n   ```\n5. Visit [https://weave.wandb.ai](https://weave.wandb.ai) and select your project.\n6. In the **Traces** tab, view the trace output. Links to any associated runs are shown in the Traces table.\n\n## Configure autopatching\n\nBy default, Weave automatically patches and tracks calls to common LLM libraries like `openai`, `anthropic`, `cohere`, and `mistral`.\nYou can control this behavior using the `autopatch_settings` argument in `weave.init`.\n\n### Disable all autopatching\n\n```python showLineNumbers\nweave.init(..., autopatch_settings={\"disable_autopatch\": True})\n```\n\n### Disable a specific integration\n\n```python showLineNumbers\nweave.init(..., autopatch_settings={\"openai\": {\"enabled\": False}})\n```\n\n### Post-process inputs and outputs \n\nYou can also customize how post-process inputs and outputs (e.g. for PII data) are handled during autopatching:\n\n```python showLineNumbers\ndef redact_inputs(inputs: dict) -> dict:\n    if \"email\" in inputs:\n        inputs[\"email\"] = \"[REDACTED]\"\n    return inputs\n\nweave.init(\n    ...,\n    autopatch_settings={\n        \"openai\": {\n            \"op_settings\": {\n                \"postprocess_inputs\": redact_inputs,\n            }\n        }\n    }\n)\n```\n\nFor more details, see [How to use Weave with PII data](../../reference/gen_notebooks/pii.md).\n\n## FAQs\n\n### How do I stop large traces from being truncated?\n\nFor more information, see [Trace data is truncated](../troubleshooting.md#trace-data-is-truncated) in the [Troubleshooting guide](../troubleshooting.md).\n\n### How do I disable tracing?\n\n#### Environment variable\n\nIn situations where you want to unconditionally disable tracing for the entire program, you can set the environment variable `WEAVE_DISABLED=true`.\n\n#### Client initialization\n\nSometimes, you may want to conditionally enable tracing for a specific initialization based on some condition. In this case, you can initialize the client with the `disabled` flag in init settings.\n\n```python\nimport weave\n\n# Initialize the client\nclient = weave.init(..., settings={\"disabled\": True})\n```\n\n#### Context manager\n\nFinally, you may want to conditionally disable tracing for a single function based on some application logic. In this case, you can use the context manager `with set_tracing_enabled(False)` which can be imported from `weave.trace.context.call_context`.\n\n```python\nimport weave\nfrom weave.trace.context.call_context import set_tracing_enabled\n\nclient = weave.init(...)\n\n@weave.op\ndef my_op():\n    ...\n\nwith set_tracing_enabled(False):\n    my_op()\n```\n\n### How do I capture information about a Call?\n\nTypically you would call an op directly:\n\n```python\n@weave.op\ndef my_op():\n    ...\n\nmy_op()\n```\n\nHowever, you can also get access to the call object directly by invoking the `call` method on the op:\n\n```python\n@weave.op\ndef my_op():\n    ...\n\noutput, call = my_op.call()\n```\n\nFrom here, the `call` object will have all the information about the call, including the inputs, outputs, and other metadata."
  },
  {
    "title": "Feedback",
    "url": "https://weave-docs.wandb.ai/guides/tracking/feedback",
    "section": "Docs",
    "category": "Tracking",
    "content": "# Feedback\n\nEfficiently evaluating LLM applications requires robust tooling to collect and analyze feedback. Weave provides an integrated feedback system, allowing users to provide call feedback directly through the UI or programmatically via the SDK. Various feedback types are supported, including emoji reactions, textual comments, and structured data, enabling teams to:\n\n- Build evaluation datasets for performance monitoring.\n- Identify and resolve LLM content issues effectively.\n- Gather examples for advanced tasks like fine-tuning.\n\nThis guide covers how to use Weave\u2019s feedback functionality in both the UI and SDK, query and manage feedback, and use human annotations for detailed evaluations.\n\n- [Provide feedback in the UI](#provide-feedback-in-the-ui)\n- [Provide feedback via the SDK](#provide-feedback-via-the-sdk)\n- [Add human annotations](#add-human-annotations)\n\n## Provide feedback in the UI\n\nIn the Weave UI, you can add and view feedback [from the call details page](#from-the-call-details-page) or [using the icons](#use-the-icons).\n\n### From the call details page\n\n1. In the sidebar, navigate to **Traces**.\n2. Find the row for the call that you want to add feedback to.\n3. Open the call details page.\n4. Select the **Feedback** column for the call.\n5. Add, view, or delete feedback:\n   - _[Add and view feedback using the icons](#use-the-icons)_ located in the upper right corner of the call details feedback view.\n   - _View and delete feedback from the call details feedback table._ Delete feedback by clicking the trashcan icon in the rightmost column of the appropriate feedback row.\n\n\n\n### Use the icons\n\nYou can add or remove a reaction, and add a note using the icons that are located in both the call table and individual call details pages.\n\n- _Call table_: Located in **Feedback** column in the appropriate row in the call table.\n- _Call details page_: Located in the upper right corner of each call details page.\n\nTo add a reaction:\n\n1. Click the emoji icon.\n2. Add a thumbs up, thumbs down, or click the **+** icon for more emojis.\n\nTo remove a reaction:\n\n1. Hover over the emoji reaction you want to remove.\n2. Click the reaction to remove it.\n\n> You can also delete feedback from the [**Feedback** column on the call details page.](#from-the-call-details-page).\n\nTo add a comment:\n\n1. Click the comment bubble icon.\n2. In the text box, add your note.\n3. To save the note, press the **Enter** key. You can add additional notes.\n\n> \ud83d\udea8 **Important**: The maximum number of characters in a feedback note is 1024. If a note exceeds this limit, it will not be created.\n\n\n\n## Provide feedback via the SDK\n\n> You can find SDK usage examples for feedback in the UI under the **Use** tab in the call details page.\n\nYou can use the Weave SDK to programmatically add, remove, and query feedback on calls.\n\n### Query a project's feedback\n\nYou can query the feedback for your Weave project using the SDK. The SDK supports the following feedback query operations:\n\n- `client.get_feedback()`: Returns all feedback in a project.\n- `client.get_feedback(\"\")`: Return a specific feedback object specified by `` as a collection.\n- `client.get_feedback(reaction=\"\")`: Returns all feedback objects for a specific reaction type.\n\nYou can also get additional information for each feedback object in `client.get_feedback()`:\n\n- `id`: The feedback object ID.\n- `created_at`: The creation time information for the feedback object.\n- `feedback_type`: The type of feedback (reaction, note, custom).\n- `payload`: The feedback payload\n\n\n  \n    ```python\n    import weave\n    client = weave.init('intro-example')\n\n    # Get all feedback in a project\n    all_feedback = client.get_feedback()\n\n    # Fetch a specific feedback object by id.\n    # The API returns a collection, which is expected to contain at most one item.\n    one_feedback = client.get_feedback(\"\")[0]\n\n    # Find all feedback objects with a specific reaction. You can specify offset and limit.\n    thumbs_up = client.get_feedback(reaction=\"\ud83d\udc4d\", limit=10)\n\n    # After retrieval, view the details of individual feedback objects.\n    for f in client.get_feedback():\n        print(f.id)\n        print(f.created_at)\n        print(f.feedback_type)\n        print(f.payload)\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n### Add feedback to a call\n\nYou can add feedback to a call using the call's UUID. To use the UUID to get a particular call, [retrieve it during or after call execution](#retrieve-the-call-uuid). The SDK supports the following operations for adding feedback to a call:\n\n- `call.feedback.add_reaction(\"\")`: Add one of the supported `` (emojis), such as \ud83d\udc4d.\n- `call.feedback.add_note(\"\")`: Add a note.\n- `call.feedback.add(\"\", )`: Add a custom feedback `` specified by ``.\n\n> \ud83d\udea8 **Important**: The maximum number of characters in a feedback note is 1024. If a note exceeds this limit, it will not be created.\n\n\n  \n    ```python\n    import weave\n    client = weave.init('intro-example')\n\n    call = client.get_call(\"\")\n\n    # Adding an emoji reaction\n    call.feedback.add_reaction(\"\ud83d\udc4d\")\n\n    # Adding a note\n    call.feedback.add_note(\"this is a note\")\n\n    # Adding custom key/value pairs.\n    # The first argument is a user-defined \"type\" string.\n    # Feedback must be JSON serializable and less than 1 KB when serialized.\n    call.feedback.add(\"correctness\", { \"value\": 5 })\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n#### Retrieve the call UUID\n\nFor scenarios where you need to add feedback immediately after a call, you can retrieve the call UUID programmatically during or after the call execution.\n\n- [During call execution](#during-call-execution)\n- [After call execution](#after-call-execution)\n\n##### During call execution\n\nTo retrieve the UUID during call execution, get the current call, and return the ID.\n\n\n  \n    ```python\n\n    import weave\n    weave.init(\"uuid\")\n\n    @weave.op()\n    def simple_operation(input_value):\n        # Perform some simple operation\n        output = f\"Processed {input_value}\"\n        # Get the current call ID\n        current_call = weave.require_current_call()\n        call_id = current_call.id\n        return output, call_id\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n##### After call execution\n\nAlternatively, you can use `call()` method to execute the operation and retrieve the ID after call execution:\n\n\n  \n    ```python\n    import weave\n    weave.init(\"uuid\")\n\n    @weave.op()\n    def simple_operation(input_value):\n        return f\"Processed {input_value}\"\n\n    # Execute the operation and retrieve the result and call ID\n    result, call = simple_operation.call(\"example input\")\n    call_id = call.id\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n### Delete feedback from a call\n\nYou can delete feedback from a particular call by specifying a UUID.\n\n\n  \n    ```python\n    call.feedback.purge(\"\")\n    ```\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n## Add human annotations\n\nHuman annotations are supported in the Weave UI. To make human annotations, you must first create a Human Annotation scorer using either the [UI](#create-a-human-annotation-scorer-in-the-ui) or the [API](#create-a-human-annotation-scorer-using-the-api). Then, you can [use the scorer in the UI to make annotations](#use-the-human-annotation-scorer-in-the-ui), and [modify your annotation scorers using the API](#modify-a-human-annotation-scorer-using-the-api).\n\n### Create a human annotation scorer in the UI\n\nTo create a human annotation scorer in the UI, do the following:\n\n1. In the sidebar, navigate to **Scorers**.\n2. In the upper right corner, click **+ Create scorer**.\n3. In the configuration page, set:\n   - `Scorer type` to `Human annotation`\n   - `Name`\n   - `Description`\n   - `Type`, which determines the type of feedback that will be collected, such as `boolean` or `integer`.\n4. Click **Create scorer**. Now, you can [use your scorer to make annotations](#use-the-human-annotation-scorer-in-the-ui).\n\nIn the following example, a human annotator is asked to select which type of document the LLM ingested. As such, the `Type` selected for the score configuration is an `enum` containing the possible document types.\n\n\n\n### Use the human annotation scorer in the UI\n\nOnce you [create a human annotation scorer](#create-a-human-annotation-scorer-in-the-ui), it will automatically display in the **Feedback** sidebar of the call details page with the configured options. To use the scorer, do the following:\n\n1. In the sidebar, navigate to **Traces**\n2. Find the row for the call that you want to add a human annotation to.\n3. Open the call details page.\n4. In the upper right corner, click the **Show feedback** button.\n\n   \n\n   Your available human annotation scorers display in the sidebar.\n\n   \n\n5. Make an annotation.\n6. Click **Save**.\n7. In the call details page, click **Feedback** to view the calls table. The new annotation displays in the table. You can also view the annotations in the **Annotations** column in the call table in **Traces**.\n\n   > Refresh the call table to view the most up-to-date information.\n\n\n\n### Create a human annotation scorer using the API\n\nHuman annotation scorers can also be created through the API. Each scorer is its own object, which is created and updated independently. To create a human annotation scorer programmatically, do the following:\n\n1. Import the `AnnotationSpec` class from `weave.flow.annotation_spec`\n2. Use the `publish` method from `weave` to create the scorer.\n\nIn the following example, two scorers are created. The first scorer, `Temperature`, is used to score the perceived temperature of the LLM call. The second scorer, `Tone`, is used to score the tone of the LLM response. Each scorer is created using `save` with an associated object ID (`temperature-scorer` and `tone-scorer`).\n\n\n  \n    ```python\n    import weave\n    from weave.flow.annotation_spec import AnnotationSpec\n\n    client = weave.init(\"feedback-example\")\n\n    spec1 = AnnotationSpec(\n      name=\"Temperature\",\n      description=\"The perceived temperature of the llm call\",\n      field_schema={\n        \"type\": \"number\",\n        \"minimum\": -1,\n        \"maximum\": 1,\n      }\n    )\n    spec2 = AnnotationSpec(\n      name=\"Tone\",\n      description=\"The tone of the llm response\",\n      field_schema={\n        \"type\": \"string\",\n        \"enum\": [\"Aggressive\", \"Neutral\", \"Polite\", \"N/A\"],\n      },\n    )\n    weave.publish(spec1, \"temperature-scorer\")\n    weave.publish(spec2, \"tone-scorer\")\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n### Modify a human annotation scorer using the API\n\nExpanding on [creating a human annotation scorer using the API](#create-a-human-annotation-scorer-using-the-api), the following example creates an updated version of the `Temperature` scorer, by using the original object ID (`temperature-scorer`) on `publish`. The result is an updated object, with a history of all versions.\n\n> You can view human annotation scorer object history in the **Scorers** tab under **Human annotations**.\n\n\n  \n    ```python\n    import weave\n    from weave.flow.annotation_spec import AnnotationSpec\n\n    client = weave.init(\"feedback-example\")\n\n    # create a new version of the scorer\n    spec1 = AnnotationSpec(\n      name=\"Temperature\",\n      description=\"The perceived temperature of the llm call\",\n      field_schema={\n        \"type\": \"integer\",  # <<- change type to integer\n        \"minimum\": -1,\n        \"maximum\": 1,\n      }\n    )\n    weave.publish(spec1, \"temperature-scorer\")\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```\n  \n\n\n\n\n### Use a human annotation scorer using the API\n\nThe feedback API allows you to use a human annotation scorer by specifying a specially constructed name and an `annotation_ref` field. You can obtain the `annotation_spec_ref` from the UI by selecting the appropriate tab, or during the creation of the `AnnotationSpec`.\n\n\n  \n    ```python\n    import weave\n\n    client = weave.init(\"feedback-example\")\n\n    call = client.get_call(\"\")\n    annotation_spec = weave.ref(\"\")\n\n    call.feedback.add(\n      feedback_type=\"wandb.annotation.\" + annotation_spec.name,\n      payload={\"value\": 1},\n      annotation_ref=annotation_spec.uri(),\n    )\n    ```"
  },
  {
    "title": "Redact Pii",
    "url": "https://weave-docs.wandb.ai/guides/tracking/redact-pii",
    "section": "Docs",
    "category": "Tracking",
    "content": "# Redacting PII\n\n> \ud83d\udea8 **Important**: This feature is only accessible via the Python SDK.\n\nSome organizations process Personally Identifiable Information (PII) such as names, phone numbers, and email addresses in their Large Language Model (LLM) workflows. Storing this data in Weights & Biases (W&B) Weave poses compliance and security risks.\n\nThe _Sensitive Data Protection_ feature allows you to automatically redact Personally Identifiable Information (PII) from a [trace](../tracking/index.md) before it is sent to Weave servers. This feature integrates [Microsoft Presidio](https://microsoft.github.io/presidio/) into the Weave Python SDK, which means that you can control redaction settings at the SDK level.\n\nThe Sensitive Data Protection feature introduces the following functionality to the Python SDK:\n\n- A `redact_pii` setting, which can be toggled on or off in the `weave.init` call to enable PII redaction.\n- Automatic redaction of [common entities](#entities-redacted-by-default) when `redact_pii = True`.\n- Customizable redaction fields using the configurable `redact_pii_fields` setting.\n\n## Enable PII redaction\n\nTo get started with the Sensitive Data Protection feature in Weave, complete the following steps:\n\n1. Install the required dependencies:\n\n    ```bash\n    pip install presidio-analyzer presidio-anonymizer\n    ```\n\n2. Modify your `weave.init` call to enable redaction. When `redact_pii=True`, [common entities are redacted by default](#entities-redacted-by-default):\n\n    ```python\n    import weave\n\n    weave.init(\"my-project\", settings={\"redact_pii\": True})\n    ```\n\n3. (Optional) Customize redaction fields using the `redact_pii_fields` parameter:\n\n    ```python\n    weave.init(\"my-project\", settings={\"redact_pii\": True, \"redact_pii_fields\":[\"CREDIT_CARD\", \"US_SSN\"]})\n    ```\n\n    For a full list of the entities that can be detected and redacted, see [PII entities supported by Presidio](https://microsoft.github.io/presidio/supported_entities/).\n\n## Entities redacted by default\n\nThe following entities are automatically redacted when PII redaction is enabled:\n\n- `CREDIT_CARD`\n- `CRYPTO`\n- `EMAIL_ADDRESS`\n- `ES_NIF`\n- `FI_PERSONAL_IDENTITY_CODE`\n- `IBAN_CODE`\n- `IN_AADHAAR`\n- `IN_PAN`\n- `IP_ADDRESS`\n- `LOCATION`\n- `PERSON`\n- `PHONE_NUMBER`\n- `UK_NHS`\n- `UK_NINO`\n- `US_BANK_NUMBER`\n- `US_DRIVER_LICENSE`\n- `US_PASSPORT`\n- `US_SSN`\n\n## Redacting sensitive keys with `REDACT_KEYS`\n\nIn addition to PII redaction, the Weave SDK also supports redaction of custom keys using `REDACT_KEYS`. This is useful when you want to protect additional sensitive data that might not fall under the PII category but needs to be kept private. Examples include:\n\n- API keys\n- Authentication headers\n- Tokens\n- Internal IDs\n- Config values\n\n### Pre-defined `REDACT_KEYS`\n\nWeave automatically redacts the following sensitive keys by default:\n\n```json\n[\n  \"api_key\",\n  \"auth_headers\",\n  \"authorization\"\n]\n```\n\n### Adding your own keys\n\nYou can extend this list with your own custom keys that you want to redact from traces:\n\n```python\nimport weave\n\nclient = weave.init(\"my-project\")\n\n# Add custom keys to redact\nweave.trace.sanitize.REDACT_KEYS.add(\"client_id\")\nweave.trace.sanitize.REDACT_KEYS.add(\"whatever_else\")\n\nclient_id = \"123\"\nwhatever_else = \"456\"\n\n@weave.op()\ndef test():\n    a = client_id\n    b = whatever_else\n    return 1\n```\n\nWhen viewed in the Weave UI, the values of `client_id` and `whatever_else` will appear as `\"REDACTED\"`:\n\n```python\nclient_id = \"REDACTED\"\nwhatever_else = \"REDACTED\"\n```\n\n## Usage information\n\n- This feature is only available in the Python SDK.\n- Enabling redaction increases processing time due to the Presidio dependency."
  },
  {
    "title": "Models",
    "url": "https://weave-docs.wandb.ai/guides/core-types/models",
    "section": "Docs",
    "category": "Core Types",
    "content": "# Models\n\nA `Model` is a combination of data (which can include configuration, trained model weights, or other information) and code that defines how the model operates. By structuring your code to be compatible with this API, you benefit from a structured way to version your application so you can more systematically keep track of your experiments.\n\n\n  \n    To create a model in Weave, you need the following:\n\n    - a class that inherits from `weave.Model`\n    - type definitions on all parameters\n    - a typed `predict` function with `@weave.op()` decorator\n\n    ```python\n    from weave import Model\n    import weave\n\n    class YourModel(Model):\n        attribute1: str\n        attribute2: int\n\n        @weave.op()\n        def predict(self, input_data: str) -> dict:\n            # Model logic goes here\n            prediction = self.attribute1 + ' ' + input_data\n            return {'pred': prediction}\n    ```\n\n    You can call the model as usual with:\n\n    ```python\n    import weave\n    weave.init('intro-example')\n\n    model = YourModel(attribute1='hello', attribute2=5)\n    model.predict('world')\n    ```\n\n    This will track the model settings along with the inputs and outputs anytime you call `predict`.\n\n    ## Automatic versioning of models\n\n    When you change the parameters or the code that defines your model, these changes will be logged and the version will be updated.\n    This ensures that you can compare the predictions across different versions of your model. Use this to iterate on prompts or to try the latest LLM and compare predictions across different settings.\n\n    For example, here we create a new model:\n\n    ```python\n    import weave\n    weave.init('intro-example')\n\n    model = YourModel(attribute1='howdy', attribute2=10)\n    model.predict('world')\n    ```\n\n    After calling this, you will see that you now have two versions of this Model in the UI, each with different tracked calls.\n\n    ## Serve models\n\n    To serve a model, you can easily spin up a FastAPI server by calling:\n\n    ```bash\n    weave serve \n    ```\n\n    For additional instructions, see [serve](/guides/tools/serve).\n\n    ## Track production calls\n\n    To separate production calls, you can add an additional attribute to the predictions for easy filtering in the UI or API.\n\n    ```python\n    with weave.attributes({'env': 'production'}):\n        model.predict('world')\n    ```\n\n  \n  \n    ```plaintext\n    This feature is not available in TypeScript yet.  Stay tuned!\n    ```"
  },
  {
    "title": "Media",
    "url": "https://weave-docs.wandb.ai/guides/core-types/media",
    "section": "Docs",
    "category": "Core Types",
    "content": "# Logging media\n\nWeave supports logging and displaying video, images, and audio.\n\n## Video\n\nWeave automatically logs videos using [`moviepy`](https://zulko.github.io/moviepy/). This allows you to pass video inputs and outputs to traced functions, and Weave will automatically handle uploading and storing video data.\n\n> \ud83d\udca1 **Note**: Video support is currently only available in Python.\n\nFor usage information, see [Video Support](../tracking/video).\n\n## Images\n\nLogging type: `PIL.Image.Image`. \n\n> \ud83d\udea8 **Important**: Base64-encoded image strings (e.g., `data:image/jpeg;base64,...`) are technically supported but discouraged. They can cause performance issues and should only be used if absolutely necessary (e.g., for integration with specific APIs).\n\nThe following example shows how to log an image generated via the OpenAI DALL-E API:\n\n\n  \n  \n    ```python\n    import weave\n    from openai import OpenAI\n    import requests\n    from PIL import Image\n\n    weave.init('image-example')\n    client = OpenAI()\n\n    @weave.op\n    def generate_image(prompt: str) -> Image:\n        response = client.images.generate(\n            model=\"dall-e-3\",\n            prompt=prompt,\n            size=\"1024x1024\",\n            quality=\"standard\",\n            n=1,\n        )\n        image_url = response.data[0].url\n        image_response = requests.get(image_url, stream=True)\n        image = Image.open(image_response.raw)\n\n        # return a PIL.Image.Image object to be logged as an image\n        return image\n\n    generate_image(\"a cat with a pumpkin hat\")\n    ```\n\n  \n  \n\n    ```typescript\n        \n    async function main() {\n        const client = await weave.init('image-example');\n        const openai = new OpenAI();\n\n        const generateImage = weave.op(async (prompt: string) => {\n            const response = await openai.images.generate({\n                model: 'dall-e-3',\n                prompt: prompt,\n                size: '1024x1024',\n                quality: 'standard',\n                n: 1,\n            });\n            const imageUrl = response.data[0].url;\n            const imgResponse = await fetch(imageUrl);\n            const data = Buffer.from(await imgResponse.arrayBuffer());\n\n            return weave.weaveImage({data});\n        });\n\n        generateImage('a cat with a pumpkin hat');\n    }\n\n    main();\n    ```\n\n  \n\n\nThis image is logged to Weave and automatically displayed in the UI. \n\n\n\n## Audio\n\nLogging type: `wave.Wave_read`. \n\nThe following example shows how to log an audio file using OpenAI's speech generation API.\n\n\n  \n  \n    ```python\n    import weave\n    from openai import OpenAI\n    import wave\n\n    weave.init(\"audio-example\")\n    client = OpenAI()\n\n\n    @weave.op\n    def make_audio_file_streaming(text: str) -> wave.Wave_read:\n        with client.audio.speech.with_streaming_response.create(\n            model=\"tts-1\",\n            voice=\"alloy\",\n            input=text,\n            response_format=\"wav\",\n        ) as res:\n            res.stream_to_file(\"output.wav\")\n\n        # return a wave.Wave_read object to be logged as audio\n        return wave.open(\"output.wav\")\n\n    make_audio_file_streaming(\"Hello, how are you?\")\n    ```\n\n  \n  \n\n    ```typescript\n        \n    async function main() {\n        await weave.init('audio-example');\n        const openai = new OpenAI();\n\n        const makeAudioFileStreaming = weave.op(async function audio(text: string) {\n            const response = await openai.audio.speech.create({\n                model: 'tts-1',\n                voice: 'alloy',\n                input: text,\n                response_format: 'wav',\n            });\n\n            const chunks: Uint8Array[] = [];\n            for await (const chunk of response.body) {\n                chunks.push(chunk);\n            }\n            return weave.weaveAudio({data: Buffer.concat(chunks)});\n        });\n\n        await makeAudioFileStreaming('Hello, how are you?');\n    }\n\n    main();\n    ```\n\n  \n\n\nThis audio is logged to Weave and automatically displayed in the UI, along with an audio player. In the audio player, you can view and download the raw audio waveform.\n\n\n\n> \ud83c\udf1f **Tip**: Try our cookbook for [Audio Logging](/reference/gen_notebooks/audio_with_weave) or Open in Colab. The cookbook also includes an advanced example of a Real Time Audio API based assistant integrated with Weave."
  },
  {
    "title": "Env Vars",
    "url": "https://weave-docs.wandb.ai/guides/core-types/env-vars",
    "section": "Docs",
    "category": "Core Types",
    "content": "# Environment variables\n\nWeave provides a set of environment variables to configure and optimize its behavior. You can set these variables in your shell or within scripts to control specific functionality.\n\n```bash\n# Example of setting environment variables in the shell\nexport WEAVE_PARALLELISM=10  # Controls the number of parallel workers\nexport WEAVE_PRINT_CALL_LINK=false  # Disables call link output\n```\n\n```python\n# Example of setting environment variables in Python\nimport os\n\nos.environ[\"WEAVE_PARALLELISM\"] = \"10\"\nos.environ[\"WEAVE_PRINT_CALL_LINK\"] = \"false\"\n```\n\n## Available Environment Variables\n\n| Variable | Type | Default | Description |\n|----------|------|---------|-------------|\n| `WANDB_API_KEY` | `string` | `None` | If set, automatically log into W&B Weave without being prompted for your API key. To generate an API key, log in to your W&B account and go to [https://wandb.ai/authorize](https://wandb.ai/authorize). |\n| `WEAVE_DISABLED` | `bool` | `false` | When set to `true`, disables all Weave tracing. Weave ops will behave like regular functions. |\n| `WEAVE_PRINT_CALL_LINK` | `bool` | `true` | Controls whether to print a link to the Weave UI when calling a Weave op. |\n| `WEAVE_CAPTURE_CODE` | `bool` | `true` | Controls whether to save code for ops so they can be reloaded for later use. |\n| `WEAVE_DEBUG_HTTP` | `bool` | `false` | When set to `true`, turns on HTTP request and response logging for debugging. |\n| `WEAVE_PARALLELISM` | `int` | `20` | In evaluations, controls the number of examples to evaluate in parallel. Set to `1` to run examples sequentially. |\n| `WEAVE_TRACE_LANGCHAIN` | `bool` | `true` | Controls global tracing for LangChain. Set to `false` to explicitly disable LangChain tracing. |\n| `WEAVE_USE_SERVER_CACHE` | `bool` | `false` | Enables server response caching. When enabled, responses from the server are cached to disk to improve performance for repeated queries. |\n| `WEAVE_SERVER_CACHE_SIZE_LIMIT` | `int` | `1000000000` | Sets the maximum size limit for the server cache in bytes. When the cache reaches this size, older entries are automatically removed to make space for new ones. Important: the underlying implementation uses SQLite which has a Write Ahead Log (WAL) that will grow to 4MB regardless of this setting. This WAL will be removed when the program exits. |\n| `WEAVE_SERVER_CACHE_DIR` | `str` | `None` | Specifies the directory where cache files should be stored. If not set, a temporary directory is used. |\n| `WEAVE_MAX_CALLS_QUEUE_SIZE` | `int` | `100000` | Sets the maximum size of the calls queue.  Defaults to 100_000.  Setting a value of 0 means the queue can grow unbounded. |\n| `WEAVE_RETRY_MAX_ATTEMPTS` | `int` | `3` | Sets the maximum number of retry attempts for failed requests. |\n| `WEAVE_RETRY_MAX_INTERVAL` | `float` | `300.0` | Sets the maximum interval between retry attempts in seconds. |\n| `WANDB_BASE_URL` | `string` | `None` | Sets the Weave host URL. Equivalent to entering the host URL when prompted by `wandb.login()`. You can specify `WANDB_BASE_URL` and `WANDB_API_KEY` before using `weave.init()` to automatically log into and authenticate to Weave. |\n\n> \ud83d\udca1 **Note**: All boolean environment variables accept the following values (case-insensitive):\n- `true`, `1`, `yes`, `on` for True\n- `false`, `0`, `no`, `off` for False"
  },
  {
    "title": "Datasets",
    "url": "https://weave-docs.wandb.ai/guides/core-types/datasets",
    "section": "Docs",
    "category": "Core Types",
    "content": "# Datasets\n\nWeave `Dataset`s help you to organize, collect, track, and version examples for LLM application evaluation for easy comparison. You can create and interact with `Dataset`s programmatically and via the UI. \n\nThis page describes:\n\n- Basic `Dataset` operations in Python and TypeScript and how to get started  \n- How to create a `Dataset` in Python and TypeScript from objects such as Weave [calls](../tracking/tracing.mdx)\n- Available operations on a `Dataset` in the UI\n\n## `Dataset` quickstart\n\nThe following code samples demonstrate how to perform fundamental `Dataset` operations using Python and TypeScript. Using the SDKs, you can:\n\n- Create a `Dataset`\n- Publish the `Dataset`\n- Retrieve the `Dataset`\n- Access a specific example in the `Dataset`\n\nSelect a tab to see Python and TypeScript-specific code. \n\n\n  \n    ```python\n    import weave\n    from weave import Dataset\n    # Initialize Weave\n    weave.init('intro-example')\n\n    # Create a dataset\n    dataset = Dataset(\n        name='grammar',\n        rows=[\n            {'id': '0', 'sentence': \"He no likes ice cream.\", 'correction': \"He doesn't like ice cream.\"},\n            {'id': '1', 'sentence': \"She goed to the store.\", 'correction': \"She went to the store.\"},\n            {'id': '2', 'sentence': \"They plays video games all day.\", 'correction': \"They play video games all day.\"}\n        ]\n    )\n\n    # Publish the dataset\n    weave.publish(dataset)\n\n    # Retrieve the dataset\n    dataset_ref = weave.ref('grammar').get()\n\n    # Access a specific example\n    example_label = dataset_ref.rows[2]['sentence']\n    ```\n\n  \n  \n    ```typescript\n    \n    // Initialize Weave\n    await weave.init('intro-example');\n\n    // Create a dataset\n    const dataset = new weave.Dataset({\n        name: 'grammar',\n        rows: [\n            {id: '0', sentence: \"He no likes ice cream.\", correction: \"He doesn't like ice cream.\"},\n            {id: '1', sentence: \"She goed to the store.\", correction: \"She went to the store.\"},\n            {id: '2', sentence: \"They plays video games all day.\", correction: \"They play video games all day.\"}\n        ]\n    });\n\n    // Publish the dataset\n    await dataset.save();\n\n    // Access a specific example\n    const exampleLabel = datasetRef.getRow(2).sentence;\n    ```\n\n  \n\n\n## Create a `Dataset` from other objects\n\n\n  \n  In Python, `Dataset`s can also be constructed from common Weave objects like [calls](../tracking/tracing.mdx), and Python objects like `pandas.DataFrame`s. This feature is useful if you want to create an example `Dataset` from specific examples.\n\n  ### Weave call\n\n  To create a `Dataset` from one or more Weave calls, retrieve the call object(s), and add them to a list in the `from_calls` method.\n\n  ```python\n  @weave.op\n  def model(task: str) -> str:\n      return f\"Now working on {task}\"\n\n  res1, call1 = model.call(task=\"fetch\")\n  res2, call2 = model.call(task=\"parse\")\n\n  dataset = Dataset.from_calls([call1, call2])\n  # Now you can use the dataset to evaluate the model, etc.\n  ```\n\n  ### Pandas DataFrame\n\n  To create a `Dataset` from a Pandas `DataFrame` object, use the `from_pandas` method. \n\n  To convert the `Dataset` back, use `to_pandas`.\n\n  ```python\n  import pandas as pd\n\n  df = pd.DataFrame([\n      {'id': '0', 'sentence': \"He no likes ice cream.\", 'correction': \"He doesn't like ice cream.\"},\n      {'id': '1', 'sentence': \"She goed to the store.\", 'correction': \"She went to the store.\"},\n      {'id': '2', 'sentence': \"They plays video games all day.\", 'correction': \"They play video games all day.\"}\n  ])\n  dataset = Dataset.from_pandas(df)\n  df2 = dataset.to_pandas()\n\n  assert df.equals(df2)\n  ```\n\n  \n  \n   This feature is not currently available in TypeScript.  Stay tuned!\n  \n\n\n## Create, edit, and delete a `Dataset` in the UI\n\nYou can create, edit, and delete `Dataset`s in the UI.\n\n### Create a new `Dataset`\n\n1. Navigate to the Weave project you want to edit.\n\n2. In the sidebar, select **Traces**.\n\n3. Select one or more calls that you want to create a new `Dataset` for.\n\n4. In the upper right-hand menu, click the **Add selected rows to a dataset** icon (located next to the trashcan icon).\n\n5. From the **Choose a dataset** dropdown, select **Create new**. The **Dataset name** field appears.\n\n6. In the **Dataset name** field, enter a name for your dataset. Options to **Configure dataset fields**  appear.\n\n    :::important\n    Dataset names must start with a letter or number and can only contain letters, numbers, hyphens, and underscores.\n    :::\n\n7. (Optional) In **Configure dataset fields**, select the fields from your calls to include in the dataset.  \n    - You can customize the column names for each selected field.\n    - You can select a subset of fields to include in the new `Dataset`, or deselect all fields.\n\n8. Once you've configured the dataset fields, click **Next**. A preview of your new `Dataset` appears. \n\n9. (Optional) Click any of the editable fields in your **Dataset** to edit the entry.\n\n10. Click **Create dataset**. Your new dataset is created.\n\n11. In the confirmation popup, click **View the dataset** to view the new `Dataset`. Alternatively, go to the **Datasets** tab.\n\n### Edit a `Dataset` \n\n1. Navigate to the Weave project containing the `Dataset` you want to edit.\n\n2. From the sidebar, select **Datasets**. Your available `Dataset`s display.\n\n   \n\n3. In the **Object** column, click the name and version of the `Dataset` you want to edit. A pop-out modal showing `Dataset` information like name, version, author, and `Dataset` rows displays.\n\n   \n\n4. In the upper right-hand corner of the modal, click the **Edit dataset** button (the pencil icon). An **+ Add row** button displays at the bottom of the modal.\n\n    \n\n5. Click **+ Add row**. A green row displays at the top of your existing `Dataset` rows, indicating that you can add a new row to the `Dataset`. \n\n    \n\n6. To add data to a new row, click the desired column within that row. The default **id** column in a `Dataset` row cannot be edited, as Weave assigns it automatically upon creation. An editing modal appears with **Text**, **Code**, and **Diff** options for formatting.\n\n    \n\n7. Repeat step 6 for each column that you want to add data to in the new row. \n\n    \n\n8. Repeat step 5 for each row that you want to add to the `Dataset`.\n\n9. Once you're done editing, publish your `Dataset` by clicking **Publish** in the upper right-hand corner of the modal. Alternatively, if you don't want to publish your changes, click **Cancel**. \n\n    \n\n   Once published, the new version of the `Dataset` with updated rows is available in the UI. \n\n     \n     \n   \n### Delete a `Dataset`\n\n1. Navigate to the Weave project containing the `Dataset` you want to edit.\n\n2. From the sidebar, select **Datasets**. Your available `Dataset`s display.\n\n3. In the **Object** column, click the name and version of the `Dataset` you want to delete. A pop-out modal showing `Dataset` information like name, version, author, and `Dataset` rows displays.\n\n4. In the upper right-hand corner of the modal, click the trashcan icon. \n\n   A pop-up modal prompting you to confirm `Dataset` deletion displays. \n\n   \n\n5. In the pop-up modal, click the red **Delete** button to delete the `Dataset`. Alternatively, click **Cancel** if you don't want to delete the `Dataset`. \n\n   Now, the `Dataset` is deleted, and no longer visible in the **Datasets** tab in your Weave dashboard.\n\n### Add a new example to a `Dataset`\n\n1. Navigate to the Weave project you want to edit.\n\n2. In the sidebar, select **Traces**.\n\n3. Select one or more calls with `Datasets` for which you want to create new examples.\n\n4. In the upper right-hand menu, click the **Add selected rows to a dataset** icon (located next to the trashcan icon). Optionally, toggle **Show latest versions** to off to display all versions of all available datasets.\n\n5. From the **Choose a dataset** dropdown, select the `Dataset` you want to add examples to. Options to **Configure field mapping** will display.\n\n6. (Optional) In **Configure field mapping**, you can adjust the mapping of fields from your calls to the corresponding dataset columns.\n\n7. Once you've configured field mappings, click **Next**. A preview of your new `Dataset` appears.\n\n8. In the empty row (green), add your new example value(s). Note that the **id** field is not editable and is created automatically by Weave.\n\n9. Click **Add to dataset**. Alternatively, to return to the **Configure field mapping** screen, click **Back**.\n\n10. In the confirmation popup, click **View the dataset** to see the changes. Alternatively, navigate to the **Datasets** tab to view the updates to your `Dataset`."
  },
  {
    "title": "Prompts",
    "url": "https://weave-docs.wandb.ai/guides/core-types/prompts",
    "section": "Docs",
    "category": "Core Types",
    "content": "# Prompts\n\n> \ud83d\udea8 **Important**: This feature is only accessible through the Python SDK. All code examples on this page are provided in Python.\n\nCreating, evaluating, and refining prompts is a core activity for AI engineers.\nSmall changes to a prompt can have big impacts on your application's behavior.\nWeave lets you create prompts, save and retrieve them, and evolve them over time.\n\nWeave is unopinionated about how a Prompt is constructed. If your needs are simple you can use our built-in `weave.StringPrompt` or `weave.MessagesPrompt` classes. If your needs are more complex you can subclass those or our base class `weave.Prompt` and override the\n`format` method.\n\nWhen you publish one of these objects with `weave.publish`, it will appear in your Weave project on the \"Prompts\" page.\n\n## StringPrompt\n\n```python\nimport weave\nweave.init('intro-example')\nsystem_prompt = weave.StringPrompt(\"You are a pirate\")\nweave.publish(system_prompt, name=\"pirate_prompt\")\n\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-4o\",\n  messages=[\n    {\n      \"role\": \"system\",\n      \"content\": system_prompt.format()\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Explain general relativity in one paragraph.\"\n    }\n  ],\n)\n```\n\nPerhaps this prompt does not yield the desired effect, so we modify the prompt to be more\nclearly instructive.\n\n```python\nimport weave\nweave.init('intro-example')\nsystem_prompt = weave.StringPrompt(\"Talk like a pirate. I need to know I'm listening to a pirate.\")\nweave.publish(system_prompt, name=\"pirate_prompt\")\n\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-4o\",\n  messages=[\n    {\n      \"role\": \"system\",\n      \"content\": system_prompt.format()\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Explain general relativity in one paragraph.\"\n    }\n  ],\n)\n```\n\nWhen viewing this prompt object, I can see that it has two versions.\n\n\n\nI can also select them for comparison to see exactly what changed.\n\n\n\n## MessagesPrompt\n\nThe `MessagesPrompt` can be used to replace an array of Message objects.\n\n```python\nimport weave\nweave.init('intro-example')\nprompt = weave.MessagesPrompt([\n    {\n        \"role\": \"system\",\n        \"content\": \"You are a stegosaurus, but don't be too obvious about it.\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"What's good to eat around here?\"\n    }\n])\nweave.publish(prompt, name=\"dino_prompt\")\n\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-4o\",\n  messages=prompt.format(),\n)\n```\n\n## Parameterizing prompts\n\nAs the `format` method's name suggests, you can pass arguments to\nfill in template placeholders in the content string.\n\n```python\nimport weave\nweave.init('intro-example')\nprompt = weave.StringPrompt(\"Solve the equation {equation}\")\nweave.publish(prompt, name=\"calculator_prompt\")\n\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-4o\",\n  messages=[\n    {\n      \"role\": \"user\",\n      \"content\": prompt.format(equation=\"1 + 1 = ?\")\n    }\n  ],\n)\n```\n\nThis also works with `MessagesPrompt`.\n\n```python\nimport weave\nweave.init('intro-example')\nprompt = weave.MessagesPrompt([\n{\n    \"role\": \"system\",\n    \"content\": \"You will be provided with a description of a scene and your task is to provide a single word that best describes an associated emotion.\"\n},\n{\n    \"role\": \"user\",\n    \"content\": \"{scene}\"\n}\n])\nweave.publish(prompt, name=\"emotion_prompt\")\n\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-4o\",\n  messages=prompt.format(scene=\"A dog is lying on a dock next to a fisherman.\"),\n)\n```"
  },
  {
    "title": "Evaluations",
    "url": "https://weave-docs.wandb.ai/guides/core-types/evaluations",
    "section": "Docs",
    "category": "Core Types",
    "content": "# Evaluation Overview\n\nEvaluation-driven development helps you reliably iterate on an application. The `Evaluation` class is designed to assess the performance of a `Model` on a given `Dataset` or set of examples using scoring functions.\n\n\n\n```python\nimport weave\nfrom weave import Evaluation\nimport asyncio\n\n# Collect your examples\nexamples = [\n    {\"question\": \"What is the capital of France?\", \"expected\": \"Paris\"},\n    {\"question\": \"Who wrote 'To Kill a Mockingbird'?\", \"expected\": \"Harper Lee\"},\n    {\"question\": \"What is the square root of 64?\", \"expected\": \"8\"},\n]\n\n# Define any custom scoring function\n@weave.op()\ndef match_score1(expected: str, output: dict) -> dict:\n    # Here is where you'd define the logic to score the model output\n    return {'match': expected == output['generated_text']}\n\n@weave.op()\ndef function_to_evaluate(question: str):\n    # here's where you would add your LLM call and return the output\n    return  {'generated_text': 'Paris'}\n\n# Score your examples using scoring functions\nevaluation = Evaluation(\n    dataset=examples, scorers=[match_score1]\n)\n\n# Start tracking the evaluation\nweave.init('intro-example')\n# Run the evaluation\nasyncio.run(evaluation.evaluate(function_to_evaluate))\n```\n\n:::info Looking for a less opinionated approach?\n\nIf you prefer a more flexible evaluation framework, check out Weave's [`EvaluationLogger`](../evaluation/evaluation_logger.md). The imperative approach offers more flexibility for complex workflows, while the standard evaluation framework provides more structure and guidance.\n:::\n\n## Create an Evaluation\n\nTo systematically improve your application, it's helpful to test your changes against a consistent dataset of potential inputs so that you catch regressions and can inspect your apps behaviour under different conditions. Using the `Evaluation` class, you can be sure you're comparing apples-to-apples by keeping track of all of the details that you're experimenting and evaluating with.\n\nWeave will take each example, pass it through your application and score the output on multiple custom scoring functions. By doing this, you'll have a view of the performance of your application, and a rich UI to drill into individual outputs and scores.\n\n### Define an evaluation dataset\n\nFirst, define a [Dataset](/guides/core-types/datasets) or list of dictionaries with a collection of examples to be evaluated. These examples are often failure cases that you want to test for, these are similar to unit tests in Test-Driven Development (TDD).\n\n### Defining scoring functions\n\nThen, create a list of scoring functions. These are used to score each example. Each function should have a `output` and optionally, other inputs from your examples, and return a dictionary with the scores.\n\nScoring functions need to have a `output` keyword argument, but the other arguments are user defined and are taken from the dataset examples. It will only take the necessary keys by using a dictionary key based on the argument name.\n\nThis will take `expected` from the dictionary for scoring.\n\n```python\nimport weave\n\n# Collect your examples\nexamples = [\n    {\"question\": \"What is the capital of France?\", \"expected\": \"Paris\"},\n    {\"question\": \"Who wrote 'To Kill a Mockingbird'?\", \"expected\": \"Harper Lee\"},\n    {\"question\": \"What is the square root of 64?\", \"expected\": \"8\"},\n]\n\n# Define any custom scoring function\n@weave.op()\ndef match_score1(expected: str, output: dict) -> dict:\n    # Here is where you'd define the logic to score the model output\n    return {'match': expected == output['generated_text']}\n```\n\n### Optional: Define a custom `Scorer` class\n\nIn some applications we want to create custom `Scorer` classes - where for example a standardized `LLMJudge` class should be created with specific parameters (e.g. chat model, prompt), specific scoring of each row, and specific calculation of an aggregate score.\n\nSee the tutorial on defining a `Scorer` class in the next chapter on [Model-Based Evaluation of RAG applications](/tutorial-rag#optional-defining-a-scorer-class) for more information.\n\n### Define a Model to evaluate\n\nTo evaluate a `Model`, call `evaluate` on it using an `Evaluation`. `Models` are used when you have parameters that you want to experiment with and capture in weave.\n\n```python\nfrom weave import Model, Evaluation\nimport asyncio\n\nclass MyModel(Model):\n    prompt: str\n\n    @weave.op()\n    def predict(self, question: str):\n        # here's where you would add your LLM call and return the output\n        return {'generated_text': 'Hello, ' + self.prompt}\n\nmodel = MyModel(prompt='World')\n\nevaluation = Evaluation(\n    dataset=examples, scorers=[match_score1]\n)\nweave.init('intro-example') # begin tracking results with weave\nasyncio.run(evaluation.evaluate(model))\n```\n\nThis will run `predict` on each example and score the output with each scoring functions.\n\n#### Custom Naming\n\nYou can change the name of the Evaluation itself by passing a `name` parameter to the `Evaluation` class.\n\n```python\nevaluation = Evaluation(\n    dataset=examples, scorers=[match_score1], name=\"My Evaluation\"\n)\n```\n\nYou can also change the name of individual evaluations by setting the `display_name` key of the `__weave` dictionary.\n\n> \ud83d\udca1 **Note**: Using the `__weave` dictionary sets the call display name which is distinct from the Evaluation object name. In the\nUI, you will see the display name if set, otherwise the Evaluation object name will be used.\n\n\n```python\nevaluation = Evaluation(\n    dataset=examples, scorers=[match_score1]\n)\nevaluation.evaluate(model, __weave={\"display_name\": \"My Evaluation Run\"})\n```\n\n### Define a function to evaluate\n\nAlternatively, you can also evaluate a function that is wrapped in a `@weave.op()`.\n\n```python\n@weave.op()\ndef function_to_evaluate(question: str):\n    # here's where you would add your LLM call and return the output\n    return  {'generated_text': 'some response'}\n\nasyncio.run(evaluation.evaluate(function_to_evaluate))\n```\n\n### Pulling it all together\n\n```python\nfrom weave import Evaluation, Model\nimport weave\nimport asyncio\nweave.init('intro-example')\nexamples = [\n    {\"question\": \"What is the capital of France?\", \"expected\": \"Paris\"},\n    {\"question\": \"Who wrote 'To Kill a Mockingbird'?\", \"expected\": \"Harper Lee\"},\n    {\"question\": \"What is the square root of 64?\", \"expected\": \"8\"},\n]\n\n@weave.op()\ndef match_score1(expected: str, output: dict) -> dict:\n    return {'match': expected == output['generated_text']}\n\n@weave.op()\ndef match_score2(expected: dict, output: dict) -> dict:\n    return {'match': expected == output['generated_text']}\n\nclass MyModel(Model):\n    prompt: str\n\n    @weave.op()\n    def predict(self, question: str):\n        # here's where you would add your LLM call and return the output\n        return {'generated_text': 'Hello, ' + question + self.prompt}\n\nmodel = MyModel(prompt='World')\nevaluation = Evaluation(dataset=examples, scorers=[match_score1, match_score2])\n\nasyncio.run(evaluation.evaluate(model))\n\n@weave.op()\ndef function_to_evaluate(question: str):\n    # here's where you would add your LLM call and return the output\n    return  {'generated_text': 'some response' + question}\n\nasyncio.run(evaluation.evaluate(function_to_evaluate))\n```\n\n## Advanced evaluation usage\n\n### Using `preprocess_model_input` to format dataset rows before evaluating\n\n> \ud83d\udea8 **Important**: The `preprocess_model_input` function is only applied to inputs before passing them to the model's prediction function.  \nScorer functions always receive the original dataset example, without any preprocessing applied.\n\nThe `preprocess_model_input` parameter allows you to transform your dataset examples before they are passed to your evaluation function. This is useful when you need to:\n\n- Rename fields to match your model's expected input\n- Transform data into the correct format\n- Add or remove fields\n- Load additional data for each example\n\nHere's a simple example that shows how to use `preprocess_model_input` to rename fields:\n\n```python\nimport weave\nfrom weave import Evaluation\nimport asyncio\n\n# Our dataset has \"input_text\" but our model expects \"question\"\nexamples = [\n    {\"input_text\": \"What is the capital of France?\", \"expected\": \"Paris\"},\n    {\"input_text\": \"Who wrote 'To Kill a Mockingbird'?\", \"expected\": \"Harper Lee\"},\n    {\"input_text\": \"What is the square root of 64?\", \"expected\": \"8\"},\n]\n\n@weave.op()\ndef preprocess_example(example):\n    # Rename input_text to question\n    return {\n        \"question\": example[\"input_text\"]\n    }\n\n@weave.op()\ndef match_score(expected: str, output: dict) -> dict:\n    return {'match': expected == output['generated_text']}\n\n@weave.op()\ndef function_to_evaluate(question: str):\n    return {'generated_text': f'Answer to: {question}'}\n\n# Create evaluation with preprocessing\nevaluation = Evaluation(\n    dataset=examples,\n    scorers=[match_score],\n    preprocess_model_input=preprocess_example\n)\n\n# Run the evaluation\nweave.init('preprocessing-example')\nasyncio.run(evaluation.evaluate(function_to_evaluate))\n```\n\nIn this example, our dataset contains examples with an `input_text` field, but our evaluation function expects a `question` parameter. The `preprocess_example` function transforms each example by renaming the field, allowing the evaluation to work correctly.\n\nThe preprocessing function:\n\n1. Receives the raw example from your dataset\n2. Returns a dictionary with the fields your model expects\n3. Is applied to each example before it's passed to your evaluation function\n\nThis is particularly useful when working with external datasets that may have different field names or structures than what your model expects.\n\n### Using HuggingFace Datasets with evaluations\n\nWe are continuously improving our integrations with third-party services and libraries.\n\nWhile we work on building more seamless integrations, you can use `preprocess_model_input` as a temporary workaround for using HuggingFace Datasets in Weave evaluations.\n\nSee our [Using HuggingFace Datasets in evaluations cookbook](/reference/gen_notebooks/hf_dataset_evals) for the current approach.\n\n## Saved views \n\nYou can save your Evals table configurations, filters, and sorts as _saved views_ for quick access to your preferred setup. You can configure and access saved views via the UI and the Python SDK. For more information, see [Saved Views](/guides/tools/saved-views.md)."
  }
]