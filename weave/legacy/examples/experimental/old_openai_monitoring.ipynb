{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "30ccfdbc",
      "metadata": {},
      "source": [
        "This notebook shows how to use our openai logging integration to monitor api calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8107732a-fb90-45f8-8377-6381bd28475d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import weave\n",
        "weave.use_frontend_devmode()\n",
        "from weave.legacy.weave.monitoring import openai, init_monitor\n",
        "\n",
        "OPENAI_MODEL = 'gpt-3.5-turbo'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba2b2070",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pass <wandb_team_or_user>/<wandb_project>/<table_name>\n",
        "m = init_monitor('shawn/oai-mon/test21')\n",
        "\n",
        "# Do an initial request, otherwise we don't have a type on which to recommend the OpenAI board!\n",
        "# We need at least 2 requests for the Board to work, otherwise we get divide by zero errors.\n",
        "# TODO: fix this onboarding issue\n",
        "r = openai.ChatCompletion.create(model=OPENAI_MODEL, messages=[{\"role\": \"user\", \"content\": f\"hello world!\"}])\n",
        "r = openai.ChatCompletion.create(model=OPENAI_MODEL, messages=[{\"role\": \"user\", \"content\": f\"what is 2+2?\"}])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb51abb4",
      "metadata": {},
      "source": [
        "Click the link above to go to the Weave UI for the table we're logging to.\n",
        "\n",
        "From there you can click \"OpenAI Monitor Board\" to create a Weave Board for this data stream."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e711d521",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monitor ChatCompletion requests\n",
        "r = openai.ChatCompletion.create(model=OPENAI_MODEL, messages=[\n",
        "        {\"role\": \"user\", \"content\": f\"who won the world series in 2006?\"},\n",
        "    ])\n",
        "r['choices'][0]['message']['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7930e774",
      "metadata": {},
      "outputs": [],
      "source": [
        "# To keep track of prompts and parameters, add them to attributes on the logged\n",
        "# record.\n",
        "\n",
        "system_prompt = \"you always write in bullet points\"\n",
        "prompt = 'solve the following equation step by step: {equation}'\n",
        "params = {'equation': '4 * (3 - 1)'}\n",
        "openai.ChatCompletion.create(model=OPENAI_MODEL,\n",
        "                             messages=[\n",
        "                                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                                    {\"role\": \"user\", \"content\": prompt.format(**params)},\n",
        "                                ],\n",
        "                             # you can add additional attributes to the logged record\n",
        "                             # see the monitor_api notebook for more examples\n",
        "                             monitor_attributes={\n",
        "                                 'system_prompt': system_prompt,\n",
        "                                 'prompt': prompt,\n",
        "                                 'params': params\n",
        "                             })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8b423df",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monitor streaming requests\n",
        "# TODO: we don't get token counts here yet.\n",
        "from weave.legacy.weave.monitoring.openai import message_from_stream\n",
        "r = openai.ChatCompletion.create(model=OPENAI_MODEL, messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Your are a robot and only speak in robot, like beep bloop bop.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Tell me a 50 word story.\"},\n",
        "    ], stream=True)\n",
        "for s in message_from_stream(r):\n",
        "    print(s, end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bca62fdb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Render table inline\n",
        "#m.rows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdae9ba5-aa2b-4191-9a42-c1078ba0698a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Render board inline\n",
        "# from weave.legacy.weave.panels_py import panel_llm_monitor\n",
        "# board = panel_llm_monitor.board.raw_resolve_fn(m.rows())\n",
        "# board"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d237a885",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Other examples\n",
        "\n",
        "# TODO: restore async variant\n",
        "\n",
        "# result = await monitored_a_create(model=\"gpt-3.5-turbo\", messages=[\n",
        "#         {\"role\": \"system\", \"content\": \"You are a world-class machine learning researcher.\"},\n",
        "#         {\"role\": \"user\", \"content\": f\"Please provide a simple, fact-based question to send to an AI system. Do not say anything other than the question itself. Use this random number as inspiration: {random.random()}.\"},\n",
        "#     ])\n",
        "# result\n",
        "\n",
        "# TODO: ensure works with function calls\n",
        "# functions = [\n",
        "#     {\n",
        "#         \"name\": \"get_current_weather\",\n",
        "#         \"description\": \"Get the current weather\",\n",
        "#         \"parameters\": {\n",
        "#             \"type\": \"object\",\n",
        "#             \"properties\": {\n",
        "#                 \"location\": {\n",
        "#                     \"type\": \"string\",\n",
        "#                     \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "#                 },\n",
        "#                 \"format\": {\n",
        "#                     \"type\": \"string\",\n",
        "#                     \"enum\": [\"celsius\", \"fahrenheit\"],\n",
        "#                     \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
        "#                 },\n",
        "#             },\n",
        "#             \"required\": [\"location\", \"format\"],\n",
        "#         },\n",
        "#     },\n",
        "#     {\n",
        "#         \"name\": \"get_n_day_weather_forecast\",\n",
        "#         \"description\": \"Get an N-day weather forecast\",\n",
        "#         \"parameters\": {\n",
        "#             \"type\": \"object\",\n",
        "#             \"properties\": {\n",
        "#                 \"location\": {\n",
        "#                     \"type\": \"string\",\n",
        "#                     \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "#                 },\n",
        "#                 \"format\": {\n",
        "#                     \"type\": \"string\",\n",
        "#                     \"enum\": [\"celsius\", \"fahrenheit\"],\n",
        "#                     \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
        "#                 },\n",
        "#                 \"num_days\": {\n",
        "#                     \"type\": \"integer\",\n",
        "#                     \"description\": \"The number of days to forecast\",\n",
        "#                 }\n",
        "#             },\n",
        "#             \"required\": [\"location\", \"format\", \"num_days\"]\n",
        "#         },\n",
        "#     },\n",
        "# ]\n",
        "\n",
        "# result = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", functions=functions, messages=[\n",
        "#         {\"role\": \"system\", \"content\": \"You love to call functions.\"},\n",
        "#         {\"role\": \"user\", \"content\": f\"what's the weather today\"},\n",
        "#     ])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
